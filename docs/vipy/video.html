<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>vipy.video API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}#lunr-search{width:100%;font-size:1em;padding:6px 9px 5px 9px;border:1px solid silver}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>vipy.video</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L0-L4200" class="git-link">Browse git</a>
</summary>
<pre><code class="python">import os
import sys
import dill
from vipy.globals import print
from vipy.util import remkdir, tempMP4, isurl, \
    isvideourl, templike, tempjpg, filetail, tempdir, isyoutubeurl, try_import, isnumpy, temppng, \
    istuple, islist, isnumber, tolist, filefull, fileext, isS3url, totempdir, flatlist, tocache, premkdir, writecsv, iswebp, ispng, isgif, filepath, Stopwatch, toextension, isjsonfile, isRTSPurl, isRTMPurl, iswebp, isgif
from vipy.image import Image
import vipy.geometry
import vipy.math
import vipy.image
import vipy.downloader
import copy
import numpy as np
import ffmpeg
import urllib.request
import urllib.error
import urllib.parse
import http.client as httplib
import io
import matplotlib.pyplot as plt
import PIL.Image
import warnings
import shutil
import types
import uuid
import platform
import time
from io import BytesIO
import itertools
import vipy.globals
import vipy.activity
import hashlib
from pathlib import PurePath
import queue 
import threading
from concurrent.futures import ThreadPoolExecutor
import collections

try:
    import ujson as json  # faster
except ImportError:
    import json

    
ffmpeg_exe = shutil.which(&#39;ffmpeg&#39;)
has_ffmpeg = ffmpeg_exe is not None and os.path.exists(ffmpeg_exe)
ffprobe_exe = shutil.which(&#39;ffprobe&#39;)        
has_ffprobe = ffprobe_exe is not None and os.path.exists(ffprobe_exe)
ffplay_exe = shutil.which(&#39;ffplay&#39;)        
has_ffplay = ffplay_exe is not None and os.path.exists(ffplay_exe)


class Stream(object):
    &#34;&#34;&#34;vipy.video.Stream class. 

    This class is the primary mechanism for streaming frames and clips from long videos or live video streams.
    
    - The stream is constructed from a shared underlying video in self._video.  
    - As the shared video is updated with annotations, the stream can generate frames and clips that contain these annotations
    - The shared video allows for multiple concurrent iterators all sourced from the same video, iterating over different frames, clips and rates
    - The iterator leverages a pipe to FFMPEG, reading numpy frames from the video filter chain.  
    - The pipe is written from a thread which is dedicated to reading frames from ffmpeg
    - Each numpy frame is added to a queue, with a null termintor when end of stream is reached
    - The iterator then reads from the queue, and returns annotated frames
        
    This iterator can also be used as a buffered stream.  Buffered streams have a primary iterator which saves a fixed stream buffer
    of frames so that subsequent iterators can pull temporally aligned frames.  This is useful to avoid having multiple FFMPEG pipes 
    open simultaneously, and can allow for synchronized access to live video streams without timestamping.  

    - The primary iterator is the first iterator over the video with stream(buffered=True)
    - The primary iterator creates a private attribute self._video.attributes[&#39;__stream_buffer&#39;] which caches frames
    - The stream buffer saves numpy arrays from the iterator with a fixed buffer length (number of frames)
    - The secondary iterator (e.g. any iterator that accesses the video after the primary iterator is initially created) will read from the stream buffer
    - All iterators share the underlying self._video object in the stream so that if the video annotations are updated by an iterator, the annotated frames are accessible in the iterators
    - The secondary iterators are synchronized to the stream buffer that is read by the primary iterator.  This is useful for synchronizing streams for live camera streams without absolute timestamps.
    - There can be an unlimited number of secondary iterators, without incurring a penalty on frame access

    This iterator can iterate over clips, frames or batches.  
        
    - A clip is a sequence of frames such that each clip is separated by a fixed number of frames.  
    - Clips are useful for temporal encoding of short atomic activities
    - A batch is a sequence of n frames with a stride of n.  
    - A batch is useful for iterating over groups of frames that are operated in parallel on a GPU

    ```python
    for (im1, im2, v3) in zip(v.stream(buffered=True), v.stream(buffered=True).frame(delay=30), v.stream(buffered=True).clip(n=16,m=1):
        # im1: `vipy.image.Scene` at frame index k
        # im2: `vipy.image.Scene` at frame index k-30
        # v3: `vipy.video.Scene` at frame range [k, k-16]
    ```

    .. note::
        - This is designed to be accessed as `vipy.video.Video.stream` and not accessed as a standalone class..

    &#34;&#34;&#34;
    def __init__(self, v, queuesize, write, overwrite, bitrate=None, buffered=False, bufsize=256, rebuffered=False):
        self._video = v   # do not clone
        self._write_pipe = None
        self._vcodec = &#39;libx264&#39;
        self._bitrate = bitrate  # e.g. &#39;2000k&#39;, recommended settings for live streaming
        self._framerate = self._video.framerate()
        self._outfile = self._video.filename()
        self._write = write or overwrite               
        assert self._write is False or (overwrite is True or not os.path.exists(self._outfile)), &#34;Output file &#39;%s&#39; exists - Writable stream cannot overwrite existing video file unless overwrite=True&#34; % self._outfile
        if overwrite and os.path.exists(self._outfile):
            os.remove(self._outfile)                
        self._shape = self._video.shape() if (not self._write) or (self._write and self._video.canload()) else None  # shape for write can be defined by first frame
        assert (write is True or overwrite is True) or self._shape is not None, &#34;Invalid video &#39;%s&#39;&#34; % (str(v))
        self._queuesize = queuesize
        self._bufsize = bufsize
        self._buffered = buffered
        self._is_stream_buffer_owner = False                            
        assert self._bufsize &gt;= 1
        if rebuffered:
            self._video.attributes.pop(&#34;__stream_buffer&#34;, None)  # force reinitialization
        
    def __enter__(self):
        &#34;&#34;&#34;Write pipe context manager&#34;&#34;&#34;
        assert self._write, &#34;invalid parameters for write only context manager&#34;

        if self._shape is not None:
            (height, width) = self._shape
            outfile = self._outfile if self._outfile is not None else self._url  # may be youtube/twitch live stream
            outrate = 30 if vipy.util.isRTMPurl(outfile) else self._video.framerate()
            fiv = (ffmpeg.input(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;, s=&#39;{}x{}&#39;.format(width, height), r=self._video.framerate()) 
                   .filter(&#39;pad&#39;, &#39;ceil(iw/2)*2&#39;, &#39;ceil(ih/2)*2&#39;))
            fi = ffmpeg.concat(fiv.filter(&#39;fps&#39;, fps=30, round=&#39;up&#39;), ffmpeg.input(&#39;anullsrc&#39;, f=&#39;lavfi&#39;), v=1, a=1) if isRTMPurl(outfile) else fiv  # empty audio for youtube-live
            kwargs = {&#39;video_bitrate&#39;:self._bitrate} if self._bitrate is not None else {}
            fo = (fi.output(filename=self._outfile if self._outfile is not None else self._url,
                            pix_fmt=&#39;yuv420p&#39;,
                            vcodec=self._vcodec,
                            f=&#39;flv&#39; if vipy.util.isRTMPurl(outfile) else vipy.util.fileext(outfile, withdot=False),
                            g=2*outrate,
                            **kwargs)                              
                  .overwrite_output() 
                  .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;quiet&#39; if not vipy.globals.isdebug() else &#39;debug&#39;))
            self._write_pipe = fo.run_async(pipe_stdin=True)
                    
        self._writeindex = 0
        return self
            
    def __exit__(self, type, value, tb):
        &#34;&#34;&#34;Write pipe context manager
                
        ..note:: This is triggered on ctrl-c as the last step for cleanup
        &#34;&#34;&#34;
        if self._write_pipe is not None:
            self._write_pipe.stdin.close()
            self._write_pipe.wait()
            del self._write_pipe
            self._write_pipe = None
        if type is not None:
            raise
        return self
                
    def __call__(self, im):
        &#34;&#34;&#34;alias for write()&#34;&#34;&#34;
        return self.write(im)

    def _read_pipe(self):
        if not self._video.isloaded():
            p = self._video._ffmpeg.output(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;).global_args(&#39;-nostdin&#39;, &#39;-loglevel&#39;, &#39;debug&#39; if vipy.globals.isdebug() else &#39;quiet&#39;).run_async(pipe_stdout=True, pipe_stderr=True)
            assert p is not None, &#34;Invalid read pipe&#34;
            p.poll()
            return p
        else:
            return None

    def framerate(self):
        return self._video.framerate()
    
    def __iter__(self):
        &#34;&#34;&#34;Stream individual video frames.
        &#34;&#34;&#34;
        try:
            if self._video.isloaded():
                # For loaded video, just use the existing iterator for in-memory video
                for k in range(len(self._video)): 
                    yield self._video[k]

            else:
                # First stream iterator: read from video and store in stream buffer for all other iterators to access
                if self._buffered and not self._video.hasattribute(&#39;__stream_buffer&#39;):
                    self._video.attributes[&#39;__stream_buffer&#39;] = {}  # for synchronized frames with secondary iterator
                    self._is_stream_buffer_owner = True  # track which iterator created the stream buffer for cleanup in &#39;finally&#39;

                # Video pipe thread:
                # - Initialized only if not buffered (the default) or if primary iterator
                # - read numpy frames from the ffmpeg filter chain via a pipe
                # - store the resulting frames in a queue with a null terminated frame when the stream ends
                # - Threading is useful here because there is often time to switch when waiting on GPU I/O 
                if not self._buffered or self._is_stream_buffer_owner:
                    p = self._read_pipe()
                    q = queue.Queue(self._queuesize)
                    (h, w) = self._shape
                    
                    def _f_threadloop(pipe, queue, height, width, event):
                        assert pipe is not None, &#34;Invalid pipe&#34;
                        assert queue is not None, &#34;invalid queue&#34;
                        f = 0
                        while True:
                            in_bytes = pipe.stdout.read(height * width * 3)
                            if not in_bytes:
                                queue.put(None)
                                pipe.poll()
                                pipe.wait()
                                if pipe.returncode != 0:
                                    raise ValueError(&#39;Stream iterator exited with returncode %d&#39; % (pipe.returncode))
                                event.wait()
                                break
                            else:
                                queue.put(np.frombuffer(in_bytes, np.uint8).reshape([height, width, 3]))

                    e = threading.Event()
                    t = threading.Thread(target=_f_threadloop, args=(p, q, h, w, e), daemon=True)
                    t.start()

                    
                # Stream iterator:
                # -read frames from the thread queue and write to the private stream buffer stored as a video attribute with a frame index
                # -Frames are also yielded for the primary iterator
                # -The stream buffer is a dictionary that is n frames long, and if the newest frame from the pipe is frame k, the oldest frame is k-n which is yielded first
                # -If the stream is unbuffered, just read from the queue directly and yield the numpy frame
                b = self._video.attributes[&#39;__stream_buffer&#39;] if self._buffered else None  # buffer (if requested)
                k = 0   # current frame 
                while True:
                    if not self._buffered or self._is_stream_buffer_owner:
                        # Primary iterator: read from thread queue
                        if b is None:
                            (f, img) = (k, q.get())  # unbuffered: to yield latest from thread queue directly
                            k += 1                            
                        else:
                            b[k] = q.get()  # add to stream buffer, cache frames only, annotations are added synchronously on yield
                            (f, img) = (k, b[k])  # primary buffer: yield current frame from pipe
                            k += 1
                    else:
                        # Secondary iterator: read from stream buffer
                        while k not in b:
                            # &#34;Event&#34; wait: wait for primary iterator to start up and fill buffer, after it starts filling, this sleep should be unnecessary
                            time.sleep(0.001)  
                            
                        (f, img) = (k, b[k])  # secondary buffers: yield from stream buffer
                        k += 1
                        
                    if img is not None:
                        yield self._video.frame(f, img)  # yield a vipy.image.Scene object with annotations at frame f, using the latest annotation from the shared video object and shallow copy of img
                        if b is not None and self._is_stream_buffer_owner:
                            if len(b) &gt; self._bufsize:
                                del b[min(b.keys())]  # remove oldest frame from stream buffer
                    else:
                        if not self._buffered or self._is_stream_buffer_owner:
                            e.set()
                        break  # termination
                    
        except:
            raise
        
        finally:
            if self._is_stream_buffer_owner:
                self._video.delattribute(&#39;__stream_buffer&#39;)  # cleanup, or force a reinitialization by passing the rebuffered=True to the primary iterator
            
        
    def __getitem__(self, k):
        &#34;&#34;&#34;Retrieve individual frame index - this is inefficient, use __iter__ instead&#34;&#34;&#34;
        return self._video.preview(frame=k)  # this is inefficient

    def write(self, im, flush=False):
        &#34;&#34;&#34;Write individual frames to write stream&#34;&#34;&#34;
                
        assert isinstance(im, vipy.image.Image)
        if self._shape is None:
            self._shape = im.shape()
            assert im.channels() == 3, &#34;RGB frames required&#34;
            self.__enter__()
        assert self._write_pipe is not None, &#34;Write stream cannot be initialized&#34;                
        assert im.shape() == self._shape, &#34;Shape cannot change during writing&#34;
        self._write_pipe.stdin.write(im.array().astype(np.uint8).tobytes())
        if flush:
            self._write_pipe.stdin.flush()  # do we need this?
        if isinstance(im, vipy.image.Scene) and len(im.objects()) &gt; 0 and isinstance(self._video, vipy.video.Scene):
            for obj in im.objects():
                self._video.add(obj, frame=self._writeindex, rangecheck=False)
        self._writeindex += 1  # assumes that the source image is at the appropriate frame rate for this video

    def clip(self, n, m=1, continuous=False, tracks=True, activities=True, delay=0, ragged=False):
        &#34;&#34;&#34;Stream clips of length n such that the yielded video clip contains frame(0+delay) to frame(n+delay), and next contains frame(m+delay) to frame(n+m+delay). 
            
        Usage examples:
           
        ```python 
        for vc in v.stream().clip(n=16, m=2):
            # yields video vc with frames [0,16] from v
            # then video vc with frames [2,18] from v
            # ... finally video with frames [len(v)-n-1, len(v)-1]
        ```
            
        Introducing a delay so that the clips start at a temporal offset from v

        ```python
        for vc in v.stream().clip(n=8, m=3, delay=1):
            # yields video vc with frames [1,9]
            # then video vc with frames [4,12] ...
        ```

        Args:
            n: [int] the length of the clip in frames
            m: [int] the stride between clips in frames
            delay: [int] The temporal delay in frames for the clip, must be less than n and &gt;= 0
            continuous: [bool]  if true, then yield None for the sequential frames not aligned with a stride so that a clip is yielded on every frame
            activities: [bool]  if false, then activities from the source video are not copied into the clip
            tracks: [bool]  if false, then tracks from the source video are not copied into the clip

        Returns:
            An iterator that yields `vipy.video.Video` objects each of length n with startframe += m, starting at frame=delay, such that each video contains the tracks and activities (if requested) for this clip sourced from the shared stream video.

        .. note:: This iterator runs in a thread to help speed up fetching of frames for GPU I/Oe bound operations

        &#34;&#34;&#34;
        assert isinstance(n, int) and n&gt;0, &#34;Clip length must be a positive integer&#34;
        assert isinstance(m, int) and m&gt;0, &#34;Clip stride must be a positive integer&#34;
        assert isinstance(delay, int) and delay &gt;= 0 and delay &lt; n, &#34;Clip delay must be a positive integer less than n&#34;
        assert not self._buffered or 3*n &lt; self._bufsize, &#34;increase buffered stream size (bufsize) from %d to &gt;%d&#34; % (self._bufsize, 3*n)
        
        def _f_threadloop(v, streamiter, queue, event, ragged, m, n):
            (frames, newframes) = ([], [])            
            for (k,im) in enumerate(streamiter()):
                newframes.append(im)            
                if len(newframes) &gt;= m and len(frames)+len(newframes) &gt;= n:                                
                    # Use frameindex+1 so that we include (0,1), (1,2), (2,3), ... for n=2, m=1
                    # The delay shifts the clip +delay frames (1,2,3), (3,4,5), ... for n=3, m=2, delay=1                
                    frames.extend(newframes)
                    (frames, newframes) = (frames[-n:], [])
                    queue.put( (v.clear().clone(shallow=True).fromframes(frames), k) )  # fromframes() triggers array copy of frames
                elif continuous:
                    queue.put( (None, k) )
            if ragged and len(newframes) &gt; 0:
                queue.put( (v.clear().clone(shallow=True).fromframes(newframes), k) )  # fromframes() triggers array copy of newframes
            queue.put( (None, None) )
            event.wait()            

        vc = self._video.clone(flushfilter=True).clear().nourl().nofilename()
        q = queue.Queue(3)  # warning: if this queuesize*n &gt; buffersize, then there can be a deadlock
        e = threading.Event()        
        t = threading.Thread(target=_f_threadloop, args=(vc, self.__iter__, q, e, ragged, m, n), daemon=True)
        t.start()

        f_copy_annotations = lambda v, k, n: (v.activities([a.clone().offset(-(k-(n-1))).truncate(0,n-1) for (ak,a) in self._video.activities().items() if a.during_interval(k-(n-1), k, inclusive=False)] if activities else [])
                                              .tracks([t.clone(k-(n-1), k).offset(-(k-(n-1))).truncate(0,n-1) for (tk,t) in self._video.tracks().items() if t.during_interval(k-(n-1), k)] if tracks else [])
                                              if (v is not None and isinstance(v, vipy.video.Scene)) else v)
                
        while True:
            # The queue can be filled with more expensive copies and clones to speed up iteration when waiting for GPU I/O
            (v, k) = q.get()
            if k is not None:
                # This copy must be done sychronized at frame k with the current state of the annotations in the shared self._video
                yield f_copy_annotations(v, k, len(v)) if v is not None else None
            else:
                e.set()
                break
                
    def batch(self, n):
        &#34;&#34;&#34;Stream batches of length n such that each batch contains frames [0, n-1], [n, 2n-1], ...  Last batch will be ragged.
            
        The primary use case for batch() is to provide a mechanism for parallel batch processing on a GPU.
        
        ```python
        for im_gpu in myfunc(vi.stream().batch(16))):
            print(im_gpu)
        
        def myfunc(gen):
            for vb in gen:
                # process the batch vb (length n) in parallel by encoding on a GPU with batchsize=n
                for im in f_gpu(vb):
                    yield im_gpu:
        ```
        
        This will then yield the GPU batched processed image im_gpu.
        
        &#34;&#34;&#34;
        return self.clip(n=n, m=n, continuous=False, ragged=True) 


    def frame(self, delay=0):
        &#34;&#34;&#34;Stream individual frames of video with negative offset n frames to the stream head. If delay=30, this will return a frame 30 frames ago&#34;&#34;&#34;
        assert isinstance(delay, int) and delay &gt;= 0, &#34;Frame delay must be non-positive integer&#34;        
        n = -delay
        frames = []
        i = 0
        for (k,im) in enumerate(self):
            frames.append( (k,im) )
            (kout, imout) = frames[0]
            frames.pop(0) if len(frames) &gt; abs(n) else None
            i = k
            yield self._video.frame(kout, imout.array()) if len(frames) == delay  else None   # refetch for track interpolation
            


class Video(object):
    &#34;&#34;&#34; vipy.video.Video class

    The vipy.video class provides a fluent, lazy interface for representing, transforming and visualizing videos.
    The following constructors are supported:

    ```python
    vid = vipy.video.Video(filename=&#39;/path/to/video.ext&#39;)
    ```

    Valid video extensions are those that are supported by ffmpeg [&#39;.avi&#39;,&#39;.mp4&#39;,&#39;.mov&#39;,&#39;.wmv&#39;,&#39;.mpg&#39;, &#39;mkv&#39;, &#39;webm&#39;].

    ```python
    vid = vipy.video.Video(url=&#39;https://www.youtube.com/watch?v=MrIN959JuV8&#39;)
    vid = vipy.video.Video(url=&#39;http://path/to/video.ext&#39;, filename=&#39;/path/to/video.ext&#39;)
    ```

    Youtube URLs are downloaded to a temporary filename, retrievable as vid.download().filename().  If the environment
    variable &#39;VIPY_CACHE&#39; is defined, then videos are saved to this directory rather than the system temporary directory.
    If a filename is provided to the constructor, then that filename will be used instead of a temp or cached filename.
    URLs can be defined as an absolute URL to a video file, or to a site supported by &#39;youtube-dl&#39; (https://ytdl-org.github.io/youtube-dl/supportedsites.html)

    ```python
    vid = vipy.video.Video(url=&#39;s3://BUCKET.s3.amazonaws.com/PATH/video.ext&#39;)
    ```

    If you set the environment variables VIPY_AWS_ACCESS_KEY_ID and VIPY_AWS_SECRET_ACCESS_KEY, then this will download videos directly from S3 using boto3 and store in VIPY_CACHE.
    Note that the URL protocol should be &#39;s3&#39; and not &#39;http&#39; to enable keyed downloads.  

    ```python
    vid = vipy.video.Video(array=array, colorspace=&#39;rgb&#39;)
    ```
    
    The input &#39;array&#39; is an NxHxWx3 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video
    Note that some video transformations are only available prior to load(), and the array() is assumed immutable after load().

    ```python
    frames = [im for im in vipy.video.RandomVideo()]
    vid = vipy.video.Video(frames=frames)
    ```

    The input can be an RTSP video stream.  Note that streaming is most efficiently performed using `vipy.video.Scene`.  The URL must contain the &#39;rtsp://&#39; url scheme.  
    You can experiment with this using the free Periscope H.264 RTSP App (https://apps.apple.com/us/app/periscope-hd-h-264-rtsp-cam/id1095600218)

    ```python
    vipy.video.Scene(url=&#39;rtsp://127.0.0.1:8554/live.sdp&#39;).show()
    for im in vipy.video.Scene(url=&#39;rtsp://127.0.0.1:8554/live.sdp&#39;).stream():
        print(im)
    ```

    See also &#39;pip install heyvi&#39; 

    Args:
        filename: [str] The path to a video file.  
        url: [str] The URL to a video file.  If filename is not provided, then a random filename is assigned in VIPY_CACHE on download
        framerate: [float] The framerate of the video file.  This is required.  You can introspect this using ffprobe.
        attributes: [dict]  A user supplied dictionary of metadata about this video.
        colorspace: [str] Must be in [&#39;rgb&#39;, &#39;float&#39;]
        array: [numpy] An NxHxWxC numpy array for N frames each HxWxC shape
        startframe: [int]  A start frame to clip the video
        endframe: [int] An end frame to clip the video
        startsec: [float] A start time in seconds to clip the video (this requires setting framerate)
        endsec: [float] An end time in seconds to clip the video (this requires setting framerate)
        frames: [list of `vipy.image.Image`] A list of frames in the video
        probeshape: [bool] If true, then probe the shape of the video from ffprobe to avoid an explicit preview later.  This can speed up loading in some circumstances.

    &#34;&#34;&#34;
    def __init__(self, filename=None, url=None, framerate=30.0, attributes=None, array=None, colorspace=None, startframe=None, endframe=None, startsec=None, endsec=None, frames=None, probeshape=False):
        self._url = None
        self._filename = None
        self._array = None
        self._colorspace = None
        self._ffmpeg = None
        self._framerate = None

        self.attributes = attributes if attributes is not None else {}
        assert isinstance(self.attributes, dict), &#34;Attributes must be a python dictionary&#34;
        assert filename is not None or url is not None or array is not None or frames is not None, &#39;Invalid constructor - Requires &#34;filename&#34;, &#34;url&#34; or &#34;array&#34; or &#34;frames&#34;&#39;
        assert not isurl(filename)
        
        # FFMPEG installed?
        if not has_ffmpeg:
            warnings.warn(&#39;&#34;ffmpeg&#34; executable not found on path, this is required for vipy.video - Install from http://ffmpeg.org/download.html&#39;)

        # Constructor clips
        startframe = startframe if startframe is not None else (0 if endframe is not None else startframe)
        assert (startsec is not None and endsec is not None) or (startsec is None and endsec is None), &#34;Invalid input - (startsec,endsec) are both required&#34;        
        (self._startframe, self._endframe) = (None, None)  # __repr__ only
        (self._startsec, self._endsec) = (None, None)  # __repr__ only (legacy, no longer used)

        # Input filenames
        if url is not None:
            assert isurl(url), &#39;Invalid URL &#34;%s&#34; &#39; % url
            self._url = url
        if filename is not None:
            self._filename = os.path.normpath(os.path.expanduser(filename))
        elif self._url is not None:
            if isS3url(self._url):
                self._filename = totempdir(self._url)  # Preserve S3 Object ID
            elif isRTSPurl(self._url) or isRTMPurl(self._url):
                # https://ffmpeg.org/ffmpeg-protocols.html#rtsp                
                self._filename = self._url                
            elif isvideourl(self._url):
                self._filename = templike(self._url)
            elif isyoutubeurl(self._url):
                self._filename = os.path.join(tempdir(), &#39;%s&#39; % (self._url.split(&#39;?&#39;)[1].split(&#39;&amp;&#39;)[0] if &#39;?&#39; in self._url else self._url.split(&#39;/&#39;)[-1]))
            else:
                self._filename = totempdir(self._url)  
            if vipy.globals.cache() is not None and self._filename is not None and not isRTSPurl(self._filename) and not isRTMPurl(self._filename):
                self._filename = os.path.join(remkdir(vipy.globals.cache()), filetail(self._filename))

        # Initial video shape: useful to avoid preview()
        self._ffmpeg = ffmpeg.input(self.filename())  # restore, no other filters        
        if probeshape and (frames is None and array is None) and has_ffprobe and self.hasfilename():
            self.shape(self.probeshape())
        else:
            self._shape = None  # preview() on shape()
            
        # Video filter chain
        if framerate is not None:
            if array is None and frames is None:
                self.framerate(framerate)
            self._framerate = framerate        
        if startframe is not None:
            self.clip(startframe, endframe)  
        if startsec is not None:
            # WARNING: if the user does not supply the correct framerate for the video, then this will be wrong since these are converted to frames 
            self.clip(int(round(startsec/self.framerate())), int(round(endsec/self.framerate())) if endsec is not None else None)

        # Array input
        assert not (array is not None and frames is not None)
        if array is not None:
            self.array(array)
            self.colorspace(colorspace)
        elif frames is not None and (isinstance(frames, list) or isinstance(frames, tuple)) and all([isinstance(im, vipy.image.Image) for im in frames]):
            self.fromframes(frames)
        elif frames is not None and (isinstance(frames, list) or isinstance(frames, tuple)) and all([isinstance(im, str) and os.path.exists(im) for im in frames]):
            self.fromframes([vipy.image.Image(filename=f) for f in frames])
        elif frames is not None and (isinstance(frames, str) and os.path.isdir(frames)):
            self.fromdirectory(frames)
            
    @classmethod
    def cast(cls, v):
        &#34;&#34;&#34;Cast a conformal video object to a `vipy.video.Video` object.
        
        This is useful for downcasting superclasses.

        ```python
        vs = vipy.video.RandomScene()
        v = vipy.video.Video.cast(vs)
        ```

        &#34;&#34;&#34;
        assert isinstance(v, vipy.video.Video), &#34;Invalid input - must be derived from vipy.video.Video&#34;
        v.__class__ = vipy.video.Video
        return v
            
    @classmethod
    def from_json(cls, s):
        &#34;&#34;&#34;Import a json string as a `vipy.video.Video` object.

        This will perform a round trip from a video to json and back to a video object.
        This same operation is used for serialization of all vipy objects to JSON for storage.

        ```python
        v = vipy.video.Video.from_json(vipy.video.RandomVideo().json())
        ```

        &#34;&#34;&#34;
        
        d = json.loads(s) if not isinstance(s, dict) else s
        v = cls(filename=d[&#39;_filename&#39;],
                url=d[&#39;_url&#39;],
                framerate=d[&#39;_framerate&#39;],
                array=np.array(d[&#39;_array&#39;]) if d[&#39;_array&#39;] is not None else None,
                colorspace=d[&#39;_colorspace&#39;],
                attributes=d[&#39;attributes&#39;],
                startframe=d[&#39;_startframe&#39;],
                endframe=d[&#39;_endframe&#39;],
                startsec=d[&#39;_startsec&#39;],
                endsec=d[&#39;_endsec&#39;])
        v._ffmpeg = v._from_ffmpeg_commandline(d[&#39;_ffmpeg&#39;])
        return v.filename(d[&#39;_filename&#39;]) if d[&#39;_filename&#39;] is not None else v.nofilename()

    def __repr__(self):
        strlist = []
        if self.isloaded():
            strlist.append(&#34;height=%d, width=%d, frames=%d, color=%s&#34; % (self.height(), self.width(), len(self), self.colorspace()))
        if self.filename() is not None:
            strlist.append(&#39;filename=&#34;%s&#34;&#39; % self.filename())
        if self.hasurl():
            strlist.append(&#39;url=&#34;%s&#34;&#39; % self.url())
        if not self.isloaded() and self._startframe is not None and self._endframe is not None:
            strlist.append(&#39;clip=(%d,%d)&#39; % (self._startframe, self._endframe))
        if not self.isloaded() and self._startframe is not None and self._endframe is None:
            strlist.append(&#39;clip=(%d,)&#39; % (self._startframe))
        if self._framerate is not None:
            strlist.append(&#39;fps=%1.1f&#39; % float(self._framerate))
        return str(&#39;&lt;vipy.video: %s&gt;&#39; % (&#39;, &#39;.join(strlist)))

    def __len__(self):
        &#34;&#34;&#34;Number of frames in the video if loaded, else zero.  
        
        .. notes:: Do not automatically trigger a load, since this can interact in unexpected ways with other tools that depend on fast __len__()
        &#34;&#34;&#34;
        if not self.isloaded():
            warnings.warn(&#39;Load() video to see number of frames - Returning zero&#39;)  # should this just throw an exception?
        return len(self.array()) if self.isloaded() else 0

    def __getitem__(self, k):
        &#34;&#34;&#34;Alias for `vipy.video.Video.frame`&#34;&#34;&#34;
        return self.frame(k)

    def metadata(self):
        &#34;&#34;&#34;Return a dictionary of metadata about this video.

        This is an alias for the &#39;attributes&#39; dictionary. 
        &#34;&#34;&#34;
        return self.attributes

    def sanitize(self):
        &#34;&#34;&#34;Remove all private keys from the attributes dictionary.
        
        The attributes dictionary is useful storage for arbitrary (key,value) pairs.  However, this storage may contain sensitive information that should be scrubbed from the video before serialization.  As a general rule, any key that is of the form &#39;__keyname&#39; prepended by two underscores is a private key.  This is analogous to private or reserved attributes in the python lanugage.  Users should reserve these keynames for those keys that should be sanitized and removed before any seerialization of this object.
        
        ```python
        assert self.setattribute(&#39;__mykey&#39;, 1).sanitize().hasattribute(&#39;__mykey&#39;) == False
        ```

        &#34;&#34;&#34;
        if self._has_private_attribute():
            self.attributes = {k:v for (k,v) in self.attributes.items() if not k.startswith(&#39;__&#39;)}
        return self
        
        
    def videoid(self, newid=None):
        &#34;&#34;&#34;Return a unique video identifier for this video, as specified in the &#39;video_id&#39; attribute, or by SHA1 hash of the `vipy.video.Video.filename` and `vipy.video.Video.url`.

        Args:
            newid: [str] If not None, then update the video_id as newid. 

        Returns:
            The video ID if newid=None else self

        .. note::
            - If the video filename changes (e.g. from transformation), and video_id is not set in self.attributes, then the video ID will change.
            - If a video does not have a filename or URL or a video ID in the attributes, then this will return None
            - To preserve a video ID independent of transformations, set self.setattribute(&#39;video_id&#39;, ${MY_ID}), or pass in newid
        &#34;&#34;&#34;
        if newid is not None:
            self.setattribute(&#39;video_id&#39;, newid)
            return self
        else:
            return self.attributes[&#39;video_id&#39;] if &#39;video_id&#39; in self.attributes else (hashlib.sha1(str(str(self.filename())+str(self.url())).encode(&#34;UTF-8&#34;)).hexdigest() if (self.filename() is not None or self.url() is not None) else None)
        

    def frame(self, k=0, img=None):
        &#34;&#34;&#34;Return the kth frame as an `vipy.image Image` object&#34;&#34;&#34;        
        assert isinstance(k, int) and k&gt;=0, &#34;Frame index must be non-negative integer&#34;
        return Image(array=img if img is not None else (self._array[k] if self.isloaded() else self.preview(k).array()), colorspace=self.colorspace())       
        
    def __iter__(self):
        &#34;&#34;&#34;Iterate over video, yielding read only frames.
        
        ```python
        for im in vipy.video.RandomScene():
            print(im)
        ```

        &#34;&#34;&#34;
        return self.stream().__iter__()
        
    def store(self):
        &#34;&#34;&#34;Store the current video file as an attribute of this object.  

        Useful for archiving an object to be fully self contained without any external references.  

        ```python
        v == v.store().restore(v.filename()) 
        ```
        
        .. note::
        -Remove this stored video using unstore()
        -Unpack this stored video and set up the video chains using restore() 
        -This method is more efficient than load() followed by pkl(), as it stores the encoded video as a byte string.
        -Useful for creating a single self contained object for distributed processing.  
        &#34;&#34;&#34;
        assert self.hasfilename(), &#34;Video file not found.  Try saveas() first to create a video file to store.&#34;
        with open(self.filename(), &#39;rb&#39;) as f:
            self.attributes[&#39;__video__&#39;] = f.read()
        return self

    def unstore(self):
        &#34;&#34;&#34;Delete the currently stored video from `vipy.video.Video.store&#34;&#34;&#34;
        return self.delattribute(&#39;__video__&#39;)

    def restore(self, filename):
        &#34;&#34;&#34;Save the currently stored video as set using `vipy.video.Video.store` to filename, and set up filename&#34;&#34;&#34;
        assert self.hasattribute(&#39;__video__&#39;), &#34;Video not stored&#34;
        with open(filename, &#39;wb&#39;) as f:
            f.write(self.attributes[&#39;__video__&#39;])
        return self.filename(filename)                

    
    @classmethod
    def concatenate(cls, videos, outfile, framerate=30, youtube_chapters=None):
        &#34;&#34;&#34;Temporally concatenate a sequence of videos into a single video stored in outfile.
        
        ```python
        (v1, v2, v3) = (vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32))
        vc = vipy.video.Video.concatenate((v1, v2, v3), &#39;concatenated.mp4&#39;, youtube_chapters=lambda v: v.category())
        ```

        In this example, vc will point to concatenated.mp4 which will contain (v1,v2,v3) concatenated temporally .  

        Args:
            videos: a single video or an iterable of videos of type `vipy.video.Video` or an iterable of video files
            outfile: the output filename to store the concatenation. 
            youtube_chapters: [bool, callable]:  If true, output a string that can be used to define the start and end times of chapters if this video is uploaded to youtube.  The string output should be copied to the youtube video description in order to enable chapters on playback.  This argument will default to the string representation ofo the video, but you may also pass a callable of the form: &#39;youtube_chapters=lambda v: str(v)&#39; which will output the provided string for each video chapter.  A useful lambda is &#39;youtube_chapters=lambda v: v.category()&#39;
            framerate: [float]: The output frame rate of outfile

        Returns:
            A `vipy.video.Video` object with filename()=outfile, such that outfile contains the temporal concatenation of pixels in (self, videos).
        
        .. note::
            - self will not be modified, this will return a new `vipy.video.Video` object.
            - All videos must be the same shape().  If the videos are different shapes, you must pad them to a common size equal to self.shape().  Try `vipy.video.Video.zeropadlike`.
            - The output video will be at the framerate of self.framerate().
            - if you want to concatenate annotations, call `vipy.video.Scene.annotate` first on the videos to save the annotations into the pixels, then concatenate.
        &#34;&#34;&#34;

        assert len(tolist(videos))&gt;0 and (all([isinstance(v, vipy.video.Video) for v in tolist(videos)]) or all([os.path.exists(f) and vipy.util.isvideofile(f) for f in tolist(videos)]))
        vi = tolist(videos) if all([isinstance(v, vipy.video.Video) for v in tolist(videos)]) else [cls(filename=f) for f in tolist(videos)]

        assert all([vij.shape() == vik.shape() for vij in vi for vik in vi]), &#34;Video shapes must all the same, try padding&#34;
        vo = cls(filename=outfile, framerate=vi[0].framerate())
        with vo.stream(overwrite=True) as s:
            for v in vi:
                for im in v.clone().framerate(framerate).stream():
                    s.write(im)

        if youtube_chapters is not None:        
            f = youtube_chapters if callable(youtube_chapters) else lambda v: str(v).replace(&#39;&lt;&#39;,&#39;&#39;).replace(&#39;&gt;&#39;,&#39;&#39;)  # angle brackets not allowed
            print(&#39;[vipy.video.concatenate]: Copy the following into the video Description after uploading the videofile &#34;%s&#34; to YouTube to enable chapters on playback.\n&#39; % outfile)
            print(&#39;\n&#39;.join([&#39;%s  %s&#39; % (vipy.util.seconds_to_MMSS_colon_notation(int(s)), str(f(v))) for (s,v) in zip(np.cumsum([0] + [v.duration() for v in vi][:-1]), vi)])); print(&#39;\n&#39;)
            if any([v.duration() &lt; 10 for v in vi]):
                warnings.warn(&#39;YouTube chapters must be a minimum duration of 10 seconds&#39;)
        return vo
    

    def stream(self, write=False, overwrite=False, queuesize=512, bitrate=None, buffered=False, rebuffered=False, bufsize=256):
        &#34;&#34;&#34;Iterator to yield groups of frames streaming from video.

        A video stream is a real time iterator to read or write from a video.  Streams are useful to group together frames into clips that are operated on as a group.

        The following use cases are supported:
        
        ```python
        v = vipy.video.RandomScene()
        ```

        Stream individual video frames lagged by 10 frames and 20 frames

        ```python
        for (im1, im2) in zip(v.stream().frame(n=-10), v.stream().frame(n=-20)):
            print(im1, im2)
        ```
        
        Stream overlapping clips such that each clip is a video n=16 frames long and starts at frame i, and the next clip is n=16 frames long and starts at frame i=i+m

        ```python
        for vc in v.stream().clip(n=16, m=4):
            print(vc)
        ```

        Stream non-overlapping batches of frames such that each clip is a video of length n and starts at frame i, and the next clip is length n and starts at frame i+n

        ```python
        for vb in v.stream().batch(n=16):
            print(vb)        
        ```

        Create a write stream to incrementally add frames to long video.  

        ```python
        vi = vipy.video.Video(filename=&#39;/path/to/output.mp4&#39;)
        vo = vipy.video.Video(filename=&#39;/path/to/input.mp4&#39;)
        with vo.stream(write=True) as s:
            for im in vi.stream():
                s.write(im)  # manipulate pixels of im, if desired
        ```

        Create a 480p YouTube live stream from an RTSP camera at 5Hz 
        
        ```python
        vo = vipy.video.Scene(url=&#39;rtmp://a.rtmp.youtube.com/live2/$SECRET_STREAM_KEY&#39;)
        vi = vipy.video.Scene(url=&#39;rtsp://URL&#39;).framerate(5)
        with vo.framerate(5).stream(write=True, bitrate=&#39;1000k&#39;) as s:
            for im in vi.framerate(5).resize(cols=854, rows=480):
                s.write(im)
        ```

        Args:
            write: [bool]  If true, create a write stream
            overwrite: [bool]  If true, and the video output filename already exists, overwrite it
            bufsize: [int]  The maximum queue size for the ffmpeg pipe thread in the primary iterator.  The queue size is the maximum size of pre-fetched frames from the ffmpeg pip.  This should be big enough that you are never waiting for queue fills
            bitrate: [str] The ffmpeg bitrate of the output encoder for writing, written like &#39;2000k&#39;
            bufsize: [int]  The maximum size of the stream buffer in frames.  The stream buffer length should be big enough so that all iterators can yield before deleting old frames

        Returns:
            A Stream object

        ..note:: Using this iterator may affect PDB debugging due to stdout/stdin redirection.  Use ipdb instead.

        &#34;&#34;&#34;
        return Stream(self, queuesize=queuesize, write=write, overwrite=overwrite, bitrate=bitrate, buffered=buffered, rebuffered=rebuffered, bufsize=bufsize)  # do not clone


    def clear(self):
        &#34;&#34;&#34;no-op for `vipy.video.Video` object, used only for `vipy.video.Scene`&#34;&#34;&#34;
        return self
    
    def bytes(self):
        &#34;&#34;&#34;Return a bytes representation of the video file&#34;&#34;&#34;
        assert self.hasfilename(), &#34;Invalid filename&#34;
        with open(self.filename(), &#39;rb&#39;) as f:
            data = io.BytesIO(f.read())
        return str(data.read()).encode(&#39;UTF-8&#39;)
    
    def frames(self):
        &#34;&#34;&#34;Alias for __iter__()&#34;&#34;&#34;
        return self.__iter__()
                
    def framelist(self):
        return list(self.frames())

    def _update_ffmpeg_seek(self, timestamp_in_seconds=0, offset=0):
        if timestamp_in_seconds == 0 and offset == 0:
            return self
        nodes = ffmpeg.nodes.get_stream_spec_nodes(self._ffmpeg)
        sorted_nodes, outgoing_edge_maps = ffmpeg.dag.topo_sort(nodes)
        for n in sorted_nodes:
            if &#39;input&#39; == n.__dict__[&#39;name&#39;]:
                if &#39;ss&#39; not in n.__dict__[&#39;kwargs&#39;]:
                    n.__dict__[&#39;kwargs&#39;][&#39;ss&#39;] = 0
                if timestamp_in_seconds == 0:
                    n.__dict__[&#39;kwargs&#39;][&#39;ss&#39;] = n.__dict__[&#39;kwargs&#39;][&#39;ss&#39;] + offset
                else: 
                    n.__dict__[&#39;kwargs&#39;][&#39;ss&#39;] = timestamp_in_seconds + offset                   
                return self
        raise ValueError(&#39;invalid ffmpeg argument &#34;%s&#34; -&gt; &#34;%s&#34;&#39; % (&#39;ss&#39;, timestamp_in_seconds))

        
    def _update_ffmpeg(self, argname, argval, node_name=None):
        &#34;&#34;&#34;Update the ffmpeg filter chain to overwrite the (argname, argval) elements. 

        Useful for fine-tuning a filter chain without rewwriring the whole thing.
        &#34;&#34;&#34;
        nodes = ffmpeg.nodes.get_stream_spec_nodes(self._ffmpeg)
        sorted_nodes, outgoing_edge_maps = ffmpeg.dag.topo_sort(nodes)
        for n in sorted_nodes:
            if argname in n.__dict__[&#39;kwargs&#39;] or node_name == n.__dict__[&#39;name&#39;]:
                n.__dict__[&#39;kwargs&#39;][argname] = argval
                return self
        raise ValueError(&#39;invalid ffmpeg argument &#34;%s&#34; -&gt; &#34;%s&#34;&#39; % (argname, argval))
               
    def _ffmpeg_commandline(self, f=None):
        &#34;&#34;&#34;Return the ffmpeg command line string that will be used to process the video&#34;&#34;&#34;
        cmd = f.compile() if f is not None else self._ffmpeg.output(&#39;dummyfile&#39;).compile()
        for (k,c) in enumerate(cmd):
            if c is None:
                cmd[k] = str(c)
            elif &#39;filter&#39; in c:
                cmd[k+1] = &#39;&#34;%s&#34;&#39; % str(cmd[k+1])
            elif &#39;map&#39; in c:
                cmd[k+1] = &#39;&#34;%s&#34;&#39; % str(cmd[k+1])
        return str(&#39; &#39;).join(cmd)

    def commandline(self):
        &#34;&#34;&#34;Return the equivalent ffmpeg command line string that will be used to transcode the video.
        
           This is useful for introspecting the complex filter chain that will be used to process the video.  You can try to run this command line yourself for debugging purposes, by replacing &#39;dummyfile&#39; with an appropriately named output file.
        &#34;&#34;&#34;        
        return self._ffmpeg_commandline()
    
    def _from_ffmpeg_commandline(self, cmd, strict=False):
        &#34;&#34;&#34;Convert the ffmpeg command line string (e.g. from `vipy.video.Video.commandline`) to the corresponding ffmpeg-python filter chain and update self&#34;&#34;&#34;
        args = copy.copy(cmd).replace(str(self.filename()), &#39;FILENAME&#39;).split(&#39; &#39;)  # filename may contain spaces
        
        assert args[0] == &#39;ffmpeg&#39;, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd
        assert args[1] == &#39;-i&#39; or (args[3] == &#39;-i&#39; and args[1] == &#39;-ss&#39;), &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd
        assert args[-1] == &#39;dummyfile&#39;, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd
        assert len(args) &gt;= 4, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd

        if args[1] == &#39;-ss&#39;:
            timestamp_in_seconds = float(args[2])
            timestamp_in_seconds = int(timestamp_in_seconds) if timestamp_in_seconds == 0 else timestamp_in_seconds  # 0.0 -&gt; 0
            args = [args[0]] + args[3:]
            f = ffmpeg.input(args[2].replace(&#39;FILENAME&#39;, self.filename()), ss=timestamp_in_seconds)   # restore filename, set offset time
            self._startframe = int(round(timestamp_in_seconds*self.framerate()))  # necessary for clip() and __repr__
        else:
            f = ffmpeg.input(args[2].replace(&#39;FILENAME&#39;, self.filename()))  # restore filename

        if len(args) &gt; 4:
            assert args[3] == &#39;-filter_complex&#39;, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd
            assert args[4][0] == &#39;&#34;&#39; and args[4][-1] == &#39;&#34;&#39;, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd

            filterargs = args[4][1:-1].split(&#39;;&#39;)
            for a in filterargs:
                assert a.count(&#39;]&#39;) == 2 and a.count(&#39;[&#39;) == 2
                kwstr = a.split(&#39;]&#39;, maxsplit=1)[1].split(&#39;[&#39;, maxsplit=1)[0]
                if kwstr.count(&#39;=&#39;) == 0:
                    f = f.filter(kwstr)
                else:
                    (a, kw) = ([], {}) 
                    (filtername, kwstr) = kwstr.split(&#39;=&#39;, maxsplit=1)
                    for s in kwstr.split(&#39;:&#39;):
                        if s.count(&#39;=&#39;) &gt; 0:
                            (k,v) = s.split(&#39;=&#39;)
                            kw[k] = v
                        else:
                            a.append(s)

                    if &#39;end&#39; in kw:
                        self._endframe = (self._startframe if self._startframe is not None else 0) + int(round(float(kw[&#39;end&#39;])*self.framerate()))  # for __repr__
                    if &#39;start&#39; in kw:
                        pass
                    if &#39;start_frame&#39; in kw or &#39;end_frame&#39; in kw:
                        f = f.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 before trim filter in seconds
                        if &#39;end_frame&#39; in kw:
                            self._endframe = (self._startframe if self._startframe is not None else 0) + int(kw[&#39;end_frame&#39;])  # for __repr__
                            kw[&#39;end&#39;] = int(kw[&#39;end_frame&#39;])/self.framerate()  # convert end_frame to end (legacy)
                            del kw[&#39;end_frame&#39;]  # use only end and not end frame
                        if &#39;start_frame&#39; in kw:
                            self._startframe = (self._startframe if self._startframe is not None else 0) + int(kw[&#39;start_frame&#39;])  # for __repr__
                            kw[&#39;start&#39;] = int(kw[&#39;start_frame&#39;])/self.framerate()  # convert start_frame to start (legacy)
                            del kw[&#39;start_frame&#39;]  # use only start and not start_frame

                    f = f.filter(filtername, *a, **kw)

        if strict:
            assert self._ffmpeg_commandline(f.output(&#39;dummyfile&#39;)) == cmd, &#34;FFMPEG command line &#39;%s&#39; != &#39;%s&#39;&#34; % (self._ffmpeg_commandline(f.output(&#39;dummyfile&#39;)), cmd)
        return f

    def _isdirty(self):
        &#34;&#34;&#34;Has the FFMPEG filter chain been modified from the default?  If so, then ffplay() on the video file will be different from self.load().play()&#34;&#34;&#34;
        return &#39;-filter_complex&#39; in self._ffmpeg_commandline()

    def probeshape(self):
        &#34;&#34;&#34;Return the (height, width) of underlying video file as determined from ffprobe
        
        .. warning:: this does not take into account any applied ffmpeg filters.  The shape will be the (height, width) of the underlying video file.  
        &#34;&#34;&#34;
        p = self.probe()
        assert len(p[&#39;streams&#39;]) &gt; 0
        return (p[&#39;streams&#39;][0][&#39;height&#39;], p[&#39;streams&#39;][0][&#39;width&#39;])
        
    def duration_in_seconds_of_videofile(self):
        &#34;&#34;&#34;Return video duration of the source filename (NOT the filter chain) in seconds, requires ffprobe.  Fetch once and cache.
        
        .. notes:: This is the duration of the source video and NOT the duration of the filter chain.  If you load(), this may be different duration depending on clip() or framerate() directives.
        &#34;&#34;&#34;
        filehash = hashlib.md5(str(self.downloadif().filename()).encode()).hexdigest()            
        if self.hasattribute(&#39;_duration_in_seconds_of_videofile&#39;) and self.attributes[&#39;__duration_in_seconds_of_videofile&#39;][&#39;filehash&#39;] == filehash:
            return self.attributes[&#39;__duration_in_seconds_of_videofile&#39;][&#39;duration&#39;]
        else:
            d = float(self.probe()[&#39;format&#39;][&#39;duration&#39;])
            self.attributes[&#39;__duration_in_seconds_of_videofile&#39;] = {&#39;duration&#39;:d, &#39;filehash&#39;:filehash}  # for next time, private attribute
            return d

    def duration_in_frames_of_videofile(self):
        &#34;&#34;&#34;Return video duration of the source video file (NOT the filter chain) in frames, requires ffprobe.

        .. notes:: This is the duration of the source video and NOT the duration of the filter chain.  If you load(), this may be different duration depending on clip() or framerate() directives.
        &#34;&#34;&#34;
        return int(np.floor(self.duration_in_seconds_of_videofile()*self.framerate_of_videofile()))
    
    def duration(self, frames=None, seconds=None, minutes=None):
        &#34;&#34;&#34;Return a video clipped with frame indexes between (0, frames) or (0,seconds*self.framerate()) or (0,minutes*60*self.framerate().  Return duration in seconds if no arguments are provided.&#34;&#34;&#34;
        if frames is None and seconds is None and minutes is None:
            return self.duration_in_seconds_of_videofile() if not self.isloaded() else (len(self) / self.framerate())
        assert frames is not None or seconds is not None or minutes is not None
        frames = frames if frames is not None else ((int(seconds*self.framerate()) if seconds is not None else 0) + (int(minutes*60*self.framerate()) if minutes is not None else 0))
        return self.clip(0, frames)

    def duration_in_frames(self):
        &#34;&#34;&#34;Return the duration of the video filter chain in frames, equal to round(self.duration()*self.framerate()).  Requires a probe() of the video to get duration&#34;&#34;&#34;
        return int(round(self.duration()*self.framerate()))
    
    def framerate_of_videofile(self):
        &#34;&#34;&#34;Return video framerate in frames per second of the source video file (NOT the filter chain), requires ffprobe.
        &#34;&#34;&#34;
        p = self.probe()        
        assert &#39;streams&#39; in p and len([&#39;streams&#39;]) &gt; 0
        fps = p[&#39;streams&#39;][0][&#39;avg_frame_rate&#39;]
        return float(fps) if &#39;/&#39; not in fps else (float(fps.split(&#39;/&#39;)[0]) / float(fps.split(&#39;/&#39;)[1]))  # fps=&#39;30/1&#39; or fps=&#39;30.0&#39;

    def resolution_of_videofile(self):
        &#34;&#34;&#34;Return video resolution in (height, width) in pixels (NOT the filter chain), requires ffprobe.
        &#34;&#34;&#34;
        p = self.probe()
        assert &#39;streams&#39; in p and len([&#39;streams&#39;]) &gt; 0
        (H,W) = (p[&#39;streams&#39;][0][&#39;height&#39;], p[&#39;streams&#39;][0][&#39;width&#39;])  # (height, width) in pixels
        return (W,H) if (&#39;tags&#39; in p[&#39;streams&#39;][0] and &#39;rotate&#39; in p[&#39;streams&#39;][0][&#39;tags&#39;] and p[&#39;streams&#39;][0][&#39;tags&#39;][&#39;rotate&#39;] in [&#39;90&#39;,&#39;270&#39;]) else (H,W)
    
    def probe(self):
        &#34;&#34;&#34;Run ffprobe on the filename and return the result as a dictionary&#34;&#34;&#34;
        if not has_ffprobe:
            raise ValueError(&#39;&#34;ffprobe&#34; executable not found on path, this is optional for vipy.video - Install from http://ffmpeg.org/download.html&#39;)            
        assert self.downloadif().hasfilename(), &#34;Invalid video file &#39;%s&#39; for ffprobe&#34; % self.filename() 
        return ffmpeg.probe(self.filename())

    def print(self, prefix=&#39;&#39;, verbose=True, sleep=None):
        &#34;&#34;&#34;Print the representation of the video

        This is useful for debugging in long fluent chains.  Sleep is useful for adding in a delay for distributed processing.

        Args:
            prefix: prepend a string prefix to the video __repr__ when printing.  Useful for logging.
            verbose:  Print out the video __repr__.  Set verbose=False to just sleep
            sleep:  Integer number of seconds to sleep[ before returning
            fluent [bool]:  If true, return self else return None.  This is useful for terminating long fluent chains in lambdas that return None

        Returns:  
            The video object after sleeping 
        &#34;&#34;&#34;
        if verbose:
            print(prefix+self.__repr__())
        if sleep is not None:
            assert isinstance(sleep, int) and sleep &gt; 0, &#34;Sleep must be a non-negative integer number of seconds&#34;
            time.sleep(sleep)
        return self

    def __array__(self):
        &#34;&#34;&#34;Called on np.array(self) for custom array container, (requires numpy &gt;=1.16)&#34;&#34;&#34;
        return self.numpy()

    def dict(self):
        &#34;&#34;&#34;Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding.&#34;&#34;&#34;
        return self.json(encode=False)

    def json(self, encode=True):
        &#34;&#34;&#34;Return a json representation of the video.
        
        Args:
            encode: If true, return a JSON encoded string using json.dumps
        
        Returns:
            A JSON encoded string if encode=True, else returns a dictionary object 

        .. note::  If the video is loaded, then the JSON will not include the pixels.  Try using `vipy.video.Video.store` to serialize videos, or call `vipy.video.Video.flush` first.
        &#34;&#34;&#34;
        
        if self.isloaded():
            warnings.warn(&#34;JSON serialization of video requires flushed buffers, will not include the loaded video.  Try store()/restore()/unstore() instead to serialize videos as standalone objects efficiently, or flush() any loaded videos prior to serialization to quiet this warning.&#34;)
        d = {&#39;_filename&#39;:self._filename,
             &#39;_url&#39;:self._url,
             &#39;_framerate&#39;:self._framerate,
             &#39;_array&#39;:None,
             &#39;_colorspace&#39;:self._colorspace,
             &#39;attributes&#39;:self.attributes,
             &#39;_startframe&#39;:self._startframe,
             &#39;_endframe&#39;:self._endframe,
             &#39;_endsec&#39;:self._endsec,
             &#39;_startsec&#39;:self._startsec,
             &#39;_ffmpeg&#39;:self._ffmpeg_commandline()}
        return json.dumps(d) if encode else d
    

    def take(self, n):
        &#34;&#34;&#34;Return n frames from the clip uniformly spaced as numpy array
        
        Args:
            n: Integer number of uniformly spaced frames to return 
        
        Returns:
            A numpy array of shape (n,W,H)

        .. warning:: This assumes that the entire video is loaded into memory (e.g. call `vipy.video.Video.load`).  Use with caution.
        &#34;&#34;&#34;
        assert self.isloaded(), &#34;load() is required before take()&#34;
        dt = int(np.round(len(self._array) / float(n)))  # stride
        return self._array[::dt][0:n]

    def framerate(self, fps=None):
        &#34;&#34;&#34;Change the input framerate for the video and update frame indexes for all annotations

        Args:
            fps: [Float] frames per second to process the underlying video

        Returns:
            If fps is None, return the current framerate, otherwise set the framerate to fps

        &#34;&#34;&#34;
        if fps is None:
            return self._framerate
        elif float(fps) == self._framerate:
            return self
        else:            
            assert not self.isloaded(), &#34;Filters can only be applied prior to load()&#34;
            if &#39;fps=&#39; in self._ffmpeg_commandline():
                self._update_ffmpeg(&#39;fps&#39;, float(fps))  # replace fps filter, do not add to it
            else:
                self._ffmpeg = self._ffmpeg.filter(&#39;fps&#39;, fps=float(fps), round=&#39;up&#39;)  # create fps filter first time
        
            # if &#39;-ss&#39; in self._ffmpeg_commandline():
            #     No change is needed here.  The seek is in seconds and is independent of the framerate
            # if &#39;trim&#39; in self._ffmpeg_commandline():
            #     No change is needed here.  The trim is in units of seconds which is independent of the framerate

            self._framerate = float(fps)
            return self
            
    def colorspace(self, colorspace=None):
        &#34;&#34;&#34;Return or set the colorspace as [&#39;rgb&#39;, &#39;bgr&#39;, &#39;lum&#39;, &#39;float&#39;].  This will not change pixels, only the colorspace interpretation of pixels.&#34;&#34;&#34;
        if colorspace is None:
            return self._colorspace
        elif self.isloaded():
            assert str(colorspace).lower() in [&#39;rgb&#39;, &#39;bgr&#39;, &#39;lum&#39;, &#39;float&#39;]
            if self.array().dtype == np.float32:
                assert str(colorspace).lower() in [&#39;float&#39;]
            elif self.array().dtype == np.uint8:
                assert str(colorspace).lower() in [&#39;rgb&#39;, &#39;bgr&#39;, &#39;lum&#39;]
                if str(colorspace).lower() in [&#39;lum&#39;]:
                    assert self.channels() == 1, &#34;Luminance colorspace must be one channel uint8&#34;
                elif str(colorspace).lower() in [&#39;rgb&#39;, &#39;bgr&#39;]:
                    assert self.channels() == 3, &#34;RGB or BGR colorspace must be three channel uint8&#34;
            else:
                raise ValueError(&#39;Invalid array() type &#34;%s&#34; - only np.float32 or np.uint8 allowed&#39; % str(self.array().dtype))
            self._colorspace = str(colorspace).lower()
        return self

    def nourl(self):
        &#34;&#34;&#34;Remove the `vipy.video.Video.url` from the video&#34;&#34;&#34;
        (self._url, self._urluser, self._urlpassword, self._urlsha1) = (None, None, None, None)
        return self

    def url(self, url=None, username=None, password=None, sha1=None):
        &#34;&#34;&#34;Video URL and URL download properties&#34;&#34;&#34;
        if url is not None:
            self._url = url  # note that this does not change anything else, better to use the constructor for this
        if url is not None and (isRTSPurl(url) or isRTMPurl(url)):
            self.filename(self._url) 
        if username is not None:
            self._urluser = username  # basic authentication
        if password is not None:
            self._urlpassword = password  # basic authentication
        if sha1 is not None:
            self._urlsha1 = sha1  # file integrity
        if url is None and username is None and password is None and sha1 is None:
            return self._url
        else:
            return self

    def isloaded(self):
        &#34;&#34;&#34;Return True if the video has been loaded&#34;&#34;&#34;
        return self._array is not None

    def isloadable(self, flush=True):
        &#34;&#34;&#34;Return True if the video can be loaded successfully.
        
        This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.
        
        Args:
            flush: [bool] If true, flush the video after it loads.  This will clear the video pixel buffer

        Returns:
            True if load() can be called without FFMPEG exception.  
            If flush=False, then self will contain the loaded video, which is helpful to avoid load() twice in some conditions
        
        .. warning:: This requires loading and flushing the video.  This is an expensive operation when performed on many videos and may result in out of memory conditions with long videos.  Use with caution!  Try `vipy.video.Video.canload` to test if a single frame can be loaded as a less expensive alternative.
        &#34;&#34;&#34;
        if not self.isloaded():
            try:
                self.load()  # try to load the whole thing
                if flush:
                    self.flush()
                return True
            except:
                return False
        else:
            return True
        
        
    def canload(self, frame=0):
        &#34;&#34;&#34;Return True if the video can be previewed at frame=k successfully.
        
        This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.

        .. notes:: This will only try to preview a single frame.  This will not check if the entire video is loadable.  Use `vipy.video.Video.isloadable` in this case
        &#34;&#34;&#34;
        if not self.isloaded():
            try:
                self.preview(framenum=frame)  # try to preview
                return True
            except:
                return False
        else:
            return True

    def iscolor(self):
        &#34;&#34;&#34;Is the video a three channel color video as returned from `vipy.video.Video.channels`?&#34;&#34;&#34;
        return self.channels() == 3

    def isgrayscale(self):
        &#34;&#34;&#34;Is the video a single channel as returned from `vipy.video.Video.channels`?&#34;&#34;&#34;
        return self.channels() == 1

    def hasfilename(self):
        &#34;&#34;&#34;Does the filename returned from `vipy.video.Video.filename` exist?&#34;&#34;&#34;
        return self._filename is not None and (os.path.exists(self._filename) or isRTSPurl(self._filename) or isRTMPurl(self._filename))

    def isdownloaded(self):
        &#34;&#34;&#34;Does the filename returned from `vipy.video.Video.filename` exist, meaning that the url has been downloaded to a local file?&#34;&#34;&#34;
        return self._filename is not None and os.path.exists(self._filename)

    def hasurl(self):
        &#34;&#34;&#34;Is the url returned from `vipy.video.Video.url` a well formed url?&#34;&#34;&#34;
        return self._url is not None and isurl(self._url)

    def islive(self):
        return self.hasurl() and (isRTSPurl(self._url) or isRTMPurl(self._url))
    
    def array(self, array=None, copy=False):
        &#34;&#34;&#34;Set or return the video buffer as a numpy array.
        
        Args:
            array: [np.array] A numpy array of size NxHxWxC = (frames, height, width, channels)  of type uint8 or float32.
            copy: [bool] If true, copy the buffer by value instaed of by reference.  Copied buffers do not share pixels.

        Returns:
            if array=None, return a reference to the pixel buffer as a numpy array, otherwise return the video object.

        &#34;&#34;&#34;
        if array is None:
            return self._array
        elif isnumpy(array):
            assert array.dtype == np.float32 or array.dtype == np.uint8, &#34;Invalid input - array() must be type uint8 or float32&#34;
            assert array.ndim == 4, &#34;Invalid input array() must be of shape NxHxWxC, for N frames, of size HxW with C channels&#34;
            self._array = np.copy(array) if copy else array
            if copy:
                self._array.setflags(write=True)  # mutable iterators, triggers copy
            self.colorspace(None)  # must be set with colorspace() after array() before _convert()
            return self
        else:
            raise ValueError(&#39;Invalid input - array() must be numpy array&#39;)            

    def fromarray(self, array):
        &#34;&#34;&#34;Alias for self.array(..., copy=True), which forces the new array to be a copy&#34;&#34;&#34;
        return self.array(array, copy=True)

    def fromdirectory(self, indir, sortkey=None):
        &#34;&#34;&#34;Create a video from a directory of frames stored as individual image filenames.
        
        Given a directory with files:
        
        framedir/image_0001.jpg
        framedir/image_0002.jpg
        
        ```python
        vipy.video.Video(frames=&#39;/path/to/framedir&#39;)
        ```

        &#34;&#34;&#34;
        return self.fromframes([vipy.image.Image(filename=f) for f in sorted(vipy.util.imlist(indir), key=sortkey)])
                                
    def fromframes(self, framelist, copy=True):
        &#34;&#34;&#34;Create a video from a list of frames&#34;&#34;&#34;
        assert all([isinstance(im, vipy.image.Image) for im in framelist]), &#34;Invalid input&#34;
        return self.array(np.stack([im.load().array() if im.load().array().ndim == 3 else np.expand_dims(im.load().array(), 2) for im in framelist]), copy=copy).colorspace(framelist[0].colorspace())
    
    def tonumpy(self):
        &#34;&#34;&#34;Alias for numpy()&#34;&#34;&#34;
        return self.numpy()

    def mutable(self):
        &#34;&#34;&#34;Return a video object with a writeable mutable frame array.  Video must be loaded, triggers copy of underlying numpy array if the buffer is not writeable.  
        
        Returns:
            This object with a mutable frame buffer in self.array() or self.numpy()
        &#34;&#34;&#34;
        assert self.isloaded()
        self._array = np.copy(self._array) if not self._array.flags[&#39;WRITEABLE&#39;] else self._array  # triggers copy
        self._array.setflags(write=True)  # mutable iterators, torch conversion
        return self        
        
    def numpy(self):
        &#34;&#34;&#34;Convert the video to a writeable numpy array, triggers a load() and copy() as needed.  Returns the numpy array.&#34;&#34;&#34;
        self.load()
        self._array = np.copy(self._array) if not self._array.flags[&#39;WRITEABLE&#39;] else self._array  # triggers copy
        self._array.setflags(write=True)  # mutable iterators, torch conversion
        return self._array
    
    def zeros(self):
        self._array = 0*self.load()._array
        return self

    def reload(self):
        return self.clone(flush=True).load()
                       
    def nofilename(self):
        self._filename = None
        self._update_ffmpeg(&#39;filename&#39;, None)
        return self

    def filename(self, newfile=None, copy=False, symlink=False):
        &#34;&#34;&#34;Update video Filename with optional copy or symlink from existing file (self.filename()) to new file&#34;&#34;&#34;
        if newfile is None:
            return self._filename
        newfile = os.path.normpath(os.path.expanduser(newfile))

        # Copy or symlink from the old filename to the new filename (if requested)
        if copy:
            assert self.hasfilename(), &#34;File not found for copy&#34;
            remkdir(filepath(newfile))
            shutil.copyfile(self._filename, newfile)
        elif symlink:
            assert self.hasfilename(), &#34;File not found for symlink&#34;
            remkdir(filepath(newfile))
            if os.path.islink(newfile) and os.path.abspath(os.readlink(newfile)) == os.path.normpath(os.path.abspath(os.path.expanduser(self.filename()))):
                pass  # already points to the same place, nothing to do
            else:
                os.symlink(self._filename, newfile)                    
                    
        # Update ffmpeg filter chain with new input node filename (this file may not exist yet)
        self._update_ffmpeg(&#39;filename&#39;, newfile)
        self._filename = newfile
        
        return self

    def abspath(self):
        &#34;&#34;&#34;Change the path of the filename from a relative path to an absolute path (not relocatable)&#34;&#34;&#34;
        return self.filename(os.path.normpath(os.path.abspath(os.path.expanduser(self.filename()))))

    def relpath(self, parent=None, start=None):
        &#34;&#34;&#34;Replace the filename with a relative path to parent (or current working directory if none).
        
        Usage:
         
        ```python
        v = vipy.video.Video(filename=&#39;/path/to/dataset/video/category/out.mp4&#39;)
        v.relpath(parent=&#39;/path/to/dataset&#39;)
        v.filename() == &#39;video/category/out.mp4&#39;
        ```

        If the current working directory is /path/to/dataset, and v.load() is called, the filename will be loaded.

        Args:
            parent [str]: A parent path of the current filename to remove and be relative to.  If filename is &#39;/path/to/video.mp4&#39; then filename must start with parent, then parent will be remvoed from filename. 
            start [str]:  Return a relative filename starting from path start=&#39;/path/to/dir&#39; that will create a relative path to this filename.  If start=&#39;/a/b/c&#39; and filename=&#39;/a/b/d/e/f.ext&#39; then return filename &#39;../d/e/f.ext&#39;
        Returns:
            This video object with the filename changed to be a relative path

        &#34;&#34;&#34;
        assert parent is not None or start is not None
        if parent is not None:
            parent = parent if parent is not None else os.getcwd()
            assert parent in os.path.expanduser(self.filename()), &#34;Parent path &#39;%s&#39; not found in abspath &#39;%s&#39;&#34; % (parent, self.filename())
            self.filename(PurePath(os.path.expanduser(self.filename())).relative_to(parent))
        if start is not None: 
            self.filename(os.path.join(os.path.relpath(os.path.expanduser(filepath(self.filename())), start), filetail(self.filename())))
        return self
            
    def rename(self, newname):
        &#34;&#34;&#34;Move the underlying video file preserving the absolute path, such that self.filename() == &#39;/a/b/c.ext&#39; and newname=&#39;d.ext&#39;, then self.filename() -&gt; &#39;/a/b/d.ext&#39;, and move the corresponding file&#34;&#34;&#34;
        newfile = os.path.join(filepath(self.filename()), newname)
        shutil.move(self.filename(), newfile)        
        return self.filename(newfile)
    
    def filesize(self):
        &#34;&#34;&#34;Return the size in bytes of the filename(), None if the filename() is invalid&#34;&#34;&#34;
        return os.path.getsize(self.filename()) if self.hasfilename() else None

    def downloadif(self, ignoreErrors=False, timeout=10, verbose=True, max_filesize=&#39;350m&#39;):
        &#34;&#34;&#34;Download URL to filename if the filename has not already been downloaded&#34;&#34;&#34;
        return self.download(ignoreErrors=ignoreErrors, timeout=timeout, verbose=verbose, max_filesize=max_filesize) if self.hasurl() and not self.isdownloaded() else self
    
    def download(self, ignoreErrors=False, timeout=10, verbose=True, max_filesize=&#39;350m&#39;):
        &#34;&#34;&#34;Download URL to filename provided by constructor, or to temp filename.
        
        Args:
            ignoreErrors: [bool] If true, show a warning and return the video object, otherwise throw an exception
            timeout: [int] An integer timeout in seconds for the download to connect
            verbose: [bool] If trye, show more verbose console output
            max_filesize: [str] A string of the form &#39;NNNg&#39; or &#39;NNNm&#39; for youtube downloads to limit the maximum size of a URL to &#39;350m&#39; 350MB or &#39;12g&#39; for 12GB.

        Returns:
            This video object with the video downloaded to the filename()        
        &#34;&#34;&#34;
        if self._url is None and self._filename is not None:
            return self
        if self._url is None:
            raise ValueError(&#39;[vipy.video.download]: No URL to download&#39;)
        elif not isurl(str(self._url)):
            raise ValueError(&#39;[vipy.video.download]: Invalid URL &#34;%s&#34; &#39; % self._url)

        try:
            url_scheme = urllib.parse.urlparse(self._url)[0]
            if isyoutubeurl(self._url):
                f = self._filename if filefull(self._filename) is None else filefull(self._filename)
                vipy.videosearch.download(self._url, f, writeurlfile=False, skip=ignoreErrors, verbose=verbose, max_filesize=max_filesize)
                for ext in [&#39;mkv&#39;, &#39;mp4&#39;, &#39;webm&#39;]:
                    f = &#39;%s.%s&#39; % (self.filename(), ext)
                    if os.path.exists(f):
                        self.filename(f)  # change the filename to match the youtube extension
                        break    
                if not self.hasfilename():
                    raise ValueError(&#39;Downloaded file not found &#34;%s.*&#34;&#39; % self.filename())
            
            elif url_scheme in [&#39;http&#39;, &#39;https&#39;] and (isvideourl(self._url) or iswebp(self._url)):
                vipy.downloader.download(self._url,
                                         self._filename,
                                         verbose=verbose,
                                         timeout=timeout,
                                         sha1=None,
                                         username=None,
                                         password=None)
                                
            elif url_scheme == &#39;file&#39;:
                shutil.copyfile(self._url, self._filename)
            elif url_scheme == &#39;s3&#39;:
                if self.filename() is None:
                    self.filename(totempdir(self._url))
                    if vipy.globals.cache() is not None:
                        self.filename(os.path.join(remkdir(vipy.globals.cache()), filetail(self._url)))
                vipy.downloader.s3(self.url(), self.filename(), verbose=verbose)
                    
            elif url_scheme == &#39;scp&#39;:                
                if self.filename() is None:
                    self.filename(templike(self._url))                    
                    if vipy.globals.cache() is not None:
                        self.filename(os.path.join(remkdir(vipy.globals.cache()), filetail(self._url)))
                vipy.downloader.scp(self._url, self.filename(), verbose=verbose)
 
            elif not isvideourl(self._url) and vipy.videosearch.is_downloadable_url(self._url):
                vipy.videosearch.download(self._url, filefull(self._filename), writeurlfile=False, skip=ignoreErrors, verbose=verbose, max_filesize=max_filesize)
                for ext in [&#39;mkv&#39;, &#39;mp4&#39;, &#39;webm&#39;]:
                    f = &#39;%s.%s&#39; % (self.filename(), ext)
                    if os.path.exists(f):
                        self.filename(f)
                        break    
                if not self.hasfilename():
                    raise ValueError(&#39;Downloaded filenot found &#34;%s.*&#34;&#39; % self.filename())

            elif url_scheme == &#39;rtsp&#39;:
                # https://ffmpeg.org/ffmpeg-protocols.html#rtsp
                pass

            else:
                raise NotImplementedError(
                    &#39;Invalid URL scheme &#34;%s&#34; for URL &#34;%s&#34;&#39; %
                    (url_scheme, self._url))

        except (httplib.BadStatusLine,
                urllib.error.URLError,
                urllib.error.HTTPError):
            if ignoreErrors:
                warnings.warn(&#39;[vipy.video][WARNING]: download failed - Ignoring Video&#39;)
                self._array = None
            else:
                raise

        except IOError:
            if ignoreErrors:
                warnings.warn(&#39;[vipy.video][WARNING]: IO error - Invalid video file, url or invalid write permissions &#34;%s&#34; - Ignoring video&#39; % self.filename())
                self._array = None
            else:
                raise

        except KeyboardInterrupt:
            raise

        except Exception:
            if ignoreErrors:
                warnings.warn(&#39;[vipy.video][WARNING]: load error for video &#34;%s&#34;&#39; % self.filename())
            else:
                raise
        return self

    def fetch(self, ignoreErrors=False):
        &#34;&#34;&#34;Download only if hasfilename() is not found&#34;&#34;&#34;
        return self.download(ignoreErrors=ignoreErrors) if not self.hasfilename() else self

    def shape(self, shape=None, probe=False):
        &#34;&#34;&#34;Return (height, width) of the frames, requires loading a preview frame from the video if the video is not already loaded, or providing the shape=(height,width) by the user&#34;&#34;&#34;
        if probe:
            # Set the shape of the video from the filename by ffprobe, this should be deprecated
            return self.shape(self.probeshape(), probe=False)
        elif shape is not None:
            # Set the shape of the video using the shape provided by the user (e.g. sometimes the user knows what this will be)
            assert isinstance(shape, tuple), &#34;shape=(height, width) tuple&#34;
            self._shape = shape
            self._channels = self.channels()
            #self._previewhash = hashlib.md5(str(self._ffmpeg_commandline()).encode()).hexdigest() 
            return self
            
        elif not self.isloaded():
            # Preview a frame from the ffmpeg filter chain (more expensive)
            if self._shape is None or len(self._shape) == 0:  # dirty filter chain
                im = self.preview()  # ffmpeg chain changed, load a single frame of video, triggers fetch
                self._shape = (im.height(), im.width())  # cache the shape
                self._channels = im.channels()
                #self._previewhash = previewhash
            return self._shape
        else:
            # Frames already loaded - get shape from numpy array
            return (self._array.shape[1], self._array.shape[2])

    def channelshape(self):
        &#34;&#34;&#34;Return a tuple (channels, height, width) for the video&#34;&#34;&#34;
        return (self.channels(), self.height(), self.width())
    
    def issquare(self):
        &#34;&#34;&#34;Return true if the video has square dimensions (height == width), else false&#34;&#34;&#34;
        s = self.shape()
        return s[0] == s[1]

    def channels(self):
        &#34;&#34;&#34;Return integer number of color channels&#34;&#34;&#34;
        if not self.isloaded():
            self._channels = 3   # always color video
            
            #previewhash = hashlib.md5(str(self._ffmpeg_commandline()).encode()).hexdigest()            
            #if not hasattr(self, &#39;_previewhash&#39;) or previewhash != self._previewhash:
            #    im = self.preview()  # ffmpeg chain changed, load a single frame of video
            #    self._shape = (im.height(), im.width())  # cache the shape                
            #    self._channels = im.channels()  # cache
            #    self._previewhash = previewhash
            
            return self._channels  # cached
        else:
            return 1 if self.load().array().ndim == 3 else self.load().array().shape[3]
        
    def width(self):
        &#34;&#34;&#34;Width (cols) in pixels of the video for the current filter chain&#34;&#34;&#34;
        return self.shape()[1]

    def height(self):
        &#34;&#34;&#34;Height (rows) in pixels of the video for the current filter chain&#34;&#34;&#34;
        return self.shape()[0]

    def aspect_ratio(self):
        &#34;&#34;&#34;The width/height of the video expressed as a fraction&#34;&#34;&#34;
        return self.width() / self.height()

    def preview(self, framenum=0):
        &#34;&#34;&#34;Return selected frame of filtered video, return vipy.image.Image object.  This is useful for previewing the frame shape of a complex filter chain or the frame contents at a particular location without loading the whole video&#34;&#34;&#34;
        if self.isloaded():
            return self[framenum]
        elif self.hasurl() and not self.hasfilename():
            self.download(verbose=True)  
        if not self.hasfilename():
            raise ValueError(&#39;Video file not found&#39;)
        if iswebp(self.filename()) or isgif(self.filename()):
            return self.load().frame(framenum)
        
        # Convert frame to mjpeg and pipe to stdout, used to get dimensions of video
        #   - The MJPEG encoder will generally output lower quality than H.264 encoded frames
        #   - This means that frame indexing from preview() will generate slightly different images than streaming raw
        #   - Beware running convnets, as the pixels will be slightly different (~4 grey levels in uint8) ... 
        try:
            # FFMPEG frame indexing is inefficient for large framenum.  Need to add &#34;-ss sec.msec&#34; flag before input
            #   - the &#34;ss&#34; option must be provided before the input filename, and is supported by ffmpeg-python as &#34;.input(in_filename, ss=time)&#34;
            #   - Seek to the frame before the desired frame in order to pipe the next (desired) frame 
            timestamp_in_seconds = max(0.0, (framenum-1)/float(self.framerate()))
            f_prepipe = self.clone(shallow=True)._update_ffmpeg_seek(offset=timestamp_in_seconds)._ffmpeg.filter(&#39;select&#39;, &#39;gte(n,{})&#39;.format(0))
            f = f_prepipe.output(&#39;pipe:&#39;, vframes=1, format=&#39;image2&#39;, vcodec=&#39;mjpeg&#39;)\
                         .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;debug&#39; if vipy.globals.isdebug() else &#39;error&#39;)
            (out, err) = f.run(capture_stdout=True, capture_stderr=True)
        except Exception as e:            
            raise ValueError(&#39;[vipy.video.load]: Video preview failed with error &#34;%s&#34;\n  - Video: &#34;%s&#34;\n  - FFMPEG command: \&#39;sh&gt; %s\&#39;\n  - Try manually running this ffmpeg command to see errors.  This error usually means that the video is corrupted.&#39; % (str(e), str(self), str(self._ffmpeg_commandline(f_prepipe.output(&#39;preview.jpg&#39;, vframes=1)))))

        # [EXCEPTION]:  UnidentifiedImageError: cannot identify image file, means usually that FFMPEG piped a zero length image
        try:
            return Image(array=np.array(PIL.Image.open(BytesIO(out))))
        except Exception as e:
            print(&#39;[vipy.video.Video.preview][ERROR]:  %s&#39; % str(e))
            print(&#39;  - FFMPEG attempted to extract a single frame from the following video and failed:\n    %s&#39; % str(self))
            print(&#39;  - This may occur after calling clip() with too short a duration, try increasing the clip to be &gt; 1 sec&#39;)
            print(&#39;  - This may occur after calling clip() with a startframe or endframe outside the duration of the video&#39;)
            print(&#39;  - This may occur if requesting a frame number greater than the length of the video.  At this point, we do not know the video length, and cannot fail gracefully&#39;)
            print(&#39;  - This may occur when the framerate of the video from ffprobe (tbr) does not match that passed to fps filter, resulting in a zero length image preview piped to stdout&#39;)
            print(&#39;  - This may occur if the filter chain fails for some unknown reason on this video.  Try running this ffmpeg command manually and inspect the FFMPEG console output:\n     sh&gt; %s&#39; % str(self._ffmpeg_commandline(f_prepipe.output(&#39;preview.jpg&#39;, vframes=1))))
            raise

    def thumbnail(self, outfile=None, frame=0):
        &#34;&#34;&#34;Return annotated frame=k of video, save annotation visualization to provided outfile.

        This is functionally equivalent to `vipy.video.Video.frame` with an additional outfile argument to easily save an annotated thumbnail image.

        Args:
            outfile: [str] an optional outfile to save the annotated frame 
            frame: [int &gt;= 0] The frame to output the thumbnail

        Returns:
            A `vipy.image.Image` object for frame k.  
        &#34;&#34;&#34;
        im = self.frame(frame, img=self.preview(frame).array())
        return im.savefig(outfile) if outfile is not None else im
    
    def load(self, verbose=False, ignoreErrors=False, shape=None):
        &#34;&#34;&#34;Load a video using ffmpeg, applying the requested filter chain.  
           
        Args:
            verbose: [bool] if True. then ffmpeg console output will be displayed. 
            ignoreErrors: [bool] if True, then all load errors are warned and skipped.  Be sure to call isloaded() to confirm loading was successful.
            shape: [tuple (height, width, channels)]  If provided, use this shape for reading and reshaping the byte stream from ffmpeg.  This is useful for efficient loading in some scenarios. Knowing the final output shape can speed up loads by avoiding a preview() of the filter chain to get the frame size

        Returns:
            this video object, with the pixels loaded in self.array()

        .. warning:: Loading long videos can result in out of memory conditions.  Try to call clip() first to extract a video segment to load().
        &#34;&#34;&#34;
        if self.isloaded():
            return self
        elif not self.hasfilename() and self.hasurl():
            self.download(ignoreErrors=ignoreErrors)
        elif not self.hasfilename() and not ignoreErrors:
            raise ValueError(&#39;Invalid input - load() requires a valid URL, filename or array&#39;)
        if not self.hasfilename() and ignoreErrors:
            print(&#39;[vipy.video.load]: Video file &#34;%s&#34; not found - Ignoring&#39; % self.filename())
            return self
        if iswebp(self.filename()) or isgif(self.filename()):
            frames = []
            pil = PIL.Image.open(self.filename())
            self._framerate = (1000.0 / pil.info[&#39;duration&#39;]) if &#39;duration&#39; in pil.info else self._framerate
            for k in range(pil.n_frames):
                pil.seek(k)
                frames.append(np.array(pil.convert(&#39;RGB&#39;)))
            return self.array(np.stack(frames)).colorspace(&#39;RGB&#39;)
                        
        # Load the video with ffmpeg
        # 
        # [EXCEPTION]:  older ffmpeg versions may segfault on complex crop filter chains
        #    -On some versions of ffmpeg setting -cpuflags=0 fixes it, but the right solution is to rebuild from the head (30APR20)
        if verbose:
            print(&#39;[vipy.video.load]: Loading &#34;%s&#34;&#39; % self.filename())                    
        try:
            
            f_prepipe = copy.deepcopy(self._ffmpeg)
            f = self._ffmpeg.output(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;)\
                            .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;debug&#39; if vipy.globals.isdebug() else &#39;quiet&#39;)
            (out, err) = f.run(capture_stdout=True, capture_stderr=True)
        except Exception as e:
            if not ignoreErrors:
                raise ValueError(&#39;[vipy.video.load]: Load failed with error &#34;%s&#34;\n\n  - Video: &#34;%s&#34;\n  - FFMPEG command: \&#39;sh&gt; %s\&#39;\n  - This error usually means that the video is corrupted or that you need to upgrade your FFMPEG distribution to the latest stable version.\n  - Try running the output of the ffmpeg command for debugging.&#39; % (str(e), str(self), str(self._ffmpeg_commandline(f_prepipe.output(&#39;preview.mp4&#39;)))))
            else:
                return self  # Failed, return immediately, useful for calling canload() 

        # Video shape:
        #   - due to complex filter chains, we may not know the final video size without executing it
        #   - However, this introduces extra cost by calling preview() on each filter chain
        #   - If we know what the shape will be (e.g. we made the video square with a known size), then use it here directly
        (height, width, channels) = (self.height(), self.width(), self.channels()) if shape is None else shape
        
        # [EXCEPTION]:  older ffmpeg versions may be off by one on the size returned from self.preview() which uses an image decoder vs. f.run() which uses a video decoder
        #    -Try to correct this manually by searching for a off-by-one-pixel decoding that works.  The right way is to upgrade your FFMPEG version to the FFMPEG head (11JUN20)
        #    -We cannot tell which is the one that the end-user wanted, so we leave it up to the calling function to check dimensions (see self.resize())
        if (len(out) % (height*width*channels)) != 0:
            #warnings.warn(&#39;Your FFMPEG version is triggering a known bug that is being worked around in an inefficient manner.  Consider upgrading your FFMPEG distribution.&#39;)
            if (len(out) % ((height-1)*(width-1)*channels) == 0):
                (newwidth, newheight) = (width-1, height-1)
            elif (len(out) % ((height-1)*(width)*channels) == 0):
                (newwidth, newheight) = (width, height-1)
            elif (len(out) % ((height-1)*(width+1)*channels) == 0):
                (newwidth, newheight) = (width+1, height-1)
            elif (len(out) % ((height)*(width-1)*channels) == 0):
                (newwidth, newheight) = (width-1, height)
            elif (len(out) % ((height)*(width+1)*channels) == 0):
                (newwidth, newheight) = (width+1, height)
            elif (len(out) % ((height+1)*(width-1)*channels) == 0):
                (newwidth, newheight) = (width-1, height+1)
            elif (len(out) % ((height+1)*(width)*channels) == 0):
                (newwidth, newheight) = (width, height+1)
            elif (len(out) % ((height+1)*(width+1)*channels) == 0):
                (newwidth, newheight) = (width+1, height+1)
            else:
                (newwidth, newheight) = (width, height)

            is_loadable = (len(out) % (newheight*newwidth*channels)) == 0

            if not is_loadable:
                im = self.preview()  # get the real shape...
                (newheight, newwidth, newchannels) = (im.height(), im.width(), im.channels()) 
                        
            assert is_loadable or ignoreErrors, &#34;Load failed for video &#39;%s&#39;, and FFMPEG command line: &#39;%s&#39;&#34; % (str(self), str(self._ffmpeg_commandline(f)))
            self._array = np.frombuffer(out, np.uint8).reshape([-1, newheight, newwidth, channels]) if is_loadable else None  # read-only                        
            self.colorspace(&#39;rgb&#39; if channels == 3 else &#39;lum&#39;)
            self.resize(rows=height, cols=width)  # Very expensive framewise resizing so that the loaded video is identical shape to preview
        else:
            self._array = np.frombuffer(out, np.uint8).reshape([-1, height, width, channels])  # read-only            
            self.colorspace(&#39;rgb&#39; if channels == 3 else &#39;lum&#39;)
        return self

    def speed(self, s):
        &#34;&#34;&#34;Change the speed by a multiplier s.  If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)&#34;&#34;&#34;
        assert s &gt; 0, &#34;Invalid input&#34;
        self._ffmpeg = self._ffmpeg.setpts(&#39;%1.3f*PTS&#39; % float(1.0/float(s)))
        return self
        
    def clip(self, startframe, endframe=None):
        &#34;&#34;&#34;Load a video clip betweeen start and end frames&#34;&#34;&#34;
        assert (endframe is None or startframe &lt;= endframe) and startframe &gt;= 0, &#34;Invalid start and end frames (%s, %s)&#34; % (str(startframe), str(endframe))
        if not self.isloaded():
            timestamp_in_seconds = ((self._startframe if self._startframe is not None else 0)+startframe)/float(self.framerate())            
            self._update_ffmpeg_seek(timestamp_in_seconds)
            if endframe is not None:
                self._ffmpeg = self._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 before trim filter            
                self._ffmpeg = self._ffmpeg.trim(start=0, end=(endframe-startframe)/self.framerate())  # must be in seconds to allow for framerate conversion
            self._ffmpeg = self._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 after trim filter            
            self._startframe = startframe if self._startframe is None else self._startframe + startframe  # for __repr__ only
            self._endframe = (self._startframe + (endframe-startframe)) if endframe is not None else endframe  # for __repr__ only
        else:
            endframe = endframe if endframe is not None else len(self._array)
            self._array = self._array[startframe:endframe]
            (self._startframe, self._endframe) = (0, endframe-startframe)
        return self

    def cliprange(self):
        &#34;&#34;&#34;Return the planned clip (startframe, endframe) range.
        
        This is useful for introspection of the planned clip() before load(), such as for data augmentation purposes without triggering a load. 
        
        Returns:
            (startframe, endframe) of the video() such that after load(), the pixel buffer will contain frame=0 equivalent to startframe in the source video, and frame=endframe-startframe-1 equivalent to endframe in the source video.
            (0, None) If a video does not have a clip() (e.g. clip() was never called, the filter chain does not include a &#39;trim&#39;)

        .. notes:: The endframe can be retrieved (inefficiently) using:

        ```python
        int(round(self.duration_in_frames_of_videofile() * (self.framerate() / self.framerate_of_videofile())))
        ```

        &#34;&#34;&#34;
        return (self._startframe if self._startframe is not None else 0, self._endframe)

    #def cliptime(self, startsec, endsec):
    #    &#34;&#34;&#34;Load a video clip betweeen start seconds and end seconds, should be initialized by constructor, which will work but will not set __repr__ correctly&#34;&#34;&#34;
    #    assert startsec &lt;= endsec and startsec &gt;= 0, &#34;Invalid start and end seconds (%s, %s)&#34; % (str(startsec), str(endsec))
    #    assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
    #    self._ffmpeg = self._ffmpeg.trim(start=startsec, end=endsec)\
    #                               .setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 after trim filter
    #    self._startsec = startsec if self._startsec is None else self._startsec + startsec  # for __repr__ only
    #    self._endsec = endsec if self._endsec is None else self._startsec + (endsec-startsec)  # for __repr__ only
    #    return self
    
    def rot90cw(self):
        &#34;&#34;&#34;Rotate the video 90 degrees clockwise, can only be applied prior to load()&#34;&#34;&#34;
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        self.shape(shape=(self.width(), self.height()))  # transposed        
        self._ffmpeg = self._ffmpeg.filter(&#39;transpose&#39;, 1)
        return self

    def rot90ccw(self):
        &#34;&#34;&#34;Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()&#34;&#34;&#34;        
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        self.shape(shape=(self.width(), self.height()))  # transposed                
        self._ffmpeg = self._ffmpeg.filter(&#39;transpose&#39;, 2)
        return self

    def fliplr(self):
        &#34;&#34;&#34;Mirror the video left/right by flipping horizontally&#34;&#34;&#34;
        if not self.isloaded():
            self._ffmpeg = self._ffmpeg.filter(&#39;hflip&#39;)
        else:
            self.array(np.stack([np.fliplr(f) for f in self._array]), copy=False)
        return self

    def flipud(self):
        &#34;&#34;&#34;Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()&#34;&#34;&#34;        
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        self._ffmpeg = self._ffmpeg.filter(&#39;vflip&#39;)
        return self

    def rescale(self, s):
        &#34;&#34;&#34;Rescale the video by factor s, such that the new dimensions are (s*H, s*W), can only be applied prior to load()&#34;&#34;&#34;
        if s == 1:
            return self
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        self.shape(shape=(int(np.round(self.height()*float(np.ceil(s*1e6)/1e6))), int(np.round(self.width()*float(np.ceil(s*1e6)/1e6)))))  # update the known shape        
        self._ffmpeg = self._ffmpeg.filter(&#39;scale&#39;, &#39;iw*%1.6f&#39; % float(np.ceil(s*1e6)/1e6), &#39;ih*%1.6f&#39; % float(np.ceil(s*1e6)/1e6))  # ceil last significant digit to avoid off by one
        return self

    def resize(self, rows=None, cols=None, width=None, height=None):
        &#34;&#34;&#34;Resize the video to be (rows=height, cols=width)&#34;&#34;&#34;
        assert not (rows is not None and height is not None)
        assert not (cols is not None and width is not None)
        rows = rows if rows is not None else height
        cols = cols if cols is not None else width
                
        newshape = (rows if rows is not None else int(np.round(self.height()*(cols/self.width()))),
                    cols if cols is not None else int(np.round(self.width()*(rows/self.height()))))
                            
        if (rows is None and cols is None):
            return self  # only if strictly necessary
        if not self.isloaded():
            self._ffmpeg = self._ffmpeg.filter(&#39;scale&#39;, cols if cols is not None else -1, rows if rows is not None else -1)
        else:            
            # Do not use self.__iter__() which triggers copy for mutable arrays
            #self.array(np.stack([Image(array=self._array[k]).resize(rows=rows, cols=cols).array() for k in range(len(self))]), copy=False)
            
            # Faster: RGB-&gt;RGBX to allow for PIL.Image.fromarray() without tobytes() copy, padding faster than np.concatenate()
            #self.array(np.stack([PIL.Image.fromarray(x, mode=&#39;RGBX&#39;).resize( (cols, rows), resample=PIL.Image.BILINEAR) for x in np.pad(self._array, ((0,0),(0,0),(0,0),(0,1)))])[:,:,:,:-1], copy=False)  # RGB-&gt;RGBX-&gt;RGB
            
            # Fastest: padding introduces more overhead than just accepting tobytes(), image size dependent?
            self.array(np.stack([PIL.Image.fromarray(x).resize( (newshape[1], newshape[0]), resample=PIL.Image.BILINEAR) for x in np.ascontiguousarray(self._array)]), copy=False)
        self.shape(shape=newshape)  # manually set newshape
        return self

    def mindim(self, dim=None):
        &#34;&#34;&#34;Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        return min(self.shape()) if dim is None else (self if min(H,W)==dim else (self.resize(cols=dim) if W&lt;H else self.resize(rows=dim)))

    def maxdim(self, dim=None):
        &#34;&#34;&#34;Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        return max(H,W) if dim is None else (self.resize(cols=dim) if W&gt;H else self.resize(rows=dim))
    
    def randomcrop(self, shape, withbox=False):
        &#34;&#34;&#34;Crop the video to shape=(H,W) with random position such that the crop contains only valid pixels, and optionally return the box&#34;&#34;&#34;
        assert shape[0] &lt;= self.height() and shape[1] &lt;= self.width()  # triggers preview()
        (xmin, ymin) = (np.random.randint(self.height()-shape[0]), np.random.randint(self.width()-shape[1]))
        bb = vipy.geometry.BoundingBox(xmin=int(xmin), ymin=int(ymin), width=int(shape[1]), height=int(shape[0]))  # may be outside frame
        self.crop(bb, zeropad=True)
        return self if not withbox else (self, bb)

    def centercrop(self, shape, withbox=False):
        &#34;&#34;&#34;Crop the video to shape=(H,W) preserving the integer centroid position, and optionally return the box&#34;&#34;&#34;
        assert shape[0] &lt;= self.height() and shape[1] &lt;= self.width()  # triggers preview()
        bb = vipy.geometry.BoundingBox(xcentroid=float(self.width()/2.0), ycentroid=float(self.height()/2.0), width=float(shape[1]), height=float(shape[0])).int()  # may be outside frame
        self.crop(bb, zeropad=True)
        return self if not withbox else (self, bb)

    def centersquare(self):
        &#34;&#34;&#34;Crop video of size (NxN) in the center, such that N=min(width,height), keeping the video centroid constant&#34;&#34;&#34;
        return self.centercrop( (min(self.height(), self.width()), min(self.height(), self.width())))

    def cropeven(self):
        &#34;&#34;&#34;Crop the video to the largest even (width,height) less than or equal to current (width,height).  This is useful for some codecs or filters which require even shape.&#34;&#34;&#34;
        return self.crop(vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(vipy.math.even(self.width())), height=int(vipy.math.even(self.height()))))
    
    def maxsquare(self):
        &#34;&#34;&#34;Pad the video to be square, preserving the upper left corner of the video&#34;&#34;&#34;
        # This ffmpeg filter can throw the error:  &#34;Padded dimensions cannot be smaller than input dimensions.&#34; since the preview is off by one.  Add one here to make sure.
        # FIXME: not sure where in some filter chains this off-by-one error is being introduced, but probably does not matter since it does not affect any annotations 
        # and since the max square always preserves the scale and the upper left corner of the source video. 
        # FIXME: this may trigger an inefficient resizing operation during load()
        if not self.issquare():
            d = max(self.shape())
            self._ffmpeg = self._ffmpeg.filter(&#39;pad&#39;, d+1, d+1, 0, 0)
            self.shape(shape=(d+1, d+1))
            return self.crop(vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(d), height=int(d)))
        else:
            return self

    def minsquare(self):
        &#34;&#34;&#34;Return a square crop of the video, preserving the upper left corner of the video&#34;&#34;&#34;
        d = min(self.shape())
        self.shape(shape=(d, d))
        return self.crop(vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(d), height=int(d)))
    
    def maxmatte(self):
        &#34;&#34;&#34;Return a square video with dimensions (self.maxdim(), self.maxdim()) with zeropadded lack bars or mattes above or below the video forming a letterboxed video.&#34;&#34;&#34;
        return self.zeropad(max(1, int((max(self.shape()) - self.width())/2)), max(int((max(self.shape()) - self.height())/2), 1)).maxsquare()
    
    def zeropad(self, padwidth, padheight):
        &#34;&#34;&#34;Zero pad the video with padwidth columns before and after, and padheight rows before and after
           
        .. notes:: Older FFMPEG implementations can throw the error &#34;Input area #:#:#:# not within the padded area #:#:#:# or zero-sized, this is often caused by odd sized padding. 
             Recommend calling self.cropeven().zeropad(...) to avoid this

        &#34;&#34;&#34;
        assert isinstance(padwidth, int) and isinstance(padheight, int)        
        if not self.isloaded():
            self.shape(shape=(self.height()+2*padheight, self.width()+2*padwidth))  # manually set shape to avoid preview            
            self._ffmpeg = self._ffmpeg.filter(&#39;pad&#39;, &#39;iw+%d&#39; % (2*padwidth), &#39;ih+%d&#39; % (2*padheight), &#39;%d&#39;%padwidth, &#39;%d&#39;%padheight)
        elif padwidth &gt; 0 or padheight &gt; 0:
            self.array( np.pad(self.array(), ((0,0), (padheight,padheight), (padwidth,padwidth), (0,0)), mode=&#39;constant&#39;), copy=False)  # this is very expensive, since np.pad() must copy (once in np.pad &gt;=1.17)            
        return self

    def pad(self, padwidth=0, padheight=0):
        &#34;&#34;&#34;Alias for zeropad&#34;&#34;&#34;
        return self.zeropad(padwidth=padwidth, padheight=padheight)

    def zeropadlike(self, width, height):
        &#34;&#34;&#34;Zero pad the video balancing the border so that the resulting video size is (width, height).&#34;&#34;&#34;
        assert width &gt;= self.width() and height &gt;= self.height(), &#34;Invalid input - final (width=%d, height=%d) must be greater than current image size (width=%d, height=%d)&#34; % (width, height, self.width(), self.height())
        assert int(np.floor((width - self.width())/2)) == int(np.ceil((width - self.width())/2)), &#34;Zero pad must be symmetric, this is often due to odd zeropadding which ffmpeg doesn&#39;t like.  Try changing the width +/- 1 pixel&#34;
        assert int(np.floor((height - self.height())/2)) == int(np.ceil((height - self.height())/2)), &#34;Zero pad must be symmetric, this is often due to odd zeropadding which ffmpeg doesn&#39;t like.  Try changing the height +/- 1 pixel&#34;        
        return self.zeropad(int(np.floor((width - self.width())/2)),
                            int(np.floor((height - self.height())/2)))
    
    def crop(self, bbi, zeropad=True):
        &#34;&#34;&#34;Spatially crop the video using the supplied vipy.geometry.BoundingBox, can only be applied prior to load().
        
        .. note:: Crop is performed in place overwriting pixels of self.array().  Clone() before crop() if array() must be preserved.
        &#34;&#34;&#34;
        assert isinstance(bbi, vipy.geometry.BoundingBox), &#34;Invalid input&#34;
        bbc = bbi.clone().imclipshape(self.width(), self.height()).int()  # clipped box to image rectangle
        bb = bbi.int() if zeropad else bbc  # use clipped box if not zeropad 

        if bb.isdegenerate():
            return None
        elif not self.isloaded():
            if zeropad and bb != bbc:
                # Crop outside the image rectangle will segfault ffmpeg, pad video first (if zeropad=False, then rangecheck will not occur!)
                self.zeropad(int(np.ceil(bb.width()-bbc.width())), int(np.ceil(bb.height()-bbc.height())))     # cannot be called in derived classes
                bb = bb.offset(int(np.ceil(bb.width()-bbc.width())), int(np.ceil(bb.height()-bbc.height())))   # Shift boundingbox by padding (integer coordinates)
            self._ffmpeg = self._ffmpeg.filter(&#39;crop&#39;, &#39;%d&#39; % bb.width(), &#39;%d&#39; % bb.height(), &#39;%d&#39; % bb.xmin(), &#39;%d&#39; % bb.ymin(), keep_aspect=0)  # keep_aspect=False (disable exact=True, this is not present in older ffmpeg)
        else:
            self.array( bbc.crop(self.array()), copy=False )  # crop first, in-place, valid pixels only
            if zeropad and bb != bbc:
                ((dyb, dya), (dxb, dxa)) = ((max(0, int(abs(np.ceil(bb.ymin() - bbc.ymin())))), max(0, int(abs(np.ceil(bb.ymax() - bbc.ymax()))))),
                                            (max(0, int(abs(np.ceil(bb.xmin() - bbc.xmin())))), max(0, int(abs(np.ceil(bb.xmax() - bbc.xmax()))))))
                self._array = np.pad(self.load().array(), ((0,0), (dyb, dya), (dxb, dxa), (0, 0)), mode=&#39;constant&#39;)
        self.shape(shape=(bb.height(), bb.width()))  # manually set shape
        return self

    def pkl(self, pklfile=None):
        &#34;&#34;&#34;save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains&#34;&#34;&#34;
        pklfile = pklfile if pklfile is not None else toextension(self.filename(), &#39;.pkl&#39;)
        remkdir(filepath(pklfile))
        vipy.util.save(self, pklfile)
        return self

    def pklif(self, b, pklfile=None):
        &#34;&#34;&#34;Save the object to the provided pickle file only if b=True. Uuseful for conditional intermediate saving in long fluent chains&#34;&#34;&#34;
        assert isinstance(b, bool)
        return self.pkl(pklfile) if b else self

    def webp(self, outfile=None, pause=3, strict=True, smallest=False, smaller=False, framerate=None):
        &#34;&#34;&#34;Save a video to an animated WEBP file, with pause=N seconds on the last frame between loops.  
        
        Args:
            strict: If true, assert that the filename must have an .webp extension
            pause: Integer seconds to pause between loops of the animation
            smallest:  if true, create the smallest possible file but takes much longer to run
            smaller:  If true, create a smaller file, which takes a little longer to run 
            framerate [float]:  The output framerate of the webp file.  The default is the framerate of the video. 

        Returns:
            The filename of the webp file for this video

        .. warning::  This may be slow for very long or large videos
        &#34;&#34;&#34;
        outfile = vipy.util.tempWEBP() if outfile is None else outfile        
        assert strict is False or iswebp(outfile)
        outfile = os.path.normpath(os.path.abspath(os.path.expanduser(outfile)))
        framerate = framerate if framerate is not None else self._framerate
        self.load().frame(0).pil().save(outfile, loop=0, save_all=True, method=6 if smallest else 3 if smaller else 0,
                                        append_images=[self.frame(k).pil() for k in range(1, len(self))],
                                        duration=[int(1000.0/framerate) for k in range(0, len(self)-1)] + [pause*1000])
        return outfile

    def gif(self, outfile, pause=3, smallest=False, smaller=False, framerate=None):
        &#34;&#34;&#34;Save a video to an animated GIF file, with pause=N seconds between loops.  

        Args:
            pause: Integer seconds to pause between loops of the animation
            smallest:  If true, create the smallest possible file but takes much longer to run
            smaller:  if trye, create a smaller file, which takes a little longer to run 
            framerate [float]:  The output framerate of the webp file.  The default is the framerate of the video. 

        Returns:
            The filename of the animated GIF of this video

        .. warning::  This will be very large for big videos, consider using `vipy.video.Video.webp` instead.
        &#34;&#34;&#34;        
        assert isgif(outfile)
        return self.webp(outfile, pause, strict=False, smallest=smallest, smaller=True, framerate=framerate)
        
    def saveas(self, outfile=None, framerate=None, vcodec=&#39;libx264&#39;, verbose=False, ignoreErrors=False, flush=False, pause=5):
        &#34;&#34;&#34;Save video to new output video file.  This function does not draw boxes, it saves pixels to a new video file.

        Args:
            outfile: the absolute path to the output video file.  This extension can be .mp4 (for video) or [&#34;.webp&#34;,&#34;.gif&#34;]  (for animated image)
            ignoreErrors:  if True, then exit gracefully without throwing an exception.  Useful for chaining download().saveas() on parallel dataset downloads
            flush:  If true, then flush the buffer for this object right after saving the new video. This is useful for transcoding in parallel
            framerate:  input framerate of the frames in the buffer, or the output framerate of the transcoded video.  If not provided, use framerate of source video
            pause:  an integer in seconds to pause between loops of animated images if the outfile is webp or animated gif

        Returns:
            a new video object with this video filename, and a clean video filter chain

        .. note:: 
            - If self.array() is loaded, then export the contents of self._array to the video file
            - If self.array() is not loaded, and there exists a valid video file, apply the filter chain directly to the input video
            - If outfile==None or outfile==self.filename(), then overwrite the current filename 

        &#34;&#34;&#34;        
        outfile = tocache(tempMP4()) if outfile is None else os.path.normpath(os.path.abspath(os.path.expanduser(outfile)))
        premkdir(outfile)  # create output directory for this file if not exists
        framerate = framerate if framerate is not None else self._framerate
        assert vipy.util.isvideofile(outfile), &#34;Invalid filename extension for video filename&#34;

        if verbose:
            print(&#39;[vipy.video.saveas]: Saving video &#34;%s&#34; ...&#39; % outfile)                      
        try:
            if iswebp(outfile):
                return self.webp(outfile, pause)
            elif isgif(outfile):
                return self.gif(outfile, pause)
            elif isjsonfile(outfile):
                with open(outfile) as f:
                    f.write(self.json(encode=True))
                return outfile
            elif self.isloaded():
                # Save numpy() from load() to video, forcing to be even shape
                (n, height, width, channels) = self._array.shape
                process = ffmpeg.input(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;, s=&#39;{}x{}&#39;.format(width, height), r=framerate) \
                                .filter(&#39;pad&#39;, &#39;ceil(iw/2)*2&#39;, &#39;ceil(ih/2)*2&#39;) \
                                .output(filename=outfile, pix_fmt=&#39;yuv420p&#39;, vcodec=vcodec) \
                                .overwrite_output() \
                                .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;quiet&#39; if not vipy.globals.isdebug() else &#39;debug&#39;) \
                                .run_async(pipe_stdin=True)                
                for frame in self._array:
                    process.stdin.write(frame.astype(np.uint8).tobytes())
                process.stdin.close()
                process.wait()
            
            elif (self.isdownloaded() and self._isdirty()) or isRTSPurl(self.filename()) or isRTMPurl(self.filename()):
                # Transcode the video file directly, do not load() then export
                # Requires saving to a tmpfile if the output filename is the same as the input filename
                tmpfile = &#39;%s.tmp%s&#39; % (filefull(outfile), fileext(outfile)) if outfile == self.filename() else outfile
                self._ffmpeg.filter(&#39;pad&#39;, &#39;ceil(iw/2)*2&#39;, &#39;ceil(ih/2)*2&#39;) \
                            .output(filename=tmpfile, pix_fmt=&#39;yuv420p&#39;, vcodec=vcodec, r=framerate) \
                            .overwrite_output() \
                            .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;quiet&#39; if not vipy.globals.isdebug() else &#39;debug&#39;) \
                            .run()
                if outfile == self.filename():
                    if os.path.exists(self.filename()):
                        os.remove(self.filename())
                    shutil.move(tmpfile, self.filename())
            elif self.hasfilename() and not self._isdirty():
                shutil.copyfile(self.filename(), outfile)
            elif self.hasurl() and not self.hasfilename():
                raise ValueError(&#39;Input video url &#34;%s&#34; not downloaded, call download() first&#39; % self.url())
            elif not self.hasfilename():
                raise ValueError(&#39;Input video file not found &#34;%s&#34;&#39; % self.filename())
            else: 
                raise ValueError(&#39;saveas() failed&#39;)
        except Exception as e:
            if ignoreErrors:
                # useful for saving a large number of videos in parallel where some failed download
                print(&#39;[vipy.video.saveas]:  Failed with error &#34;%s&#34; - Returning empty video&#39; % str(repr(e)))
            else:
                raise

        # Return a new video, cloned from this video with the new video file, optionally flush the video we loaded before returning
        return self.clone(flushforward=True, flushfilter=True, flushbackward=flush).filename(outfile).nourl()
    
    def savetmp(self):
        &#34;&#34;&#34;Call `vipy.video.Video.saveas` using a new temporary video file, and return the video object with this new filename&#34;&#34;&#34;
        return self.saveas(outfile=tempMP4())
    def savetemp(self):
        &#34;&#34;&#34;Alias for `vipy.video.Video.savetmp`&#34;&#34;&#34;
        return self.savetmp()

    def ffplay(self):
        &#34;&#34;&#34;Play the video file using ffplay&#34;&#34;&#34;
        assert self.hasfilename() or (self.hasurl() and self.download().hasfilename())  # triggers download if needed
        cmd = &#39;ffplay &#34;%s&#34;&#39; % self.filename()
        print(&#39;[vipy.video.play]: Executing &#34;%s&#34;&#39; % cmd)
        os.system(cmd)
        return self
        
    def play(self, verbose=False, notebook=False):
        &#34;&#34;&#34;Play the saved video filename in self.filename()

        If there is no filename, try to download it.  If the filter chain is dirty or the pixels are loaded, dump to temp video file first then play it.  This uses &#39;ffplay&#39; on the PATH if available, otherwise uses a fallback player by showing a sequence of matplotlib frames.
        If the output of the ffmpeg filter chain has modified this video, then this will be saved to a temporary video file.  To play the original video (indepenedent of the filter chain of this video), use `vipy.video.Video.ffplay`.
        
        Args:
            verbose: If true, show more verbose output 
            notebook:  If true, play in a jupyter notebook

        Returns:
            The unmodified video object
        &#34;&#34;&#34;
        

        if not self.isdownloaded() and self.hasurl():
            self.download()
        if iswebp(self.filename()) or isgif(self.filename()):
            self.load()
            
        if notebook:
            # save to temporary video, this video is not cleaned up and may accumulate            
            try_import(&#34;IPython.display&#34;, &#34;ipython&#34;); import IPython.display
            if not self.hasfilename() or self.isloaded() or self._isdirty():
                v = self.saveas(tempMP4())                 
                warnings.warn(&#39;Saving video to temporary file &#34;%s&#34; for notebook viewer ... &#39; % v.filename())
                return IPython.display.Video(v.filename(), embed=True)
            return IPython.display.Video(self.filename(), embed=True)
        elif has_ffplay:
            if self.isloaded() or self._isdirty():
                f = tempMP4()
                if verbose:
                    warnings.warn(&#39;%s - Saving video to temporary file &#34;%s&#34; for ffplay ... &#39; % (&#39;Video loaded into memory&#39; if self.isloaded() else &#39;Dirty FFMPEG filter chain&#39;, f))
                v = self.saveas(f)
                cmd = &#39;ffplay &#34;%s&#34;&#39; % v.filename()
                if verbose:
                    print(&#39;[vipy.video.play]: Executing &#34;%s&#34;&#39; % cmd)
                os.system(cmd)
                if verbose:
                    print(&#39;[vipy.video.play]:  Removing temporary file &#34;%s&#34;&#39; % v.filename())                    
                os.remove(v.filename())  # cleanup
            elif self.hasfilename() or (self.hasurl() and self.download().hasfilename()):  # triggers download
                self.ffplay()
            else:
                raise ValueError(&#39;Invalid video file &#34;%s&#34; - ffplay requires a video filename&#39; % self.filename())
            return self

        else:
            &#34;&#34;&#34;Fallback player.  This can visualize videos without ffplay, but it cannot guarantee frame rates. Large videos with complex scenes will slow this down and will render at lower frame rates.&#34;&#34;&#34;
            fps = self.framerate()
            assert fps &gt; 0, &#34;Invalid display framerate&#34;
            with Stopwatch() as sw:            
                for (k,im) in enumerate(self.load() if self.isloaded() else self.stream()):
                    time.sleep(max(0, (1.0/self.framerate())*int(np.ceil((self.framerate()/fps))) - sw.since()))                                
                    im.show(figure=figure)
                    if vipy.globals._user_hit_escape():
                        break                    
            vipy.show.close(figure)
            return self

    def show(self):
        &#34;&#34;&#34;Alias for play&#34;&#34;&#34;
        return self.play()
    
    def quicklook(self, n=9, mindim=256, startframe=0, animate=False, dt=30):
        &#34;&#34;&#34;Generate a montage of n uniformly spaced frames.
           Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame.
        
           Input:
               n:  Number of images in the quicklook
               mindim:  The minimum dimension of each of the elements in the montage
               animate:  If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames
               dt:  The number of frames for animation
               startframe:  The initial frame index to start the n uniformly sampled frames for the quicklook

           ..note:: The first frame in the upper left is guaranteed to be the start frame of the labeled activity, but the last frame in the bottom right may not be precisely the end frame and may be off by at most len(video)/9.
        &#34;&#34;&#34;
        if not self.isloaded():
            self.load()  
        if animate:
            return Video(frames=[self.quicklook(n=n, startframe=k, animate=False, dt=dt) for k in range(0, min(dt, len(self)))], framerate=self.framerate())
        framelist = [min(int(np.round(f))+startframe, len(self)-1) for f in np.linspace(0, len(self)-1, n)]
        imframes = [self.frame(k).maxmatte()  # letterbox or pillarbox
                    for (j,k) in enumerate(framelist)]
        imframes = [im.savefig(figure=1).rgb() for im in imframes]  # temp storage in memory
        return vipy.visualize.montage(imframes, imgwidth=mindim, imgheight=mindim)

    def torch(self, startframe=0, endframe=None, length=None, stride=1, take=None, boundary=&#39;repeat&#39;, order=&#39;nchw&#39;, verbose=False, withslice=False, scale=1.0, withlabel=False, nonelabel=False):
        &#34;&#34;&#34;Convert the loaded video of shape NxHxWxC frames to an MxCxHxW torch tensor/

        Args:
            startframe: [int &gt;= 0] The start frame of the loaded video to use for constructig the torch tensor
            endframe: [int &gt;= 0] The end frame of the loaded video to use for constructing the torch tensor
            length: [int &gt;= 0] The length of the torch tensor if endframe is not provided. 
            stride: [int &gt;= 1] The temporal stride in frames.  This is the number of frames to skip.
            take: [int &gt;= 0]  The number of uniformly spaced frames to include in the tensor.  
            boundary: [&#39;repeat&#39;, &#39;cyclic&#39;] The boundary handling for when the requested tensor slice goes beyond the end of the video
            order: [&#39;nchw&#39;, &#39;nhwc&#39;, &#39;chwn&#39;, &#39;cnhw&#39;]  The axis ordering of the returned torch tensor N=number of frames (batchsize), C=channels, H=height, W=width
            verbose [bool]: Print out the slice used for contructing tensor
            withslice: [bool] Return a tuple (tensor, slice) that includes the slice used to construct the tensor.  Useful for data provenance.
            scale: [float] An optional scale factor to apply to the tensor. Useful for converting [0,255] -&gt; [0,1]
            withlabel: [bool] Return a tuple (tensor, labels) that includes the N framewise activity labels.  
            nonelabel: [bool] returns tuple (t, None) if withlabel=False

        Returns
            Returns torch float tensor, analogous to torchvision.transforms.ToTensor()           
            Return (tensor, slice) if withslice=True (withslice takes precedence)
            Returns (tensor, labellist) if withlabel=True

        .. notes::
            - This triggers a load() of the video
            - The precedence of arguments is (startframe, endframe) or (startframe, startframe+length), then stride and take.
            - Follows numpy slicing rules.  Optionally return the slice used if withslice=True
        &#34;&#34;&#34;
        try_import(&#39;torch&#39;); import torch
        frames = self.load().numpy() if self.load().numpy().ndim == 4 else np.expand_dims(self.load().numpy(), 3)  # NxHxWx(C=1, C=3)
        assert boundary in [&#39;repeat&#39;, &#39;strict&#39;, &#39;cyclic&#39;], &#34;Invalid boundary mode - must be in [&#39;repeat&#39;, &#39;strict&#39;, &#39;cyclic&#39;]&#34;

        # Slice index (i=start (zero-indexed), j=end (non-inclusive), k=step)
        (i,j,k) = (startframe, endframe, stride)
        if startframe == &#39;random&#39;:
            assert length is not None, &#34;Random start frame requires fixed length&#34;
            i = max(0, np.random.randint(len(frames)-length+1))
        if endframe is not None:
            assert length is None, &#34;Cannot specify both endframe and length&#34;                        
            assert endframe &gt; startframe, &#34;End frame must be greater than start frame&#34;
            (j,k) = (endframe, 1)
        if length is not None:
            assert endframe is None, &#34;Cannot specify both endframe and length&#34;
            assert length &gt;= 0, &#34;Length must be positive&#34;
            (j,k) = (i+length, 1)
        if length is None and endframe is None:
            j = len(frames)  # use them all
        if stride != 1:
            assert take is None, &#34;Cannot specify both take and stride&#34;
            assert stride &gt;= 1, &#34;Stride must be &gt;= 1&#34;
            k = stride
        if take is not None:
            # Uniformly sampled frames to result in len(frames)=take
            assert stride == 1, &#34;Cannot specify both take and stride&#34;
            assert take &lt;= len(frames), &#34;Take must be less than the number of frames&#34;
            k = int(np.ceil(len(frames)/float(take)))

        # Boundary handling
        assert i &gt;= 0, &#34;Start frame must be &gt;= 0&#34;
        assert i &lt; j, &#34;Start frame must be less then end frame&#34;
        assert k &lt;= len(frames), &#34;Stride must be &lt;= len(frames)&#34;
        n = len(frames)  # true video length for labels
        if boundary == &#39;repeat&#39; and j &gt; len(frames):
            for d in range(j-len(frames)):
                frames = np.concatenate( (frames, np.expand_dims(frames[-1], 0) ))
        elif boundary == &#39;cyclic&#39; and j &gt; len(frames):
            for d in range(j-len(frames)):
                frames = np.concatenate( (frames, np.expand_dims(frames[j % len(frames)], 0) ))
        assert j &lt;= len(frames), &#34;invalid slice=%s for frame shape=%s&#34; % (str((i,j,k)), str(frames.shape))
        if verbose:
            print(&#39;[vipy.video.torch]: slice (start,end,step)=%s for frame shape (N,C,H,W)=%s&#39; % (str((i,j,k)), str(frames.shape)))

        # Slice and transpose to torch tensor axis ordering
        t = torch.from_numpy(frames[i:j:k] if (k!=1 or i!=0 or j!=len(frames)) else frames)  # do not copy - This shares the numpy buffer of the video, be careful!
        if t.dim() == 2:
            t = t.unsqueeze(0).unsqueeze(-1)  # HxW -&gt; (N=1)xHxWx(C=1)
        if order == &#39;nchw&#39;:
            t = t.permute(0,3,1,2)  # NxCxHxW, view
        elif order == &#39;nhwc&#39;:
            pass  # NxHxWxC  (native numpy order)
        elif order == &#39;cnhw&#39; or order == &#39;cdhw&#39;:
            t = t.permute(3,0,1,2)  # CxNxHxW == CxDxHxW (for torch conv3d), view
        elif order == &#39;chwn&#39;:
            t = t.permute(3,1,2,0)  # CxHxWxN, view
        else:
            raise ValueError(&#34;Invalid order = must be in [&#39;nchw&#39;, &#39;nhwc&#39;, &#39;chwn&#39;, &#39;cnhw&#39;]&#34;)
            
        # Scaling (optional)
        if scale is not None and self.colorspace() != &#39;float&#39;:
            t = (1.0/255.0)*t  # [0,255] -&gt; [0,1]
        elif scale is not None and scale != 1.0:
            t = scale*t

        # Return tensor or (tensor, slice) or (tensor, labels)
        if withslice:
            return (t, (i,j,k))
        elif withlabel:            
            labels = [sorted(tuple(self.activitylabels( (f%n) if boundary == &#39;cyclic&#39; else min(f, n-1) ))) for f in range(i,j,k)]
            return (t, labels)
        elif nonelabel:
            return (t, None)
        else:
            return t

    def clone(self, flushforward=False, flushbackward=False, flush=False, flushfilter=False, rekey=False, flushfile=False, shallow=False, sharedarray=False, sanitize=True):
        &#34;&#34;&#34;Create deep copy of video object, flushing the original buffer if requested and returning the cloned object.

        Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned 
        object which can be used for encoding and will be garbage collected.
        
        Args:
            flushforward: copy the object, and set the cloned object `vipy.video.Video.array` to None.  This flushes the video buffer for the clone, not the object
            flushbackward:  copy the object, and set the object array() to None.  This flushes the video buffer for the object, not the clone.
            flush:  set the object array() to None and clone the object.  This flushes the video buffer for both the clone and the object.
            flushfilter:  Set the ffmpeg filter chain to the default in the new object, useful for saving new videos
            flushfile:  Remove the filename and the URL from the video object.  Useful for creating new video objects from loaded pixels.  
            rekey: Generate new unique track ID and activity ID keys for this scene
            shallow:  shallow copy everything (copy by reference), except for ffmpeg object.  attributes dictionary is shallow copied
            sharedarray:  deep copy of everything, except for pixel buffer which is shared.  Changing the pixel buffer on self is reflected in the clone.
            sanitize:  remove private attributes from self.attributes dictionary.  A private attribute is any key with two leading underscores &#39;__&#39; which should not be propagated to clone

        Returns:
            A deepcopy of the video object such that changes to self are not reflected in the copy

        .. note:: Cloning videos is an expensive operation and can slow down real time code. Use sparingly. 

        &#34;&#34;&#34;
        if sanitize:
            a = self.attributes  # copy reference to attributes to restore 
            self.attributes = {}  # remove attributes on self for fast clone() since private attributes will be filtered anyway
        if flush or (flushforward and flushbackward):
            self._array = None  # flushes buffer on object and clone
            #self._previewhash = None
            self._shape = None
            v = copy.deepcopy(self)  # object and clone are flushed
        elif flushbackward:
            v = copy.deepcopy(self)  # propagates _array to clone
            self._array = None   # object flushed, clone not flushed
            #self._previewhash = None
            self._shape = None
        elif flushforward:
            array = self._array;
            self._array = None
            #self._previewhash = None
            self._shape = None
            v = copy.deepcopy(self)   # does not propagate _array to clone
            self._array = array    # object not flushed
            v._array = None   # clone flushed
        elif shallow:
            v = copy.copy(self)  # shallow copy
            v._ffmpeg = copy.deepcopy(self._ffmpeg)  # except for ffmpeg object
            v.attributes = {k:v for (k,v) in self.attributes.items()}  # shallow copy of keys
            v._array = np.asarray(self._array) if self._array is not None else None  # shared pixels
        elif sharedarray:
            array = self._array
            self._array = None
            v = copy.deepcopy(self)  # deep copy of everything but pixels
            v._array = np.asarray(array) if array is not None else None  # shared pixels
            self._array = array # restore
        else:
            v = copy.deepcopy(self)            

        if flushfilter:
            v._ffmpeg = ffmpeg.input(v.filename())  # no other filters
            #v._previewhash = None
            v._shape = None
            (v._startframe, v._endframe) = (None, None)
            (v._startsec, v._endsec) = (None, None)
        if rekey:
            v.rekey()
        if flushfile:
            v.nofilename().nourl()
        if sanitize:
            self.attributes = a  # restore attributes            
            v.attributes = {k:v for (k,v) in self.attributes.items()}  # shallow copy
            v.sanitize()  # remove private attributes
        return v

    def flush(self):
        &#34;&#34;&#34;Alias for clone(flush=True), returns self not clone&#34;&#34;&#34;
        self._array = None  # flushes buffer on object and clone
        #self._previewhash = None
        self._shape = None
        return self

    def returns(self, r=None):
        &#34;&#34;&#34;Return the provided value, useful for terminating long fluent chains without returning self&#34;&#34;&#34;
        return r

    def flush_and_return(self, retval):
        &#34;&#34;&#34;Flush the video and return the parameter supplied, useful for long fluent chains&#34;&#34;&#34;
        self.flush()
        return retval

    def map(self, func):
        &#34;&#34;&#34;Apply lambda function to the loaded numpy array img, changes pixels not shape
        
        Lambda function must have the following signature:
            * newimg = func(img)
            * img: HxWxC numpy array for a single frame of video
            * newimg:  HxWxC modified numpy array for this frame.  Change only the pixels, not the shape

        The lambda function will be applied to every frame in the video in frame index order.
        &#34;&#34;&#34;
        assert isinstance(func, types.LambdaType), &#34;Input must be lambda function with np.array() input and np.array() output&#34;
        oldimgs = self.load().array()
        self.array(np.apply_along_axis(func, 0, self._array))   # FIXME: in-place operation?
        if (any([oldimg.dtype != newimg.dtype for (oldimg, newimg) in zip(oldimgs, self.array())]) or
            any([oldimg.shape != newimg.shape for (oldimg, newimg) in zip(oldimgs, self.array())])):            
            self.colorspace(&#39;float&#39;)  # unknown colorspace after shape or type transformation, set generic
        return self

    def gain(self, g):
        &#34;&#34;&#34;Pixelwise multiplicative gain, such that each pixel p_{ij} = g * p_{ij}&#34;&#34;&#34;
        return self.normalize(0, 1, scale=g)

    def bias(self, b):
        &#34;&#34;&#34;Pixelwise additive bias, such that each pixel p_{ij} = b + p_{ij}&#34;&#34;&#34;
        return self.normalize(mean=0, std=1, scale=1.0, bias=b)
    
    def float(self):
        self.load()
        self._array = self._array.astype(np.float32) if self._array is not None else self._array
        return self

    def channel(self, c):
        self.load()
        assert c &gt;= 0 and c &lt; self.channels()
        self._array = self._array[:,:,:,c] if self._array is not None else self._array
        return self

    def normalize(self, mean, std, scale=1, bias=0):
        &#34;&#34;&#34;Pixelwise whitening, out = ((scale*in) - mean) / std); triggers load().  All computations float32&#34;&#34;&#34;
        assert scale &gt;= 0, &#34;Invalid input&#34;
        assert all([s &gt; 0 for s in tolist(std)]), &#34;Invalid input&#34;
        self._array = vipy.math.normalize(self._array, np.array(mean, dtype=np.float32), np.array(std, dtype=np.float32), np.float32(scale))
        if bias != 0:
            self._array = self._array + np.array(bias, dtype=np.float32)
        return self.colorspace(&#39;float&#39;)

    def setattribute(self, k, v=None):
        if self.attributes is None:
            self.attributes = {}
        self.attributes[k] = v
        return self

    def _has_private_attribute(self):
        &#34;&#34;&#34;Does the attributes dictionary contain any private attributes (e.g. those keys prepended with &#39;__&#39;)&#34;&#34;&#34;
        return isinstance(self.attributes, dict) and any([k.startswith(&#39;__&#39;) for k in self.attributes.keys()])      
    
    def hasattribute(self, k):
        &#34;&#34;&#34;Does the attributes dictionary (self.attributes) contain the provided key&#34;&#34;&#34;
        return isinstance(self.attributes, dict) and k in self.attributes

    def delattribute(self, k):
        if k in self.attributes:
            self.attributes.pop(k)
        return self

    def getattribute(self, k):
        return self.attributes[k]

    
class VideoCategory(Video):
    &#34;&#34;&#34;vipy.video.VideoCategory class

    A VideoCategory is a video with associated category, such as an activity class.  This class includes all of the constructors of vipy.video.Video 
    along with the ability to extract a clip based on frames or seconds.

    &#34;&#34;&#34;
    def __init__(self, filename=None, url=None, framerate=30.0, attributes=None, category=None, array=None, colorspace=None, startframe=None, endframe=None, startsec=None, endsec=None):
        super().__init__(url=url, filename=filename, framerate=framerate, attributes=attributes, array=array, colorspace=colorspace,
                                            startframe=startframe, endframe=endframe, startsec=startsec, endsec=endsec)
        self._category = category                

    @classmethod
    def from_json(cls, s):
        d = json.loads(s) if not isinstance(s, dict) else s                        
        v = super().from_json(s)
        v._category = d[&#39;_category&#39;]
        return v
        
    def __repr__(self):
        strlist = []
        if self.isloaded():
            strlist.append(&#34;height=%d, width=%d, frames=%d&#34; % (self._array[0].shape[0], self._array[0].shape[1], len(self._array)))
        if self.filename() is not None:
            strlist.append(&#39;filename=&#34;%s&#34;&#39; % self.filename())
        if self.hasurl():
            strlist.append(&#39;url=&#34;%s&#34;&#39; % self.url())
        if self.category() is not None:
            strlist.append(&#39;category=&#34;%s&#34;&#39; % self.category())
        if not self.isloaded() and self._startframe is not None and self._endframe is not None:
            strlist.append(&#39;clip=(%d,%d)&#39; % (self._startframe, self._endframe))
        if not self.isloaded() and self._startframe is not None and self._endframe is None:
            strlist.append(&#39;clip=(%d,)&#39; % (self._startframe))
        return str(&#39;&lt;vipy.video.VideoCategory: %s&gt;&#39; % (&#39;, &#39;.join(strlist)))

    def json(self, encode=True):
        d = json.loads(super().json())
        d[&#39;_category&#39;] = self._category
        return json.dumps(d) if encode else d
    
    def category(self, c=None):
        if c is None:
            return self._category
        else:
            self._category = c
            return self


    
class Scene(VideoCategory):
    &#34;&#34;&#34; vipy.video.Scene class

    The vipy.video.Scene class provides a fluent, lazy interface for representing, transforming and visualizing annotated videos.
    The following constructors are supported:

    ```python
    vid = vipy.video.Scene(filename=&#39;/path/to/video.ext&#39;)
    ```

    Valid video extensions are those that are supported by ffmpeg [&#39;.avi&#39;,&#39;.mp4&#39;,&#39;.mov&#39;,&#39;.wmv&#39;,&#39;.mpg&#39;, &#39;mkv&#39;, &#39;webm&#39;].

    ```python
    vid = vipy.video.Scene(url=&#39;https://www.youtube.com/watch?v=MrIN959JuV8&#39;)
    vid = vipy.video.Scene(url=&#39;http://path/to/video.ext&#39;, filename=&#39;/path/to/video.ext&#39;)
    ```

    Youtube URLs are downloaded to a temporary filename, retrievable as vid.download().filename().  If the environment
    variable &#39;VIPY_CACHE&#39; is defined, then videos are saved to this directory rather than the system temporary directory.
    If a filename is provided to the constructor, then that filename will be used instead of a temp or cached filename.
    URLs can be defined as an absolute URL to a video file, or to a site supported by &#39;youtube-dl&#39; 
    [https://ytdl-org.github.io/youtube-dl/supportedsites.html]

    ```python
    vid = vipy.video.Scene(array=frames, colorspace=&#39;rgb&#39;)
    ```
    
    The input &#39;frames&#39; is an NxHxWx3 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video
    Note that the video transformations (clip, resize, rescale, rotate) are only available prior to load(), and the array() is assumed immutable after load().

    ```python
    vid = vipy.video.Scene(array=greyframes, colorspace=&#39;lum&#39;)
    ```
    
    The input &#39;greyframes&#39; is an NxHxWx1 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video
    This corresponds to the luminance of an RGB colorspace

    ```python
    vid = vipy.video.Scene(array=greyframes, colorspace=&#39;lum&#39;, tracks=tracks, activities=activities)
    ```

    - tracks = [vipy.object.Track(), ...]
    - activities = [vipy.object.Activity(), ...]
 
    The inputs are lists of tracks and/or activities.  An object is a spatial bounding box with a category label.  A track is a spatiotemporal bounding 
    box with a category label, such that the box contains the same instance of an object.  An activity is one or more tracks with a start and end frame for an 
    activity performed by the object instances.  Track and activity timing must be relative to the start frame of the Scene() constructor.  

    &#34;&#34;&#34;
        
    def __init__(self, filename=None, url=None, framerate=30.0, array=None, colorspace=None, category=None, tracks=None, activities=None,
                 attributes=None, startframe=None, endframe=None, startsec=None, endsec=None):

        self._tracks = {}
        self._activities = {}        
        super().__init__(url=url, filename=filename, framerate=framerate, attributes=attributes, array=array, colorspace=colorspace,
                                    category=category, startframe=startframe, endframe=endframe, startsec=startsec, endsec=endsec)

        # Tracks must be defined relative to the clip specified by this constructor
        if tracks is not None:
            tracks = tracks if isinstance(tracks, list) or isinstance(tracks, tuple) else [tracks]  # canonicalize
            assert all([isinstance(t, vipy.object.Track) for t in tracks]), &#34;Invalid track input; tracks=[vipy.object.Track(), ...]&#34;
            self._tracks = {t.id():t for t in tracks}

        # Activities must be defined relative to the clip specified by this constructor            
        if activities is not None:
            activities = activities if isinstance(activities, list) or isinstance(activities, tuple) else [activities]  # canonicalize            
            assert all([isinstance(a, vipy.activity.Activity) for a in activities]), &#34;Invalid activity input; activities=[vipy.activity.Activity(), ...]&#34;
            self._activities = {a.id():a for a in activities}

        self._currentframe = None  # deprecated

    @classmethod
    def cast(cls, v, flush=False):
        &#34;&#34;&#34;Cast a conformal vipy object to this class.  This is useful for downcast and upcast conversion of video objects.&#34;&#34;&#34;
        assert isinstance(v, vipy.video.Video), &#34;Invalid input - must be derived from vipy.video.Video&#34;
        if v.__class__ != vipy.video.Scene:
            v.__class__ = vipy.video.Scene            
            v._tracks = {} if flush or not hasattr(v, &#39;_tracks&#39;) else v._tracks
            v._activities = {} if flush or not hasattr(v, &#39;_activities&#39;) else v._activities
            v._category = None if flush or not hasattr(v, &#39;_category&#39;) else v._category
        return v

    @classmethod
    def asjson(cls, s):
        &#34;&#34;&#34;Restore an object serialized with self.json().  Alas for `vipy.video.Scene.from_json`.
        
        Usage:

        ```python
        vs = vipy.video.Scene.asjson(v.json())
        ```

        &#34;&#34;&#34;
        return vipy.video.Scene.from_json(s)

    @classmethod
    def from_json(cls, s):
        &#34;&#34;&#34;Restore an object serialized with self.json()
        
        Usage:
        
        ```python
        vs = vipy.video.Scene.from_json(v.json())
        ```

        &#34;&#34;&#34;

        d = json.loads(s) if not isinstance(s, dict) else s                                
        v = super().from_json(s)

        # Packed attribute storage:
        #   - When loading a large number of vipy objects, the python garbage collector slows down signficantly due to reference cycle counting
        #   - Mutable objects and custom containers are tracked by the garbage collector and the more of them that are loaded the longer GC takes
        #   - To avoid this, load attributes as tuples of packed strings.  This is an immutable type that is not reference counted.  Check this with gc.is_tracked()
        #   - Then, unpack load the attributes on demand when accessing tracks() or activities().  Then, the nested containers are reference counted (even though they really should not since there are no cycles by construction)
        #   - This is useful when calling vipy.util.load(...) on archives that contain hundreds of thousands of objects
        #   - Do not access the private attributes self._tracks and self._attributes as they will be packed until needed
        #   - Should install ultrajson (pip install ujson) for super fast parsing
        v._tracks = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_tracks&#39;].values()])  # track ID key is embedded in object, legacy unpack of doubly JSON encoded strings (vipy-1.11.16)
        v._activities = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_activities&#39;].values()])  # track ID key is embedded in object, legacy unpack of doubly JSON encoded strings (vipy-1.11.16)
        return v
        
    def pack(self):
        &#34;&#34;&#34;Packing a scene returns the scene with the annotations JSON serialized.  
               
        - This is useful for fast garbage collection when there are many objects in memory
        - This is useful for distributed processing prior to serializing from a scheduler to a client
        - This is useful for lazy deserialization of complex attributes when loading many videos into memory
        - Unpacking is transparent to the end user and is performed on the fly when annotations are accessed.  There is no unpack() method.
        - See the notes in from_json() for why this helps with nested containers and reference cycle tracking with the python garbage collector        

        &#34;&#34;&#34;
        d = json.loads(self.json())
        self._tracks = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_tracks&#39;].values()]) # efficient garbage collection: store as a packed string to avoid reference cycle tracking, unpack on demand
        self._activities = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_activities&#39;].values()])  # efficient garbage collection: store as a packed string to avoid reference cycle tracking, unpack on demand 
        return self

    def __repr__(self):
        strlist = []
        if self.isloaded():
            strlist.append(&#34;height=%d, width=%d, frames=%d, color=%s&#34; % (self.height(), self.width(), len(self._array), self.colorspace()))
        if self.filename() is not None:
            strlist.append(&#39;filename=&#34;%s&#34;&#39; % (self.filename()))
        if self.hasurl():
            strlist.append(&#39;url=&#34;%s&#34;&#39; % self.url())
        if self._framerate is not None:
            strlist.append(&#39;fps=%1.1f&#39; % float(self._framerate))
        if not self.isloaded() and self._startframe is not None and self._endframe is not None:
            strlist.append(&#39;clip=(%d,%d)&#39; % (self._startframe, self._endframe))
        if not self.isloaded() and self._startframe is not None and self._endframe is None:
            strlist.append(&#39;clip=(%d,)&#39; % (self._startframe))
        if self.category() is not None:
            strlist.append(&#39;category=&#34;%s&#34;&#39; % self.category())
        if self.hastracks():
            strlist.append(&#39;tracks=%d&#39; % len(self._tracks))
        if self.hasactivities():
            strlist.append(&#39;activities=%d&#39; % len(self._activities))
        return str(&#39;&lt;vipy.video.scene: %s&gt;&#39; % (&#39;, &#39;.join(strlist)))


    def instanceid(self, newid=None):
        &#34;&#34;&#34;Return an annotation instance identifier for this video.  

        An instance ID is a unique identifier for a ground truth annotation within a video, either a track or an activity.  More than one instance ID may share the same video ID if they are from the same source videofile.  

        This is useful when calling `vipy.video.Scene.activityclip` or `vipy.video.Scene.activitysplit` to clip a video into segments such that each clip has a unique identifier, but all share the same underlying `vipy.video.Video.videoid`.
        This is useful when calling `vipy.video.Scene.trackclip` or `vipy.video.Scene.tracksplit` to clip a video into segments such that each clip has a unique identifier, but all share the same underlying `vipy.video.Video.videoid`.
        
        Returns:
            INSTANCEID: if &#39;instance_id&#39; key is in self.attribute
            VIDEOID_INSTANCEID: if &#39;_instance_id&#39; key is in self.attribute, as set by activityclip() or trackclip().  This is set using INSTANCE_ID=ACTIVITYID_ACTIVITYINDEX or INSTANCEID=TRACKID_TRACKINDEX, where the index is the temporal order of the annotation in the source video prior to clip().
            VIDEOID_ACTIVITYINDEX: if &#39;activityindex&#39; key is in self.attribute, as set by activityclip().  (fallback for legacy datasets).
            VIDEOID: otherwise 
        &#34;&#34;&#34;
        if newid is not None:
            self.setattribute(&#39;instance_id&#39;, newid)
            return self
        else:
            if &#39;instance_id&#39; in self.attributes:
                return self.attributes[&#39;instance_id&#39;]  # set at video creation time (e.g. pycollector)
            elif &#39;_instance_id&#39; in self.attributes:
                return self.attributes[&#39;_instance_id&#39;]  # set at activityclip() time for provenance from clips back to videos
            elif &#39;activityindex&#39; in self.attributes:
                return &#39;%s_%s&#39; % (self.videoid(), str(self.attributes[&#39;activityindex&#39;]))  # set at activityclip() time for provenance from clips back to videos (deprecated)
            else:
                return self.videoid()

    def frame(self, k=0, img=None, noimage=False):
        &#34;&#34;&#34;Return `vipy.image.Scene` object at frame k

        -The attributes of each of the `vipy.image.Scene.objects` in the scene contains helpful metadata for the provenance of the detection, including:  
            - &#39;trackid&#39; of the track this detection
            - &#39;activityid&#39; associated with this detection 
            - &#39;jointlabel&#39; of this detection, used for visualization
            - &#39;noun verb&#39; of this detection, used for visualization

        Args:
            k: [int &gt;=- 0] The frame index requested.  This is relative to the current frame rate of the video.
            img: [numpy, None]  An optional image to be used for this frame.  This is useful to construct frames efficiently for videos if the pixel buffer is already available from a stream rather than a preview.  
            noimage [bool]:  If True, then return only annotations at frame k with empty frame buffer (e.g. no image pixels in the returned image object)

        Return:
            A `vipy.image.Scene` object for frame k containing all objects in this frame and pixels if img != None or preview=True
        
        .. note::
            - Modifying this frame will not affect the source video
            - If multiple objects are associated with an activity and a primary actor is defined, then only the primary actor is displayed as &#34;Noun Verbing&#34;, objects are shown as &#34;Noun&#34; with the activityid in the attribute
            - If noun is associated with more than one activity, then this is shown as &#34;Noun Verbing1\nNoun Verbing2&#34;, with a newline separator

        &#34;&#34;&#34;
        assert isinstance(k, int) and k&gt;=0, &#34;Frame index must be non-negative integer&#34;
        assert img is not None or (self.isloaded() and k&lt;len(self)) or not self.isloaded(), &#34;Invalid frame index %d - Indexing video by frame must be integer within (0, %d)&#34; % (k, len(self)-1)

        img = img if (img is not None or noimage) else (self._array[k] if self.isloaded() else self.preview(k).array())
        dets = [t[k].clone(deep=True).setattribute(&#39;trackindex&#39;, j) for (j, t) in enumerate(self.tracklist()) if len(t)&gt;0 and (t.during(k) or t.boundary()==&#39;extend&#39;)]  # track interpolation (cloned) with boundary handling
        for d in dets:
            d.attributes[&#39;activityid&#39;] = []  # reset
            jointlabel = [(d.shortlabel(),&#39;&#39;)]  # [(Noun, Verbing1), (Noun, Verbing2), ...], initialized with empty verbs as [(Noun, &#34;&#34;), ... ]
            activityconf = [None]   # for display 

            for (aid, a) in self.activities().items():  # insertion order:  First activity is primary, next is secondary (not in confidence order) 
                if a.hastrack(d.attributes[&#39;trackid&#39;]) and a.during(k):
                    # Display assumptions:
                    # - Jointlabel is always displayed as &#34;Noun Verbing&#34; during activity (e.g. Person Carrying, Vehicle Turning) using noun=track shortlabel, verb=activity shortlabel
                    # - If noun is associated with more than one activity, then this is shown as &#34;Noun Verbing1\nNoun Verbing2&#34;, with a newline separator
                    # - If multiple objects are associated with an activity and a primary actor is defined, then only the primary actor is displayed as &#34;Noun Verbing&#34;, objects are shown as &#34;Noun&#34; with the activityid in the attributes
                    if (a.actorid() is None or (a.actorid() == d.attributes[&#39;trackid&#39;])) and not any([a.shortlabel() == v for (n,v) in jointlabel]):
                        jointlabel.append( (d.shortlabel(), a.shortlabel()) )  # only show each activity once (even if repeated)
                        activityconf.append(a.confidence())
                    d.attributes[&#39;activityid&#39;].append(a.id())  # for activity correspondence (if desired)

            # For display purposes
            # - See `vipy.image.mutator_show_trackindex_verbonly`
            # - Double prepended underscore attributes are private and cleaned using `vipy.image.Image.sanitize`
            d.attributes[&#39;__jointlabel&#39;] = &#39;\n&#39;.join([(&#39;%s %s&#39; % (n,v)).strip() for (n,v) in jointlabel[0 if len(jointlabel)==1 else 1:]])  # to be deprecated
            d.attributes[&#39;__noun verb&#39;] = jointlabel[0 if len(jointlabel)==1 else 1:]
            d.attributes[&#39;__activityconf&#39;] = activityconf[0 if len(jointlabel)==1 else 1:]
            d.attributes[&#39;__trackindex&#39;] = d.attributes[&#39;trackindex&#39;]  # trackindex to be replaced with __trackindex
            d.attributes[&#39;__trackid&#39;] = d.attributes[&#39;trackid&#39;]  # trackid to be replaced with __trackid
            d.attributes[&#39;__activityid&#39;] = d.attributes[&#39;activityid&#39;]  # activityid to be replaced with __activityid            
        dets.sort(key=lambda d: (d.confidence() if d.confidence() is not None else 0, d.shortlabel()))   # layering in video is ordered by decreasing track confidence and alphabetical shortlabel
        return vipy.image.Scene(array=img, colorspace=self.colorspace(), objects=dets, category=self.category())  
                
        
    def during(self, frameindex):
        try:
            self.__getitem__(frameindex)  # triggers load
            return True
        except:
            return False
            
    def labeled_frames(self):
        &#34;&#34;&#34;Iterate over frames, yielding tuples (activity+object labelset in scene, vipy.image.Scene())&#34;&#34;&#34;
        self.load()
        for k in range(0, len(self)):
            #self._currentframe = k    # used only for incremental add()
            yield (self.labels(k), self.__getitem__(k))
        #self._currentframe = None
        

    def framecomposite(self, n=2, dt=10, mindim=256):
        &#34;&#34;&#34;Generate a single composite image with minimum dimension mindim as the uniformly blended composite of n frames each separated by dt frames&#34;&#34;&#34;
        if not self.isloaded():
            self.mindim(mindim).load()
        imframes = [self.frame(k).maxmatte() for k in range(0, dt*n, dt)]
        img = np.uint8(np.sum([1/float(n)*im.array() for im in imframes], axis=0))
        return imframes[0].clone().array(img)

    def isdegenerate(self):
        &#34;&#34;&#34;Degenerate scene has empty or malformed tracks&#34;&#34;&#34;
        return len(self.tracklist()) == 0 or any([t.isempty() or t.isdegenerate() for t in self.tracklist()])
    
    def quicklook(self, n=9, dilate=1.5, mindim=256, fontsize=10, context=False, startframe=0, animate=False, dt=30):
        &#34;&#34;&#34;Generate a montage of n uniformly spaced annotated frames centered on the union of the labeled boxes in the current frame to show the activity ocurring in this scene at a glance
           Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame.  This quicklook is most useful when len(self.activities()==1)
           for generating a quicklook from an activityclip().
        
           Args:
               n: [int]:  Number of images in the quicklook
               dilate: [float]:  The dilation factor for the bounding box prior to crop for display
               mindim: [int]:  The minimum dimension of each of the elemnets in the montage
               fontsize: [int]:  The size of the font for the bounding box label
               context: [bool]:  If true, replace the first and last frame in the montage with the full frame annotation, to help show the scale of the scene
               animate: [bool]:  If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames
               dt: [int]:  The number of frames for animation
               startframe: [int]:  The initial frame index to start the n uniformly sampled frames for the quicklook
        &#34;&#34;&#34;
        if not self.isloaded():
            self.load()  
        if animate:
            return Video(frames=[self.quicklook(n=n, dilate=dilate, mindim=mindim, fontsize=fontsize, context=context, startframe=k, animate=False, dt=dt) for k in range(0, min(dt, len(self)))], framerate=self.framerate())
        f_mutator = vipy.image.mutator_show_jointlabel()
        framelist = [min(int(np.round(f))+startframe, len(self)-1) for f in np.linspace(0, len(self)-1, n)]
        isdegenerate = [self.frame(k).boundingbox() is None or self.frame(k).boundingbox().dilate(dilate).intersection(self.framebox(), strict=False).isdegenerate() for (j,k) in enumerate(framelist)]
        imframes = [self.frame(k).maxmatte()  # letterbox or pillarbox
                    if (isdegenerate[j] or (context is True and (j == 0 or j == (n-1)))) else
                    self.frame(k).padcrop(self.frame(k).boundingbox().dilate(dilate).imclipshape(self.width(), self.height()).maxsquare().int()).mindim(mindim, interp=&#39;nearest&#39;)
                    for (j,k) in enumerate(framelist)]
        imframes = [f_mutator(im) for im in imframes]  # show jointlabel from frame interpolation
        imframes = [im.savefig(fontsize=fontsize, figure=1).rgb() for im in imframes]  # temp storage in memory
        return vipy.visualize.montage(imframes, imgwidth=mindim, imgheight=mindim)
    
    def tracks(self, tracks=None, id=None):
        &#34;&#34;&#34;Return mutable dictionary of tracks,
        
           Args:
               tracks [dict]: If provided, replace track dictionary with provided track dictionary, and return self
               id [str]: If provided, return just the track associated with the provided track id
    
           Returns:
               This object if tracks!=None, otherwise the requested track (if id!=None) or trackdict (tracks=None)

        &#34;&#34;&#34;        
        if isinstance(self._tracks, tuple):
            self._tracks = {t.id():t for t in [vipy.object.Track.from_json(json.loads(s)) for s in self._tracks]}  # on-demand unpack (efficient garbage collection for large list of objects)
        if tracks is None and id is None:
            return self._tracks  # mutable dict
        elif id is not None:
            return self._tracks[id]
        elif isinstance(tracks, dict):
            assert all([isinstance(t, vipy.object.Track) and k == t.id() for (k,t) in tracks.items()]), &#34;Invalid input - Must be dictionary of vipy.object.Track&#34;
            self._tracks = tracks.copy()  # shallow copy
            return self
        else:
            assert all([isinstance(t, vipy.object.Track) for t in tolist(tracks)]), &#34;Invalid input - Must be vipy.object.Track or list of vipy.object.Track&#34;
            self._tracks = {t.id():t for t in tolist(tracks)}  # insertion order preserved (python &gt;=3.6)
            return self

    def track(self, id):
        return self.tracks(id=id)

    def trackindex(self, id):
        &#34;&#34;&#34;Return the index in the tracklist of the track with the provided track id&#34;&#34;&#34;
        assert id in self.tracks()
        return [t.id() for t in self.tracklist()].index(id)

    def trackidx(self, idx):
        &#34;&#34;&#34;Return the track at the specified index in the tracklist&#34;&#34;&#34;
        return self.tracklist()[idx]

    def activity(self, id=None):
        return self.activities(id=id) if id is not None else self.primary_activity()
        
    def next_activity(self, id):
        &#34;&#34;&#34;Return the next activity just after the given activityid&#34;&#34;&#34;
        assert id in self.activities()
        A = self.activitylist()
        k = [k for (k,a) in enumerate(A) if a.id() == id][0]
        return A[k+1] if k&lt;len(A)-1 else None

    def prev_activity(self, id):
        &#34;&#34;&#34;Return the previous activity just before the given activityid&#34;&#34;&#34;
        assert id in self.activities()
        A = self.activitylist()
        k = [k for (k,a) in enumerate(A) if a.id() == id][0]
        return A[k-1] if k&gt;=1 else None

    def tracklist(self):
        return list(self.tracks().values())  # triggers shallow copy

    def objects(self, casesensitive=True):
        &#34;&#34;&#34;The objects in a scene are the unique categories of tracks&#34;&#34;&#34;
        return sorted(list(set([t.category() if casesensitive else t.category().lower() for t in self.tracklist()])))
    
    def actorid(self, id=None, fluent=False):
        &#34;&#34;&#34;Return or set the actor ID for the video.

        - The actor ID is the track ID of the primary actor in the scene.  This is useful for assigning a role for activities that are performed by the actor.
        - The actor ID is the first track is in the tracklist       
        
        Args:
            id: [str] if not None, then use this track ID as the actor
            fluent: [bool] If true, always return self. This is useful for those cases where the actorid being set is None.
        
        Returns:
            [id=None, fluent=False] the actor ID
            [id is not None] The video with the actor ID set, only if the ID is found in the tracklist

        .. note:: Not to be confused with biometric subject id.  For videos collected with Visym Collector platform (https://visym.com/collector), the biometric subject ID can be retrieved via `vipy.video.Video.metadata` (e.g. self.metadata()[&#39;subject_ids&#39;]).
        &#34;&#34;&#34;
        if id is None:
            return next(iter(self.tracks().keys())) if not fluent else self  # Python &gt;=3.6
        elif id in self._tracks:
            # Reorder tracks so that id is first
            idlist = [id] + [ti for ti in self.tracks().keys() if ti != id]
            self._tracks = {k:self.track(k) for k in idlist}
        else:
            warnings.warn(&#39;trackid=%s not found in &#34;%s&#34;&#39; % (str(id), str(self)))
        return self

    def setactorid(self, id):
        &#34;&#34;&#34;Alias for `vipy.video.Scene.actorid`&#34;&#34;&#34;
        return self.actorid(id, fluent=True)

    def actor(self):
        &#34;&#34;&#34;Return the primary actor (first `vipy.object.Track`) in the video&#34;&#34;&#34;
        return next(iter(self.tracks().values())) if len(self._tracks)&gt;0 else None   # Python &gt;=3.6
        
    def primary_activity(self):
        &#34;&#34;&#34;Return the primary activity of the video.

        - The primary activity is the first activity in the activitylist.  
        - This is useful for activityclip() videos that are centered on a single activity
        
        Returns:
            `vipy.activity.Activity` that is first in the `vipy.video.Scene.activitylist`
        &#34;&#34;&#34;
        return next(iter(self.activities().values())) if len(self._activities)&gt;0 else None  # Python &gt;=3.6        

    def first_activity(self):
        &#34;&#34;&#34;Return the first activity of the video with the earliest start frame&#34;&#34;&#34;
        return sorted(self.activitylist(), key=lambda a: a.startframe())[0] if len(self._activities)&gt;0 else None

    def last_activity(self):
        &#34;&#34;&#34;Return the last activity of the video with the latest end frame&#34;&#34;&#34;
        return sorted(self.activitylist(), key=lambda a: a.endframe())[-1] if len(self._activities)&gt;0 else None
    
    def activities(self, activities=None, id=None):
        &#34;&#34;&#34;Return mutable dictionary of activities.  All temporal alignment is relative to the current clip().&#34;&#34;&#34;
        if isinstance(self._activities, tuple):
            self._activities = {a.id():a for a in [vipy.activity.Activity.from_json(json.loads(s)) for s in self._activities]}  # on-demand
        if activities is None and id is None:
            return self._activities  # mutable dict
        elif id is not None:
            return self._activities[id]
        elif isinstance(activities, dict):
            assert all([isinstance(a, vipy.activity.Activity) and k == a.id() for (k,a) in activities.items()]), &#34;Invalid input - Must be dictionary of vipy.activity.Activity&#34;
            self._activities = activities.copy()  # shallow copy
            return self
        else:
            assert all([isinstance(a, vipy.activity.Activity) for a in tolist(activities)]), &#34;Invalid input - Must be vipy.activity.Activity or list of vipy.activity.Activity&#34;
            self._activities = {a.id():a for a in tolist(activities)}   # insertion order preserved (python &gt;=3.6)
            return self

    def activityindex(self, k):
        &#34;&#34;&#34;Return the `vipy.activity.Activity` at the requested index order in the video&#34;&#34;&#34;
        alist = self.activitylist()
        assert k &gt;= 0 and k &lt; len(alist), &#34;Invalid index&#34;        
        return alist[k]

    def activitylist(self):
        &#34;&#34;&#34;Return a list of activities in the video, returned in insertion order.

        Returns:
            A list of `vipy.activity.Activity` insertion ordered into the original video

        .. note::  The order of the activitylist() will not match the order of activityclip(), which is sorted by activity startframe.  To match, use sorted(activitylist, key=lambda a: a.startframe())
        &#34;&#34;&#34;
        return list(self.activities().values())  # insertion ordered (python &gt;=3.6), triggers shallow copy
        
    def activityfilter(self, f):
        &#34;&#34;&#34;Apply boolean lambda function f to each activity and keep activity if function is true, remove activity if function is false
        
        Filter out all activities longer than 128 frames 

        ```python
        vid = vid.activityfilter(lambda a: len(a)&lt;128)
        ```

        Filter out activities with category in set

        ```python
        vid = vid.activityfilter(lambda a: a.category() in set([&#39;category1&#39;, &#39;category2&#39;]))
        ```
       
        Args:
            f: [lambda] a lambda function that takes an activity and returns a boolean

        Returns:
            This video with the activities f(a)==False removed.

        &#34;&#34;&#34;
        assert callable(f)
        self._activities = {k:a for (k,a) in self.activities().items() if f(a) == True}
        return self
        
    def trackfilter(self, f, activitytrack=True):
        &#34;&#34;&#34;Apply lambda function f to each object and keep if filter is True.  
        
        Args:
            activitytrack: [bool] If true, remove track assignment from activities also, may result in activities with no tracks
            f: [lambda]  The lambda function to apply to each track t, and if f(t) returns True, then keep the track
        
        Returns:
            self, with tracks removed in-place

        .. note:: Applying track filter with activitytrack=True may result in activities with no associated tracks.  You should follow up with self.activityfilter(lambda a: len(a.trackids()) &gt; 0).
        &#34;&#34;&#34;
        assert callable(f)
        self._tracks = {k:t for (k,t) in self.tracks().items() if f(t) == True}
        if activitytrack:
            self.activitymap(lambda a: a.trackfilter(lambda ti: ti in self._tracks))  # remove track association in activities
            #if any([len(a.tracks()) == 0 for a in self.activitylist()]):
            #    warnings.warn(&#39;trackfilter(..., activitytrack=True) removed tracks which returned at least one degenerate activity with no tracks&#39;)
        return self

    def trackmap(self, f, strict=True):
        &#34;&#34;&#34;Apply lambda function f to each activity

           -strict=True: enforce that lambda function must return non-degenerate Track() objects        
        &#34;&#34;&#34;
        assert callable(f)
        self._tracks = {k:f(t) for (k,t) in self.tracks().items()}
        assert all([isinstance(t, vipy.object.Track) and (strict is False or not t.isdegenerate()) for (tk,t) in self.tracks().items()]), &#34;Lambda function must return non-degenerate vipy.object.Track()&#34;
        return self
        
    def activitymap(self, f):
        &#34;&#34;&#34;Apply lambda function f to each activity&#34;&#34;&#34;
        assert callable(f)
        self._activities = {k:f(a) for (k,a) in self.activities().items()}
        assert all([isinstance(a, vipy.activity.Activity) for a in self.activitylist()]), &#34;Lambda function must return vipy.activity.Activity()&#34;
        return self

    def rekey(self, tracks=None, activities=None):
        &#34;&#34;&#34;Change the track and activity IDs to randomly assigned UUIDs.  Useful for cloning unique scenes.
        
        
        ```python
        v = vipy.video.RandomScene()
        v.rekey()  # randomly rekey all track and activity ID
        v.rekey(tracks={...})  # rekey tracks (oldkey -&gt; newkey) according to dictionary, randomly rekey activities
        v.rekey(tracks={...}, activities={})  #  rekey tracks according to dict, no change to activities
        ```

        Args:
            tracks [dict]: If not None, use this dictionary to remap oldkey-&gt;newkey for tracks.  If None, use random keys. If empty dict, no change (do not rekey tracks)
            activities [dict]: If not None, use this dictionary to remap oldkey-&gt;newkey for activities.  If None, use random keys.  If empty dict, no change (do not rekey activities)
        
        Returns:
            This object, with all track ID and activity ID rekeyed as specified.  All actor IDs in activities will be updated.  
        
        &#34;&#34;&#34;
        assert activities is None or isinstance(activities, dict) and all([k in self.activities() for k in activities.keys()])
        assert tracks is None or isinstance(tracks, dict) and all([k in self.tracks() for k in tracks.keys()])

        d_old_to_new = {k:hex(int(uuid.uuid4().hex[0:8], 16))[2:] for (k,a) in self.activities().items()} if activities is None else activities
        self._activities = dict([(d_old_to_new[k], a.id(d_old_to_new[k])) if k in d_old_to_new else (k,a) for (k,a) in self.activities().items()])
        d_old_to_new = {k:hex(int(uuid.uuid4().hex[0:8], 16))[2:] for (k,t) in self.tracks().items()} if tracks is None else tracks
        self._tracks = dict([(d_old_to_new[k], t.id(d_old_to_new[k])) if k in d_old_to_new else (k,t) for (k,t) in self.tracks().items()])
        for (k,v) in d_old_to_new.items():
            self.activitymap(lambda a: a.replaceid(k,v) )
        return self

    def annotation(self):
        &#34;&#34;&#34;Return an iterator over annotations in each frame.
        
        ```python
        for y in self.annotation():
            for (bb,a) in y:
                print((bb,a))
        ```

        Yields:
            for each frame yield the tuple:  ( (`vipy.object.Detection`, (tuple of `vipy.activity.Activity` performed by the actor in this bounding box)), ... )

        .. note:: The preferred method for accessing annotations is a frame iterator, which includes pixels.  However, this method provides access to just the annotations without pixels.

        &#34;&#34;&#34;
        endframe = max([a.endframe() for a in self.activitylist()]+[t.endframe() for (tk,t) in self.tracks().items()]) if (len(self._tracks) &gt; 0 or len(self._activities) &gt; 0) else 0
        for k in range(0,endframe):
            yield tuple( [tuple( [t[k] if t.during(k) else None, tuple( [a for a in self.activitylist() if a.during(k) and a.hastrackoverlap(t)] ) ]) for t in self.tracklist()])
        
    def label(self):
        &#34;&#34;&#34;Return an iterator over labels in each frame&#34;&#34;&#34;
        endframe = max([a.endframe() for a in self.activitylist()]+[t.endframe() for (tk,t) in self.tracks().items()]) if (len(self._tracks) &gt; 0 or len(self._activities) &gt; 0) else 0
        for k in range(0,endframe):
            yield self.labels(k)
    
    def labels(self, k=None):
        &#34;&#34;&#34;Return a set of all object and activity labels in this scene, or at frame int(k)&#34;&#34;&#34;
        return self.activitylabels(k).union(self.objectlabels(k))

    def activitylabel(self, startframe=None, endframe=None):
        &#34;&#34;&#34;Return an iterator over activity labels in each frame, starting from startframe and ending when there are no more activities&#34;&#34;&#34;        
        endframe = endframe if endframe is not None else (max([a.endframe() for a in self.activitylist()]) if len(self.activities())&gt;0 else 0)
        startframe = startframe if startframe is not None else (min([a.startframe() for a in self.activitylist()]) if len(self.activities())&gt;0 else 0)
        assert startframe &lt;= endframe
        for k in range(startframe, endframe):
            yield self.activitylabels(k)
        
    def activitylabels(self, startframe=None, endframe=None):
        &#34;&#34;&#34;Return a set of all activity categories in this scene, or at startframe, or in range [startframe, endframe]&#34;&#34;&#34;        
        if startframe is None:
            return set([a.category() for a in self.activities().values()])
        elif startframe is not None and endframe is None:
            return set([a.category() for a in self.activities().values() if a.during(startframe)])
        elif startframe is not None and endframe is not None:
            return [set([a.category() for a in self.activities().values() if a.during(k)]) for k in range(startframe, endframe)] 
        else:
            raise ValueError(&#39;Invalid input - must specify both startframe and endframe, or only startframe&#39;)            
    
    def objectlabels(self, k=None, lower=False):
        &#34;&#34;&#34;Return a python set of all activity categories in this scene, or at frame k.
        
        Args:
            k: [int] The object labels present at frame k.  If k=None, then all object labels in the video
            lower: [bool] If true, return the object labels in alll lower case for case invariant string comparisonsn            
        &#34;&#34;&#34;
        return set([t.category() if not lower else t.category().lower() for t in self.tracks().values() if k is None or t.during(k)])        

    def categories(self):
        &#34;&#34;&#34;Alias for labels()&#34;&#34;&#34;
        return self.labels()
    
    def activity_categories(self):
        &#34;&#34;&#34;Alias for activitylabels()&#34;&#34;&#34;
        return self.activitylabels()        
        
    def hasactivities(self):
        &#34;&#34;&#34;Does this video have any activities?&#34;&#34;&#34;
        return len(self._activities) &gt; 0

    def hasactivity(self, activityid):
        &#34;&#34;&#34;Does this video have this activity id?&#34;&#34;&#34;
        return activityid in self.activities()
    
    def hastracks(self):
        &#34;&#34;&#34;Does this video have any tracks?&#34;&#34;&#34;
        return len(self._tracks) &gt; 0

    def hastrack(self, trackid):
        &#34;&#34;&#34;Does the video have this trackid?  
        
        .. note:: Track IDs are available as vipy.object.Track().id()
        &#34;&#34;&#34;
        return trackid in self.tracks()

    def add(self, obj, category=None, attributes=None, rangecheck=True, frame=None, fluent=False):
        &#34;&#34;&#34;Add the object obj to the scene, and return an index to this object for future updates
        
        This function is used to incrementally build up a scene frame by frame.  Obj can be one of the following types:

        - obj = vipy.object.Detection(), this must be called from within a frame iterator (e.g. for im in video) to get the current frame index
        - obj = vipy.object.Track()  
        - obj = vipy.activity.Activity()
        - obj = [xmin, ymin, width, height], with associated category kwarg, this must be called from within a frame iterator to get the current frame index
        
        It is recomended that the objects are added as follows.  For a v=vipy.video.Scene():
           
        ```python
            for im in v:
                # Do some processing on frame im to detect objects
                (object_labels, xywh) = object_detection(im)
        
                # Add them to the scene, note that each object instance is independent in each frame, use tracks for object correspondence
                for (lbl,bb) in zip(object_labels, xywh):
                    v.add(bb, lbl)
        
                # Do some correspondences to track objects
                t2 = v.add( vipy.object.Track(...) )
        
                # Update a previous track to add a keyframe
                v.track(t2).add( ... )
        ```
        
        The frame iterator will keep track of the current frame in the video and add the objects in the appropriate place.  Alternatively,

        ```python
            v.add(vipy.object.Track(..), frame=k)
        ```

        Args:
            obj: A conformal python object to add to the scene (`vipy.object.Detection`, `vipy.object.Track`, `vipy.activity.Activity`, [xmin, ymin, width, height]
            category:  Used if obj is an xywh tuple
            attributes:  Used only if obj is an xywh tuple
            frame:  [int] The frame to add the object
            rangecheck: [bool] If true, check if the object is within the image rectangle and throw an exception if not.  This requires introspecting the video shape using `vipy.video.Video.shape`.
            fluent: [bool] If true, return self instead of the object index 

        &#34;&#34;&#34;        
        if isinstance(obj, vipy.object.Detection):
            assert frame is not None, &#34;add() for vipy.object.Detection() must be added during frame iteration (e.g. for im in video: )&#34;
            k = frame
            if obj.hasattribute(&#39;trackid&#39;) and obj.attributes[&#39;trackid&#39;] in self.tracks():
                # The attribute &#34;trackid&#34; is set for a detection when interpolating a track at a frame.  This is useful for reconstructing a track from previously enumerated detections
                trackid = obj.attributes[&#39;trackid&#39;]
                self.trackmap(lambda t: t.update(k, obj) if obj.attributes[&#39;trackid&#39;] == t.id() else t) 
                return None if not fluent else self
            else:
                t = vipy.object.Track(category=obj.category(), keyframes=[k], boxes=[obj], boundary=&#39;strict&#39;, attributes=obj.attributes, trackid=obj.attributes[&#39;trackid&#39;] if obj.hasattribute(&#39;trackid&#39;) else None, framerate=self.framerate())
                if rangecheck and not obj.hasoverlap(width=self.width(), height=self.height()):
                    raise ValueError(&#34;Track &#39;%s&#39; does not intersect with frame shape (%d, %d)&#34; % (str(t), self.height(), self.width()))
                self.tracks()[t.id()] = t  # by-reference
                return t.id() if not fluent else self
        elif isinstance(obj, vipy.object.Track):
            if rangecheck and not obj.boundingbox().isinside(vipy.geometry.imagebox(self.shape())):
                obj = obj.imclip(self.width(), self.height())  # try to clip it, will throw exception if all are bad 
                warnings.warn(&#39;[vipy.video.add]: Clipping trackid=%s track=&#34;%s&#34; to image rectangle&#39; % (str(obj.id()), str(obj)))
            if obj.framerate() != self.framerate():
                obj.framerate(self.framerate())  # convert framerate of track to framerate of video
            self.tracks()[obj.id()] = obj  # by-reference
            return obj.id() if not fluent else self
        elif isinstance(obj, vipy.activity.Activity):
            if rangecheck and obj.startframe() &gt;= obj.endframe():
                raise ValueError(&#34;Activity &#39;%s&#39; has invalid (startframe, endframe)=(%d, %d)&#34; % (str(obj), obj.startframe(), obj.endframe()))
            self.activities()[obj.id()] = obj  # by-reference, activity may have no tracks
            return obj.id() if not fluent else self
        elif (istuple(obj) or islist(obj)) and len(obj) == 4 and isnumber(obj[0]):
            assert frame is not None, &#34;add() for obj=xywh must be added at a specific frame&#34;
            t = vipy.object.Track(category=category, keyframes=[frame], boxes=[vipy.geometry.BoundingBox(xywh=obj)], boundary=&#39;strict&#39;, attributes=attributes, framerate=self.framerate())
            if rangecheck and not t.boundingbox().isinside(vipy.geometry.imagebox(self.shape())):
                t = t.imclip(self.width(), self.height())  # try to clip it, will throw exception if all are bad 
                warnings.warn(&#39;Clipping track &#34;%s&#34; to image rectangle&#39; % (str(t)))
            self.tracks()[t.id()] = t  # by-reference
            return t.id() if not fluent else self
        else:
            raise ValueError(&#39;Undefined object type &#34;%s&#34; to be added to scene - Supported types are obj in [&#34;vipy.object.Detection&#34;, &#34;vipy.object.Track&#34;, &#34;vipy.activity.Activity&#34;, &#34;[xmin, ymin, width, height]&#34;]&#39; % str(type(obj)))

    def delete(self, id):
        &#34;&#34;&#34;Delete a given track or activity by id, if present&#34;&#34;&#34;
        return self.trackfilter(lambda t: t.id() != id).activityfilter(lambda a: a.id() != id)
            
    def addframe(self, im, frame):
        &#34;&#34;&#34;Add im=vipy.image.Scene() into vipy.video.Scene() at given frame. The input image must have been generated using im=self[k] for this to be meaningful, so that trackid can be associated&#34;&#34;&#34;
        assert isinstance(im, vipy.image.Scene), &#34;Invalid input - Must be vipy.image.Scene()&#34;
        assert im.shape() == self.shape(), &#34;Frame input (shape=%s) must be same shape as video (shape=%s)&#34; % (str(im.shape()), str(self.shape()))
        
        # Copy framewise vipy.image.Scene() into vipy.video.Scene(). 
        self.numpy()[frame] = im.array()  # will trigger copy        
        for bb in im.objects():
            self.trackmap(lambda t: t.update(frame, bb) if bb.attributes[&#39;trackid&#39;] == t.id() else t) 
        return self
    
    def clear(self):
        &#34;&#34;&#34;Remove all activities and tracks from this object&#34;&#34;&#34;
        self._activities = {}
        self._tracks = {}
        return self

    def cleartracks(self):
        self._tracks = {}
        return self

    def clearactivities(self):
        self._activities = {}
        return self
    
    def replace(self, other, frame=None):
        &#34;&#34;&#34;Replace tracks and activities with other if activity/track is during frame&#34;&#34;&#34;
        assert isinstance(other, vipy.video.Scene)
        self.activities([a for a in other.activitylist() if frame is None or a.during(frame)])
        self.tracks([t for t in other.tracklist() if frame is None or t.during(frame)])
        return self
    
    def json(self, encode=True):
        &#34;&#34;&#34;Return JSON encoded string of this object.  This may fail if attributes contain non-json encodeable object&#34;&#34;&#34;
        try:
            json.loads(json.dumps(self.attributes))  # round trip for the attributes dictionary - this can be any arbitrary object and contents may not be json encodable
        except:
            raise ValueError(&#39;Video contains non-JSON encodable object in self.attributes dictionary - Try self.sanitize() or to clear with self.attributes = {} first&#39;)
        d = json.loads(super().json())
        d[&#39;_tracks&#39;] = {k:t.json(encode=False) for (k,t) in self.tracks().items()}
        d[&#39;_activities&#39;] = {k:a.json(encode=False) for (k,a) in self.activities().items()}
        try:
            return json.dumps(d) if encode else d
        except:
            # Legacy support for non JSON serializable objects (&lt;= vipy.1.9.2)
            v = self.clone()
            for (ti, t) in v.tracks().items():
                for o in t._keyboxes:
                    vipy.geometry.BoundingBox.cast(o, flush=True)
                    o.float().significant_digits(2)

            for (ai, a) in v.activities().items():
                a._startframe = int(a._startframe)
                a._endframe = int(a._endframe)
            return v.json(encode=encode)
        
    def csv(self, outfile=None):
        &#34;&#34;&#34;Export scene to CSV file format with header.  If there are no tracks, this will be empty. &#34;&#34;&#34;
        assert self.load().isloaded()
        csv = [(self.filename(), # video filename
                k,  # frame number (zero indexed)
                d.category(), d.shortlabel(), # track category and shortlabel (displayed in caption)
                &#39;;&#39;.join([self.activities(id=aid).category() for aid in tolist(d.attributes[&#39;activityid&#39;])] if &#39;activityid&#39; in d.attributes else &#39;&#39;), # semicolon separated activity category associated with track
                d.xmin(), d.ymin(), d.width(), d.height(),   # bounding box
                d.attributes[&#39;trackid&#39;],  # globally unique track ID
                &#39;;&#39;.join([aid for aid in tolist(d.attributes[&#39;activityid&#39;])] if &#39;activityid&#39; in d.attributes else &#39;&#39;)) # semicolon separated activity ID associated with track
               for (k,im) in enumerate(self) for d in im.objects()]
        csv = [(&#39;# video_filename&#39;, &#39;frame_number&#39;, &#39;object_category&#39;, &#39;object_shortlabel&#39;, &#39;activity categories(;)&#39;, &#39;xmin&#39;, &#39;ymin&#39;, &#39;width&#39;, &#39;height&#39;, &#39;track_id&#39;, &#39;activity_ids(;)&#39;)] + csv
        return writecsv(csv, outfile) if outfile is not None else csv


    def framerate(self, fps=None):
        &#34;&#34;&#34;Change the input framerate for the video and update frame indexes for all annotations.

        ```python
        fps = self.framerate()
        self.framerate(fps=15.0)
        ```

        &#34;&#34;&#34;
        if fps is None:
            return self._framerate
        elif float(fps) == self._framerate:
            return self
        else:
            assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
            fps = float(fps)
            self._startframe = int(round(self._startframe * (fps/self._framerate))) if self._startframe is not None else self._startframe  # __repr__ only
            self._endframe = int(round(self._endframe * (fps/self._framerate))) if self._endframe is not None else self._endframe  # __repr__only
            self._tracks = {k:t.framerate(fps) for (k,t) in self.tracks().items()}
            self._activities = {k:a.framerate(fps) for (k,a) in self.activities().items()}        
            if &#39;fps=&#39; in self._ffmpeg_commandline():
                self._update_ffmpeg(&#39;fps&#39;, fps)  # replace fps filter, do not add to it
            else:
                self._ffmpeg = self._ffmpeg.filter(&#39;fps&#39;, fps=fps, round=&#39;up&#39;)  # create fps filter first time
            self._framerate = fps
            return self
        
    def activitysplit(self, idx=None):
        &#34;&#34;&#34;Split the scene into k separate scenes, one for each activity.  Do not include overlapping activities.  

        Args:
            idx: [int],[tuple],[list].  Return only those activities in the provided activity index list, where the activity index is the integer index of the activity in the video.

        .. note:: This is useful for union()
        &#34;&#34;&#34;
        vid = self.clone(flushforward=True)
        if any([(a.endframe()-a.startframe()) &lt;= 0 for a in vid.activities().values()]):
            warnings.warn(&#39;Filtering invalid activity with degenerate lengths: %s&#39; % str([a for a in vid.activities().values() if (a.endframe()-a.startframe()) &lt;= 0]))
        activities = sorted([a.clone() for a in vid.activities().values() if (a.endframe()-a.startframe()) &gt; 0], key=lambda a: a.startframe())   # only activities with at least one frame, sorted in temporal order
        tracks = [ [t.clone() for (tid, t) in vid.tracks().items() if a.hastrack(t)] for a in activities]  # tracks associated with each activity (may be empty)
        vid._activities = {}  # for faster clone
        vid._tracks = {}      # for faster clone
        return [vid.clone()
                .setattribute(&#39;_instance_id&#39;, (&#39;%s_%d&#39; % (vid.videoid(), k)) if not vid.hasattribute(&#39;_instance_id&#39;) else vid.getattribute(&#39;_instance_id&#39;))
                .activities(pa)
                .tracks(t)
                .setactorid(pa.actorid())
                for (k,(pa,t)) in enumerate(zip(activities, tracks)) if idx is None or k in tolist(idx)]

    def tracksplit(self):
        &#34;&#34;&#34;Split the scene into k separate scenes, one for each track.  Each scene starts at frame 0 and is a shallow copy of self containing exactly one track.  

        - This is useful for visualization by breaking a scene into a list of scenes that contain only one track.
        - The attribute &#39;_trackindex&#39; is set in the attributes dictionary to provide provenance for the track relative to the source video

        .. notes:: Use clone() to create a deep copy if needed.
        &#34;&#34;&#34;
        return [self.clone(shallow=True).setattribute(&#39;_trackindex&#39;, k).tracks(t).activityfilter(lambda a: a.hastrack(tk)) for (k,(tk,t)) in enumerate(self.tracks().items())]

    def trackclip(self):
        &#34;&#34;&#34;Split the scene into k separate scenes, one for each track.  Each scene starts and ends when the track starts and ends&#34;&#34;&#34;
        return [t.setattribute(&#39;_instance_id&#39;, &#39;%s_%d_trackclip&#39; % (t.videoid(), k)).clip(t.track(t.actorid()).startframe(), t.track(t.actorid()).endframe()) for (k,t) in enumerate(self.tracksplit())]
    
    def activityclip(self, padframes=0, multilabel=True, idx=None, padto=None, padtosec=None):
        &#34;&#34;&#34;Return a list of `vipy.video.Scene` objects each clipped to be temporally centered on a single activity, with an optional padframes before and after.  

        Args:
            padframes: [int] for symmetric padding same before and after
            padframes: [tuple] (int, int) for asymmetric padding before and after
            padframes: [list[tuples]] [(int, int), ...] for activity specific asymmetric padding.  See also padto.
            multilabel: [bool] include overlapping multilabel secondary activities in each activityclip
            idx: [int], [tuple], [list].  The indexes of the activities to return, where the index is the integer index order of the activity in the video.  Useful for complex videos.
            padto: [int] padding so that each activity clip is at least padto frames long, with symmetric padding around the activity.  
            padtosec: [float] padding so that each activity clip is at least padtosec seconds long, with symmetric padding around the activity.  

        Returns:
            A list of `vipy.video.Scene` each cloned from the source video and clipped on one activity in the scene

        .. notes::
           - The Scene() category is updated to be the activity category of the clip, and only the objects participating in the activity are included.
           - Clips are returned ordered in the temporal order they appear in the video.
           - The returned vipy.video.Scene() objects for each activityclip are clones of the video, with the video buffer flushed.
           - Each activityclip() is associated with each activity in the scene, and includes all other secondary activities that the objects in the primary activity also perform (if multilabel=True).  See activityclip().labels(). 
           - Calling activityclip() on activityclip(multilabel=True) will duplicate activities, due to the overlapping secondary activities being included in each clip with an overlap.  Be careful!
        &#34;&#34;&#34;
        assert isinstance(padframes, int) or istuple(padframes) or islist(padframes)

        vid = self.clone(flushforward=True)
        if any([(a.endframe()-a.startframe()) &lt;= 0 for a in vid.activities().values()]):
            warnings.warn(&#39;Filtering invalid activity clips with degenerate lengths: %s&#39; % str([a for a in vid.activities().values() if (a.endframe()-a.startframe()) &lt;= 0]))
        primary_activities = sorted([a.clone() for a in vid.activities().values() if (a.endframe()-a.startframe()) &gt; 0], key=lambda a: a.startframe())   # only activities with at least one frame, sorted in temporal order
        padframelist = [padframes if istuple(padframes) else (padframes, padframes) for k in range(len(primary_activities))] if not islist(padframes) else padframes                    
        tracks = [ [t.clone() for (tid, t) in vid.tracks().items() if a.hastrackoverlap(t)] for a in primary_activities]  # tracks associated with and temporally overlapping each primary activity (may be empty)
        secondary_activities = [[sa.clone() for sa in primary_activities if (sa.id() != pa.id() and pa.clone().temporalpad((prepad, postpad)).hasoverlap(sa) and (len(T)==0 or any([sa.hastrack(t) for t in T])))] for (pa, T, (prepad,postpad)) in zip(primary_activities, tracks, padframelist)]  # overlapping secondary activities that includes any track in the primary activity
        secondary_activities = [sa if multilabel else [] for sa in secondary_activities]  
        vid._activities = {}  # for faster clone
        vid._tracks = {}      # for faster clone
        maxframes = self.duration_in_frames() if (padframes != 0 or padto is not None or padtosec is not None) else None                    
        if padto is not None or padtosec is not None:
            cliplist = [(a.startframe(), a.endframe()) for a in primary_activities]
            padto = padto if padto is not None else int(round(padtosec*self.framerate()))            
            padframelist = [(sp+int(np.ceil(((padto-(ef-sf))/2))), ep+int(np.ceil(((padto-(ef-sf))/2)))) if (ef-sf)&lt;padto else (sp,ep) for ((sp,ep),(sf,ef)) in zip(padframelist, cliplist)]  
            padframelist = [(0,ep+(-sp)) if (sp&lt;0) else ((sp+(ep-(maxframes-ef)), maxframes-ef) if ((ef+ep)&gt;maxframes) else (sp,ep)) for ((sp,ep),(sf,ef)) in zip(padframelist, cliplist)]  # truncate to video boundary
            
        return [vid.clone()
                .activities([pa]+sa)  # primary activity first
                .tracks(t)
                .clip(startframe=max(pa.startframe()-prepad, 0), endframe=min(pa.endframe()+postpad, (maxframes if maxframes is not None else pa.endframe()+postpad)))
                .category(pa.category())
                .setactorid(pa.actorid())  # actor is actor of primary activity
                .setattribute(&#39;_instance_id&#39;, (&#39;%s_%d&#39; % (vid.videoid(), k)) if not vid.hasattribute(&#39;_instance_id&#39;) else vid.getattribute(&#39;_instance_id&#39;))
                for (k,(pa,sa,t,(prepad,postpad))) in enumerate(zip(primary_activities, secondary_activities, tracks, padframelist))
                if (idx is None or k in tolist(idx))]

    def noactivitylist(self, label=None, shortlabel=None):
        &#34;&#34;&#34;Return a list of `vipy.activity.Activity` which are segments of each track with no associated activities.

        Args:
            label: [str] The activity label to give the background activities.  Defaults to the track category (lowercase)
        
        Returns:
            A list of `vipy.activity.Activity` such that each activity is associated with a track with temporal support where no activities are performed. The union of activitylist() and noactivitylist() should cover the temporal support of all track
        &#34;&#34;&#34;
        A = []
        for t in self.tracklist():
            (startframe, endframe) = (t.startframe(), t.startframe())
            for k in range(t.startframe(), t.endframe()):
                if not any([a.hastrack(t) and a.during(k) for a in self.activitylist()]) and k &lt; (t.endframe()-1):
                    endframe = k  # background
                else:
                    if startframe &lt; endframe:
                        A.append(vipy.activity.Activity(label=t.category() if label is None else label, 
                                                        shortlabel=&#39;&#39; if label is None else (label if shortlabel is None else shortlabel),
                                                        startframe=startframe,
                                                        endframe=endframe,
                                                        actorid=t.id(),
                                                        framerate=self.framerate(),
                                                        attributes={&#39;_noactivitylist&#39;:True}))
                    (startframe, endframe) = (k+1,k+1)                        
        return A
    
        
    def noactivityclip(self, label=None, shortlabel=None, padframes=0):
        &#34;&#34;&#34;Return a list of vipy.video.Scene() each clipped on a track segment that has no associated activities.  

        Args:
            label: [str] The activity label to give the background activities.  Defaults to the track category (lowercase)
            shortlabel: [str] The activity shortlabel to give the background activities when visualized.  Defaults to the track category (lowercase)
            padframes: [int]  The amount of temporal padding to apply to the clips before and after in frames.  See `vipy.video.Scene.activityclip` for options.
        
        Returns:
            A list of `vipy.video.Scene` each cloned from the source video and clipped in the temporal region between activities.  The union of activityclip() and noactivityclip() should equal the entire video.

        .. notes::
            - Each clip will contain exactly one activity &#34;Background&#34; which is the interval for this track where no activities are occurring
            - Each clip will be at least one frame long
        &#34;&#34;&#34;
        A = self.clone().activities(self.noactivitylist(label=label, shortlabel=shortlabel)).activityclip(padframes=padframes, multilabel=False)
        return [a.setattribute(&#39;_instance_id&#39;, &#39;%s_bg&#39; % a.getattribute(&#39;_instance_id&#39;)) for a in A]
    
    def trackbox(self, dilate=1.0):
        &#34;&#34;&#34;The trackbox is the union of all track bounding boxes in the video, or None if there are no tracks
        
        Args:
            dilate: [float] A dilation factor to apply to the trackbox before returning.  See `vipy.geometry.BoundingBox.dilate`

        Returns:
            A `vipy.geometry.BoundingBox` which is the union of all boxes in the track (or None if no boxes exist)
        &#34;&#34;&#34;
        boxes = [t.clone().boundingbox() for t in self.tracklist()]
        boxes = [bb.dilate(dilate) for bb in boxes if bb is not None]
        return boxes[0].union(boxes[1:]) if len(boxes) &gt; 0 else None

    def framebox(self):
        &#34;&#34;&#34;Return the bounding box for the image rectangle.

        Returns:
            A `vipy.geometry.BoundingBox` which defines the image rectangle

        .. notes: This requires calling `vipy.video.Video.preview` to get the frame shape from the current filter chain, which touches the video file&#34;&#34;&#34;
        return vipy.geometry.BoundingBox(xmin=0, ymin=0, width=self.width(), height=self.height())

    def trackcrop(self, dilate=1.0, maxsquare=False, zeropad=True):
        &#34;&#34;&#34;Return the trackcrop() of the scene which is the crop of the video using the `vipy.video.Scene.trackbox`.
         
        Args:
            zeropad: [bool] If True, the zero pad the crop if it is outside the image rectangle, otherwise return only valid pixels inside the image rectangle
            maxsquare: [bool] If True, make the bounding box the maximum square before cropping
            dilate: [float] The dilation factor to apply to the trackbox prior to cropping
        
        Returns:
           A `vipy.video.Scene` object from cropping the video using the trackbox.  If there are no tracks, return None.  

        &#34;&#34;&#34;
        bb = self.trackbox(dilate)  # may be None if trackbox is degenerate
        return self.crop(bb.maxsquareif(maxsquare), zeropad=zeropad) if bb is not None else None  

    def activitybox(self, activityid=None, dilate=1.0):
        &#34;&#34;&#34;The activitybox is the union of all activity bounding boxes in the video, which is the union of all tracks contributing to all activities.  This is most useful after activityclip().
           The activitybox is the smallest bounding box that contains all of the boxes from all of the tracks in all activities in this video.
        &#34;&#34;&#34;
        activities = [a for (k,a) in self.activities().items() if (activityid is None or k in set(activityid))]
        boxes = [t.clone().boundingbox().dilate(dilate) for t in self.tracklist() if any([a.hastrack(t) for a in activities])]
        return boxes[0].union(boxes[1:]) if len(boxes) &gt; 0 else vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(self.width()), height=int(self.height()))

    def activitycuboid(self, activityid=None, dilate=1.0, maxdim=256, bb=None):
        &#34;&#34;&#34;The activitycuboid() is the fixed square spatial crop corresponding to the activitybox (or supplied bounding box), which contains all of the valid activities in the scene.  This is most useful after activityclip().
           The activitycuboid() is a spatial crop of the video corresponding to the supplied boundingbox or the square activitybox().
           This crop must be resized such that the maximum dimension is provided since the crop can be tiny and will not be encodable by ffmpeg
        &#34;&#34;&#34;
        bb = self.activitybox(activityid).maxsquare() if bb is None else bb  
        assert bb is None or isinstance(bb, vipy.geometry.BoundingBox)
        assert bb.issquare(), &#34;Add support for non-square boxes&#34;
        return self.clone().crop(bb.dilate(dilate).int(), zeropad=True).resize(maxdim, maxdim)  # crop triggers preview()

    def activitysquare(self, activityid=None, dilate=1.0, maxdim=256):
        &#34;&#34;&#34;The activity square is the maxsquare activitybox that contains only valid (non-padded) pixels interior to the image&#34;&#34;&#34;
        bb = self.activitybox(activityid).maxsquare().dilate(dilate).int().iminterior(self.width(), self.height()).minsquare()
        return self.activitycuboid(activityid, dilate=1.0, maxdim=maxdim, bb=bb)

    def activitytube(self, activityid=None, dilate=1.0, maxdim=256):
        &#34;&#34;&#34;The activitytube() is a sequence of crops where the spatial box changes on every frame to track the activity.  
           The box in each frame is the square activitybox() for this video which is the union of boxes contributing to this activity in each frame.
           This function does not perform any temporal clipping.  Use activityclip() first to split into individual activities.  
           Crops will be optionally dilated, with zeropadding if the box is outside the image rectangle.  All crops will be resized so that the maximum dimension is maxdim (and square by default)
        &#34;&#34;&#34;
        vid = self.clone().load()  # triggers load
        self.activityfilter(lambda a: activityid is None or a.id() in set(activityid))  # only requested IDs (or all of them)
        frames = [im.padcrop(im.boundingbox().maxsquare().dilate(dilate).int()).resize(maxdim, maxdim) for im in vid if im.boundingbox() is not None]  # track interpolation, for frames with boxes only
        if len(frames) != len(vid):
            warnings.warn(&#39;[vipy.video.activitytube]: Removed %d frames with no spatial bounding boxes&#39; % (len(vid) - len(frames)))
            vid.attributes[&#39;__activtytube&#39;] = {&#39;truncated&#39;:len(vid) - len(frames)}  # provenance to reject
        if len(frames) == 0:
            warnings.warn(&#39;[vipy.video.activitytube]: Resulting video is empty!  Setting activitytube to zero&#39;)
            frames = [ vid[0].resize(maxdim, maxdim).zeros() ]  # empty frame
            vid.attributes[&#39;__activitytube&#39;] = {&#39;empty&#39;:True}   # provenance to reject 
        vid._tracks = {ti:vipy.object.Track(keyframes=[f for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],
                                            boxes=[d for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],
                                            category=t.category(), trackid=ti, framerate=self.framerate())
                       for (k,(ti,t)) in enumerate(self.tracks().items())}  # replace tracks with boxes relative to tube
        return vid.array(np.stack([im.numpy() for im in frames]))

    def actortube(self, trackid=None, dilate=1.0, maxdim=256, strict=True):
        &#34;&#34;&#34;The actortube() is a sequence of crops where the spatial box changes on every frame to track the primary actor performing an activity.  
           The box in each frame is the square box centered on the primary actor performing the activity, dilated by a given factor (the original box around the actor is unchanged, this just increases the context, with zero padding)
           This function does not perform any temporal clipping.  Use activityclip() first to split into individual activities.  
           All crops will be resized so that the maximum dimension is maxdim (and square by default)
        &#34;&#34;&#34;
        assert trackid is not None or len(self.tracks()) == 1, &#34;Track ID must be provided if there exists more than one track in the scene&#34;
        trackid = trackid if trackid is not None else list(self.tracks().keys())[0]
        assert self.hastrack(trackid), &#34;Track ID %s not found - Actortube requires a track ID in the scene (tracks=%s)&#34; % (str(trackid), str(self.tracks()))
        vid = self.clone().load()  # triggers load        
        t = vid.tracks(id=trackid)  # actor track
        frames = [im.padcrop(t[k].maxsquare().dilate(dilate).int()).resize(maxdim, maxdim) for (k,im) in enumerate(vid) if t.during(k)] if len(t)&gt;0 else []  # actor interpolation, padding may introduce frames with no tracks
        if len(frames) == 0:
            if not strict:
                warnings.warn(&#39;[vipy.video.actortube]: Empty track for trackid=&#34;%s&#34; - Setting actortube to zero&#39; % trackid)
                frames = [ vid[0].resize(maxdim, maxdim).zeros() ]  # empty frame
                vid.attributes[&#39;__actortube&#39;] = {&#39;empty&#39;:True}   # provenance to reject             
            else:
                raise ValueError(&#39;[vipy.video.actortube]: Empty track for track=%s, trackid=%s&#39; % (str(t), trackid))
        vid._tracks = {ti:vipy.object.Track(keyframes=[f for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],  # keyframes zero indexed, relative to [frames]
                                            boxes=[d for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],  # one box per frame
                                            category=t.category(), trackid=ti, framerate=self.framerate())  # preserve trackid
                       for (k,(ti,t)) in enumerate(self.tracks().items())}  # replace tracks with interpolated boxes relative to tube defined by actor
        return vid.array(np.stack([im.numpy() for im in frames]))

    def speed(self, s):
        &#34;&#34;&#34;Change the speed by a multiplier s.  If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)&#34;&#34;&#34;        
        super().speed(s)
        return self.trackmap(lambda t: t.framerate(speed=s)).activitymap(lambda a: a.framerate(speed=s))
        

    
    def clip(self, startframe, endframe=None):
        &#34;&#34;&#34;Clip the video to between (startframe, endframe).  This clip is relative to clip() shown by __repr__(). 

        Args:
            startframe: [int] the start frame relative to the video framerate() for the clip
            endframe: [int] the end frame relative to the video framerate for the clip, may be none
        
        Returns:
            This video object, clipped so that a load() will result in frame=0 equivalent to startframe.  All tracks and activities updated relative to the new startframe.

        .. note:  
            - This return a clone of the video for idempotence
            - This does not load the video.  This updates the ffmpeg filter chain to temporally trim the video.  See self.commandline() for the updated filter chain to run.
        &#34;&#34;&#34;
        assert (endframe is None or startframe &lt;= endframe) and startframe &gt;= 0, &#34;Invalid start and end frames (%s, %s)&#34; % (str(startframe), str(endframe))

        v = self.clone()
        if not v.isloaded():
            # -- Copied from super().clip() to allow for clip on clone (for indempotence)
            # -- This code copy is used to avoid super(Scene, self.clone()) which screws up class inheritance for iPython reload
            assert not v.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;            
            timestamp_in_seconds = ((v._startframe if v._startframe is not None else 0)+startframe)/float(v.framerate())
            v._update_ffmpeg_seek(timestamp_in_seconds)
            if endframe is not None:
                v._ffmpeg = v._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 before trim filter            
                v._ffmpeg = v._ffmpeg.trim(start=0, end=(endframe-startframe)/self.framerate())  # must be in seconds to allow for framerate conversion
            v._ffmpeg = v._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 after trim filter            
            v._startframe = startframe if v._startframe is None else v._startframe + startframe  # for __repr__ only
            v._endframe = (v._startframe + (endframe-startframe)) if endframe is not None else v._endframe  # for __repr__ only
            # -- end copy
        else:
            endframe = endframe if endframe is not None else len(self._array)
            v._array = self._array[startframe:endframe]
            (v._startframe, v._endframe) = (0, endframe-startframe)
        v._tracks = {k:t.offset(dt=-startframe).truncate(startframe=0, endframe=(endframe-startframe) if endframe is not None else None) for (k,t) in v.tracks().items()}   # may be degenerate
        v._activities = {k:a.offset(dt=-startframe).truncate(startframe=0, endframe=(endframe-startframe) if endframe is not None else None) for (k,a) in v.activities().items()}  # may be degenerate
        return v.trackfilter(lambda t: len(t)&gt;0).activityfilter(lambda a: len(a)&gt;0)  # remove degenerate tracks and activities

    def crop(self, bb, zeropad=True):
        &#34;&#34;&#34;Crop the video using the supplied box, update tracks relative to crop, video is zeropadded if box is outside frame rectangle&#34;&#34;&#34;
        assert isinstance(bb, vipy.geometry.BoundingBox), &#34;Invalid input&#34;
        bb = bb.int()
        bbc = bb.clone().imclipshape(self.width(), self.height()).int()
        #if zeropad and bb != bbc:
        #    self.zeropad(bb.width()-bbc.width(), bb.height()-bbc.height())  
        #    bb = bb.offset(bb.width()-bbc.width(), bb.height()-bbc.height())            
        super().crop(bb, zeropad=zeropad)  # range check handled here to correctly apply zeropad
        bb = bb if zeropad else bbc
        self._tracks = {k:t.offset(dx=-bb.xmin(), dy=-bb.ymin()) for (k,t) in self.tracks().items()}
        return self
    
    def zeropad(self, padwidth, padheight):
        &#34;&#34;&#34;Zero pad the video with padwidth columns before and after, and padheight rows before and after
           Update tracks accordingly. 

        &#34;&#34;&#34;
        
        assert isinstance(padwidth, int) and isinstance(padheight, int)
        super().zeropad(padwidth, padheight)  
        self._tracks = {k:t.offset(dx=padwidth, dy=padheight) for (k,t) in self.tracks().items()}
        return self
        
    def fliplr(self):
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        self._tracks = {k:t.fliplr(H,W) for (k,t) in self.tracks().items()}
        super().fliplr()
        return self

    def flipud(self):
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        self._tracks = {k:t.flipud(H,W) for (k,t) in self.tracks().items()}
        super().flipud()
        return self

    def rot90ccw(self):
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        self._tracks = {k:t.rot90ccw(H,W) for (k,t) in self.tracks().items()}
        super().rot90ccw()
        return self

    def rot90cw(self):
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        self._tracks = {k:t.rot90cw(H,W) for (k,t) in self.tracks().items()}
        super().rot90cw()
        return self

    def resize(self, rows=None, cols=None, width=None, height=None):
        &#34;&#34;&#34;Resize the video to (rows, cols), preserving the aspect ratio if only rows or cols is provided&#34;&#34;&#34;
        assert not (rows is not None and height is not None)  # cannot be both
        assert not (cols is not None and width is not None)   # cannot be both
        rows = rows if rows is not None else height
        cols = cols if cols is not None else width        
        
        assert rows is not None or cols is not None, &#34;Invalid input&#34;
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter, manually set this prior to calling resize if known
        sy = rows / float(H) if rows is not None else cols / float(W)
        sx = cols / float(W) if cols is not None else rows / float(H)
        self._tracks = {k:t.scalex(sx) for (k,t) in self.tracks().items()}
        self._tracks = {k:t.scaley(sy) for (k,t) in self.tracks().items()}
        super().resize(rows=rows, cols=cols)        
        return self

    def mindim(self, dim=None):
        &#34;&#34;&#34;Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        return min(self.shape()) if dim is None else (self if min(H,W) == dim else (self.resize(cols=dim) if W&lt;H else self.resize(rows=dim)))

    def maxdim(self, dim=None):
        &#34;&#34;&#34;Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        return max(H,W) if dim is None else (self.resize(cols=dim) if W&gt;H else self.resize(rows=dim))        
    
    def rescale(self, s):
        &#34;&#34;&#34;Spatially rescale the scene by a constant scale factor.

        Args:
            s: [float] Scale factor &gt; 0 to isotropically scale the image.
        &#34;&#34;&#34;
        assert s == 1 or not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        self._tracks = {k:t.rescale(s) for (k,t) in self.tracks().items()}
        super().rescale(s)
        return self

    def startframe(self):
        return self._startframe

    def extrapolate(self, f, dt=None):
        &#34;&#34;&#34;Extrapolate the video to frame f and add the extrapolated tracks to the video&#34;&#34;&#34;
        return self.trackmap(lambda t: t.add(f, t.linear_extrapolation(f, dt=dt if dt is not None else self.framerate()), strict=False))
        
    def dedupe(self, spatial_iou_threshold=0.8, dt=5):
        &#34;&#34;&#34;Find and delete duplicate tracks by track segmentiou() overlap.
        
        Algorithm
        - For each pair of tracks with the same category, find the larest temporal segment that contains both tracks.
        - For this segment, compute the IOU for each box interpolated at a stride of dt frames
        - Compute the mean IOU for this segment.  This is the segment IOU. 
        - If the segment IOU is greater than the threshold, merge the shorter of the two tracks with the current track.  

        &#34;&#34;&#34;
        deleted = set([])
        for tj in sorted(self.tracklist(), key=lambda t: len(t), reverse=True):  # longest to shortest
            for (s, ti) in sorted([(0,t) if (len(tj) &lt; len(t) or t.id() in deleted or t.id() == tj.id() or t.category() != tj.category()) else (tj.fragmentiou(t, dt=dt), t) for t in self.tracklist()], key=lambda x: x[0], reverse=True):
                if s &gt; spatial_iou_threshold:  # best mean framewise overlap during overlapping segment of two tracks (ti, tj)
                    print(&#39;[vipy.video.dedupe]: merging duplicate track &#34;%s&#34; (id=%s) which overlaps with &#34;%s&#34; (id=%s)&#39; % (ti, ti.id(), tj, tj.id()))
                    self.tracks()[tj.id()] = tj.union(ti)  # merge
                    self.activitymap(lambda a: a.replace(ti, tj))  # replace merged track reference in activity
                    deleted.add(ti.id())
        self.trackfilter(lambda t: t.id() not in deleted)  # remove duplicate tracks
        return self

    def combine(self, other, tracks=True, activities=True, rekey=True):
        &#34;&#34;&#34;Combine the activities and tracks from both scenes into self. 
        
        .. note:: This does not perform a union, it simply combines dictionaries.  For deduplication, see `vipy.video.union`
        &#34;&#34;&#34;
        assert isinstance(other, Scene), &#34;Invalid input - must be vipy.video.Scene() object and not type=%s&#34; % str(type(other))
        assert self.framerate() == other.framerate()
        o = other.clone(rekey=True) if rekey else other   # make sure keys are unique
        if activities:
            self.activities().update(o.activities())
        if tracks:
            self.tracks().update(o.tracks())
        return self
    
        
    def union(self, other, temporal_iou_threshold=0.5, spatial_iou_threshold=0.6, strict=True, overlap=&#39;average&#39;, percentilecover=0.8, percentilesamples=100, activity=True, track=True):
        &#34;&#34;&#34;Compute the union two scenes as the set of unique activities and tracks.  

           A pair of activities or tracks are non-unique if they overlap spatially and temporally by a given IoU threshold.  Merge overlapping tracks. 
           Tracks are merged by considering the mean IoU at the overlapping segment of two tracks with the same category greater than the provided spatial_iou_threshold threshold
           Activities are merged by considering the temporal IoU of the activities of the same class greater than the provided temporal_iou_threshold threshold
  
           Args:
               Other: Scene or list of scenes for union.  Other may be a clip of self at a different framerate, spatial isotropic scake, clip offset
               spatial_iou_threshold:  The intersection over union threshold for the mean of the two segments of an overlapping track, Disable by setting to 1.0
               temporal_iou_threshold:  The intersection over union threshold for a temporal bounding box for a pair of activities to be declared duplicates.  Disable by setting to 1.0
               strict:  Require both scenes to share the same underlying video filename
               overlap=[&#39;average&#39;, &#39;replace&#39;, &#39;keep&#39;]
                   - average: Merge two tracks by averaging the boxes (average=True) if overlapping
                   - replace:  merge two tracks by replacing overlapping boxes with other (discard self)
                   - keep: merge two tracks by keeping overlapping boxes with other (discard other)
               percentilecover: [0,1]:  When determining the assignment of two tracks, compute the percentilecover of two tracks by ranking the cover in the overlapping segment and computing the mean of the top-k assignments, where k=len(segment)*percentilecover.
               percentilesamples: [&gt;1]:  the number of samples along the overlapping scemgne for computing percentile cover
               activity: [bool]: union() of activities only
               track: [bool]: union() of tracks only

           Returns:
               Updates this scene to include the non-overlapping activities from other.  By default, it takes the strict union of all activities and tracks. 

           .. note::
               - This is useful for merging scenes computed using a lower resolution/framerate/clipped  object or activity detector without running the detector on the high-res scene
               - This function will preserve the invariance for v == v.clear().union(v.rescale(0.5).framerate(5).activityclip()), to within the quantization error of framerate() downsampling.
               - percentileiou is a robust method of track assignment when boxes for two tracks (e.g. ground truth and detections) where one track may deform due to occlusion.
        &#34;&#34;&#34;
        assert overlap in [&#39;average&#39;, &#39;replace&#39;, &#39;keep&#39;], &#34;Invalid input - &#39;overlap&#39; must be in [average, replace, keep]&#34;
        assert spatial_iou_threshold &gt;= 0 and spatial_iou_threshold &lt;= 1, &#34;invalid spatial_iou_threshold, must be between [0,1]&#34;
        assert temporal_iou_threshold &gt;= 0 and temporal_iou_threshold &lt;= 1, &#34;invalid temporal_iou_threshold, must be between [0,1]&#34;        
        assert percentilesamples &gt;= 1, &#34;invalid samples, must be &gt;= 1&#34;
        if not activity and not track:
            return self  # nothing to do

        sc = self.clone()  # do not change self yet, make a copy then merge at the end
        for o in tolist(other):
            assert isinstance(o, Scene), &#34;Invalid input - must be vipy.video.Scene() object and not type=%s&#34; % str(type(o))

            if strict:
                assert sc.filename() == o.filename(), &#34;Invalid input - Scenes must have the same underlying video.  Disable this with strict=False.&#34;
            oc = o.clone()   # do not change other, make a copy

            # Key collision?
            if len(set(sc.tracks().keys()).intersection(set(oc.tracks().keys()))) &gt; 0:
                print(&#39;[vipy.video.union]: track key collision - Rekeying other... Use other.rekey() to suppress this warning.&#39;)
                oc.rekey()
            if len(set(sc.activities().keys()).intersection(set(oc.activities().keys()))) &gt; 0:
                print(&#39;[vipy.video.union]: activity key collision - Rekeying other... Use other.rekey() to suppress this warning.&#39;)                
                oc.rekey()

            # Similarity transform?  Other may differ from self by a temporal scale (framerate), temporal translation (clip) or spatial isotropic scale (rescale)
            assert np.isclose(sc.aspect_ratio(), oc.aspect_ratio(), atol=1E-2), &#34;Invalid input - Scenes must have the same aspect ratio&#34;
            if sc.width() != oc.width():
                oc = oc.rescale(sc.width() / oc.width())   # match spatial scale
            if not np.isclose(sc.framerate(), oc.framerate(), atol=1E-3):
                oc = oc.framerate(sc.framerate())   # match temporal scale (video in oc will not match, only annotations)
            if sc.startframe() != oc.startframe():
                dt = (oc.startframe() if oc.startframe() is not None else 0) - (sc.startframe() if sc.startframe() is not None else 0)
                oc = oc.trackmap(lambda t: t.offset(dt=dt)).activitymap(lambda a: a.offset(dt=dt))  # match temporal translation of tracks and activities
            oc = oc.trackfilter(lambda t: ((not t.isdegenerate()) and len(t)&gt;0), activitytrack=False)  

            # Merge other tracks into selfclone: one-to-many mapping from self to other
            merged = {}  # dictionary mapping trackid in other to the trackid in self, each track in other can be merged at most once
            for ti in sorted(sc.tracklist(), key=lambda t: len(t), reverse=True):  # longest to shortest
                for tj in sorted(oc.tracklist(), key=lambda t: len(t), reverse=True):  
                    if ti.category() == tj.category() and (tj.id() not in merged) and tj.segment_percentilecover(sc.track(ti.id()), percentile=percentilecover, samples=percentilesamples) &gt; spatial_iou_threshold:  # mean framewise overlap during overlapping segment of two tracks
                        sc.tracks()[ti.id()] = sc.track(ti.id()).union(tj, overlap=overlap)  # merge duplicate/fragmented tracks from other into self, union() returns clone
                        merged[tj.id()] = ti.id()  
                        print(&#39;[vipy.video.union]: merging track &#34;%s&#34;(id=%s) + &#34;%s&#34;(id=%s) for scene &#34;%s&#34;&#39; % (str(ti), str(ti.id()), str(tj), str(tj.id()), str(sc)))                        
            oc.trackfilter(lambda t: t.id() not in merged, activitytrack=False)  # remove duplicate other track for final union

            # Merge other activities into selfclone: one-to-one mapping
            for (i,j) in merged.items():  # i=id of other, j=id of self
                oc.activitymap(lambda a: a.replaceid(i, j) if a.hastrack(i) else a)  # update track IDs referenced in activities for merged tracks
            for (i,ai) in sc.activities().items():
                for (j,aj) in oc.activities().items():
                    if ai.category() == aj.category() and set(ai.trackids()) == set(aj.trackids()) and ai.temporal_iou(aj) &gt; temporal_iou_threshold:
                        oc.activityfilter(lambda a: a.id() != j)  # remove duplicate activity from final union
            oc.activityfilter(lambda a: len(a.tracks())&gt;0)  # remove empty activities not merged

            # Union
            sc.tracks().update(oc.tracks())
            sc.activities().update(oc.activities())

        # Final union of unique tracks/activities
        if track:
            self.tracks(sc.tracklist())  # union of tracks only
        if activity:
            self.activities(sc.activitylist())  # union of activities only: may reference tracks not in self of track=False
        return self        


    def annotate(self, outfile=None, fontsize=10, captionoffset=(0,0), textfacecolor=&#39;white&#39;, textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={&#39;Person&#39;:&#39;green&#39;, &#39;Vehicle&#39;:&#39;blue&#39;, &#39;Object&#39;:&#39;red&#39;}, categories=None, nocaption=False, nocaption_withstring=[], mutator=None, timestamp=None, timestampcolor=&#39;black&#39;, timestampfacecolor=&#39;white&#39;, verbose=False):
        &#34;&#34;&#34;Generate a video visualization of all annotated objects and activities in the video.
        
        The annotation video will be at the resolution and framerate of the underlying video, and pixels in this video will now contain the overlay.
        This function does not play the video, it only generates an annotation video frames.  Use show() which is equivalent to annotate().saveas().play()
        
        Args:
            outfile: [str] An optional file to stream the anntation to without storing the annotated video in memory
            fontsize: [int] The fontsize of bounding box captions, used by matplotlib
            captionoffset: (tuple) The (x,y) offset relative to the bounding box to place the caption for each box.
            textfacecolor: [str] The color of the text in the bounding box caption.  Must be in `vipy.gui.using_matplotlib.colorlist`.
            textfacealpha: [float] The transparency of the text in the bounding box caption.  Must be in [0,1], where 0=transparent and 1=opaque.
            shortlabel: [bool] If true, display the shortlabel for each object in the scene, otherwise show the full category
            boxalpha: [float]  The transparency of the box face behind the text.  Must be in [0,1], where 0=transparent and 1=opaque.
            d_category2color: [dict]  A dictionary mapping categories of objects in the scene to their box colors.  Named colors must be in `vipy.gui.using_matplotlib.colorlist`. 
            categories: [list]  Only show these categories, or show them all if None
            nocaption_withstring: [list]:  Do not show captions for those detection categories (or shortlabels) containing any of the strings in the provided list
            nocaption: [bool] If true, do not show any captions, just boxes
            mutator: [lambda] A lambda function that will mutate an image to allow for complex visualizations.  This should be a mutator like `vipy.image.mutator_show_trackid`.
            timestamp: [bool] If true, show a semitransparent timestamp (when the annotation occurs, not when the video was collected) with frame number in the upper left corner of the video
            timestampcolor: [str] The color of the timstamp text.  Named colors must be in `vipy.gui.using_matplotlib.colorlist`.
            timestampfacecolor: [str]  The color of the timestamp background.  Named colors must be in `vipy.gui.using_matplotlib.colorlist`.  
            verbose: [bool] Show more helpful messages if true

        Returns:
            A `vipy.video.Video` with annotations in the pixels.  If outfile is provided, then the returned video will be flushed.  

        .. note::  In general, this function should not be run on very long videos without the outfile kwarg, as it requires loading the video framewise into memory.  
        &#34;&#34;&#34;
        assert outfile is None or vipy.util.isvideofile(outfile), &#34;Invalid filename extension for annotated video&#34;
        
        if verbose:
            print(&#39;[vipy.video.annotate]: Annotating video ...&#39;)  
            
        f_mutator = mutator if mutator is not None else vipy.image.mutator_show_jointlabel()
        f_timestamp = (lambda k: &#39;%s %d&#39; % (vipy.util.clockstamp(), k)) if timestamp is True else timestamp

        if outfile is None:        
            assert self.load().isloaded(), &#34;Load() failed&#34;
            imgs = [f_mutator(self[k].clone(), k).savefig(fontsize=fontsize,
                                                  captionoffset=captionoffset,
                                                  textfacecolor=textfacecolor,
                                                  textfacealpha=textfacealpha,
                                                  shortlabel=shortlabel,
                                                  boxalpha=boxalpha,
                                                  d_category2color=d_category2color,
                                                  categories=categories,
                                                  nocaption=nocaption,
                                                  timestampcolor=timestampcolor,
                                                  timestampfacecolor=timestampfacecolor,
                                                  timestamp=f_timestamp(k) if timestamp is not None else None,
                                                  figure=1 if k&lt;(len(self)-1) else None,  # cleanup on last frame
                                                  nocaption_withstring=nocaption_withstring).numpy() for k in range(0, len(self))]
            
            # Replace pixels with annotated pixels and downcast object to vipy.video.Video (since there are no more objects to show)
            return vipy.video.Video(array=np.stack([np.array(PIL.Image.fromarray(img).convert(&#39;RGB&#39;)) for img in imgs], axis=0), framerate=self.framerate(), attributes=self.attributes)  # slow for large videos
        else:
            # Stream to output video without loading all frames into memory
            n = self.duration_in_frames_of_videofile() if not self.isloaded() else len(self)
            vo = vipy.video.Video(filename=outfile, framerate=self.framerate())
            with vo.stream(overwrite=True) as so:
                for (k,im) in enumerate(self.stream()):
                    so.write(f_mutator(im.clone(), k).savefig(fontsize=fontsize,
                                                      captionoffset=captionoffset,
                                                      textfacecolor=textfacecolor,
                                                      textfacealpha=textfacealpha,
                                                      shortlabel=shortlabel,
                                                      boxalpha=boxalpha,
                                                      d_category2color=d_category2color,
                                                      categories=categories,
                                                      nocaption=nocaption,
                                                      timestampcolor=timestampcolor,
                                                      timestampfacecolor=timestampfacecolor,
                                                      timestamp=f_timestamp(k) if timestamp is not None else None,
                                                      figure=1 if k&lt;(n-1) else None,  # cleanup on last frame
                                                      nocaption_withstring=nocaption_withstring).rgb())
            return vo


    def _show(self, outfile=None, verbose=True, fontsize=10, captionoffset=(0,0), textfacecolor=&#39;white&#39;, textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={&#39;Person&#39;:&#39;green&#39;, &#39;Vehicle&#39;:&#39;blue&#39;, &#39;Object&#39;:&#39;red&#39;}, categories=None, nocaption=False, nocaption_withstring=[], notebook=False, timestamp=None, timestampcolor=&#39;black&#39;, timestampfacecolor=&#39;white&#39;):
        &#34;&#34;&#34;Generate an annotation video saved to outfile (or tempfile if outfile=None) and show it using ffplay when it is done exporting.  Do not modify the original video buffer.  Returns a clone of the video with the shown annotation.&#34;&#34;&#34;
        return self.clone().annotate(verbose=verbose, 
                                     fontsize=fontsize,
                                     captionoffset=captionoffset,
                                     textfacecolor=textfacecolor,
                                     textfacealpha=textfacealpha,
                                     shortlabel=shortlabel,
                                     boxalpha=boxalpha,
                                     d_category2color=d_category2color,
                                     categories=categories,
                                     nocaption=nocaption,
                                     timestampcolor=timestampcolor,
                                     timestampfacecolor=timestampfacecolor,
                                     timestamp=timestamp,
                                     nocaption_withstring=nocaption_withstring).saveas(outfile).play(notebook=notebook)
    

    def show(self, outfile=None, verbose=True, fontsize=10, captionoffset=(0,0), textfacecolor=&#39;white&#39;, textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={&#39;Person&#39;:&#39;green&#39;, &#39;Vehicle&#39;:&#39;blue&#39;, &#39;Object&#39;:&#39;red&#39;}, categories=None, nocaption=False, nocaption_withstring=[], figure=1, fps=None, timestamp=None, timestampcolor=&#39;black&#39;, timestampfacecolor=&#39;white&#39;, mutator=None):
        &#34;&#34;&#34;Faster show using interative image show for annotated videos.  This can visualize videos before video rendering is complete, but it cannot guarantee frame rates. Large videos with complex scenes will slow this down and will render at lower frame rates.&#34;&#34;&#34;
        fps = min(fps, self.framerate()) if fps is not None else self.framerate()
        assert fps &gt; 0, &#34;Invalid display framerate&#34;
        f_timestamp = (lambda k: &#39;%s %d&#39; % (vipy.util.clockstamp(), k)) if timestamp is True else timestamp
        f_mutator = mutator if mutator is not None else vipy.image.mutator_show_jointlabel()        
        if not self.isdownloaded() and self.hasurl():
            self.download()
        with Stopwatch() as sw:            
            for (k,im) in enumerate(self.load() if self.isloaded() else self.stream()):
                time.sleep(max(0, (1.0/self.framerate())*int(np.ceil((self.framerate()/fps)))))
                f_mutator(im,k).show(categories=categories,
                                     figure=figure,
                                     nocaption=nocaption,
                                     nocaption_withstring=nocaption_withstring,
                                     fontsize=fontsize,
                                     boxalpha=boxalpha,
                                     d_category2color=d_category2color,
                                     captionoffset=captionoffset,
                                     textfacecolor=textfacecolor,
                                     textfacealpha=textfacealpha,
                                     timestampcolor=timestampcolor,
                                     timestampfacecolor=timestampfacecolor,
                                     timestamp=f_timestamp(k) if timestamp is not None else None,
                                     shortlabel=shortlabel)
                
                if vipy.globals._user_hit_escape():
                    break
        vipy.show.close(figure)
        return self

    def thumbnail(self, outfile=None, frame=0, fontsize=10, nocaption=False, boxalpha=0.25, dpi=200, textfacecolor=&#39;white&#39;, textfacealpha=1.0):
        &#34;&#34;&#34;Return annotated frame=k of video, save annotation visualization to provided outfile if provided, otherwise return vipy.image.Scene&#34;&#34;&#34;
        im = self.frame(frame, img=self.preview(framenum=frame).array())
        return im.savefig(outfile=outfile, fontsize=fontsize, nocaption=nocaption, boxalpha=boxalpha, dpi=dpi, textfacecolor=textfacecolor, textfacealpha=textfacealpha) if outfile is not None else im
    
    def stabilize(self, padheightfrac=0.125, padwidthfrac=0.25, padheightpx=None, padwidthpx=None, gpu=None, outfile=None):
        &#34;&#34;&#34;Background stablization using flow based stabilization masking foreground region.  
        
        - This will output a video with all frames aligned to the first frame, such that the background is static.
        - This uses the flow based approach described in `vipy.flow.Flow.stabilize`

        Args:
        
            padheightfrac: [float] The height padding (relative to video height) to be applied to output video to allow for vertical stabilization
            padwidthfrac: [float]  The width padding (relative to video width) to be applied to output video to allow for horizontal stabilization
            padheightpx: [int]  The height padding to be applied to output video to allow for vertical stabilization.  Overrides padheight.
            padwidthpx: [int]  The width padding to be applied to output video to allow for horizontal stabilization.  Overrides padwidth.
            gpu: [int] The GPU index to use, if opencv has been compiled with GPU support (this is rare)
            outfile: [str]  The output filename to store the stabilized video

        Returns:
        
            A clone of this video with background pixels stabilized to the first frame.  

        .. note::
        
            - If the camera pans outside the image rectangle, increase the padheight or padwidth to make sure that the actor stays inside the stabilized image rectangle
            - If there are moving actors in the scene, include bounding boxes for each and these boxes are ignored as keeyouts in the flow stabilization

        &#34;&#34;&#34;
        from vipy.flow import Flow  # requires opencv
        return Flow(flowdim=256, gpu=gpu).stabilize(self.clone(), residual=True, strict=True, padheightfrac=padheightfrac, padwidthfrac=padwidthfrac, padheightpx=padheightpx, padwidthpx=padwidthpx, outfile=outfile)
    
    def pixelmask(self, pixelsize=8):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with pixelation (e.g. bigger pixels, like privacy glass)&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy          
            im.pixelmask(pixelsize)  # shared numpy array
        return self

    def pixelize(self, radius=16):
        &#34;&#34;&#34;Alias for pixelmask()&#34;&#34;&#34;
        return self.pixelmask(pixelsize=radius)
    def pixelate(self, radius=16):
        &#34;&#34;&#34;Alias for pixelmask()&#34;&#34;&#34;
        return self.pixelmask(pixelsize=radius)
    
    def binarymask(self):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with white, zero in background&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy  
            im.binarymask()  # shared numpy array
        return self

    def asfloatmask(self, fg=1.0, bg=0.0):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with fg, and bg in background, return a copy&#34;&#34;&#34;
        assert self.isloaded()
        self.numpy()  # convert to writeable numpy array, triggers writeable copy        
        array = np.full( (len(self.load()), self.height(), self.width(), 1), dtype=np.float32, fill_value=bg)
        for (k,im) in enumerate(self):
            for bb in im.objects():
                if bb.hasintersection(im.imagebox()):
                    array[k, int(round(bb._ymin)):int(round(bb._ymax)), int(round(bb._xmin)):int(round(bb._xmax))] = fg   # does not need imclip
        return vipy.video.Video(array=array, framerate=self.framerate(), colorspace=&#39;float&#39;)
    
    def meanmask(self):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with mean color&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy                  
            im.meanmask()  # shared numpy array
        return self

    def fgmask(self):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with zero&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy                          
            im.fgmask()  # shared numpy array
        return self

    def zeromask(self):
        &#34;&#34;&#34;Alias for fgmask&#34;&#34;&#34;
        return self.fgmask()
    
    def blurmask(self, radius=7):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with gaussian blurred foreground&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy                                  
            im.blurmask(radius)  # shared numpy array
        return self

    def downcast(self):
        &#34;&#34;&#34;Cast the object to a `vipy.video.Video` class&#34;&#34;&#34;
        self.__class__ = vipy.video.Video
        return self

    def merge_tracks(self, dilate_height=2.0, dilate_width=2.0, framedist=5):
        &#34;&#34;&#34;Merge tracks if a track endpoint dilated by a fraction overlaps exactly one track startpoint, and the endpoint and startpoint are close enough together temporally.
        
        .. note::
        - This is useful for continuing tracking when the detection framerate was too low and the assignment falls outside the measurement gate.
        - This will not work for complex scenes, as it assumes that there is exactly one possible continuation for a track.  
        
        &#34;&#34;&#34;
        merged = set([])
        for ti in sorted(self.tracklist(), key=lambda t: t.startframe()):
            for tj in sorted(self.tracklist(), key=lambda t: t.startframe()):
                if (tj.id() not in merged) and (ti.id() != tj.id()) and (tj.startframe() &gt;= ti.endframe()) and ((tj.startframe()-ti.endframe()) &lt;= framedist) and (ti.category() == tj.category()):
                    di = ti[ti.endframe()].dilate_height(dilate_height).dilate_width(dilate_width)
                    dj = tj[tj.startframe()]
                    if di.iou(dj) &gt; 0 and not any([di.iou(tk[tj.startframe()]) &gt; 0 for tk in self.tracklist() if (tk.id() not in [ti.id(), tj.id()]) and tk.during(tj.startframe())]):
                        self.tracks()[ti.id()] = ti.union(tj)  # Merge tracks that are within gating distance
                        self.delete(tj.id())  # remove merged track
                        merged.add(tj.id())
                        break
        return self

    def assign(self, frame, dets, minconf=0.2, maxhistory=5, activityiou=0.5, trackcover=0.2, trackconfsamples=4, gate=0, activitymerge=True, activitynms=False):
        &#34;&#34;&#34;Assign a list of `vipy.object.Detection` object detections and `vipy.activity.Activity` activity detections at frame k to scene tracks and activities by greedy assignment. In-place update.
        
        Approach:

            - This approach is equivalent to greedy, constant velocity SORT tracking (https://arxiv.org/abs/1602.00763) 
            - Individual detections are assigned to tracks using a greedy velocity only track propagation, sorted by `vipy.geometry.BoundingBox.maxcover` and detection confidence within a spatial tracking gate 
            - New tracks are created if the detection is unassigned and above a minimum confidence 
            - Updated tracks resulting from assignment are stored in `vipy.video.tracks` 

        Args:
        
            frame: [int] The frame index to assign the detections into the scene
            dets: [list] A list of `vipy.object.Detection` or `vipy.activity.Activity` objects as returned from a detector 
            miniou: [float] the minimum temporal IOU for activity assignment
            minconf: [float] the minimum confidence for a detection to be considered as a new track
            maxhistory: [int]  the maximum propagation length of a track with no measurements, the frame history used for velocity estimates  
            trackconfsamples: [int]  the number of uniformly spaced samples along a track to compute a mean track confidence
            gate: [int] the gating distance in pixels used for assignment of fast moving detections.  Useful for low detection framerates if a detection does not overlap with the track.
            trackcover: [float] the minimum cover necessary for assignment of a detection to a track
            activitymerge: [bool] if true, then merge overlapping activity detections of the same track and category, otherwise each activity detection is added as a new detection
            activitynms: [bool] if true, then perform non-maximum suppression of activity detections of the same actor and category that overlap more than activityiou

        Returns:

            This video object with each det assigned to corresponding track or activity.

        &#34;&#34;&#34;
        assert dets is None or all([isinstance(d, vipy.object.Detection) or isinstance(d, vipy.activity.Activity) for d in tolist(dets)]), &#34;invalid input&#34;
        assert frame &gt;= 0 and minconf &gt;= 0 and minconf &lt;= 1.0 and maxhistory &gt; 0, &#34;invalid input&#34;
        
        if dets is None or len(tolist(dets)) == 0:
            return self
        dets = tolist(dets)

        if any([d.confidence() is None for d in dets]):
            warnings.warn(&#39;Removing %d detections with no confidence&#39; % len([d.confidence() is None for d in dets]))
            dets = [d for d in dets if d.confidence() is not None]
        objdets = [d for d in dets if isinstance(d, vipy.object.Detection)]
        activitydets = [d for d in dets if isinstance(d, vipy.activity.Activity)]        

        # Object detection to track assignment
        if len(objdets) &gt; 0:
            # Track propagation:  Constant velocity motion model for active tracks 
            t_ref = [(t, t.linear_extrapolation(frame, dt=maxhistory, shape=False)) for (k,t) in self.tracks().items() if ((frame - t.endframe()) &lt;= maxhistory)]
            trackarea = [ti.area() for (t,ti) in t_ref]
            detarea = [d.area() for d in objdets]
            
            # Track assignment:
            #   - Each track is assigned at most one detection
            #   - Each detection is assigned to at most one track.  
            #   - Assignment is the highest confidence maximum overlapping detection by cover within tracking gate
            trackconf = {t.id():t.confidence(samples=trackconfsamples) for (t, ti) in t_ref}
            assignments = [(t, d.confidence(), d.iou(ti, area=detarea[j], otherarea=trackarea[i]), d.shapeiou(ti, area=detarea[j], otherarea=trackarea[i]), d.maxcover(ti, area=detarea[j], otherarea=trackarea[i]), d)
                           for (i, (t, ti)) in enumerate(t_ref)
                           for (j,d) in enumerate(objdets)
                           if (t.category() == d.category() and
                               (((ti._xmax if ti._xmax &lt; d._xmax else d._xmax) - (ti._xmin if ti._xmin &gt; d._xmin else d._xmin)) &gt; 0 and
                                ((ti._ymax if ti._ymax &lt; d._ymax else d._ymax) - (ti._ymin if ti._ymin &gt; d._ymin else d._ymin)) &gt; 0))]
            
            assigned = set([])        
            posconf = min([d.confidence() for d in objdets]) if len(objdets)&gt;0 else 0
            assignments.sort(key=lambda x: (x[1]+posconf)*(x[2]+x[3]+x[4])+trackconf[x[0].id()], reverse=True)  # in-place
            for (t, conf, iou, shapeiou, cover, d) in assignments:
                if cover &gt; (trackcover if len(t)&gt;1 else 0):  # the highest confidence detection within the assignment gate (or any overlap if not yet enough history for velocity estimate) 
                    if (t.id() not in assigned and d.id() not in assigned):  # not assigned yet, assign it!
                        self.track(t.id()).update(frame, d.clone())  # track assignment! (clone required)
                        assigned.add(t.id())  # cannot assign again to this track
                        assigned.add(d.id())  # mark detection as assigned
                
            # Track spawn from unassigned and unexplained detections 
            for (j,d) in enumerate(objdets):                
                if (d.id() not in assigned):
                    if (d.confidence() &gt;= minconf and not any([t.linear_extrapolation(frame, dt=maxhistory, shape=False).maxcover(d, otherarea=detarea[j]) &gt;= 0.7 for (i,(t,ti)) in enumerate(t_ref) if t.category() == d.category()])):
                        gated = [(t, t.linear_extrapolation(frame, dt=maxhistory, shape=False)) for (t,ti) in t_ref if (t.id() not in assigned and t.category() == d.category())] if gate&gt;0 else []
                        gated = sorted([(t, ti) for (t, ti) in gated if ti.hasintersection(d, gate=gate)], key=lambda x: d.sqdist(x[1]))
                        if len(gated) &gt; 0:
                            self.track(gated[0][0].id()).update(frame, d.clone())  # track assignment! (clone required)
                            assigned.add(gated[0][0].id())
                            assigned.add(d.id())
                        else:
                            assigned.add(self.add(vipy.object.Track(keyframes=[frame], boxes=[d.clone()], category=d.category(), framerate=self.framerate()), rangecheck=False))  # clone required
                            assigned.add(d.id())

        # Activity assignment
        if len(activitydets) &gt; 0:
            assert all([d.actorid() in self.tracks() for d in activitydets]), &#34;Invalid activity&#34;
            assigned = set([])
            if activitymerge:
                minframe = min([a._startframe for a in activitydets]) 
                activities = [a for a in self.activities().values() if a._endframe &gt;= minframe]
                for d in activitydets:
                    for a in activities:
                        if (a._label == d._label) and (a._actorid == d._actorid) and a.hasoverlap(d, activityiou): 
                            a.union(d)  # activity assignment 
                            assigned.add(d._id)
                            break  # assigned, early exit
                        
            if activitynms:
                minframe = min([a._startframe for a in activitydets]) 
                activities = sorted([a for a in self.activities().values() if a._endframe &gt;= minframe], key=lambda a: a.confidence(), reverse=True)
                for d in sorted(activitydets, key=lambda x: x.confidence(), reverse=True):
                    for a in activities:
                        if (a._label == d._label) and (a._actorid == d._actorid) and a.hasoverlap(d, activityiou):
                            assigned.add(a._id if d.confidence()&gt;a.confidence() else d._id)  # suppressed
                for id in assigned:
                    if id in self._activities:
                        del self._activities[id]  # suppression, faster than self.activityfilter(lambda a: a.id() in assigned)
                                    
            # Activity construction from unassigned detections
            for d in activitydets:
                if d._id not in assigned:
                    self.add(d.clone())  

        return self

    
    
def RandomVideo(rows=None, cols=None, frames=None):
    &#34;&#34;&#34;Return a random loaded vipy.video.video.
    
    Useful for unit testing, minimum size (32x32x32) for ffmpeg
    &#34;&#34;&#34;
    rows = np.random.randint(256, 1024) if rows is None else rows
    cols = np.random.randint(256, 1024) if cols is None else cols
    frames = np.random.randint(32, 256) if frames is None else frames
    assert rows&gt;32 and cols&gt;32 and frames&gt;=32    
    return Video(array=np.uint8(255 * np.random.rand(frames, rows, cols, 3)), colorspace=&#39;rgb&#39;)


def RandomScene(rows=None, cols=None, frames=None):
    &#34;&#34;&#34;Return a random loaded vipy.video.Scene.
    
    Useful for unit testing.
    &#34;&#34;&#34;
    v = RandomVideo(rows, cols, frames)
    (rows, cols) = v.shape()
    tracks = [vipy.object.Track(label=&#39;track%d&#39; % k, shortlabel=&#39;t%d&#39; % k,
                                keyframes=[0, np.random.randint(50,100), 150],
                                framerate=30, 
                                boxes=[vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2)),
                                       vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2)),
                                       vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2))]) for k in range(0,32)]

    activities = [vipy.activity.Activity(label=&#39;activity%d&#39; % k, shortlabel=&#39;a%d&#39; % k, tracks=[tracks[j].id() for j in [np.random.randint(32)]], startframe=np.random.randint(50,99), endframe=np.random.randint(100,150), framerate=30) for k in range(0,32)]   
    return Scene(array=v.array(), colorspace=&#39;rgb&#39;, category=&#39;scene&#39;, tracks=tracks, activities=activities, framerate=30)


def RandomSceneActivity(rows=None, cols=None, frames=256):
    &#34;&#34;&#34;Return a random loaded vipy.video.Scene.

    Useful for unit testing.
    &#34;&#34;&#34;    
    v = RandomVideo(rows, cols, frames)
    (rows, cols) = v.shape()
    tracks = [vipy.object.Track(label=[&#39;Person&#39;,&#39;Vehicle&#39;,&#39;Object&#39;][k], shortlabel=&#39;track%d&#39; % k, boundary=&#39;strict&#39;, 
                                keyframes=[0, np.random.randint(50,100), np.random.randint(50,150)],
                                framerate=30,
                                boxes=[vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2)),
                                       vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2)),
                                       vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2))]) for k in range(0,3)]

    activities = [vipy.activity.Activity(label=&#39;Person Carrying&#39;, shortlabel=&#39;Carry&#39;, tracks=[tracks[0].id(), tracks[1].id()], startframe=np.random.randint(20,50), endframe=np.random.randint(70,100), framerate=30)]   
    ims = Scene(array=v.array(), colorspace=&#39;rgb&#39;, category=&#39;scene&#39;, tracks=tracks, activities=activities, framerate=30)

    return ims
    
def EmptyScene():
    &#34;&#34;&#34;Return an empty scene&#34;&#34;&#34; 
    return vipy.video.Scene(array=np.zeros((1,1,1,3), dtype=np.uint8))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="vipy.video.EmptyScene"><code class="name flex">
<span>def <span class="ident">EmptyScene</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Return an empty scene</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L4199-L4201" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def EmptyScene():
    &#34;&#34;&#34;Return an empty scene&#34;&#34;&#34; 
    return vipy.video.Scene(array=np.zeros((1,1,1,3), dtype=np.uint8))</code></pre>
</details>
</dd>
<dt id="vipy.video.RandomScene"><code class="name flex">
<span>def <span class="ident">RandomScene</span></span>(<span>rows=None, cols=None, frames=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a random loaded vipy.video.Scene.</p>
<p>Useful for unit testing.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L4156-L4174" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def RandomScene(rows=None, cols=None, frames=None):
    &#34;&#34;&#34;Return a random loaded vipy.video.Scene.
    
    Useful for unit testing.
    &#34;&#34;&#34;
    v = RandomVideo(rows, cols, frames)
    (rows, cols) = v.shape()
    tracks = [vipy.object.Track(label=&#39;track%d&#39; % k, shortlabel=&#39;t%d&#39; % k,
                                keyframes=[0, np.random.randint(50,100), 150],
                                framerate=30, 
                                boxes=[vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2)),
                                       vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2)),
                                       vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2))]) for k in range(0,32)]

    activities = [vipy.activity.Activity(label=&#39;activity%d&#39; % k, shortlabel=&#39;a%d&#39; % k, tracks=[tracks[j].id() for j in [np.random.randint(32)]], startframe=np.random.randint(50,99), endframe=np.random.randint(100,150), framerate=30) for k in range(0,32)]   
    return Scene(array=v.array(), colorspace=&#39;rgb&#39;, category=&#39;scene&#39;, tracks=tracks, activities=activities, framerate=30)</code></pre>
</details>
</dd>
<dt id="vipy.video.RandomSceneActivity"><code class="name flex">
<span>def <span class="ident">RandomSceneActivity</span></span>(<span>rows=None, cols=None, frames=256)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a random loaded vipy.video.Scene.</p>
<p>Useful for unit testing.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L4177-L4197" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def RandomSceneActivity(rows=None, cols=None, frames=256):
    &#34;&#34;&#34;Return a random loaded vipy.video.Scene.

    Useful for unit testing.
    &#34;&#34;&#34;    
    v = RandomVideo(rows, cols, frames)
    (rows, cols) = v.shape()
    tracks = [vipy.object.Track(label=[&#39;Person&#39;,&#39;Vehicle&#39;,&#39;Object&#39;][k], shortlabel=&#39;track%d&#39; % k, boundary=&#39;strict&#39;, 
                                keyframes=[0, np.random.randint(50,100), np.random.randint(50,150)],
                                framerate=30,
                                boxes=[vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2)),
                                       vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2)),
                                       vipy.object.Detection(xmin=np.random.randint(0,cols - 16), ymin=np.random.randint(0,rows - 16),
                                                                 width=np.random.randint(16,cols//2), height=np.random.randint(16,rows//2))]) for k in range(0,3)]

    activities = [vipy.activity.Activity(label=&#39;Person Carrying&#39;, shortlabel=&#39;Carry&#39;, tracks=[tracks[0].id(), tracks[1].id()], startframe=np.random.randint(20,50), endframe=np.random.randint(70,100), framerate=30)]   
    ims = Scene(array=v.array(), colorspace=&#39;rgb&#39;, category=&#39;scene&#39;, tracks=tracks, activities=activities, framerate=30)

    return ims</code></pre>
</details>
</dd>
<dt id="vipy.video.RandomVideo"><code class="name flex">
<span>def <span class="ident">RandomVideo</span></span>(<span>rows=None, cols=None, frames=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a random loaded vipy.video.video.</p>
<p>Useful for unit testing, minimum size (32x32x32) for ffmpeg</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L4144-L4153" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def RandomVideo(rows=None, cols=None, frames=None):
    &#34;&#34;&#34;Return a random loaded vipy.video.video.
    
    Useful for unit testing, minimum size (32x32x32) for ffmpeg
    &#34;&#34;&#34;
    rows = np.random.randint(256, 1024) if rows is None else rows
    cols = np.random.randint(256, 1024) if cols is None else cols
    frames = np.random.randint(32, 256) if frames is None else frames
    assert rows&gt;32 and cols&gt;32 and frames&gt;=32    
    return Video(array=np.uint8(255 * np.random.rand(frames, rows, cols, 3)), colorspace=&#39;rgb&#39;)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="vipy.video.Scene"><code class="flex name class">
<span>class <span class="ident">Scene</span></span>
<span>(</span><span>filename=None, url=None, framerate=30.0, array=None, colorspace=None, category=None, tracks=None, activities=None, attributes=None, startframe=None, endframe=None, startsec=None, endsec=None)</span>
</code></dt>
<dd>
<div class="desc"><p>vipy.video.Scene class</p>
<p>The vipy.video.Scene class provides a fluent, lazy interface for representing, transforming and visualizing annotated videos.
The following constructors are supported:</p>
<pre><code class="language-python">vid = vipy.video.Scene(filename='/path/to/video.ext')
</code></pre>
<p>Valid video extensions are those that are supported by ffmpeg ['.avi','.mp4','.mov','.wmv','.mpg', 'mkv', 'webm'].</p>
<pre><code class="language-python">vid = vipy.video.Scene(url='https://www.youtube.com/watch?v=MrIN959JuV8')
vid = vipy.video.Scene(url='http://path/to/video.ext', filename='/path/to/video.ext')
</code></pre>
<p>Youtube URLs are downloaded to a temporary filename, retrievable as vid.download().filename().
If the environment
variable 'VIPY_CACHE' is defined, then videos are saved to this directory rather than the system temporary directory.
If a filename is provided to the constructor, then that filename will be used instead of a temp or cached filename.
URLs can be defined as an absolute URL to a video file, or to a site supported by 'youtube-dl'
[<a href="https://ytdl-org.github.io/youtube-dl/supportedsites.html]">https://ytdl-org.github.io/youtube-dl/supportedsites.html]</a></p>
<pre><code class="language-python">vid = vipy.video.Scene(array=frames, colorspace='rgb')
</code></pre>
<p>The input 'frames' is an NxHxWx3 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video
Note that the video transformations (clip, resize, rescale, rotate) are only available prior to load(), and the array() is assumed immutable after load().</p>
<pre><code class="language-python">vid = vipy.video.Scene(array=greyframes, colorspace='lum')
</code></pre>
<p>The input 'greyframes' is an NxHxWx1 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video
This corresponds to the luminance of an RGB colorspace</p>
<pre><code class="language-python">vid = vipy.video.Scene(array=greyframes, colorspace='lum', tracks=tracks, activities=activities)
</code></pre>
<ul>
<li>tracks = [vipy.object.Track(), &hellip;]</li>
<li>activities = [vipy.object.Activity(), &hellip;]</li>
</ul>
<p>The inputs are lists of tracks and/or activities.
An object is a spatial bounding box with a category label.
A track is a spatiotemporal bounding
box with a category label, such that the box contains the same instance of an object.
An activity is one or more tracks with a start and end frame for an
activity performed by the object instances.
Track and activity timing must be relative to the start frame of the Scene() constructor.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2465-L4140" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Scene(VideoCategory):
    &#34;&#34;&#34; vipy.video.Scene class

    The vipy.video.Scene class provides a fluent, lazy interface for representing, transforming and visualizing annotated videos.
    The following constructors are supported:

    ```python
    vid = vipy.video.Scene(filename=&#39;/path/to/video.ext&#39;)
    ```

    Valid video extensions are those that are supported by ffmpeg [&#39;.avi&#39;,&#39;.mp4&#39;,&#39;.mov&#39;,&#39;.wmv&#39;,&#39;.mpg&#39;, &#39;mkv&#39;, &#39;webm&#39;].

    ```python
    vid = vipy.video.Scene(url=&#39;https://www.youtube.com/watch?v=MrIN959JuV8&#39;)
    vid = vipy.video.Scene(url=&#39;http://path/to/video.ext&#39;, filename=&#39;/path/to/video.ext&#39;)
    ```

    Youtube URLs are downloaded to a temporary filename, retrievable as vid.download().filename().  If the environment
    variable &#39;VIPY_CACHE&#39; is defined, then videos are saved to this directory rather than the system temporary directory.
    If a filename is provided to the constructor, then that filename will be used instead of a temp or cached filename.
    URLs can be defined as an absolute URL to a video file, or to a site supported by &#39;youtube-dl&#39; 
    [https://ytdl-org.github.io/youtube-dl/supportedsites.html]

    ```python
    vid = vipy.video.Scene(array=frames, colorspace=&#39;rgb&#39;)
    ```
    
    The input &#39;frames&#39; is an NxHxWx3 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video
    Note that the video transformations (clip, resize, rescale, rotate) are only available prior to load(), and the array() is assumed immutable after load().

    ```python
    vid = vipy.video.Scene(array=greyframes, colorspace=&#39;lum&#39;)
    ```
    
    The input &#39;greyframes&#39; is an NxHxWx1 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video
    This corresponds to the luminance of an RGB colorspace

    ```python
    vid = vipy.video.Scene(array=greyframes, colorspace=&#39;lum&#39;, tracks=tracks, activities=activities)
    ```

    - tracks = [vipy.object.Track(), ...]
    - activities = [vipy.object.Activity(), ...]
 
    The inputs are lists of tracks and/or activities.  An object is a spatial bounding box with a category label.  A track is a spatiotemporal bounding 
    box with a category label, such that the box contains the same instance of an object.  An activity is one or more tracks with a start and end frame for an 
    activity performed by the object instances.  Track and activity timing must be relative to the start frame of the Scene() constructor.  

    &#34;&#34;&#34;
        
    def __init__(self, filename=None, url=None, framerate=30.0, array=None, colorspace=None, category=None, tracks=None, activities=None,
                 attributes=None, startframe=None, endframe=None, startsec=None, endsec=None):

        self._tracks = {}
        self._activities = {}        
        super().__init__(url=url, filename=filename, framerate=framerate, attributes=attributes, array=array, colorspace=colorspace,
                                    category=category, startframe=startframe, endframe=endframe, startsec=startsec, endsec=endsec)

        # Tracks must be defined relative to the clip specified by this constructor
        if tracks is not None:
            tracks = tracks if isinstance(tracks, list) or isinstance(tracks, tuple) else [tracks]  # canonicalize
            assert all([isinstance(t, vipy.object.Track) for t in tracks]), &#34;Invalid track input; tracks=[vipy.object.Track(), ...]&#34;
            self._tracks = {t.id():t for t in tracks}

        # Activities must be defined relative to the clip specified by this constructor            
        if activities is not None:
            activities = activities if isinstance(activities, list) or isinstance(activities, tuple) else [activities]  # canonicalize            
            assert all([isinstance(a, vipy.activity.Activity) for a in activities]), &#34;Invalid activity input; activities=[vipy.activity.Activity(), ...]&#34;
            self._activities = {a.id():a for a in activities}

        self._currentframe = None  # deprecated

    @classmethod
    def cast(cls, v, flush=False):
        &#34;&#34;&#34;Cast a conformal vipy object to this class.  This is useful for downcast and upcast conversion of video objects.&#34;&#34;&#34;
        assert isinstance(v, vipy.video.Video), &#34;Invalid input - must be derived from vipy.video.Video&#34;
        if v.__class__ != vipy.video.Scene:
            v.__class__ = vipy.video.Scene            
            v._tracks = {} if flush or not hasattr(v, &#39;_tracks&#39;) else v._tracks
            v._activities = {} if flush or not hasattr(v, &#39;_activities&#39;) else v._activities
            v._category = None if flush or not hasattr(v, &#39;_category&#39;) else v._category
        return v

    @classmethod
    def asjson(cls, s):
        &#34;&#34;&#34;Restore an object serialized with self.json().  Alas for `vipy.video.Scene.from_json`.
        
        Usage:

        ```python
        vs = vipy.video.Scene.asjson(v.json())
        ```

        &#34;&#34;&#34;
        return vipy.video.Scene.from_json(s)

    @classmethod
    def from_json(cls, s):
        &#34;&#34;&#34;Restore an object serialized with self.json()
        
        Usage:
        
        ```python
        vs = vipy.video.Scene.from_json(v.json())
        ```

        &#34;&#34;&#34;

        d = json.loads(s) if not isinstance(s, dict) else s                                
        v = super().from_json(s)

        # Packed attribute storage:
        #   - When loading a large number of vipy objects, the python garbage collector slows down signficantly due to reference cycle counting
        #   - Mutable objects and custom containers are tracked by the garbage collector and the more of them that are loaded the longer GC takes
        #   - To avoid this, load attributes as tuples of packed strings.  This is an immutable type that is not reference counted.  Check this with gc.is_tracked()
        #   - Then, unpack load the attributes on demand when accessing tracks() or activities().  Then, the nested containers are reference counted (even though they really should not since there are no cycles by construction)
        #   - This is useful when calling vipy.util.load(...) on archives that contain hundreds of thousands of objects
        #   - Do not access the private attributes self._tracks and self._attributes as they will be packed until needed
        #   - Should install ultrajson (pip install ujson) for super fast parsing
        v._tracks = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_tracks&#39;].values()])  # track ID key is embedded in object, legacy unpack of doubly JSON encoded strings (vipy-1.11.16)
        v._activities = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_activities&#39;].values()])  # track ID key is embedded in object, legacy unpack of doubly JSON encoded strings (vipy-1.11.16)
        return v
        
    def pack(self):
        &#34;&#34;&#34;Packing a scene returns the scene with the annotations JSON serialized.  
               
        - This is useful for fast garbage collection when there are many objects in memory
        - This is useful for distributed processing prior to serializing from a scheduler to a client
        - This is useful for lazy deserialization of complex attributes when loading many videos into memory
        - Unpacking is transparent to the end user and is performed on the fly when annotations are accessed.  There is no unpack() method.
        - See the notes in from_json() for why this helps with nested containers and reference cycle tracking with the python garbage collector        

        &#34;&#34;&#34;
        d = json.loads(self.json())
        self._tracks = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_tracks&#39;].values()]) # efficient garbage collection: store as a packed string to avoid reference cycle tracking, unpack on demand
        self._activities = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_activities&#39;].values()])  # efficient garbage collection: store as a packed string to avoid reference cycle tracking, unpack on demand 
        return self

    def __repr__(self):
        strlist = []
        if self.isloaded():
            strlist.append(&#34;height=%d, width=%d, frames=%d, color=%s&#34; % (self.height(), self.width(), len(self._array), self.colorspace()))
        if self.filename() is not None:
            strlist.append(&#39;filename=&#34;%s&#34;&#39; % (self.filename()))
        if self.hasurl():
            strlist.append(&#39;url=&#34;%s&#34;&#39; % self.url())
        if self._framerate is not None:
            strlist.append(&#39;fps=%1.1f&#39; % float(self._framerate))
        if not self.isloaded() and self._startframe is not None and self._endframe is not None:
            strlist.append(&#39;clip=(%d,%d)&#39; % (self._startframe, self._endframe))
        if not self.isloaded() and self._startframe is not None and self._endframe is None:
            strlist.append(&#39;clip=(%d,)&#39; % (self._startframe))
        if self.category() is not None:
            strlist.append(&#39;category=&#34;%s&#34;&#39; % self.category())
        if self.hastracks():
            strlist.append(&#39;tracks=%d&#39; % len(self._tracks))
        if self.hasactivities():
            strlist.append(&#39;activities=%d&#39; % len(self._activities))
        return str(&#39;&lt;vipy.video.scene: %s&gt;&#39; % (&#39;, &#39;.join(strlist)))


    def instanceid(self, newid=None):
        &#34;&#34;&#34;Return an annotation instance identifier for this video.  

        An instance ID is a unique identifier for a ground truth annotation within a video, either a track or an activity.  More than one instance ID may share the same video ID if they are from the same source videofile.  

        This is useful when calling `vipy.video.Scene.activityclip` or `vipy.video.Scene.activitysplit` to clip a video into segments such that each clip has a unique identifier, but all share the same underlying `vipy.video.Video.videoid`.
        This is useful when calling `vipy.video.Scene.trackclip` or `vipy.video.Scene.tracksplit` to clip a video into segments such that each clip has a unique identifier, but all share the same underlying `vipy.video.Video.videoid`.
        
        Returns:
            INSTANCEID: if &#39;instance_id&#39; key is in self.attribute
            VIDEOID_INSTANCEID: if &#39;_instance_id&#39; key is in self.attribute, as set by activityclip() or trackclip().  This is set using INSTANCE_ID=ACTIVITYID_ACTIVITYINDEX or INSTANCEID=TRACKID_TRACKINDEX, where the index is the temporal order of the annotation in the source video prior to clip().
            VIDEOID_ACTIVITYINDEX: if &#39;activityindex&#39; key is in self.attribute, as set by activityclip().  (fallback for legacy datasets).
            VIDEOID: otherwise 
        &#34;&#34;&#34;
        if newid is not None:
            self.setattribute(&#39;instance_id&#39;, newid)
            return self
        else:
            if &#39;instance_id&#39; in self.attributes:
                return self.attributes[&#39;instance_id&#39;]  # set at video creation time (e.g. pycollector)
            elif &#39;_instance_id&#39; in self.attributes:
                return self.attributes[&#39;_instance_id&#39;]  # set at activityclip() time for provenance from clips back to videos
            elif &#39;activityindex&#39; in self.attributes:
                return &#39;%s_%s&#39; % (self.videoid(), str(self.attributes[&#39;activityindex&#39;]))  # set at activityclip() time for provenance from clips back to videos (deprecated)
            else:
                return self.videoid()

    def frame(self, k=0, img=None, noimage=False):
        &#34;&#34;&#34;Return `vipy.image.Scene` object at frame k

        -The attributes of each of the `vipy.image.Scene.objects` in the scene contains helpful metadata for the provenance of the detection, including:  
            - &#39;trackid&#39; of the track this detection
            - &#39;activityid&#39; associated with this detection 
            - &#39;jointlabel&#39; of this detection, used for visualization
            - &#39;noun verb&#39; of this detection, used for visualization

        Args:
            k: [int &gt;=- 0] The frame index requested.  This is relative to the current frame rate of the video.
            img: [numpy, None]  An optional image to be used for this frame.  This is useful to construct frames efficiently for videos if the pixel buffer is already available from a stream rather than a preview.  
            noimage [bool]:  If True, then return only annotations at frame k with empty frame buffer (e.g. no image pixels in the returned image object)

        Return:
            A `vipy.image.Scene` object for frame k containing all objects in this frame and pixels if img != None or preview=True
        
        .. note::
            - Modifying this frame will not affect the source video
            - If multiple objects are associated with an activity and a primary actor is defined, then only the primary actor is displayed as &#34;Noun Verbing&#34;, objects are shown as &#34;Noun&#34; with the activityid in the attribute
            - If noun is associated with more than one activity, then this is shown as &#34;Noun Verbing1\nNoun Verbing2&#34;, with a newline separator

        &#34;&#34;&#34;
        assert isinstance(k, int) and k&gt;=0, &#34;Frame index must be non-negative integer&#34;
        assert img is not None or (self.isloaded() and k&lt;len(self)) or not self.isloaded(), &#34;Invalid frame index %d - Indexing video by frame must be integer within (0, %d)&#34; % (k, len(self)-1)

        img = img if (img is not None or noimage) else (self._array[k] if self.isloaded() else self.preview(k).array())
        dets = [t[k].clone(deep=True).setattribute(&#39;trackindex&#39;, j) for (j, t) in enumerate(self.tracklist()) if len(t)&gt;0 and (t.during(k) or t.boundary()==&#39;extend&#39;)]  # track interpolation (cloned) with boundary handling
        for d in dets:
            d.attributes[&#39;activityid&#39;] = []  # reset
            jointlabel = [(d.shortlabel(),&#39;&#39;)]  # [(Noun, Verbing1), (Noun, Verbing2), ...], initialized with empty verbs as [(Noun, &#34;&#34;), ... ]
            activityconf = [None]   # for display 

            for (aid, a) in self.activities().items():  # insertion order:  First activity is primary, next is secondary (not in confidence order) 
                if a.hastrack(d.attributes[&#39;trackid&#39;]) and a.during(k):
                    # Display assumptions:
                    # - Jointlabel is always displayed as &#34;Noun Verbing&#34; during activity (e.g. Person Carrying, Vehicle Turning) using noun=track shortlabel, verb=activity shortlabel
                    # - If noun is associated with more than one activity, then this is shown as &#34;Noun Verbing1\nNoun Verbing2&#34;, with a newline separator
                    # - If multiple objects are associated with an activity and a primary actor is defined, then only the primary actor is displayed as &#34;Noun Verbing&#34;, objects are shown as &#34;Noun&#34; with the activityid in the attributes
                    if (a.actorid() is None or (a.actorid() == d.attributes[&#39;trackid&#39;])) and not any([a.shortlabel() == v for (n,v) in jointlabel]):
                        jointlabel.append( (d.shortlabel(), a.shortlabel()) )  # only show each activity once (even if repeated)
                        activityconf.append(a.confidence())
                    d.attributes[&#39;activityid&#39;].append(a.id())  # for activity correspondence (if desired)

            # For display purposes
            # - See `vipy.image.mutator_show_trackindex_verbonly`
            # - Double prepended underscore attributes are private and cleaned using `vipy.image.Image.sanitize`
            d.attributes[&#39;__jointlabel&#39;] = &#39;\n&#39;.join([(&#39;%s %s&#39; % (n,v)).strip() for (n,v) in jointlabel[0 if len(jointlabel)==1 else 1:]])  # to be deprecated
            d.attributes[&#39;__noun verb&#39;] = jointlabel[0 if len(jointlabel)==1 else 1:]
            d.attributes[&#39;__activityconf&#39;] = activityconf[0 if len(jointlabel)==1 else 1:]
            d.attributes[&#39;__trackindex&#39;] = d.attributes[&#39;trackindex&#39;]  # trackindex to be replaced with __trackindex
            d.attributes[&#39;__trackid&#39;] = d.attributes[&#39;trackid&#39;]  # trackid to be replaced with __trackid
            d.attributes[&#39;__activityid&#39;] = d.attributes[&#39;activityid&#39;]  # activityid to be replaced with __activityid            
        dets.sort(key=lambda d: (d.confidence() if d.confidence() is not None else 0, d.shortlabel()))   # layering in video is ordered by decreasing track confidence and alphabetical shortlabel
        return vipy.image.Scene(array=img, colorspace=self.colorspace(), objects=dets, category=self.category())  
                
        
    def during(self, frameindex):
        try:
            self.__getitem__(frameindex)  # triggers load
            return True
        except:
            return False
            
    def labeled_frames(self):
        &#34;&#34;&#34;Iterate over frames, yielding tuples (activity+object labelset in scene, vipy.image.Scene())&#34;&#34;&#34;
        self.load()
        for k in range(0, len(self)):
            #self._currentframe = k    # used only for incremental add()
            yield (self.labels(k), self.__getitem__(k))
        #self._currentframe = None
        

    def framecomposite(self, n=2, dt=10, mindim=256):
        &#34;&#34;&#34;Generate a single composite image with minimum dimension mindim as the uniformly blended composite of n frames each separated by dt frames&#34;&#34;&#34;
        if not self.isloaded():
            self.mindim(mindim).load()
        imframes = [self.frame(k).maxmatte() for k in range(0, dt*n, dt)]
        img = np.uint8(np.sum([1/float(n)*im.array() for im in imframes], axis=0))
        return imframes[0].clone().array(img)

    def isdegenerate(self):
        &#34;&#34;&#34;Degenerate scene has empty or malformed tracks&#34;&#34;&#34;
        return len(self.tracklist()) == 0 or any([t.isempty() or t.isdegenerate() for t in self.tracklist()])
    
    def quicklook(self, n=9, dilate=1.5, mindim=256, fontsize=10, context=False, startframe=0, animate=False, dt=30):
        &#34;&#34;&#34;Generate a montage of n uniformly spaced annotated frames centered on the union of the labeled boxes in the current frame to show the activity ocurring in this scene at a glance
           Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame.  This quicklook is most useful when len(self.activities()==1)
           for generating a quicklook from an activityclip().
        
           Args:
               n: [int]:  Number of images in the quicklook
               dilate: [float]:  The dilation factor for the bounding box prior to crop for display
               mindim: [int]:  The minimum dimension of each of the elemnets in the montage
               fontsize: [int]:  The size of the font for the bounding box label
               context: [bool]:  If true, replace the first and last frame in the montage with the full frame annotation, to help show the scale of the scene
               animate: [bool]:  If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames
               dt: [int]:  The number of frames for animation
               startframe: [int]:  The initial frame index to start the n uniformly sampled frames for the quicklook
        &#34;&#34;&#34;
        if not self.isloaded():
            self.load()  
        if animate:
            return Video(frames=[self.quicklook(n=n, dilate=dilate, mindim=mindim, fontsize=fontsize, context=context, startframe=k, animate=False, dt=dt) for k in range(0, min(dt, len(self)))], framerate=self.framerate())
        f_mutator = vipy.image.mutator_show_jointlabel()
        framelist = [min(int(np.round(f))+startframe, len(self)-1) for f in np.linspace(0, len(self)-1, n)]
        isdegenerate = [self.frame(k).boundingbox() is None or self.frame(k).boundingbox().dilate(dilate).intersection(self.framebox(), strict=False).isdegenerate() for (j,k) in enumerate(framelist)]
        imframes = [self.frame(k).maxmatte()  # letterbox or pillarbox
                    if (isdegenerate[j] or (context is True and (j == 0 or j == (n-1)))) else
                    self.frame(k).padcrop(self.frame(k).boundingbox().dilate(dilate).imclipshape(self.width(), self.height()).maxsquare().int()).mindim(mindim, interp=&#39;nearest&#39;)
                    for (j,k) in enumerate(framelist)]
        imframes = [f_mutator(im) for im in imframes]  # show jointlabel from frame interpolation
        imframes = [im.savefig(fontsize=fontsize, figure=1).rgb() for im in imframes]  # temp storage in memory
        return vipy.visualize.montage(imframes, imgwidth=mindim, imgheight=mindim)
    
    def tracks(self, tracks=None, id=None):
        &#34;&#34;&#34;Return mutable dictionary of tracks,
        
           Args:
               tracks [dict]: If provided, replace track dictionary with provided track dictionary, and return self
               id [str]: If provided, return just the track associated with the provided track id
    
           Returns:
               This object if tracks!=None, otherwise the requested track (if id!=None) or trackdict (tracks=None)

        &#34;&#34;&#34;        
        if isinstance(self._tracks, tuple):
            self._tracks = {t.id():t for t in [vipy.object.Track.from_json(json.loads(s)) for s in self._tracks]}  # on-demand unpack (efficient garbage collection for large list of objects)
        if tracks is None and id is None:
            return self._tracks  # mutable dict
        elif id is not None:
            return self._tracks[id]
        elif isinstance(tracks, dict):
            assert all([isinstance(t, vipy.object.Track) and k == t.id() for (k,t) in tracks.items()]), &#34;Invalid input - Must be dictionary of vipy.object.Track&#34;
            self._tracks = tracks.copy()  # shallow copy
            return self
        else:
            assert all([isinstance(t, vipy.object.Track) for t in tolist(tracks)]), &#34;Invalid input - Must be vipy.object.Track or list of vipy.object.Track&#34;
            self._tracks = {t.id():t for t in tolist(tracks)}  # insertion order preserved (python &gt;=3.6)
            return self

    def track(self, id):
        return self.tracks(id=id)

    def trackindex(self, id):
        &#34;&#34;&#34;Return the index in the tracklist of the track with the provided track id&#34;&#34;&#34;
        assert id in self.tracks()
        return [t.id() for t in self.tracklist()].index(id)

    def trackidx(self, idx):
        &#34;&#34;&#34;Return the track at the specified index in the tracklist&#34;&#34;&#34;
        return self.tracklist()[idx]

    def activity(self, id=None):
        return self.activities(id=id) if id is not None else self.primary_activity()
        
    def next_activity(self, id):
        &#34;&#34;&#34;Return the next activity just after the given activityid&#34;&#34;&#34;
        assert id in self.activities()
        A = self.activitylist()
        k = [k for (k,a) in enumerate(A) if a.id() == id][0]
        return A[k+1] if k&lt;len(A)-1 else None

    def prev_activity(self, id):
        &#34;&#34;&#34;Return the previous activity just before the given activityid&#34;&#34;&#34;
        assert id in self.activities()
        A = self.activitylist()
        k = [k for (k,a) in enumerate(A) if a.id() == id][0]
        return A[k-1] if k&gt;=1 else None

    def tracklist(self):
        return list(self.tracks().values())  # triggers shallow copy

    def objects(self, casesensitive=True):
        &#34;&#34;&#34;The objects in a scene are the unique categories of tracks&#34;&#34;&#34;
        return sorted(list(set([t.category() if casesensitive else t.category().lower() for t in self.tracklist()])))
    
    def actorid(self, id=None, fluent=False):
        &#34;&#34;&#34;Return or set the actor ID for the video.

        - The actor ID is the track ID of the primary actor in the scene.  This is useful for assigning a role for activities that are performed by the actor.
        - The actor ID is the first track is in the tracklist       
        
        Args:
            id: [str] if not None, then use this track ID as the actor
            fluent: [bool] If true, always return self. This is useful for those cases where the actorid being set is None.
        
        Returns:
            [id=None, fluent=False] the actor ID
            [id is not None] The video with the actor ID set, only if the ID is found in the tracklist

        .. note:: Not to be confused with biometric subject id.  For videos collected with Visym Collector platform (https://visym.com/collector), the biometric subject ID can be retrieved via `vipy.video.Video.metadata` (e.g. self.metadata()[&#39;subject_ids&#39;]).
        &#34;&#34;&#34;
        if id is None:
            return next(iter(self.tracks().keys())) if not fluent else self  # Python &gt;=3.6
        elif id in self._tracks:
            # Reorder tracks so that id is first
            idlist = [id] + [ti for ti in self.tracks().keys() if ti != id]
            self._tracks = {k:self.track(k) for k in idlist}
        else:
            warnings.warn(&#39;trackid=%s not found in &#34;%s&#34;&#39; % (str(id), str(self)))
        return self

    def setactorid(self, id):
        &#34;&#34;&#34;Alias for `vipy.video.Scene.actorid`&#34;&#34;&#34;
        return self.actorid(id, fluent=True)

    def actor(self):
        &#34;&#34;&#34;Return the primary actor (first `vipy.object.Track`) in the video&#34;&#34;&#34;
        return next(iter(self.tracks().values())) if len(self._tracks)&gt;0 else None   # Python &gt;=3.6
        
    def primary_activity(self):
        &#34;&#34;&#34;Return the primary activity of the video.

        - The primary activity is the first activity in the activitylist.  
        - This is useful for activityclip() videos that are centered on a single activity
        
        Returns:
            `vipy.activity.Activity` that is first in the `vipy.video.Scene.activitylist`
        &#34;&#34;&#34;
        return next(iter(self.activities().values())) if len(self._activities)&gt;0 else None  # Python &gt;=3.6        

    def first_activity(self):
        &#34;&#34;&#34;Return the first activity of the video with the earliest start frame&#34;&#34;&#34;
        return sorted(self.activitylist(), key=lambda a: a.startframe())[0] if len(self._activities)&gt;0 else None

    def last_activity(self):
        &#34;&#34;&#34;Return the last activity of the video with the latest end frame&#34;&#34;&#34;
        return sorted(self.activitylist(), key=lambda a: a.endframe())[-1] if len(self._activities)&gt;0 else None
    
    def activities(self, activities=None, id=None):
        &#34;&#34;&#34;Return mutable dictionary of activities.  All temporal alignment is relative to the current clip().&#34;&#34;&#34;
        if isinstance(self._activities, tuple):
            self._activities = {a.id():a for a in [vipy.activity.Activity.from_json(json.loads(s)) for s in self._activities]}  # on-demand
        if activities is None and id is None:
            return self._activities  # mutable dict
        elif id is not None:
            return self._activities[id]
        elif isinstance(activities, dict):
            assert all([isinstance(a, vipy.activity.Activity) and k == a.id() for (k,a) in activities.items()]), &#34;Invalid input - Must be dictionary of vipy.activity.Activity&#34;
            self._activities = activities.copy()  # shallow copy
            return self
        else:
            assert all([isinstance(a, vipy.activity.Activity) for a in tolist(activities)]), &#34;Invalid input - Must be vipy.activity.Activity or list of vipy.activity.Activity&#34;
            self._activities = {a.id():a for a in tolist(activities)}   # insertion order preserved (python &gt;=3.6)
            return self

    def activityindex(self, k):
        &#34;&#34;&#34;Return the `vipy.activity.Activity` at the requested index order in the video&#34;&#34;&#34;
        alist = self.activitylist()
        assert k &gt;= 0 and k &lt; len(alist), &#34;Invalid index&#34;        
        return alist[k]

    def activitylist(self):
        &#34;&#34;&#34;Return a list of activities in the video, returned in insertion order.

        Returns:
            A list of `vipy.activity.Activity` insertion ordered into the original video

        .. note::  The order of the activitylist() will not match the order of activityclip(), which is sorted by activity startframe.  To match, use sorted(activitylist, key=lambda a: a.startframe())
        &#34;&#34;&#34;
        return list(self.activities().values())  # insertion ordered (python &gt;=3.6), triggers shallow copy
        
    def activityfilter(self, f):
        &#34;&#34;&#34;Apply boolean lambda function f to each activity and keep activity if function is true, remove activity if function is false
        
        Filter out all activities longer than 128 frames 

        ```python
        vid = vid.activityfilter(lambda a: len(a)&lt;128)
        ```

        Filter out activities with category in set

        ```python
        vid = vid.activityfilter(lambda a: a.category() in set([&#39;category1&#39;, &#39;category2&#39;]))
        ```
       
        Args:
            f: [lambda] a lambda function that takes an activity and returns a boolean

        Returns:
            This video with the activities f(a)==False removed.

        &#34;&#34;&#34;
        assert callable(f)
        self._activities = {k:a for (k,a) in self.activities().items() if f(a) == True}
        return self
        
    def trackfilter(self, f, activitytrack=True):
        &#34;&#34;&#34;Apply lambda function f to each object and keep if filter is True.  
        
        Args:
            activitytrack: [bool] If true, remove track assignment from activities also, may result in activities with no tracks
            f: [lambda]  The lambda function to apply to each track t, and if f(t) returns True, then keep the track
        
        Returns:
            self, with tracks removed in-place

        .. note:: Applying track filter with activitytrack=True may result in activities with no associated tracks.  You should follow up with self.activityfilter(lambda a: len(a.trackids()) &gt; 0).
        &#34;&#34;&#34;
        assert callable(f)
        self._tracks = {k:t for (k,t) in self.tracks().items() if f(t) == True}
        if activitytrack:
            self.activitymap(lambda a: a.trackfilter(lambda ti: ti in self._tracks))  # remove track association in activities
            #if any([len(a.tracks()) == 0 for a in self.activitylist()]):
            #    warnings.warn(&#39;trackfilter(..., activitytrack=True) removed tracks which returned at least one degenerate activity with no tracks&#39;)
        return self

    def trackmap(self, f, strict=True):
        &#34;&#34;&#34;Apply lambda function f to each activity

           -strict=True: enforce that lambda function must return non-degenerate Track() objects        
        &#34;&#34;&#34;
        assert callable(f)
        self._tracks = {k:f(t) for (k,t) in self.tracks().items()}
        assert all([isinstance(t, vipy.object.Track) and (strict is False or not t.isdegenerate()) for (tk,t) in self.tracks().items()]), &#34;Lambda function must return non-degenerate vipy.object.Track()&#34;
        return self
        
    def activitymap(self, f):
        &#34;&#34;&#34;Apply lambda function f to each activity&#34;&#34;&#34;
        assert callable(f)
        self._activities = {k:f(a) for (k,a) in self.activities().items()}
        assert all([isinstance(a, vipy.activity.Activity) for a in self.activitylist()]), &#34;Lambda function must return vipy.activity.Activity()&#34;
        return self

    def rekey(self, tracks=None, activities=None):
        &#34;&#34;&#34;Change the track and activity IDs to randomly assigned UUIDs.  Useful for cloning unique scenes.
        
        
        ```python
        v = vipy.video.RandomScene()
        v.rekey()  # randomly rekey all track and activity ID
        v.rekey(tracks={...})  # rekey tracks (oldkey -&gt; newkey) according to dictionary, randomly rekey activities
        v.rekey(tracks={...}, activities={})  #  rekey tracks according to dict, no change to activities
        ```

        Args:
            tracks [dict]: If not None, use this dictionary to remap oldkey-&gt;newkey for tracks.  If None, use random keys. If empty dict, no change (do not rekey tracks)
            activities [dict]: If not None, use this dictionary to remap oldkey-&gt;newkey for activities.  If None, use random keys.  If empty dict, no change (do not rekey activities)
        
        Returns:
            This object, with all track ID and activity ID rekeyed as specified.  All actor IDs in activities will be updated.  
        
        &#34;&#34;&#34;
        assert activities is None or isinstance(activities, dict) and all([k in self.activities() for k in activities.keys()])
        assert tracks is None or isinstance(tracks, dict) and all([k in self.tracks() for k in tracks.keys()])

        d_old_to_new = {k:hex(int(uuid.uuid4().hex[0:8], 16))[2:] for (k,a) in self.activities().items()} if activities is None else activities
        self._activities = dict([(d_old_to_new[k], a.id(d_old_to_new[k])) if k in d_old_to_new else (k,a) for (k,a) in self.activities().items()])
        d_old_to_new = {k:hex(int(uuid.uuid4().hex[0:8], 16))[2:] for (k,t) in self.tracks().items()} if tracks is None else tracks
        self._tracks = dict([(d_old_to_new[k], t.id(d_old_to_new[k])) if k in d_old_to_new else (k,t) for (k,t) in self.tracks().items()])
        for (k,v) in d_old_to_new.items():
            self.activitymap(lambda a: a.replaceid(k,v) )
        return self

    def annotation(self):
        &#34;&#34;&#34;Return an iterator over annotations in each frame.
        
        ```python
        for y in self.annotation():
            for (bb,a) in y:
                print((bb,a))
        ```

        Yields:
            for each frame yield the tuple:  ( (`vipy.object.Detection`, (tuple of `vipy.activity.Activity` performed by the actor in this bounding box)), ... )

        .. note:: The preferred method for accessing annotations is a frame iterator, which includes pixels.  However, this method provides access to just the annotations without pixels.

        &#34;&#34;&#34;
        endframe = max([a.endframe() for a in self.activitylist()]+[t.endframe() for (tk,t) in self.tracks().items()]) if (len(self._tracks) &gt; 0 or len(self._activities) &gt; 0) else 0
        for k in range(0,endframe):
            yield tuple( [tuple( [t[k] if t.during(k) else None, tuple( [a for a in self.activitylist() if a.during(k) and a.hastrackoverlap(t)] ) ]) for t in self.tracklist()])
        
    def label(self):
        &#34;&#34;&#34;Return an iterator over labels in each frame&#34;&#34;&#34;
        endframe = max([a.endframe() for a in self.activitylist()]+[t.endframe() for (tk,t) in self.tracks().items()]) if (len(self._tracks) &gt; 0 or len(self._activities) &gt; 0) else 0
        for k in range(0,endframe):
            yield self.labels(k)
    
    def labels(self, k=None):
        &#34;&#34;&#34;Return a set of all object and activity labels in this scene, or at frame int(k)&#34;&#34;&#34;
        return self.activitylabels(k).union(self.objectlabels(k))

    def activitylabel(self, startframe=None, endframe=None):
        &#34;&#34;&#34;Return an iterator over activity labels in each frame, starting from startframe and ending when there are no more activities&#34;&#34;&#34;        
        endframe = endframe if endframe is not None else (max([a.endframe() for a in self.activitylist()]) if len(self.activities())&gt;0 else 0)
        startframe = startframe if startframe is not None else (min([a.startframe() for a in self.activitylist()]) if len(self.activities())&gt;0 else 0)
        assert startframe &lt;= endframe
        for k in range(startframe, endframe):
            yield self.activitylabels(k)
        
    def activitylabels(self, startframe=None, endframe=None):
        &#34;&#34;&#34;Return a set of all activity categories in this scene, or at startframe, or in range [startframe, endframe]&#34;&#34;&#34;        
        if startframe is None:
            return set([a.category() for a in self.activities().values()])
        elif startframe is not None and endframe is None:
            return set([a.category() for a in self.activities().values() if a.during(startframe)])
        elif startframe is not None and endframe is not None:
            return [set([a.category() for a in self.activities().values() if a.during(k)]) for k in range(startframe, endframe)] 
        else:
            raise ValueError(&#39;Invalid input - must specify both startframe and endframe, or only startframe&#39;)            
    
    def objectlabels(self, k=None, lower=False):
        &#34;&#34;&#34;Return a python set of all activity categories in this scene, or at frame k.
        
        Args:
            k: [int] The object labels present at frame k.  If k=None, then all object labels in the video
            lower: [bool] If true, return the object labels in alll lower case for case invariant string comparisonsn            
        &#34;&#34;&#34;
        return set([t.category() if not lower else t.category().lower() for t in self.tracks().values() if k is None or t.during(k)])        

    def categories(self):
        &#34;&#34;&#34;Alias for labels()&#34;&#34;&#34;
        return self.labels()
    
    def activity_categories(self):
        &#34;&#34;&#34;Alias for activitylabels()&#34;&#34;&#34;
        return self.activitylabels()        
        
    def hasactivities(self):
        &#34;&#34;&#34;Does this video have any activities?&#34;&#34;&#34;
        return len(self._activities) &gt; 0

    def hasactivity(self, activityid):
        &#34;&#34;&#34;Does this video have this activity id?&#34;&#34;&#34;
        return activityid in self.activities()
    
    def hastracks(self):
        &#34;&#34;&#34;Does this video have any tracks?&#34;&#34;&#34;
        return len(self._tracks) &gt; 0

    def hastrack(self, trackid):
        &#34;&#34;&#34;Does the video have this trackid?  
        
        .. note:: Track IDs are available as vipy.object.Track().id()
        &#34;&#34;&#34;
        return trackid in self.tracks()

    def add(self, obj, category=None, attributes=None, rangecheck=True, frame=None, fluent=False):
        &#34;&#34;&#34;Add the object obj to the scene, and return an index to this object for future updates
        
        This function is used to incrementally build up a scene frame by frame.  Obj can be one of the following types:

        - obj = vipy.object.Detection(), this must be called from within a frame iterator (e.g. for im in video) to get the current frame index
        - obj = vipy.object.Track()  
        - obj = vipy.activity.Activity()
        - obj = [xmin, ymin, width, height], with associated category kwarg, this must be called from within a frame iterator to get the current frame index
        
        It is recomended that the objects are added as follows.  For a v=vipy.video.Scene():
           
        ```python
            for im in v:
                # Do some processing on frame im to detect objects
                (object_labels, xywh) = object_detection(im)
        
                # Add them to the scene, note that each object instance is independent in each frame, use tracks for object correspondence
                for (lbl,bb) in zip(object_labels, xywh):
                    v.add(bb, lbl)
        
                # Do some correspondences to track objects
                t2 = v.add( vipy.object.Track(...) )
        
                # Update a previous track to add a keyframe
                v.track(t2).add( ... )
        ```
        
        The frame iterator will keep track of the current frame in the video and add the objects in the appropriate place.  Alternatively,

        ```python
            v.add(vipy.object.Track(..), frame=k)
        ```

        Args:
            obj: A conformal python object to add to the scene (`vipy.object.Detection`, `vipy.object.Track`, `vipy.activity.Activity`, [xmin, ymin, width, height]
            category:  Used if obj is an xywh tuple
            attributes:  Used only if obj is an xywh tuple
            frame:  [int] The frame to add the object
            rangecheck: [bool] If true, check if the object is within the image rectangle and throw an exception if not.  This requires introspecting the video shape using `vipy.video.Video.shape`.
            fluent: [bool] If true, return self instead of the object index 

        &#34;&#34;&#34;        
        if isinstance(obj, vipy.object.Detection):
            assert frame is not None, &#34;add() for vipy.object.Detection() must be added during frame iteration (e.g. for im in video: )&#34;
            k = frame
            if obj.hasattribute(&#39;trackid&#39;) and obj.attributes[&#39;trackid&#39;] in self.tracks():
                # The attribute &#34;trackid&#34; is set for a detection when interpolating a track at a frame.  This is useful for reconstructing a track from previously enumerated detections
                trackid = obj.attributes[&#39;trackid&#39;]
                self.trackmap(lambda t: t.update(k, obj) if obj.attributes[&#39;trackid&#39;] == t.id() else t) 
                return None if not fluent else self
            else:
                t = vipy.object.Track(category=obj.category(), keyframes=[k], boxes=[obj], boundary=&#39;strict&#39;, attributes=obj.attributes, trackid=obj.attributes[&#39;trackid&#39;] if obj.hasattribute(&#39;trackid&#39;) else None, framerate=self.framerate())
                if rangecheck and not obj.hasoverlap(width=self.width(), height=self.height()):
                    raise ValueError(&#34;Track &#39;%s&#39; does not intersect with frame shape (%d, %d)&#34; % (str(t), self.height(), self.width()))
                self.tracks()[t.id()] = t  # by-reference
                return t.id() if not fluent else self
        elif isinstance(obj, vipy.object.Track):
            if rangecheck and not obj.boundingbox().isinside(vipy.geometry.imagebox(self.shape())):
                obj = obj.imclip(self.width(), self.height())  # try to clip it, will throw exception if all are bad 
                warnings.warn(&#39;[vipy.video.add]: Clipping trackid=%s track=&#34;%s&#34; to image rectangle&#39; % (str(obj.id()), str(obj)))
            if obj.framerate() != self.framerate():
                obj.framerate(self.framerate())  # convert framerate of track to framerate of video
            self.tracks()[obj.id()] = obj  # by-reference
            return obj.id() if not fluent else self
        elif isinstance(obj, vipy.activity.Activity):
            if rangecheck and obj.startframe() &gt;= obj.endframe():
                raise ValueError(&#34;Activity &#39;%s&#39; has invalid (startframe, endframe)=(%d, %d)&#34; % (str(obj), obj.startframe(), obj.endframe()))
            self.activities()[obj.id()] = obj  # by-reference, activity may have no tracks
            return obj.id() if not fluent else self
        elif (istuple(obj) or islist(obj)) and len(obj) == 4 and isnumber(obj[0]):
            assert frame is not None, &#34;add() for obj=xywh must be added at a specific frame&#34;
            t = vipy.object.Track(category=category, keyframes=[frame], boxes=[vipy.geometry.BoundingBox(xywh=obj)], boundary=&#39;strict&#39;, attributes=attributes, framerate=self.framerate())
            if rangecheck and not t.boundingbox().isinside(vipy.geometry.imagebox(self.shape())):
                t = t.imclip(self.width(), self.height())  # try to clip it, will throw exception if all are bad 
                warnings.warn(&#39;Clipping track &#34;%s&#34; to image rectangle&#39; % (str(t)))
            self.tracks()[t.id()] = t  # by-reference
            return t.id() if not fluent else self
        else:
            raise ValueError(&#39;Undefined object type &#34;%s&#34; to be added to scene - Supported types are obj in [&#34;vipy.object.Detection&#34;, &#34;vipy.object.Track&#34;, &#34;vipy.activity.Activity&#34;, &#34;[xmin, ymin, width, height]&#34;]&#39; % str(type(obj)))

    def delete(self, id):
        &#34;&#34;&#34;Delete a given track or activity by id, if present&#34;&#34;&#34;
        return self.trackfilter(lambda t: t.id() != id).activityfilter(lambda a: a.id() != id)
            
    def addframe(self, im, frame):
        &#34;&#34;&#34;Add im=vipy.image.Scene() into vipy.video.Scene() at given frame. The input image must have been generated using im=self[k] for this to be meaningful, so that trackid can be associated&#34;&#34;&#34;
        assert isinstance(im, vipy.image.Scene), &#34;Invalid input - Must be vipy.image.Scene()&#34;
        assert im.shape() == self.shape(), &#34;Frame input (shape=%s) must be same shape as video (shape=%s)&#34; % (str(im.shape()), str(self.shape()))
        
        # Copy framewise vipy.image.Scene() into vipy.video.Scene(). 
        self.numpy()[frame] = im.array()  # will trigger copy        
        for bb in im.objects():
            self.trackmap(lambda t: t.update(frame, bb) if bb.attributes[&#39;trackid&#39;] == t.id() else t) 
        return self
    
    def clear(self):
        &#34;&#34;&#34;Remove all activities and tracks from this object&#34;&#34;&#34;
        self._activities = {}
        self._tracks = {}
        return self

    def cleartracks(self):
        self._tracks = {}
        return self

    def clearactivities(self):
        self._activities = {}
        return self
    
    def replace(self, other, frame=None):
        &#34;&#34;&#34;Replace tracks and activities with other if activity/track is during frame&#34;&#34;&#34;
        assert isinstance(other, vipy.video.Scene)
        self.activities([a for a in other.activitylist() if frame is None or a.during(frame)])
        self.tracks([t for t in other.tracklist() if frame is None or t.during(frame)])
        return self
    
    def json(self, encode=True):
        &#34;&#34;&#34;Return JSON encoded string of this object.  This may fail if attributes contain non-json encodeable object&#34;&#34;&#34;
        try:
            json.loads(json.dumps(self.attributes))  # round trip for the attributes dictionary - this can be any arbitrary object and contents may not be json encodable
        except:
            raise ValueError(&#39;Video contains non-JSON encodable object in self.attributes dictionary - Try self.sanitize() or to clear with self.attributes = {} first&#39;)
        d = json.loads(super().json())
        d[&#39;_tracks&#39;] = {k:t.json(encode=False) for (k,t) in self.tracks().items()}
        d[&#39;_activities&#39;] = {k:a.json(encode=False) for (k,a) in self.activities().items()}
        try:
            return json.dumps(d) if encode else d
        except:
            # Legacy support for non JSON serializable objects (&lt;= vipy.1.9.2)
            v = self.clone()
            for (ti, t) in v.tracks().items():
                for o in t._keyboxes:
                    vipy.geometry.BoundingBox.cast(o, flush=True)
                    o.float().significant_digits(2)

            for (ai, a) in v.activities().items():
                a._startframe = int(a._startframe)
                a._endframe = int(a._endframe)
            return v.json(encode=encode)
        
    def csv(self, outfile=None):
        &#34;&#34;&#34;Export scene to CSV file format with header.  If there are no tracks, this will be empty. &#34;&#34;&#34;
        assert self.load().isloaded()
        csv = [(self.filename(), # video filename
                k,  # frame number (zero indexed)
                d.category(), d.shortlabel(), # track category and shortlabel (displayed in caption)
                &#39;;&#39;.join([self.activities(id=aid).category() for aid in tolist(d.attributes[&#39;activityid&#39;])] if &#39;activityid&#39; in d.attributes else &#39;&#39;), # semicolon separated activity category associated with track
                d.xmin(), d.ymin(), d.width(), d.height(),   # bounding box
                d.attributes[&#39;trackid&#39;],  # globally unique track ID
                &#39;;&#39;.join([aid for aid in tolist(d.attributes[&#39;activityid&#39;])] if &#39;activityid&#39; in d.attributes else &#39;&#39;)) # semicolon separated activity ID associated with track
               for (k,im) in enumerate(self) for d in im.objects()]
        csv = [(&#39;# video_filename&#39;, &#39;frame_number&#39;, &#39;object_category&#39;, &#39;object_shortlabel&#39;, &#39;activity categories(;)&#39;, &#39;xmin&#39;, &#39;ymin&#39;, &#39;width&#39;, &#39;height&#39;, &#39;track_id&#39;, &#39;activity_ids(;)&#39;)] + csv
        return writecsv(csv, outfile) if outfile is not None else csv


    def framerate(self, fps=None):
        &#34;&#34;&#34;Change the input framerate for the video and update frame indexes for all annotations.

        ```python
        fps = self.framerate()
        self.framerate(fps=15.0)
        ```

        &#34;&#34;&#34;
        if fps is None:
            return self._framerate
        elif float(fps) == self._framerate:
            return self
        else:
            assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
            fps = float(fps)
            self._startframe = int(round(self._startframe * (fps/self._framerate))) if self._startframe is not None else self._startframe  # __repr__ only
            self._endframe = int(round(self._endframe * (fps/self._framerate))) if self._endframe is not None else self._endframe  # __repr__only
            self._tracks = {k:t.framerate(fps) for (k,t) in self.tracks().items()}
            self._activities = {k:a.framerate(fps) for (k,a) in self.activities().items()}        
            if &#39;fps=&#39; in self._ffmpeg_commandline():
                self._update_ffmpeg(&#39;fps&#39;, fps)  # replace fps filter, do not add to it
            else:
                self._ffmpeg = self._ffmpeg.filter(&#39;fps&#39;, fps=fps, round=&#39;up&#39;)  # create fps filter first time
            self._framerate = fps
            return self
        
    def activitysplit(self, idx=None):
        &#34;&#34;&#34;Split the scene into k separate scenes, one for each activity.  Do not include overlapping activities.  

        Args:
            idx: [int],[tuple],[list].  Return only those activities in the provided activity index list, where the activity index is the integer index of the activity in the video.

        .. note:: This is useful for union()
        &#34;&#34;&#34;
        vid = self.clone(flushforward=True)
        if any([(a.endframe()-a.startframe()) &lt;= 0 for a in vid.activities().values()]):
            warnings.warn(&#39;Filtering invalid activity with degenerate lengths: %s&#39; % str([a for a in vid.activities().values() if (a.endframe()-a.startframe()) &lt;= 0]))
        activities = sorted([a.clone() for a in vid.activities().values() if (a.endframe()-a.startframe()) &gt; 0], key=lambda a: a.startframe())   # only activities with at least one frame, sorted in temporal order
        tracks = [ [t.clone() for (tid, t) in vid.tracks().items() if a.hastrack(t)] for a in activities]  # tracks associated with each activity (may be empty)
        vid._activities = {}  # for faster clone
        vid._tracks = {}      # for faster clone
        return [vid.clone()
                .setattribute(&#39;_instance_id&#39;, (&#39;%s_%d&#39; % (vid.videoid(), k)) if not vid.hasattribute(&#39;_instance_id&#39;) else vid.getattribute(&#39;_instance_id&#39;))
                .activities(pa)
                .tracks(t)
                .setactorid(pa.actorid())
                for (k,(pa,t)) in enumerate(zip(activities, tracks)) if idx is None or k in tolist(idx)]

    def tracksplit(self):
        &#34;&#34;&#34;Split the scene into k separate scenes, one for each track.  Each scene starts at frame 0 and is a shallow copy of self containing exactly one track.  

        - This is useful for visualization by breaking a scene into a list of scenes that contain only one track.
        - The attribute &#39;_trackindex&#39; is set in the attributes dictionary to provide provenance for the track relative to the source video

        .. notes:: Use clone() to create a deep copy if needed.
        &#34;&#34;&#34;
        return [self.clone(shallow=True).setattribute(&#39;_trackindex&#39;, k).tracks(t).activityfilter(lambda a: a.hastrack(tk)) for (k,(tk,t)) in enumerate(self.tracks().items())]

    def trackclip(self):
        &#34;&#34;&#34;Split the scene into k separate scenes, one for each track.  Each scene starts and ends when the track starts and ends&#34;&#34;&#34;
        return [t.setattribute(&#39;_instance_id&#39;, &#39;%s_%d_trackclip&#39; % (t.videoid(), k)).clip(t.track(t.actorid()).startframe(), t.track(t.actorid()).endframe()) for (k,t) in enumerate(self.tracksplit())]
    
    def activityclip(self, padframes=0, multilabel=True, idx=None, padto=None, padtosec=None):
        &#34;&#34;&#34;Return a list of `vipy.video.Scene` objects each clipped to be temporally centered on a single activity, with an optional padframes before and after.  

        Args:
            padframes: [int] for symmetric padding same before and after
            padframes: [tuple] (int, int) for asymmetric padding before and after
            padframes: [list[tuples]] [(int, int), ...] for activity specific asymmetric padding.  See also padto.
            multilabel: [bool] include overlapping multilabel secondary activities in each activityclip
            idx: [int], [tuple], [list].  The indexes of the activities to return, where the index is the integer index order of the activity in the video.  Useful for complex videos.
            padto: [int] padding so that each activity clip is at least padto frames long, with symmetric padding around the activity.  
            padtosec: [float] padding so that each activity clip is at least padtosec seconds long, with symmetric padding around the activity.  

        Returns:
            A list of `vipy.video.Scene` each cloned from the source video and clipped on one activity in the scene

        .. notes::
           - The Scene() category is updated to be the activity category of the clip, and only the objects participating in the activity are included.
           - Clips are returned ordered in the temporal order they appear in the video.
           - The returned vipy.video.Scene() objects for each activityclip are clones of the video, with the video buffer flushed.
           - Each activityclip() is associated with each activity in the scene, and includes all other secondary activities that the objects in the primary activity also perform (if multilabel=True).  See activityclip().labels(). 
           - Calling activityclip() on activityclip(multilabel=True) will duplicate activities, due to the overlapping secondary activities being included in each clip with an overlap.  Be careful!
        &#34;&#34;&#34;
        assert isinstance(padframes, int) or istuple(padframes) or islist(padframes)

        vid = self.clone(flushforward=True)
        if any([(a.endframe()-a.startframe()) &lt;= 0 for a in vid.activities().values()]):
            warnings.warn(&#39;Filtering invalid activity clips with degenerate lengths: %s&#39; % str([a for a in vid.activities().values() if (a.endframe()-a.startframe()) &lt;= 0]))
        primary_activities = sorted([a.clone() for a in vid.activities().values() if (a.endframe()-a.startframe()) &gt; 0], key=lambda a: a.startframe())   # only activities with at least one frame, sorted in temporal order
        padframelist = [padframes if istuple(padframes) else (padframes, padframes) for k in range(len(primary_activities))] if not islist(padframes) else padframes                    
        tracks = [ [t.clone() for (tid, t) in vid.tracks().items() if a.hastrackoverlap(t)] for a in primary_activities]  # tracks associated with and temporally overlapping each primary activity (may be empty)
        secondary_activities = [[sa.clone() for sa in primary_activities if (sa.id() != pa.id() and pa.clone().temporalpad((prepad, postpad)).hasoverlap(sa) and (len(T)==0 or any([sa.hastrack(t) for t in T])))] for (pa, T, (prepad,postpad)) in zip(primary_activities, tracks, padframelist)]  # overlapping secondary activities that includes any track in the primary activity
        secondary_activities = [sa if multilabel else [] for sa in secondary_activities]  
        vid._activities = {}  # for faster clone
        vid._tracks = {}      # for faster clone
        maxframes = self.duration_in_frames() if (padframes != 0 or padto is not None or padtosec is not None) else None                    
        if padto is not None or padtosec is not None:
            cliplist = [(a.startframe(), a.endframe()) for a in primary_activities]
            padto = padto if padto is not None else int(round(padtosec*self.framerate()))            
            padframelist = [(sp+int(np.ceil(((padto-(ef-sf))/2))), ep+int(np.ceil(((padto-(ef-sf))/2)))) if (ef-sf)&lt;padto else (sp,ep) for ((sp,ep),(sf,ef)) in zip(padframelist, cliplist)]  
            padframelist = [(0,ep+(-sp)) if (sp&lt;0) else ((sp+(ep-(maxframes-ef)), maxframes-ef) if ((ef+ep)&gt;maxframes) else (sp,ep)) for ((sp,ep),(sf,ef)) in zip(padframelist, cliplist)]  # truncate to video boundary
            
        return [vid.clone()
                .activities([pa]+sa)  # primary activity first
                .tracks(t)
                .clip(startframe=max(pa.startframe()-prepad, 0), endframe=min(pa.endframe()+postpad, (maxframes if maxframes is not None else pa.endframe()+postpad)))
                .category(pa.category())
                .setactorid(pa.actorid())  # actor is actor of primary activity
                .setattribute(&#39;_instance_id&#39;, (&#39;%s_%d&#39; % (vid.videoid(), k)) if not vid.hasattribute(&#39;_instance_id&#39;) else vid.getattribute(&#39;_instance_id&#39;))
                for (k,(pa,sa,t,(prepad,postpad))) in enumerate(zip(primary_activities, secondary_activities, tracks, padframelist))
                if (idx is None or k in tolist(idx))]

    def noactivitylist(self, label=None, shortlabel=None):
        &#34;&#34;&#34;Return a list of `vipy.activity.Activity` which are segments of each track with no associated activities.

        Args:
            label: [str] The activity label to give the background activities.  Defaults to the track category (lowercase)
        
        Returns:
            A list of `vipy.activity.Activity` such that each activity is associated with a track with temporal support where no activities are performed. The union of activitylist() and noactivitylist() should cover the temporal support of all track
        &#34;&#34;&#34;
        A = []
        for t in self.tracklist():
            (startframe, endframe) = (t.startframe(), t.startframe())
            for k in range(t.startframe(), t.endframe()):
                if not any([a.hastrack(t) and a.during(k) for a in self.activitylist()]) and k &lt; (t.endframe()-1):
                    endframe = k  # background
                else:
                    if startframe &lt; endframe:
                        A.append(vipy.activity.Activity(label=t.category() if label is None else label, 
                                                        shortlabel=&#39;&#39; if label is None else (label if shortlabel is None else shortlabel),
                                                        startframe=startframe,
                                                        endframe=endframe,
                                                        actorid=t.id(),
                                                        framerate=self.framerate(),
                                                        attributes={&#39;_noactivitylist&#39;:True}))
                    (startframe, endframe) = (k+1,k+1)                        
        return A
    
        
    def noactivityclip(self, label=None, shortlabel=None, padframes=0):
        &#34;&#34;&#34;Return a list of vipy.video.Scene() each clipped on a track segment that has no associated activities.  

        Args:
            label: [str] The activity label to give the background activities.  Defaults to the track category (lowercase)
            shortlabel: [str] The activity shortlabel to give the background activities when visualized.  Defaults to the track category (lowercase)
            padframes: [int]  The amount of temporal padding to apply to the clips before and after in frames.  See `vipy.video.Scene.activityclip` for options.
        
        Returns:
            A list of `vipy.video.Scene` each cloned from the source video and clipped in the temporal region between activities.  The union of activityclip() and noactivityclip() should equal the entire video.

        .. notes::
            - Each clip will contain exactly one activity &#34;Background&#34; which is the interval for this track where no activities are occurring
            - Each clip will be at least one frame long
        &#34;&#34;&#34;
        A = self.clone().activities(self.noactivitylist(label=label, shortlabel=shortlabel)).activityclip(padframes=padframes, multilabel=False)
        return [a.setattribute(&#39;_instance_id&#39;, &#39;%s_bg&#39; % a.getattribute(&#39;_instance_id&#39;)) for a in A]
    
    def trackbox(self, dilate=1.0):
        &#34;&#34;&#34;The trackbox is the union of all track bounding boxes in the video, or None if there are no tracks
        
        Args:
            dilate: [float] A dilation factor to apply to the trackbox before returning.  See `vipy.geometry.BoundingBox.dilate`

        Returns:
            A `vipy.geometry.BoundingBox` which is the union of all boxes in the track (or None if no boxes exist)
        &#34;&#34;&#34;
        boxes = [t.clone().boundingbox() for t in self.tracklist()]
        boxes = [bb.dilate(dilate) for bb in boxes if bb is not None]
        return boxes[0].union(boxes[1:]) if len(boxes) &gt; 0 else None

    def framebox(self):
        &#34;&#34;&#34;Return the bounding box for the image rectangle.

        Returns:
            A `vipy.geometry.BoundingBox` which defines the image rectangle

        .. notes: This requires calling `vipy.video.Video.preview` to get the frame shape from the current filter chain, which touches the video file&#34;&#34;&#34;
        return vipy.geometry.BoundingBox(xmin=0, ymin=0, width=self.width(), height=self.height())

    def trackcrop(self, dilate=1.0, maxsquare=False, zeropad=True):
        &#34;&#34;&#34;Return the trackcrop() of the scene which is the crop of the video using the `vipy.video.Scene.trackbox`.
         
        Args:
            zeropad: [bool] If True, the zero pad the crop if it is outside the image rectangle, otherwise return only valid pixels inside the image rectangle
            maxsquare: [bool] If True, make the bounding box the maximum square before cropping
            dilate: [float] The dilation factor to apply to the trackbox prior to cropping
        
        Returns:
           A `vipy.video.Scene` object from cropping the video using the trackbox.  If there are no tracks, return None.  

        &#34;&#34;&#34;
        bb = self.trackbox(dilate)  # may be None if trackbox is degenerate
        return self.crop(bb.maxsquareif(maxsquare), zeropad=zeropad) if bb is not None else None  

    def activitybox(self, activityid=None, dilate=1.0):
        &#34;&#34;&#34;The activitybox is the union of all activity bounding boxes in the video, which is the union of all tracks contributing to all activities.  This is most useful after activityclip().
           The activitybox is the smallest bounding box that contains all of the boxes from all of the tracks in all activities in this video.
        &#34;&#34;&#34;
        activities = [a for (k,a) in self.activities().items() if (activityid is None or k in set(activityid))]
        boxes = [t.clone().boundingbox().dilate(dilate) for t in self.tracklist() if any([a.hastrack(t) for a in activities])]
        return boxes[0].union(boxes[1:]) if len(boxes) &gt; 0 else vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(self.width()), height=int(self.height()))

    def activitycuboid(self, activityid=None, dilate=1.0, maxdim=256, bb=None):
        &#34;&#34;&#34;The activitycuboid() is the fixed square spatial crop corresponding to the activitybox (or supplied bounding box), which contains all of the valid activities in the scene.  This is most useful after activityclip().
           The activitycuboid() is a spatial crop of the video corresponding to the supplied boundingbox or the square activitybox().
           This crop must be resized such that the maximum dimension is provided since the crop can be tiny and will not be encodable by ffmpeg
        &#34;&#34;&#34;
        bb = self.activitybox(activityid).maxsquare() if bb is None else bb  
        assert bb is None or isinstance(bb, vipy.geometry.BoundingBox)
        assert bb.issquare(), &#34;Add support for non-square boxes&#34;
        return self.clone().crop(bb.dilate(dilate).int(), zeropad=True).resize(maxdim, maxdim)  # crop triggers preview()

    def activitysquare(self, activityid=None, dilate=1.0, maxdim=256):
        &#34;&#34;&#34;The activity square is the maxsquare activitybox that contains only valid (non-padded) pixels interior to the image&#34;&#34;&#34;
        bb = self.activitybox(activityid).maxsquare().dilate(dilate).int().iminterior(self.width(), self.height()).minsquare()
        return self.activitycuboid(activityid, dilate=1.0, maxdim=maxdim, bb=bb)

    def activitytube(self, activityid=None, dilate=1.0, maxdim=256):
        &#34;&#34;&#34;The activitytube() is a sequence of crops where the spatial box changes on every frame to track the activity.  
           The box in each frame is the square activitybox() for this video which is the union of boxes contributing to this activity in each frame.
           This function does not perform any temporal clipping.  Use activityclip() first to split into individual activities.  
           Crops will be optionally dilated, with zeropadding if the box is outside the image rectangle.  All crops will be resized so that the maximum dimension is maxdim (and square by default)
        &#34;&#34;&#34;
        vid = self.clone().load()  # triggers load
        self.activityfilter(lambda a: activityid is None or a.id() in set(activityid))  # only requested IDs (or all of them)
        frames = [im.padcrop(im.boundingbox().maxsquare().dilate(dilate).int()).resize(maxdim, maxdim) for im in vid if im.boundingbox() is not None]  # track interpolation, for frames with boxes only
        if len(frames) != len(vid):
            warnings.warn(&#39;[vipy.video.activitytube]: Removed %d frames with no spatial bounding boxes&#39; % (len(vid) - len(frames)))
            vid.attributes[&#39;__activtytube&#39;] = {&#39;truncated&#39;:len(vid) - len(frames)}  # provenance to reject
        if len(frames) == 0:
            warnings.warn(&#39;[vipy.video.activitytube]: Resulting video is empty!  Setting activitytube to zero&#39;)
            frames = [ vid[0].resize(maxdim, maxdim).zeros() ]  # empty frame
            vid.attributes[&#39;__activitytube&#39;] = {&#39;empty&#39;:True}   # provenance to reject 
        vid._tracks = {ti:vipy.object.Track(keyframes=[f for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],
                                            boxes=[d for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],
                                            category=t.category(), trackid=ti, framerate=self.framerate())
                       for (k,(ti,t)) in enumerate(self.tracks().items())}  # replace tracks with boxes relative to tube
        return vid.array(np.stack([im.numpy() for im in frames]))

    def actortube(self, trackid=None, dilate=1.0, maxdim=256, strict=True):
        &#34;&#34;&#34;The actortube() is a sequence of crops where the spatial box changes on every frame to track the primary actor performing an activity.  
           The box in each frame is the square box centered on the primary actor performing the activity, dilated by a given factor (the original box around the actor is unchanged, this just increases the context, with zero padding)
           This function does not perform any temporal clipping.  Use activityclip() first to split into individual activities.  
           All crops will be resized so that the maximum dimension is maxdim (and square by default)
        &#34;&#34;&#34;
        assert trackid is not None or len(self.tracks()) == 1, &#34;Track ID must be provided if there exists more than one track in the scene&#34;
        trackid = trackid if trackid is not None else list(self.tracks().keys())[0]
        assert self.hastrack(trackid), &#34;Track ID %s not found - Actortube requires a track ID in the scene (tracks=%s)&#34; % (str(trackid), str(self.tracks()))
        vid = self.clone().load()  # triggers load        
        t = vid.tracks(id=trackid)  # actor track
        frames = [im.padcrop(t[k].maxsquare().dilate(dilate).int()).resize(maxdim, maxdim) for (k,im) in enumerate(vid) if t.during(k)] if len(t)&gt;0 else []  # actor interpolation, padding may introduce frames with no tracks
        if len(frames) == 0:
            if not strict:
                warnings.warn(&#39;[vipy.video.actortube]: Empty track for trackid=&#34;%s&#34; - Setting actortube to zero&#39; % trackid)
                frames = [ vid[0].resize(maxdim, maxdim).zeros() ]  # empty frame
                vid.attributes[&#39;__actortube&#39;] = {&#39;empty&#39;:True}   # provenance to reject             
            else:
                raise ValueError(&#39;[vipy.video.actortube]: Empty track for track=%s, trackid=%s&#39; % (str(t), trackid))
        vid._tracks = {ti:vipy.object.Track(keyframes=[f for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],  # keyframes zero indexed, relative to [frames]
                                            boxes=[d for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],  # one box per frame
                                            category=t.category(), trackid=ti, framerate=self.framerate())  # preserve trackid
                       for (k,(ti,t)) in enumerate(self.tracks().items())}  # replace tracks with interpolated boxes relative to tube defined by actor
        return vid.array(np.stack([im.numpy() for im in frames]))

    def speed(self, s):
        &#34;&#34;&#34;Change the speed by a multiplier s.  If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)&#34;&#34;&#34;        
        super().speed(s)
        return self.trackmap(lambda t: t.framerate(speed=s)).activitymap(lambda a: a.framerate(speed=s))
        

    
    def clip(self, startframe, endframe=None):
        &#34;&#34;&#34;Clip the video to between (startframe, endframe).  This clip is relative to clip() shown by __repr__(). 

        Args:
            startframe: [int] the start frame relative to the video framerate() for the clip
            endframe: [int] the end frame relative to the video framerate for the clip, may be none
        
        Returns:
            This video object, clipped so that a load() will result in frame=0 equivalent to startframe.  All tracks and activities updated relative to the new startframe.

        .. note:  
            - This return a clone of the video for idempotence
            - This does not load the video.  This updates the ffmpeg filter chain to temporally trim the video.  See self.commandline() for the updated filter chain to run.
        &#34;&#34;&#34;
        assert (endframe is None or startframe &lt;= endframe) and startframe &gt;= 0, &#34;Invalid start and end frames (%s, %s)&#34; % (str(startframe), str(endframe))

        v = self.clone()
        if not v.isloaded():
            # -- Copied from super().clip() to allow for clip on clone (for indempotence)
            # -- This code copy is used to avoid super(Scene, self.clone()) which screws up class inheritance for iPython reload
            assert not v.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;            
            timestamp_in_seconds = ((v._startframe if v._startframe is not None else 0)+startframe)/float(v.framerate())
            v._update_ffmpeg_seek(timestamp_in_seconds)
            if endframe is not None:
                v._ffmpeg = v._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 before trim filter            
                v._ffmpeg = v._ffmpeg.trim(start=0, end=(endframe-startframe)/self.framerate())  # must be in seconds to allow for framerate conversion
            v._ffmpeg = v._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 after trim filter            
            v._startframe = startframe if v._startframe is None else v._startframe + startframe  # for __repr__ only
            v._endframe = (v._startframe + (endframe-startframe)) if endframe is not None else v._endframe  # for __repr__ only
            # -- end copy
        else:
            endframe = endframe if endframe is not None else len(self._array)
            v._array = self._array[startframe:endframe]
            (v._startframe, v._endframe) = (0, endframe-startframe)
        v._tracks = {k:t.offset(dt=-startframe).truncate(startframe=0, endframe=(endframe-startframe) if endframe is not None else None) for (k,t) in v.tracks().items()}   # may be degenerate
        v._activities = {k:a.offset(dt=-startframe).truncate(startframe=0, endframe=(endframe-startframe) if endframe is not None else None) for (k,a) in v.activities().items()}  # may be degenerate
        return v.trackfilter(lambda t: len(t)&gt;0).activityfilter(lambda a: len(a)&gt;0)  # remove degenerate tracks and activities

    def crop(self, bb, zeropad=True):
        &#34;&#34;&#34;Crop the video using the supplied box, update tracks relative to crop, video is zeropadded if box is outside frame rectangle&#34;&#34;&#34;
        assert isinstance(bb, vipy.geometry.BoundingBox), &#34;Invalid input&#34;
        bb = bb.int()
        bbc = bb.clone().imclipshape(self.width(), self.height()).int()
        #if zeropad and bb != bbc:
        #    self.zeropad(bb.width()-bbc.width(), bb.height()-bbc.height())  
        #    bb = bb.offset(bb.width()-bbc.width(), bb.height()-bbc.height())            
        super().crop(bb, zeropad=zeropad)  # range check handled here to correctly apply zeropad
        bb = bb if zeropad else bbc
        self._tracks = {k:t.offset(dx=-bb.xmin(), dy=-bb.ymin()) for (k,t) in self.tracks().items()}
        return self
    
    def zeropad(self, padwidth, padheight):
        &#34;&#34;&#34;Zero pad the video with padwidth columns before and after, and padheight rows before and after
           Update tracks accordingly. 

        &#34;&#34;&#34;
        
        assert isinstance(padwidth, int) and isinstance(padheight, int)
        super().zeropad(padwidth, padheight)  
        self._tracks = {k:t.offset(dx=padwidth, dy=padheight) for (k,t) in self.tracks().items()}
        return self
        
    def fliplr(self):
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        self._tracks = {k:t.fliplr(H,W) for (k,t) in self.tracks().items()}
        super().fliplr()
        return self

    def flipud(self):
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        self._tracks = {k:t.flipud(H,W) for (k,t) in self.tracks().items()}
        super().flipud()
        return self

    def rot90ccw(self):
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        self._tracks = {k:t.rot90ccw(H,W) for (k,t) in self.tracks().items()}
        super().rot90ccw()
        return self

    def rot90cw(self):
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        self._tracks = {k:t.rot90cw(H,W) for (k,t) in self.tracks().items()}
        super().rot90cw()
        return self

    def resize(self, rows=None, cols=None, width=None, height=None):
        &#34;&#34;&#34;Resize the video to (rows, cols), preserving the aspect ratio if only rows or cols is provided&#34;&#34;&#34;
        assert not (rows is not None and height is not None)  # cannot be both
        assert not (cols is not None and width is not None)   # cannot be both
        rows = rows if rows is not None else height
        cols = cols if cols is not None else width        
        
        assert rows is not None or cols is not None, &#34;Invalid input&#34;
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter, manually set this prior to calling resize if known
        sy = rows / float(H) if rows is not None else cols / float(W)
        sx = cols / float(W) if cols is not None else rows / float(H)
        self._tracks = {k:t.scalex(sx) for (k,t) in self.tracks().items()}
        self._tracks = {k:t.scaley(sy) for (k,t) in self.tracks().items()}
        super().resize(rows=rows, cols=cols)        
        return self

    def mindim(self, dim=None):
        &#34;&#34;&#34;Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        return min(self.shape()) if dim is None else (self if min(H,W) == dim else (self.resize(cols=dim) if W&lt;H else self.resize(rows=dim)))

    def maxdim(self, dim=None):
        &#34;&#34;&#34;Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        return max(H,W) if dim is None else (self.resize(cols=dim) if W&gt;H else self.resize(rows=dim))        
    
    def rescale(self, s):
        &#34;&#34;&#34;Spatially rescale the scene by a constant scale factor.

        Args:
            s: [float] Scale factor &gt; 0 to isotropically scale the image.
        &#34;&#34;&#34;
        assert s == 1 or not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
        self._tracks = {k:t.rescale(s) for (k,t) in self.tracks().items()}
        super().rescale(s)
        return self

    def startframe(self):
        return self._startframe

    def extrapolate(self, f, dt=None):
        &#34;&#34;&#34;Extrapolate the video to frame f and add the extrapolated tracks to the video&#34;&#34;&#34;
        return self.trackmap(lambda t: t.add(f, t.linear_extrapolation(f, dt=dt if dt is not None else self.framerate()), strict=False))
        
    def dedupe(self, spatial_iou_threshold=0.8, dt=5):
        &#34;&#34;&#34;Find and delete duplicate tracks by track segmentiou() overlap.
        
        Algorithm
        - For each pair of tracks with the same category, find the larest temporal segment that contains both tracks.
        - For this segment, compute the IOU for each box interpolated at a stride of dt frames
        - Compute the mean IOU for this segment.  This is the segment IOU. 
        - If the segment IOU is greater than the threshold, merge the shorter of the two tracks with the current track.  

        &#34;&#34;&#34;
        deleted = set([])
        for tj in sorted(self.tracklist(), key=lambda t: len(t), reverse=True):  # longest to shortest
            for (s, ti) in sorted([(0,t) if (len(tj) &lt; len(t) or t.id() in deleted or t.id() == tj.id() or t.category() != tj.category()) else (tj.fragmentiou(t, dt=dt), t) for t in self.tracklist()], key=lambda x: x[0], reverse=True):
                if s &gt; spatial_iou_threshold:  # best mean framewise overlap during overlapping segment of two tracks (ti, tj)
                    print(&#39;[vipy.video.dedupe]: merging duplicate track &#34;%s&#34; (id=%s) which overlaps with &#34;%s&#34; (id=%s)&#39; % (ti, ti.id(), tj, tj.id()))
                    self.tracks()[tj.id()] = tj.union(ti)  # merge
                    self.activitymap(lambda a: a.replace(ti, tj))  # replace merged track reference in activity
                    deleted.add(ti.id())
        self.trackfilter(lambda t: t.id() not in deleted)  # remove duplicate tracks
        return self

    def combine(self, other, tracks=True, activities=True, rekey=True):
        &#34;&#34;&#34;Combine the activities and tracks from both scenes into self. 
        
        .. note:: This does not perform a union, it simply combines dictionaries.  For deduplication, see `vipy.video.union`
        &#34;&#34;&#34;
        assert isinstance(other, Scene), &#34;Invalid input - must be vipy.video.Scene() object and not type=%s&#34; % str(type(other))
        assert self.framerate() == other.framerate()
        o = other.clone(rekey=True) if rekey else other   # make sure keys are unique
        if activities:
            self.activities().update(o.activities())
        if tracks:
            self.tracks().update(o.tracks())
        return self
    
        
    def union(self, other, temporal_iou_threshold=0.5, spatial_iou_threshold=0.6, strict=True, overlap=&#39;average&#39;, percentilecover=0.8, percentilesamples=100, activity=True, track=True):
        &#34;&#34;&#34;Compute the union two scenes as the set of unique activities and tracks.  

           A pair of activities or tracks are non-unique if they overlap spatially and temporally by a given IoU threshold.  Merge overlapping tracks. 
           Tracks are merged by considering the mean IoU at the overlapping segment of two tracks with the same category greater than the provided spatial_iou_threshold threshold
           Activities are merged by considering the temporal IoU of the activities of the same class greater than the provided temporal_iou_threshold threshold
  
           Args:
               Other: Scene or list of scenes for union.  Other may be a clip of self at a different framerate, spatial isotropic scake, clip offset
               spatial_iou_threshold:  The intersection over union threshold for the mean of the two segments of an overlapping track, Disable by setting to 1.0
               temporal_iou_threshold:  The intersection over union threshold for a temporal bounding box for a pair of activities to be declared duplicates.  Disable by setting to 1.0
               strict:  Require both scenes to share the same underlying video filename
               overlap=[&#39;average&#39;, &#39;replace&#39;, &#39;keep&#39;]
                   - average: Merge two tracks by averaging the boxes (average=True) if overlapping
                   - replace:  merge two tracks by replacing overlapping boxes with other (discard self)
                   - keep: merge two tracks by keeping overlapping boxes with other (discard other)
               percentilecover: [0,1]:  When determining the assignment of two tracks, compute the percentilecover of two tracks by ranking the cover in the overlapping segment and computing the mean of the top-k assignments, where k=len(segment)*percentilecover.
               percentilesamples: [&gt;1]:  the number of samples along the overlapping scemgne for computing percentile cover
               activity: [bool]: union() of activities only
               track: [bool]: union() of tracks only

           Returns:
               Updates this scene to include the non-overlapping activities from other.  By default, it takes the strict union of all activities and tracks. 

           .. note::
               - This is useful for merging scenes computed using a lower resolution/framerate/clipped  object or activity detector without running the detector on the high-res scene
               - This function will preserve the invariance for v == v.clear().union(v.rescale(0.5).framerate(5).activityclip()), to within the quantization error of framerate() downsampling.
               - percentileiou is a robust method of track assignment when boxes for two tracks (e.g. ground truth and detections) where one track may deform due to occlusion.
        &#34;&#34;&#34;
        assert overlap in [&#39;average&#39;, &#39;replace&#39;, &#39;keep&#39;], &#34;Invalid input - &#39;overlap&#39; must be in [average, replace, keep]&#34;
        assert spatial_iou_threshold &gt;= 0 and spatial_iou_threshold &lt;= 1, &#34;invalid spatial_iou_threshold, must be between [0,1]&#34;
        assert temporal_iou_threshold &gt;= 0 and temporal_iou_threshold &lt;= 1, &#34;invalid temporal_iou_threshold, must be between [0,1]&#34;        
        assert percentilesamples &gt;= 1, &#34;invalid samples, must be &gt;= 1&#34;
        if not activity and not track:
            return self  # nothing to do

        sc = self.clone()  # do not change self yet, make a copy then merge at the end
        for o in tolist(other):
            assert isinstance(o, Scene), &#34;Invalid input - must be vipy.video.Scene() object and not type=%s&#34; % str(type(o))

            if strict:
                assert sc.filename() == o.filename(), &#34;Invalid input - Scenes must have the same underlying video.  Disable this with strict=False.&#34;
            oc = o.clone()   # do not change other, make a copy

            # Key collision?
            if len(set(sc.tracks().keys()).intersection(set(oc.tracks().keys()))) &gt; 0:
                print(&#39;[vipy.video.union]: track key collision - Rekeying other... Use other.rekey() to suppress this warning.&#39;)
                oc.rekey()
            if len(set(sc.activities().keys()).intersection(set(oc.activities().keys()))) &gt; 0:
                print(&#39;[vipy.video.union]: activity key collision - Rekeying other... Use other.rekey() to suppress this warning.&#39;)                
                oc.rekey()

            # Similarity transform?  Other may differ from self by a temporal scale (framerate), temporal translation (clip) or spatial isotropic scale (rescale)
            assert np.isclose(sc.aspect_ratio(), oc.aspect_ratio(), atol=1E-2), &#34;Invalid input - Scenes must have the same aspect ratio&#34;
            if sc.width() != oc.width():
                oc = oc.rescale(sc.width() / oc.width())   # match spatial scale
            if not np.isclose(sc.framerate(), oc.framerate(), atol=1E-3):
                oc = oc.framerate(sc.framerate())   # match temporal scale (video in oc will not match, only annotations)
            if sc.startframe() != oc.startframe():
                dt = (oc.startframe() if oc.startframe() is not None else 0) - (sc.startframe() if sc.startframe() is not None else 0)
                oc = oc.trackmap(lambda t: t.offset(dt=dt)).activitymap(lambda a: a.offset(dt=dt))  # match temporal translation of tracks and activities
            oc = oc.trackfilter(lambda t: ((not t.isdegenerate()) and len(t)&gt;0), activitytrack=False)  

            # Merge other tracks into selfclone: one-to-many mapping from self to other
            merged = {}  # dictionary mapping trackid in other to the trackid in self, each track in other can be merged at most once
            for ti in sorted(sc.tracklist(), key=lambda t: len(t), reverse=True):  # longest to shortest
                for tj in sorted(oc.tracklist(), key=lambda t: len(t), reverse=True):  
                    if ti.category() == tj.category() and (tj.id() not in merged) and tj.segment_percentilecover(sc.track(ti.id()), percentile=percentilecover, samples=percentilesamples) &gt; spatial_iou_threshold:  # mean framewise overlap during overlapping segment of two tracks
                        sc.tracks()[ti.id()] = sc.track(ti.id()).union(tj, overlap=overlap)  # merge duplicate/fragmented tracks from other into self, union() returns clone
                        merged[tj.id()] = ti.id()  
                        print(&#39;[vipy.video.union]: merging track &#34;%s&#34;(id=%s) + &#34;%s&#34;(id=%s) for scene &#34;%s&#34;&#39; % (str(ti), str(ti.id()), str(tj), str(tj.id()), str(sc)))                        
            oc.trackfilter(lambda t: t.id() not in merged, activitytrack=False)  # remove duplicate other track for final union

            # Merge other activities into selfclone: one-to-one mapping
            for (i,j) in merged.items():  # i=id of other, j=id of self
                oc.activitymap(lambda a: a.replaceid(i, j) if a.hastrack(i) else a)  # update track IDs referenced in activities for merged tracks
            for (i,ai) in sc.activities().items():
                for (j,aj) in oc.activities().items():
                    if ai.category() == aj.category() and set(ai.trackids()) == set(aj.trackids()) and ai.temporal_iou(aj) &gt; temporal_iou_threshold:
                        oc.activityfilter(lambda a: a.id() != j)  # remove duplicate activity from final union
            oc.activityfilter(lambda a: len(a.tracks())&gt;0)  # remove empty activities not merged

            # Union
            sc.tracks().update(oc.tracks())
            sc.activities().update(oc.activities())

        # Final union of unique tracks/activities
        if track:
            self.tracks(sc.tracklist())  # union of tracks only
        if activity:
            self.activities(sc.activitylist())  # union of activities only: may reference tracks not in self of track=False
        return self        


    def annotate(self, outfile=None, fontsize=10, captionoffset=(0,0), textfacecolor=&#39;white&#39;, textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={&#39;Person&#39;:&#39;green&#39;, &#39;Vehicle&#39;:&#39;blue&#39;, &#39;Object&#39;:&#39;red&#39;}, categories=None, nocaption=False, nocaption_withstring=[], mutator=None, timestamp=None, timestampcolor=&#39;black&#39;, timestampfacecolor=&#39;white&#39;, verbose=False):
        &#34;&#34;&#34;Generate a video visualization of all annotated objects and activities in the video.
        
        The annotation video will be at the resolution and framerate of the underlying video, and pixels in this video will now contain the overlay.
        This function does not play the video, it only generates an annotation video frames.  Use show() which is equivalent to annotate().saveas().play()
        
        Args:
            outfile: [str] An optional file to stream the anntation to without storing the annotated video in memory
            fontsize: [int] The fontsize of bounding box captions, used by matplotlib
            captionoffset: (tuple) The (x,y) offset relative to the bounding box to place the caption for each box.
            textfacecolor: [str] The color of the text in the bounding box caption.  Must be in `vipy.gui.using_matplotlib.colorlist`.
            textfacealpha: [float] The transparency of the text in the bounding box caption.  Must be in [0,1], where 0=transparent and 1=opaque.
            shortlabel: [bool] If true, display the shortlabel for each object in the scene, otherwise show the full category
            boxalpha: [float]  The transparency of the box face behind the text.  Must be in [0,1], where 0=transparent and 1=opaque.
            d_category2color: [dict]  A dictionary mapping categories of objects in the scene to their box colors.  Named colors must be in `vipy.gui.using_matplotlib.colorlist`. 
            categories: [list]  Only show these categories, or show them all if None
            nocaption_withstring: [list]:  Do not show captions for those detection categories (or shortlabels) containing any of the strings in the provided list
            nocaption: [bool] If true, do not show any captions, just boxes
            mutator: [lambda] A lambda function that will mutate an image to allow for complex visualizations.  This should be a mutator like `vipy.image.mutator_show_trackid`.
            timestamp: [bool] If true, show a semitransparent timestamp (when the annotation occurs, not when the video was collected) with frame number in the upper left corner of the video
            timestampcolor: [str] The color of the timstamp text.  Named colors must be in `vipy.gui.using_matplotlib.colorlist`.
            timestampfacecolor: [str]  The color of the timestamp background.  Named colors must be in `vipy.gui.using_matplotlib.colorlist`.  
            verbose: [bool] Show more helpful messages if true

        Returns:
            A `vipy.video.Video` with annotations in the pixels.  If outfile is provided, then the returned video will be flushed.  

        .. note::  In general, this function should not be run on very long videos without the outfile kwarg, as it requires loading the video framewise into memory.  
        &#34;&#34;&#34;
        assert outfile is None or vipy.util.isvideofile(outfile), &#34;Invalid filename extension for annotated video&#34;
        
        if verbose:
            print(&#39;[vipy.video.annotate]: Annotating video ...&#39;)  
            
        f_mutator = mutator if mutator is not None else vipy.image.mutator_show_jointlabel()
        f_timestamp = (lambda k: &#39;%s %d&#39; % (vipy.util.clockstamp(), k)) if timestamp is True else timestamp

        if outfile is None:        
            assert self.load().isloaded(), &#34;Load() failed&#34;
            imgs = [f_mutator(self[k].clone(), k).savefig(fontsize=fontsize,
                                                  captionoffset=captionoffset,
                                                  textfacecolor=textfacecolor,
                                                  textfacealpha=textfacealpha,
                                                  shortlabel=shortlabel,
                                                  boxalpha=boxalpha,
                                                  d_category2color=d_category2color,
                                                  categories=categories,
                                                  nocaption=nocaption,
                                                  timestampcolor=timestampcolor,
                                                  timestampfacecolor=timestampfacecolor,
                                                  timestamp=f_timestamp(k) if timestamp is not None else None,
                                                  figure=1 if k&lt;(len(self)-1) else None,  # cleanup on last frame
                                                  nocaption_withstring=nocaption_withstring).numpy() for k in range(0, len(self))]
            
            # Replace pixels with annotated pixels and downcast object to vipy.video.Video (since there are no more objects to show)
            return vipy.video.Video(array=np.stack([np.array(PIL.Image.fromarray(img).convert(&#39;RGB&#39;)) for img in imgs], axis=0), framerate=self.framerate(), attributes=self.attributes)  # slow for large videos
        else:
            # Stream to output video without loading all frames into memory
            n = self.duration_in_frames_of_videofile() if not self.isloaded() else len(self)
            vo = vipy.video.Video(filename=outfile, framerate=self.framerate())
            with vo.stream(overwrite=True) as so:
                for (k,im) in enumerate(self.stream()):
                    so.write(f_mutator(im.clone(), k).savefig(fontsize=fontsize,
                                                      captionoffset=captionoffset,
                                                      textfacecolor=textfacecolor,
                                                      textfacealpha=textfacealpha,
                                                      shortlabel=shortlabel,
                                                      boxalpha=boxalpha,
                                                      d_category2color=d_category2color,
                                                      categories=categories,
                                                      nocaption=nocaption,
                                                      timestampcolor=timestampcolor,
                                                      timestampfacecolor=timestampfacecolor,
                                                      timestamp=f_timestamp(k) if timestamp is not None else None,
                                                      figure=1 if k&lt;(n-1) else None,  # cleanup on last frame
                                                      nocaption_withstring=nocaption_withstring).rgb())
            return vo


    def _show(self, outfile=None, verbose=True, fontsize=10, captionoffset=(0,0), textfacecolor=&#39;white&#39;, textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={&#39;Person&#39;:&#39;green&#39;, &#39;Vehicle&#39;:&#39;blue&#39;, &#39;Object&#39;:&#39;red&#39;}, categories=None, nocaption=False, nocaption_withstring=[], notebook=False, timestamp=None, timestampcolor=&#39;black&#39;, timestampfacecolor=&#39;white&#39;):
        &#34;&#34;&#34;Generate an annotation video saved to outfile (or tempfile if outfile=None) and show it using ffplay when it is done exporting.  Do not modify the original video buffer.  Returns a clone of the video with the shown annotation.&#34;&#34;&#34;
        return self.clone().annotate(verbose=verbose, 
                                     fontsize=fontsize,
                                     captionoffset=captionoffset,
                                     textfacecolor=textfacecolor,
                                     textfacealpha=textfacealpha,
                                     shortlabel=shortlabel,
                                     boxalpha=boxalpha,
                                     d_category2color=d_category2color,
                                     categories=categories,
                                     nocaption=nocaption,
                                     timestampcolor=timestampcolor,
                                     timestampfacecolor=timestampfacecolor,
                                     timestamp=timestamp,
                                     nocaption_withstring=nocaption_withstring).saveas(outfile).play(notebook=notebook)
    

    def show(self, outfile=None, verbose=True, fontsize=10, captionoffset=(0,0), textfacecolor=&#39;white&#39;, textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={&#39;Person&#39;:&#39;green&#39;, &#39;Vehicle&#39;:&#39;blue&#39;, &#39;Object&#39;:&#39;red&#39;}, categories=None, nocaption=False, nocaption_withstring=[], figure=1, fps=None, timestamp=None, timestampcolor=&#39;black&#39;, timestampfacecolor=&#39;white&#39;, mutator=None):
        &#34;&#34;&#34;Faster show using interative image show for annotated videos.  This can visualize videos before video rendering is complete, but it cannot guarantee frame rates. Large videos with complex scenes will slow this down and will render at lower frame rates.&#34;&#34;&#34;
        fps = min(fps, self.framerate()) if fps is not None else self.framerate()
        assert fps &gt; 0, &#34;Invalid display framerate&#34;
        f_timestamp = (lambda k: &#39;%s %d&#39; % (vipy.util.clockstamp(), k)) if timestamp is True else timestamp
        f_mutator = mutator if mutator is not None else vipy.image.mutator_show_jointlabel()        
        if not self.isdownloaded() and self.hasurl():
            self.download()
        with Stopwatch() as sw:            
            for (k,im) in enumerate(self.load() if self.isloaded() else self.stream()):
                time.sleep(max(0, (1.0/self.framerate())*int(np.ceil((self.framerate()/fps)))))
                f_mutator(im,k).show(categories=categories,
                                     figure=figure,
                                     nocaption=nocaption,
                                     nocaption_withstring=nocaption_withstring,
                                     fontsize=fontsize,
                                     boxalpha=boxalpha,
                                     d_category2color=d_category2color,
                                     captionoffset=captionoffset,
                                     textfacecolor=textfacecolor,
                                     textfacealpha=textfacealpha,
                                     timestampcolor=timestampcolor,
                                     timestampfacecolor=timestampfacecolor,
                                     timestamp=f_timestamp(k) if timestamp is not None else None,
                                     shortlabel=shortlabel)
                
                if vipy.globals._user_hit_escape():
                    break
        vipy.show.close(figure)
        return self

    def thumbnail(self, outfile=None, frame=0, fontsize=10, nocaption=False, boxalpha=0.25, dpi=200, textfacecolor=&#39;white&#39;, textfacealpha=1.0):
        &#34;&#34;&#34;Return annotated frame=k of video, save annotation visualization to provided outfile if provided, otherwise return vipy.image.Scene&#34;&#34;&#34;
        im = self.frame(frame, img=self.preview(framenum=frame).array())
        return im.savefig(outfile=outfile, fontsize=fontsize, nocaption=nocaption, boxalpha=boxalpha, dpi=dpi, textfacecolor=textfacecolor, textfacealpha=textfacealpha) if outfile is not None else im
    
    def stabilize(self, padheightfrac=0.125, padwidthfrac=0.25, padheightpx=None, padwidthpx=None, gpu=None, outfile=None):
        &#34;&#34;&#34;Background stablization using flow based stabilization masking foreground region.  
        
        - This will output a video with all frames aligned to the first frame, such that the background is static.
        - This uses the flow based approach described in `vipy.flow.Flow.stabilize`

        Args:
        
            padheightfrac: [float] The height padding (relative to video height) to be applied to output video to allow for vertical stabilization
            padwidthfrac: [float]  The width padding (relative to video width) to be applied to output video to allow for horizontal stabilization
            padheightpx: [int]  The height padding to be applied to output video to allow for vertical stabilization.  Overrides padheight.
            padwidthpx: [int]  The width padding to be applied to output video to allow for horizontal stabilization.  Overrides padwidth.
            gpu: [int] The GPU index to use, if opencv has been compiled with GPU support (this is rare)
            outfile: [str]  The output filename to store the stabilized video

        Returns:
        
            A clone of this video with background pixels stabilized to the first frame.  

        .. note::
        
            - If the camera pans outside the image rectangle, increase the padheight or padwidth to make sure that the actor stays inside the stabilized image rectangle
            - If there are moving actors in the scene, include bounding boxes for each and these boxes are ignored as keeyouts in the flow stabilization

        &#34;&#34;&#34;
        from vipy.flow import Flow  # requires opencv
        return Flow(flowdim=256, gpu=gpu).stabilize(self.clone(), residual=True, strict=True, padheightfrac=padheightfrac, padwidthfrac=padwidthfrac, padheightpx=padheightpx, padwidthpx=padwidthpx, outfile=outfile)
    
    def pixelmask(self, pixelsize=8):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with pixelation (e.g. bigger pixels, like privacy glass)&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy          
            im.pixelmask(pixelsize)  # shared numpy array
        return self

    def pixelize(self, radius=16):
        &#34;&#34;&#34;Alias for pixelmask()&#34;&#34;&#34;
        return self.pixelmask(pixelsize=radius)
    def pixelate(self, radius=16):
        &#34;&#34;&#34;Alias for pixelmask()&#34;&#34;&#34;
        return self.pixelmask(pixelsize=radius)
    
    def binarymask(self):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with white, zero in background&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy  
            im.binarymask()  # shared numpy array
        return self

    def asfloatmask(self, fg=1.0, bg=0.0):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with fg, and bg in background, return a copy&#34;&#34;&#34;
        assert self.isloaded()
        self.numpy()  # convert to writeable numpy array, triggers writeable copy        
        array = np.full( (len(self.load()), self.height(), self.width(), 1), dtype=np.float32, fill_value=bg)
        for (k,im) in enumerate(self):
            for bb in im.objects():
                if bb.hasintersection(im.imagebox()):
                    array[k, int(round(bb._ymin)):int(round(bb._ymax)), int(round(bb._xmin)):int(round(bb._xmax))] = fg   # does not need imclip
        return vipy.video.Video(array=array, framerate=self.framerate(), colorspace=&#39;float&#39;)
    
    def meanmask(self):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with mean color&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy                  
            im.meanmask()  # shared numpy array
        return self

    def fgmask(self):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with zero&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy                          
            im.fgmask()  # shared numpy array
        return self

    def zeromask(self):
        &#34;&#34;&#34;Alias for fgmask&#34;&#34;&#34;
        return self.fgmask()
    
    def blurmask(self, radius=7):
        &#34;&#34;&#34;Replace all pixels in foreground boxes with gaussian blurred foreground&#34;&#34;&#34;
        for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy                                  
            im.blurmask(radius)  # shared numpy array
        return self

    def downcast(self):
        &#34;&#34;&#34;Cast the object to a `vipy.video.Video` class&#34;&#34;&#34;
        self.__class__ = vipy.video.Video
        return self

    def merge_tracks(self, dilate_height=2.0, dilate_width=2.0, framedist=5):
        &#34;&#34;&#34;Merge tracks if a track endpoint dilated by a fraction overlaps exactly one track startpoint, and the endpoint and startpoint are close enough together temporally.
        
        .. note::
        - This is useful for continuing tracking when the detection framerate was too low and the assignment falls outside the measurement gate.
        - This will not work for complex scenes, as it assumes that there is exactly one possible continuation for a track.  
        
        &#34;&#34;&#34;
        merged = set([])
        for ti in sorted(self.tracklist(), key=lambda t: t.startframe()):
            for tj in sorted(self.tracklist(), key=lambda t: t.startframe()):
                if (tj.id() not in merged) and (ti.id() != tj.id()) and (tj.startframe() &gt;= ti.endframe()) and ((tj.startframe()-ti.endframe()) &lt;= framedist) and (ti.category() == tj.category()):
                    di = ti[ti.endframe()].dilate_height(dilate_height).dilate_width(dilate_width)
                    dj = tj[tj.startframe()]
                    if di.iou(dj) &gt; 0 and not any([di.iou(tk[tj.startframe()]) &gt; 0 for tk in self.tracklist() if (tk.id() not in [ti.id(), tj.id()]) and tk.during(tj.startframe())]):
                        self.tracks()[ti.id()] = ti.union(tj)  # Merge tracks that are within gating distance
                        self.delete(tj.id())  # remove merged track
                        merged.add(tj.id())
                        break
        return self

    def assign(self, frame, dets, minconf=0.2, maxhistory=5, activityiou=0.5, trackcover=0.2, trackconfsamples=4, gate=0, activitymerge=True, activitynms=False):
        &#34;&#34;&#34;Assign a list of `vipy.object.Detection` object detections and `vipy.activity.Activity` activity detections at frame k to scene tracks and activities by greedy assignment. In-place update.
        
        Approach:

            - This approach is equivalent to greedy, constant velocity SORT tracking (https://arxiv.org/abs/1602.00763) 
            - Individual detections are assigned to tracks using a greedy velocity only track propagation, sorted by `vipy.geometry.BoundingBox.maxcover` and detection confidence within a spatial tracking gate 
            - New tracks are created if the detection is unassigned and above a minimum confidence 
            - Updated tracks resulting from assignment are stored in `vipy.video.tracks` 

        Args:
        
            frame: [int] The frame index to assign the detections into the scene
            dets: [list] A list of `vipy.object.Detection` or `vipy.activity.Activity` objects as returned from a detector 
            miniou: [float] the minimum temporal IOU for activity assignment
            minconf: [float] the minimum confidence for a detection to be considered as a new track
            maxhistory: [int]  the maximum propagation length of a track with no measurements, the frame history used for velocity estimates  
            trackconfsamples: [int]  the number of uniformly spaced samples along a track to compute a mean track confidence
            gate: [int] the gating distance in pixels used for assignment of fast moving detections.  Useful for low detection framerates if a detection does not overlap with the track.
            trackcover: [float] the minimum cover necessary for assignment of a detection to a track
            activitymerge: [bool] if true, then merge overlapping activity detections of the same track and category, otherwise each activity detection is added as a new detection
            activitynms: [bool] if true, then perform non-maximum suppression of activity detections of the same actor and category that overlap more than activityiou

        Returns:

            This video object with each det assigned to corresponding track or activity.

        &#34;&#34;&#34;
        assert dets is None or all([isinstance(d, vipy.object.Detection) or isinstance(d, vipy.activity.Activity) for d in tolist(dets)]), &#34;invalid input&#34;
        assert frame &gt;= 0 and minconf &gt;= 0 and minconf &lt;= 1.0 and maxhistory &gt; 0, &#34;invalid input&#34;
        
        if dets is None or len(tolist(dets)) == 0:
            return self
        dets = tolist(dets)

        if any([d.confidence() is None for d in dets]):
            warnings.warn(&#39;Removing %d detections with no confidence&#39; % len([d.confidence() is None for d in dets]))
            dets = [d for d in dets if d.confidence() is not None]
        objdets = [d for d in dets if isinstance(d, vipy.object.Detection)]
        activitydets = [d for d in dets if isinstance(d, vipy.activity.Activity)]        

        # Object detection to track assignment
        if len(objdets) &gt; 0:
            # Track propagation:  Constant velocity motion model for active tracks 
            t_ref = [(t, t.linear_extrapolation(frame, dt=maxhistory, shape=False)) for (k,t) in self.tracks().items() if ((frame - t.endframe()) &lt;= maxhistory)]
            trackarea = [ti.area() for (t,ti) in t_ref]
            detarea = [d.area() for d in objdets]
            
            # Track assignment:
            #   - Each track is assigned at most one detection
            #   - Each detection is assigned to at most one track.  
            #   - Assignment is the highest confidence maximum overlapping detection by cover within tracking gate
            trackconf = {t.id():t.confidence(samples=trackconfsamples) for (t, ti) in t_ref}
            assignments = [(t, d.confidence(), d.iou(ti, area=detarea[j], otherarea=trackarea[i]), d.shapeiou(ti, area=detarea[j], otherarea=trackarea[i]), d.maxcover(ti, area=detarea[j], otherarea=trackarea[i]), d)
                           for (i, (t, ti)) in enumerate(t_ref)
                           for (j,d) in enumerate(objdets)
                           if (t.category() == d.category() and
                               (((ti._xmax if ti._xmax &lt; d._xmax else d._xmax) - (ti._xmin if ti._xmin &gt; d._xmin else d._xmin)) &gt; 0 and
                                ((ti._ymax if ti._ymax &lt; d._ymax else d._ymax) - (ti._ymin if ti._ymin &gt; d._ymin else d._ymin)) &gt; 0))]
            
            assigned = set([])        
            posconf = min([d.confidence() for d in objdets]) if len(objdets)&gt;0 else 0
            assignments.sort(key=lambda x: (x[1]+posconf)*(x[2]+x[3]+x[4])+trackconf[x[0].id()], reverse=True)  # in-place
            for (t, conf, iou, shapeiou, cover, d) in assignments:
                if cover &gt; (trackcover if len(t)&gt;1 else 0):  # the highest confidence detection within the assignment gate (or any overlap if not yet enough history for velocity estimate) 
                    if (t.id() not in assigned and d.id() not in assigned):  # not assigned yet, assign it!
                        self.track(t.id()).update(frame, d.clone())  # track assignment! (clone required)
                        assigned.add(t.id())  # cannot assign again to this track
                        assigned.add(d.id())  # mark detection as assigned
                
            # Track spawn from unassigned and unexplained detections 
            for (j,d) in enumerate(objdets):                
                if (d.id() not in assigned):
                    if (d.confidence() &gt;= minconf and not any([t.linear_extrapolation(frame, dt=maxhistory, shape=False).maxcover(d, otherarea=detarea[j]) &gt;= 0.7 for (i,(t,ti)) in enumerate(t_ref) if t.category() == d.category()])):
                        gated = [(t, t.linear_extrapolation(frame, dt=maxhistory, shape=False)) for (t,ti) in t_ref if (t.id() not in assigned and t.category() == d.category())] if gate&gt;0 else []
                        gated = sorted([(t, ti) for (t, ti) in gated if ti.hasintersection(d, gate=gate)], key=lambda x: d.sqdist(x[1]))
                        if len(gated) &gt; 0:
                            self.track(gated[0][0].id()).update(frame, d.clone())  # track assignment! (clone required)
                            assigned.add(gated[0][0].id())
                            assigned.add(d.id())
                        else:
                            assigned.add(self.add(vipy.object.Track(keyframes=[frame], boxes=[d.clone()], category=d.category(), framerate=self.framerate()), rangecheck=False))  # clone required
                            assigned.add(d.id())

        # Activity assignment
        if len(activitydets) &gt; 0:
            assert all([d.actorid() in self.tracks() for d in activitydets]), &#34;Invalid activity&#34;
            assigned = set([])
            if activitymerge:
                minframe = min([a._startframe for a in activitydets]) 
                activities = [a for a in self.activities().values() if a._endframe &gt;= minframe]
                for d in activitydets:
                    for a in activities:
                        if (a._label == d._label) and (a._actorid == d._actorid) and a.hasoverlap(d, activityiou): 
                            a.union(d)  # activity assignment 
                            assigned.add(d._id)
                            break  # assigned, early exit
                        
            if activitynms:
                minframe = min([a._startframe for a in activitydets]) 
                activities = sorted([a for a in self.activities().values() if a._endframe &gt;= minframe], key=lambda a: a.confidence(), reverse=True)
                for d in sorted(activitydets, key=lambda x: x.confidence(), reverse=True):
                    for a in activities:
                        if (a._label == d._label) and (a._actorid == d._actorid) and a.hasoverlap(d, activityiou):
                            assigned.add(a._id if d.confidence()&gt;a.confidence() else d._id)  # suppressed
                for id in assigned:
                    if id in self._activities:
                        del self._activities[id]  # suppression, faster than self.activityfilter(lambda a: a.id() in assigned)
                                    
            # Activity construction from unassigned detections
            for d in activitydets:
                if d._id not in assigned:
                    self.add(d.clone())  

        return self</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="vipy.video.VideoCategory" href="#vipy.video.VideoCategory">VideoCategory</a></li>
<li><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="vipy.video.Scene.asjson"><code class="name flex">
<span>def <span class="ident">asjson</span></span>(<span>s)</span>
</code></dt>
<dd>
<div class="desc"><p>Restore an object serialized with self.json().
Alas for <code><a title="vipy.video.Scene.from_json" href="#vipy.video.Scene.from_json">Scene.from_json()</a></code>.</p>
<p>Usage:</p>
<pre><code class="language-python">vs = vipy.video.Scene.asjson(v.json())
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2548-L2559" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@classmethod
def asjson(cls, s):
    &#34;&#34;&#34;Restore an object serialized with self.json().  Alas for `vipy.video.Scene.from_json`.
    
    Usage:

    ```python
    vs = vipy.video.Scene.asjson(v.json())
    ```

    &#34;&#34;&#34;
    return vipy.video.Scene.from_json(s)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.cast"><code class="name flex">
<span>def <span class="ident">cast</span></span>(<span>v, flush=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Cast a conformal vipy object to this class.
This is useful for downcast and upcast conversion of video objects.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2537-L2546" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@classmethod
def cast(cls, v, flush=False):
    &#34;&#34;&#34;Cast a conformal vipy object to this class.  This is useful for downcast and upcast conversion of video objects.&#34;&#34;&#34;
    assert isinstance(v, vipy.video.Video), &#34;Invalid input - must be derived from vipy.video.Video&#34;
    if v.__class__ != vipy.video.Scene:
        v.__class__ = vipy.video.Scene            
        v._tracks = {} if flush or not hasattr(v, &#39;_tracks&#39;) else v._tracks
        v._activities = {} if flush or not hasattr(v, &#39;_activities&#39;) else v._activities
        v._category = None if flush or not hasattr(v, &#39;_category&#39;) else v._category
    return v</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>s)</span>
</code></dt>
<dd>
<div class="desc"><p>Restore an object serialized with self.json()</p>
<p>Usage:</p>
<pre><code class="language-python">vs = vipy.video.Scene.from_json(v.json())
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2561-L2586" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@classmethod
def from_json(cls, s):
    &#34;&#34;&#34;Restore an object serialized with self.json()
    
    Usage:
    
    ```python
    vs = vipy.video.Scene.from_json(v.json())
    ```

    &#34;&#34;&#34;

    d = json.loads(s) if not isinstance(s, dict) else s                                
    v = super().from_json(s)

    # Packed attribute storage:
    #   - When loading a large number of vipy objects, the python garbage collector slows down signficantly due to reference cycle counting
    #   - Mutable objects and custom containers are tracked by the garbage collector and the more of them that are loaded the longer GC takes
    #   - To avoid this, load attributes as tuples of packed strings.  This is an immutable type that is not reference counted.  Check this with gc.is_tracked()
    #   - Then, unpack load the attributes on demand when accessing tracks() or activities().  Then, the nested containers are reference counted (even though they really should not since there are no cycles by construction)
    #   - This is useful when calling vipy.util.load(...) on archives that contain hundreds of thousands of objects
    #   - Do not access the private attributes self._tracks and self._attributes as they will be packed until needed
    #   - Should install ultrajson (pip install ujson) for super fast parsing
    v._tracks = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_tracks&#39;].values()])  # track ID key is embedded in object, legacy unpack of doubly JSON encoded strings (vipy-1.11.16)
    v._activities = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_activities&#39;].values()])  # track ID key is embedded in object, legacy unpack of doubly JSON encoded strings (vipy-1.11.16)
    return v</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="vipy.video.Scene.activities"><code class="name flex">
<span>def <span class="ident">activities</span></span>(<span>self, activities=None, id=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return mutable dictionary of activities.
All temporal alignment is relative to the current clip().</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2883-L2898" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activities(self, activities=None, id=None):
    &#34;&#34;&#34;Return mutable dictionary of activities.  All temporal alignment is relative to the current clip().&#34;&#34;&#34;
    if isinstance(self._activities, tuple):
        self._activities = {a.id():a for a in [vipy.activity.Activity.from_json(json.loads(s)) for s in self._activities]}  # on-demand
    if activities is None and id is None:
        return self._activities  # mutable dict
    elif id is not None:
        return self._activities[id]
    elif isinstance(activities, dict):
        assert all([isinstance(a, vipy.activity.Activity) and k == a.id() for (k,a) in activities.items()]), &#34;Invalid input - Must be dictionary of vipy.activity.Activity&#34;
        self._activities = activities.copy()  # shallow copy
        return self
    else:
        assert all([isinstance(a, vipy.activity.Activity) for a in tolist(activities)]), &#34;Invalid input - Must be vipy.activity.Activity or list of vipy.activity.Activity&#34;
        self._activities = {a.id():a for a in tolist(activities)}   # insertion order preserved (python &gt;=3.6)
        return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activity"><code class="name flex">
<span>def <span class="ident">activity</span></span>(<span>self, id=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2806-L2807" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activity(self, id=None):
    return self.activities(id=id) if id is not None else self.primary_activity()</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activity_categories"><code class="name flex">
<span>def <span class="ident">activity_categories</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for activitylabels()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3070-L3072" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activity_categories(self):
    &#34;&#34;&#34;Alias for activitylabels()&#34;&#34;&#34;
    return self.activitylabels()        </code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activitybox"><code class="name flex">
<span>def <span class="ident">activitybox</span></span>(<span>self, activityid=None, dilate=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>The activitybox is the union of all activity bounding boxes in the video, which is the union of all tracks contributing to all activities.
This is most useful after activityclip().
The activitybox is the smallest bounding box that contains all of the boxes from all of the tracks in all activities in this video.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3446-L3452" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activitybox(self, activityid=None, dilate=1.0):
    &#34;&#34;&#34;The activitybox is the union of all activity bounding boxes in the video, which is the union of all tracks contributing to all activities.  This is most useful after activityclip().
       The activitybox is the smallest bounding box that contains all of the boxes from all of the tracks in all activities in this video.
    &#34;&#34;&#34;
    activities = [a for (k,a) in self.activities().items() if (activityid is None or k in set(activityid))]
    boxes = [t.clone().boundingbox().dilate(dilate) for t in self.tracklist() if any([a.hastrack(t) for a in activities])]
    return boxes[0].union(boxes[1:]) if len(boxes) &gt; 0 else vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(self.width()), height=int(self.height()))</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activityclip"><code class="name flex">
<span>def <span class="ident">activityclip</span></span>(<span>self, padframes=0, multilabel=True, idx=None, padto=None, padtosec=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a list of <code><a title="vipy.video.Scene" href="#vipy.video.Scene">Scene</a></code> objects each clipped to be temporally centered on a single activity, with an optional padframes before and after.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>padframes</code></strong></dt>
<dd>[int] for symmetric padding same before and after</dd>
<dt><strong><code>padframes</code></strong></dt>
<dd>[tuple] (int, int) for asymmetric padding before and after</dd>
<dt><strong><code>padframes</code></strong></dt>
<dd>[list[tuples]] [(int, int), &hellip;] for activity specific asymmetric padding.
See also padto.</dd>
<dt><strong><code>multilabel</code></strong></dt>
<dd>[bool] include overlapping multilabel secondary activities in each activityclip</dd>
<dt><strong><code>idx</code></strong></dt>
<dd>[int], [tuple], [list].
The indexes of the activities to return, where the index is the integer index order of the activity in the video.
Useful for complex videos.</dd>
<dt><strong><code>padto</code></strong></dt>
<dd>[int] padding so that each activity clip is at least padto frames long, with symmetric padding around the activity.
</dd>
<dt><strong><code>padtosec</code></strong></dt>
<dd>[float] padding so that each activity clip is at least padtosec seconds long, with symmetric padding around the activity.
</dd>
</dl>
<div class="admonition notes">
<p class="admonition-title">Notes</p>
<ul>
<li>The Scene() category is updated to be the activity category of the clip, and only the objects participating in the activity are included.</li>
<li>Clips are returned ordered in the temporal order they appear in the video.</li>
<li>The returned vipy.video.Scene() objects for each activityclip are clones of the video, with the video buffer flushed.</li>
<li>Each activityclip() is associated with each activity in the scene, and includes all other secondary activities that the objects in the primary activity also perform (if multilabel=True).
See activityclip().labels(). </li>
<li>Calling activityclip() on activityclip(multilabel=True) will duplicate activities, due to the overlapping secondary activities being included in each clip with an overlap.
Be careful!</li>
</ul>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3312-L3361" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activityclip(self, padframes=0, multilabel=True, idx=None, padto=None, padtosec=None):
    &#34;&#34;&#34;Return a list of `vipy.video.Scene` objects each clipped to be temporally centered on a single activity, with an optional padframes before and after.  

    Args:
        padframes: [int] for symmetric padding same before and after
        padframes: [tuple] (int, int) for asymmetric padding before and after
        padframes: [list[tuples]] [(int, int), ...] for activity specific asymmetric padding.  See also padto.
        multilabel: [bool] include overlapping multilabel secondary activities in each activityclip
        idx: [int], [tuple], [list].  The indexes of the activities to return, where the index is the integer index order of the activity in the video.  Useful for complex videos.
        padto: [int] padding so that each activity clip is at least padto frames long, with symmetric padding around the activity.  
        padtosec: [float] padding so that each activity clip is at least padtosec seconds long, with symmetric padding around the activity.  

    Returns:
        A list of `vipy.video.Scene` each cloned from the source video and clipped on one activity in the scene

    .. notes::
       - The Scene() category is updated to be the activity category of the clip, and only the objects participating in the activity are included.
       - Clips are returned ordered in the temporal order they appear in the video.
       - The returned vipy.video.Scene() objects for each activityclip are clones of the video, with the video buffer flushed.
       - Each activityclip() is associated with each activity in the scene, and includes all other secondary activities that the objects in the primary activity also perform (if multilabel=True).  See activityclip().labels(). 
       - Calling activityclip() on activityclip(multilabel=True) will duplicate activities, due to the overlapping secondary activities being included in each clip with an overlap.  Be careful!
    &#34;&#34;&#34;
    assert isinstance(padframes, int) or istuple(padframes) or islist(padframes)

    vid = self.clone(flushforward=True)
    if any([(a.endframe()-a.startframe()) &lt;= 0 for a in vid.activities().values()]):
        warnings.warn(&#39;Filtering invalid activity clips with degenerate lengths: %s&#39; % str([a for a in vid.activities().values() if (a.endframe()-a.startframe()) &lt;= 0]))
    primary_activities = sorted([a.clone() for a in vid.activities().values() if (a.endframe()-a.startframe()) &gt; 0], key=lambda a: a.startframe())   # only activities with at least one frame, sorted in temporal order
    padframelist = [padframes if istuple(padframes) else (padframes, padframes) for k in range(len(primary_activities))] if not islist(padframes) else padframes                    
    tracks = [ [t.clone() for (tid, t) in vid.tracks().items() if a.hastrackoverlap(t)] for a in primary_activities]  # tracks associated with and temporally overlapping each primary activity (may be empty)
    secondary_activities = [[sa.clone() for sa in primary_activities if (sa.id() != pa.id() and pa.clone().temporalpad((prepad, postpad)).hasoverlap(sa) and (len(T)==0 or any([sa.hastrack(t) for t in T])))] for (pa, T, (prepad,postpad)) in zip(primary_activities, tracks, padframelist)]  # overlapping secondary activities that includes any track in the primary activity
    secondary_activities = [sa if multilabel else [] for sa in secondary_activities]  
    vid._activities = {}  # for faster clone
    vid._tracks = {}      # for faster clone
    maxframes = self.duration_in_frames() if (padframes != 0 or padto is not None or padtosec is not None) else None                    
    if padto is not None or padtosec is not None:
        cliplist = [(a.startframe(), a.endframe()) for a in primary_activities]
        padto = padto if padto is not None else int(round(padtosec*self.framerate()))            
        padframelist = [(sp+int(np.ceil(((padto-(ef-sf))/2))), ep+int(np.ceil(((padto-(ef-sf))/2)))) if (ef-sf)&lt;padto else (sp,ep) for ((sp,ep),(sf,ef)) in zip(padframelist, cliplist)]  
        padframelist = [(0,ep+(-sp)) if (sp&lt;0) else ((sp+(ep-(maxframes-ef)), maxframes-ef) if ((ef+ep)&gt;maxframes) else (sp,ep)) for ((sp,ep),(sf,ef)) in zip(padframelist, cliplist)]  # truncate to video boundary
        
    return [vid.clone()
            .activities([pa]+sa)  # primary activity first
            .tracks(t)
            .clip(startframe=max(pa.startframe()-prepad, 0), endframe=min(pa.endframe()+postpad, (maxframes if maxframes is not None else pa.endframe()+postpad)))
            .category(pa.category())
            .setactorid(pa.actorid())  # actor is actor of primary activity
            .setattribute(&#39;_instance_id&#39;, (&#39;%s_%d&#39; % (vid.videoid(), k)) if not vid.hasattribute(&#39;_instance_id&#39;) else vid.getattribute(&#39;_instance_id&#39;))
            for (k,(pa,sa,t,(prepad,postpad))) in enumerate(zip(primary_activities, secondary_activities, tracks, padframelist))
            if (idx is None or k in tolist(idx))]</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activitycuboid"><code class="name flex">
<span>def <span class="ident">activitycuboid</span></span>(<span>self, activityid=None, dilate=1.0, maxdim=256, bb=None)</span>
</code></dt>
<dd>
<div class="desc"><p>The activitycuboid() is the fixed square spatial crop corresponding to the activitybox (or supplied bounding box), which contains all of the valid activities in the scene.
This is most useful after activityclip().
The activitycuboid() is a spatial crop of the video corresponding to the supplied boundingbox or the square activitybox().
This crop must be resized such that the maximum dimension is provided since the crop can be tiny and will not be encodable by ffmpeg</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3454-L3462" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activitycuboid(self, activityid=None, dilate=1.0, maxdim=256, bb=None):
    &#34;&#34;&#34;The activitycuboid() is the fixed square spatial crop corresponding to the activitybox (or supplied bounding box), which contains all of the valid activities in the scene.  This is most useful after activityclip().
       The activitycuboid() is a spatial crop of the video corresponding to the supplied boundingbox or the square activitybox().
       This crop must be resized such that the maximum dimension is provided since the crop can be tiny and will not be encodable by ffmpeg
    &#34;&#34;&#34;
    bb = self.activitybox(activityid).maxsquare() if bb is None else bb  
    assert bb is None or isinstance(bb, vipy.geometry.BoundingBox)
    assert bb.issquare(), &#34;Add support for non-square boxes&#34;
    return self.clone().crop(bb.dilate(dilate).int(), zeropad=True).resize(maxdim, maxdim)  # crop triggers preview()</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activityfilter"><code class="name flex">
<span>def <span class="ident">activityfilter</span></span>(<span>self, f)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply boolean lambda function f to each activity and keep activity if function is true, remove activity if function is false</p>
<p>Filter out all activities longer than 128 frames </p>
<pre><code class="language-python">vid = vid.activityfilter(lambda a: len(a)&lt;128)
</code></pre>
<p>Filter out activities with category in set</p>
<pre><code class="language-python">vid = vid.activityfilter(lambda a: a.category() in set(['category1', 'category2']))
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>f</code></strong></dt>
<dd>[lambda] a lambda function that takes an activity and returns a boolean</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>This video with the activities f(a)==False removed.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2916-L2940" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activityfilter(self, f):
    &#34;&#34;&#34;Apply boolean lambda function f to each activity and keep activity if function is true, remove activity if function is false
    
    Filter out all activities longer than 128 frames 

    ```python
    vid = vid.activityfilter(lambda a: len(a)&lt;128)
    ```

    Filter out activities with category in set

    ```python
    vid = vid.activityfilter(lambda a: a.category() in set([&#39;category1&#39;, &#39;category2&#39;]))
    ```
   
    Args:
        f: [lambda] a lambda function that takes an activity and returns a boolean

    Returns:
        This video with the activities f(a)==False removed.

    &#34;&#34;&#34;
    assert callable(f)
    self._activities = {k:a for (k,a) in self.activities().items() if f(a) == True}
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activityindex"><code class="name flex">
<span>def <span class="ident">activityindex</span></span>(<span>self, k)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the <code><a title="vipy.activity.Activity" href="activity.html#vipy.activity.Activity">Activity</a></code> at the requested index order in the video</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2900-L2904" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activityindex(self, k):
    &#34;&#34;&#34;Return the `vipy.activity.Activity` at the requested index order in the video&#34;&#34;&#34;
    alist = self.activitylist()
    assert k &gt;= 0 and k &lt; len(alist), &#34;Invalid index&#34;        
    return alist[k]</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activitylabel"><code class="name flex">
<span>def <span class="ident">activitylabel</span></span>(<span>self, startframe=None, endframe=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return an iterator over activity labels in each frame, starting from startframe and ending when there are no more activities</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3038-L3044" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activitylabel(self, startframe=None, endframe=None):
    &#34;&#34;&#34;Return an iterator over activity labels in each frame, starting from startframe and ending when there are no more activities&#34;&#34;&#34;        
    endframe = endframe if endframe is not None else (max([a.endframe() for a in self.activitylist()]) if len(self.activities())&gt;0 else 0)
    startframe = startframe if startframe is not None else (min([a.startframe() for a in self.activitylist()]) if len(self.activities())&gt;0 else 0)
    assert startframe &lt;= endframe
    for k in range(startframe, endframe):
        yield self.activitylabels(k)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activitylabels"><code class="name flex">
<span>def <span class="ident">activitylabels</span></span>(<span>self, startframe=None, endframe=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a set of all activity categories in this scene, or at startframe, or in range [startframe, endframe]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3046-L3055" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activitylabels(self, startframe=None, endframe=None):
    &#34;&#34;&#34;Return a set of all activity categories in this scene, or at startframe, or in range [startframe, endframe]&#34;&#34;&#34;        
    if startframe is None:
        return set([a.category() for a in self.activities().values()])
    elif startframe is not None and endframe is None:
        return set([a.category() for a in self.activities().values() if a.during(startframe)])
    elif startframe is not None and endframe is not None:
        return [set([a.category() for a in self.activities().values() if a.during(k)]) for k in range(startframe, endframe)] 
    else:
        raise ValueError(&#39;Invalid input - must specify both startframe and endframe, or only startframe&#39;)            </code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activitylist"><code class="name flex">
<span>def <span class="ident">activitylist</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a list of activities in the video, returned in insertion order.</p>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;The order of the activitylist() will not match the order of activityclip(), which is sorted by activity startframe.
To match, use sorted(activitylist, key=lambda a: a.startframe())</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2906-L2914" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activitylist(self):
    &#34;&#34;&#34;Return a list of activities in the video, returned in insertion order.

    Returns:
        A list of `vipy.activity.Activity` insertion ordered into the original video

    .. note::  The order of the activitylist() will not match the order of activityclip(), which is sorted by activity startframe.  To match, use sorted(activitylist, key=lambda a: a.startframe())
    &#34;&#34;&#34;
    return list(self.activities().values())  # insertion ordered (python &gt;=3.6), triggers shallow copy</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activitymap"><code class="name flex">
<span>def <span class="ident">activitymap</span></span>(<span>self, f)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply lambda function f to each activity</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2972-L2977" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activitymap(self, f):
    &#34;&#34;&#34;Apply lambda function f to each activity&#34;&#34;&#34;
    assert callable(f)
    self._activities = {k:f(a) for (k,a) in self.activities().items()}
    assert all([isinstance(a, vipy.activity.Activity) for a in self.activitylist()]), &#34;Lambda function must return vipy.activity.Activity()&#34;
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activitysplit"><code class="name flex">
<span>def <span class="ident">activitysplit</span></span>(<span>self, idx=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Split the scene into k separate scenes, one for each activity.
Do not include overlapping activities.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>idx</code></strong></dt>
<dd>[int],[tuple],[list].
Return only those activities in the provided activity index list, where the activity index is the integer index of the activity in the video.</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;This is useful for union()</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3276-L3296" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activitysplit(self, idx=None):
    &#34;&#34;&#34;Split the scene into k separate scenes, one for each activity.  Do not include overlapping activities.  

    Args:
        idx: [int],[tuple],[list].  Return only those activities in the provided activity index list, where the activity index is the integer index of the activity in the video.

    .. note:: This is useful for union()
    &#34;&#34;&#34;
    vid = self.clone(flushforward=True)
    if any([(a.endframe()-a.startframe()) &lt;= 0 for a in vid.activities().values()]):
        warnings.warn(&#39;Filtering invalid activity with degenerate lengths: %s&#39; % str([a for a in vid.activities().values() if (a.endframe()-a.startframe()) &lt;= 0]))
    activities = sorted([a.clone() for a in vid.activities().values() if (a.endframe()-a.startframe()) &gt; 0], key=lambda a: a.startframe())   # only activities with at least one frame, sorted in temporal order
    tracks = [ [t.clone() for (tid, t) in vid.tracks().items() if a.hastrack(t)] for a in activities]  # tracks associated with each activity (may be empty)
    vid._activities = {}  # for faster clone
    vid._tracks = {}      # for faster clone
    return [vid.clone()
            .setattribute(&#39;_instance_id&#39;, (&#39;%s_%d&#39; % (vid.videoid(), k)) if not vid.hasattribute(&#39;_instance_id&#39;) else vid.getattribute(&#39;_instance_id&#39;))
            .activities(pa)
            .tracks(t)
            .setactorid(pa.actorid())
            for (k,(pa,t)) in enumerate(zip(activities, tracks)) if idx is None or k in tolist(idx)]</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activitysquare"><code class="name flex">
<span>def <span class="ident">activitysquare</span></span>(<span>self, activityid=None, dilate=1.0, maxdim=256)</span>
</code></dt>
<dd>
<div class="desc"><p>The activity square is the maxsquare activitybox that contains only valid (non-padded) pixels interior to the image</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3464-L3467" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activitysquare(self, activityid=None, dilate=1.0, maxdim=256):
    &#34;&#34;&#34;The activity square is the maxsquare activitybox that contains only valid (non-padded) pixels interior to the image&#34;&#34;&#34;
    bb = self.activitybox(activityid).maxsquare().dilate(dilate).int().iminterior(self.width(), self.height()).minsquare()
    return self.activitycuboid(activityid, dilate=1.0, maxdim=maxdim, bb=bb)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.activitytube"><code class="name flex">
<span>def <span class="ident">activitytube</span></span>(<span>self, activityid=None, dilate=1.0, maxdim=256)</span>
</code></dt>
<dd>
<div class="desc"><p>The activitytube() is a sequence of crops where the spatial box changes on every frame to track the activity.<br>
The box in each frame is the square activitybox() for this video which is the union of boxes contributing to this activity in each frame.
This function does not perform any temporal clipping.
Use activityclip() first to split into individual activities.<br>
Crops will be optionally dilated, with zeropadding if the box is outside the image rectangle.
All crops will be resized so that the maximum dimension is maxdim (and square by default)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3469-L3489" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def activitytube(self, activityid=None, dilate=1.0, maxdim=256):
    &#34;&#34;&#34;The activitytube() is a sequence of crops where the spatial box changes on every frame to track the activity.  
       The box in each frame is the square activitybox() for this video which is the union of boxes contributing to this activity in each frame.
       This function does not perform any temporal clipping.  Use activityclip() first to split into individual activities.  
       Crops will be optionally dilated, with zeropadding if the box is outside the image rectangle.  All crops will be resized so that the maximum dimension is maxdim (and square by default)
    &#34;&#34;&#34;
    vid = self.clone().load()  # triggers load
    self.activityfilter(lambda a: activityid is None or a.id() in set(activityid))  # only requested IDs (or all of them)
    frames = [im.padcrop(im.boundingbox().maxsquare().dilate(dilate).int()).resize(maxdim, maxdim) for im in vid if im.boundingbox() is not None]  # track interpolation, for frames with boxes only
    if len(frames) != len(vid):
        warnings.warn(&#39;[vipy.video.activitytube]: Removed %d frames with no spatial bounding boxes&#39; % (len(vid) - len(frames)))
        vid.attributes[&#39;__activtytube&#39;] = {&#39;truncated&#39;:len(vid) - len(frames)}  # provenance to reject
    if len(frames) == 0:
        warnings.warn(&#39;[vipy.video.activitytube]: Resulting video is empty!  Setting activitytube to zero&#39;)
        frames = [ vid[0].resize(maxdim, maxdim).zeros() ]  # empty frame
        vid.attributes[&#39;__activitytube&#39;] = {&#39;empty&#39;:True}   # provenance to reject 
    vid._tracks = {ti:vipy.object.Track(keyframes=[f for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],
                                        boxes=[d for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],
                                        category=t.category(), trackid=ti, framerate=self.framerate())
                   for (k,(ti,t)) in enumerate(self.tracks().items())}  # replace tracks with boxes relative to tube
    return vid.array(np.stack([im.numpy() for im in frames]))</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.actor"><code class="name flex">
<span>def <span class="ident">actor</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the primary actor (first <code><a title="vipy.object.Track" href="object.html#vipy.object.Track">Track</a></code>) in the video</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2860-L2862" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def actor(self):
    &#34;&#34;&#34;Return the primary actor (first `vipy.object.Track`) in the video&#34;&#34;&#34;
    return next(iter(self.tracks().values())) if len(self._tracks)&gt;0 else None   # Python &gt;=3.6</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.actorid"><code class="name flex">
<span>def <span class="ident">actorid</span></span>(<span>self, id=None, fluent=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Return or set the actor ID for the video.</p>
<ul>
<li>The actor ID is the track ID of the primary actor in the scene.
This is useful for assigning a role for activities that are performed by the actor.</li>
<li>The actor ID is the first track is in the tracklist
</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>id</code></strong></dt>
<dd>[str] if not None, then use this track ID as the actor</dd>
<dt><strong><code>fluent</code></strong></dt>
<dd>[bool] If true, always return self. This is useful for those cases where the actorid being set is None.</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;Not to be confused with biometric subject id.
For videos collected with Visym Collector platform (<a href="https://visym.com/collector">https://visym.com/collector</a>), the biometric subject ID can be retrieved via <code><a title="vipy.video.Video.metadata" href="#vipy.video.Video.metadata">Video.metadata()</a></code> (e.g. self.metadata()['subject_ids']).</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2830-L2854" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def actorid(self, id=None, fluent=False):
    &#34;&#34;&#34;Return or set the actor ID for the video.

    - The actor ID is the track ID of the primary actor in the scene.  This is useful for assigning a role for activities that are performed by the actor.
    - The actor ID is the first track is in the tracklist       
    
    Args:
        id: [str] if not None, then use this track ID as the actor
        fluent: [bool] If true, always return self. This is useful for those cases where the actorid being set is None.
    
    Returns:
        [id=None, fluent=False] the actor ID
        [id is not None] The video with the actor ID set, only if the ID is found in the tracklist

    .. note:: Not to be confused with biometric subject id.  For videos collected with Visym Collector platform (https://visym.com/collector), the biometric subject ID can be retrieved via `vipy.video.Video.metadata` (e.g. self.metadata()[&#39;subject_ids&#39;]).
    &#34;&#34;&#34;
    if id is None:
        return next(iter(self.tracks().keys())) if not fluent else self  # Python &gt;=3.6
    elif id in self._tracks:
        # Reorder tracks so that id is first
        idlist = [id] + [ti for ti in self.tracks().keys() if ti != id]
        self._tracks = {k:self.track(k) for k in idlist}
    else:
        warnings.warn(&#39;trackid=%s not found in &#34;%s&#34;&#39; % (str(id), str(self)))
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.actortube"><code class="name flex">
<span>def <span class="ident">actortube</span></span>(<span>self, trackid=None, dilate=1.0, maxdim=256, strict=True)</span>
</code></dt>
<dd>
<div class="desc"><p>The actortube() is a sequence of crops where the spatial box changes on every frame to track the primary actor performing an activity.<br>
The box in each frame is the square box centered on the primary actor performing the activity, dilated by a given factor (the original box around the actor is unchanged, this just increases the context, with zero padding)
This function does not perform any temporal clipping.
Use activityclip() first to split into individual activities.<br>
All crops will be resized so that the maximum dimension is maxdim (and square by default)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3491-L3514" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def actortube(self, trackid=None, dilate=1.0, maxdim=256, strict=True):
    &#34;&#34;&#34;The actortube() is a sequence of crops where the spatial box changes on every frame to track the primary actor performing an activity.  
       The box in each frame is the square box centered on the primary actor performing the activity, dilated by a given factor (the original box around the actor is unchanged, this just increases the context, with zero padding)
       This function does not perform any temporal clipping.  Use activityclip() first to split into individual activities.  
       All crops will be resized so that the maximum dimension is maxdim (and square by default)
    &#34;&#34;&#34;
    assert trackid is not None or len(self.tracks()) == 1, &#34;Track ID must be provided if there exists more than one track in the scene&#34;
    trackid = trackid if trackid is not None else list(self.tracks().keys())[0]
    assert self.hastrack(trackid), &#34;Track ID %s not found - Actortube requires a track ID in the scene (tracks=%s)&#34; % (str(trackid), str(self.tracks()))
    vid = self.clone().load()  # triggers load        
    t = vid.tracks(id=trackid)  # actor track
    frames = [im.padcrop(t[k].maxsquare().dilate(dilate).int()).resize(maxdim, maxdim) for (k,im) in enumerate(vid) if t.during(k)] if len(t)&gt;0 else []  # actor interpolation, padding may introduce frames with no tracks
    if len(frames) == 0:
        if not strict:
            warnings.warn(&#39;[vipy.video.actortube]: Empty track for trackid=&#34;%s&#34; - Setting actortube to zero&#39; % trackid)
            frames = [ vid[0].resize(maxdim, maxdim).zeros() ]  # empty frame
            vid.attributes[&#39;__actortube&#39;] = {&#39;empty&#39;:True}   # provenance to reject             
        else:
            raise ValueError(&#39;[vipy.video.actortube]: Empty track for track=%s, trackid=%s&#39; % (str(t), trackid))
    vid._tracks = {ti:vipy.object.Track(keyframes=[f for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],  # keyframes zero indexed, relative to [frames]
                                        boxes=[d for (f,im) in enumerate(frames) for d in im.objects() if d.attributes[&#39;trackid&#39;] == ti],  # one box per frame
                                        category=t.category(), trackid=ti, framerate=self.framerate())  # preserve trackid
                   for (k,(ti,t)) in enumerate(self.tracks().items())}  # replace tracks with interpolated boxes relative to tube defined by actor
    return vid.array(np.stack([im.numpy() for im in frames]))</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.add"><code class="name flex">
<span>def <span class="ident">add</span></span>(<span>self, obj, category=None, attributes=None, rangecheck=True, frame=None, fluent=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Add the object obj to the scene, and return an index to this object for future updates</p>
<p>This function is used to incrementally build up a scene frame by frame.
Obj can be one of the following types:</p>
<ul>
<li>obj = vipy.object.Detection(), this must be called from within a frame iterator (e.g. for im in video) to get the current frame index</li>
<li>obj = vipy.object.Track()
</li>
<li>obj = vipy.activity.Activity()</li>
<li>obj = [xmin, ymin, width, height], with associated category kwarg, this must be called from within a frame iterator to get the current frame index</li>
</ul>
<p>It is recomended that the objects are added as follows.
For a v=vipy.video.Scene():</p>
<pre><code class="language-python">    for im in v:
        # Do some processing on frame im to detect objects
        (object_labels, xywh) = object_detection(im)

        # Add them to the scene, note that each object instance is independent in each frame, use tracks for object correspondence
        for (lbl,bb) in zip(object_labels, xywh):
            v.add(bb, lbl)

        # Do some correspondences to track objects
        t2 = v.add( vipy.object.Track(...) )

        # Update a previous track to add a keyframe
        v.track(t2).add( ... )
</code></pre>
<p>The frame iterator will keep track of the current frame in the video and add the objects in the appropriate place.
Alternatively,</p>
<pre><code class="language-python">    v.add(vipy.object.Track(..), frame=k)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>obj</code></strong></dt>
<dd>A conformal python object to add to the scene (<code><a title="vipy.object.Detection" href="object.html#vipy.object.Detection">Detection</a></code>, <code><a title="vipy.object.Track" href="object.html#vipy.object.Track">Track</a></code>, <code><a title="vipy.activity.Activity" href="activity.html#vipy.activity.Activity">Activity</a></code>, [xmin, ymin, width, height]</dd>
<dt><strong><code>category</code></strong></dt>
<dd>Used if obj is an xywh tuple</dd>
<dt><strong><code>attributes</code></strong></dt>
<dd>Used only if obj is an xywh tuple</dd>
<dt><strong><code>frame</code></strong></dt>
<dd>[int] The frame to add the object</dd>
<dt><strong><code>rangecheck</code></strong></dt>
<dd>[bool] If true, check if the object is within the image rectangle and throw an exception if not.
This requires introspecting the video shape using <code><a title="vipy.video.Video.shape" href="#vipy.video.Video.shape">Video.shape()</a></code>.</dd>
<dt><strong><code>fluent</code></strong></dt>
<dd>[bool] If true, return self instead of the object index</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3093-L3172" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def add(self, obj, category=None, attributes=None, rangecheck=True, frame=None, fluent=False):
    &#34;&#34;&#34;Add the object obj to the scene, and return an index to this object for future updates
    
    This function is used to incrementally build up a scene frame by frame.  Obj can be one of the following types:

    - obj = vipy.object.Detection(), this must be called from within a frame iterator (e.g. for im in video) to get the current frame index
    - obj = vipy.object.Track()  
    - obj = vipy.activity.Activity()
    - obj = [xmin, ymin, width, height], with associated category kwarg, this must be called from within a frame iterator to get the current frame index
    
    It is recomended that the objects are added as follows.  For a v=vipy.video.Scene():
       
    ```python
        for im in v:
            # Do some processing on frame im to detect objects
            (object_labels, xywh) = object_detection(im)
    
            # Add them to the scene, note that each object instance is independent in each frame, use tracks for object correspondence
            for (lbl,bb) in zip(object_labels, xywh):
                v.add(bb, lbl)
    
            # Do some correspondences to track objects
            t2 = v.add( vipy.object.Track(...) )
    
            # Update a previous track to add a keyframe
            v.track(t2).add( ... )
    ```
    
    The frame iterator will keep track of the current frame in the video and add the objects in the appropriate place.  Alternatively,

    ```python
        v.add(vipy.object.Track(..), frame=k)
    ```

    Args:
        obj: A conformal python object to add to the scene (`vipy.object.Detection`, `vipy.object.Track`, `vipy.activity.Activity`, [xmin, ymin, width, height]
        category:  Used if obj is an xywh tuple
        attributes:  Used only if obj is an xywh tuple
        frame:  [int] The frame to add the object
        rangecheck: [bool] If true, check if the object is within the image rectangle and throw an exception if not.  This requires introspecting the video shape using `vipy.video.Video.shape`.
        fluent: [bool] If true, return self instead of the object index 

    &#34;&#34;&#34;        
    if isinstance(obj, vipy.object.Detection):
        assert frame is not None, &#34;add() for vipy.object.Detection() must be added during frame iteration (e.g. for im in video: )&#34;
        k = frame
        if obj.hasattribute(&#39;trackid&#39;) and obj.attributes[&#39;trackid&#39;] in self.tracks():
            # The attribute &#34;trackid&#34; is set for a detection when interpolating a track at a frame.  This is useful for reconstructing a track from previously enumerated detections
            trackid = obj.attributes[&#39;trackid&#39;]
            self.trackmap(lambda t: t.update(k, obj) if obj.attributes[&#39;trackid&#39;] == t.id() else t) 
            return None if not fluent else self
        else:
            t = vipy.object.Track(category=obj.category(), keyframes=[k], boxes=[obj], boundary=&#39;strict&#39;, attributes=obj.attributes, trackid=obj.attributes[&#39;trackid&#39;] if obj.hasattribute(&#39;trackid&#39;) else None, framerate=self.framerate())
            if rangecheck and not obj.hasoverlap(width=self.width(), height=self.height()):
                raise ValueError(&#34;Track &#39;%s&#39; does not intersect with frame shape (%d, %d)&#34; % (str(t), self.height(), self.width()))
            self.tracks()[t.id()] = t  # by-reference
            return t.id() if not fluent else self
    elif isinstance(obj, vipy.object.Track):
        if rangecheck and not obj.boundingbox().isinside(vipy.geometry.imagebox(self.shape())):
            obj = obj.imclip(self.width(), self.height())  # try to clip it, will throw exception if all are bad 
            warnings.warn(&#39;[vipy.video.add]: Clipping trackid=%s track=&#34;%s&#34; to image rectangle&#39; % (str(obj.id()), str(obj)))
        if obj.framerate() != self.framerate():
            obj.framerate(self.framerate())  # convert framerate of track to framerate of video
        self.tracks()[obj.id()] = obj  # by-reference
        return obj.id() if not fluent else self
    elif isinstance(obj, vipy.activity.Activity):
        if rangecheck and obj.startframe() &gt;= obj.endframe():
            raise ValueError(&#34;Activity &#39;%s&#39; has invalid (startframe, endframe)=(%d, %d)&#34; % (str(obj), obj.startframe(), obj.endframe()))
        self.activities()[obj.id()] = obj  # by-reference, activity may have no tracks
        return obj.id() if not fluent else self
    elif (istuple(obj) or islist(obj)) and len(obj) == 4 and isnumber(obj[0]):
        assert frame is not None, &#34;add() for obj=xywh must be added at a specific frame&#34;
        t = vipy.object.Track(category=category, keyframes=[frame], boxes=[vipy.geometry.BoundingBox(xywh=obj)], boundary=&#39;strict&#39;, attributes=attributes, framerate=self.framerate())
        if rangecheck and not t.boundingbox().isinside(vipy.geometry.imagebox(self.shape())):
            t = t.imclip(self.width(), self.height())  # try to clip it, will throw exception if all are bad 
            warnings.warn(&#39;Clipping track &#34;%s&#34; to image rectangle&#39; % (str(t)))
        self.tracks()[t.id()] = t  # by-reference
        return t.id() if not fluent else self
    else:
        raise ValueError(&#39;Undefined object type &#34;%s&#34; to be added to scene - Supported types are obj in [&#34;vipy.object.Detection&#34;, &#34;vipy.object.Track&#34;, &#34;vipy.activity.Activity&#34;, &#34;[xmin, ymin, width, height]&#34;]&#39; % str(type(obj)))</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.addframe"><code class="name flex">
<span>def <span class="ident">addframe</span></span>(<span>self, im, frame)</span>
</code></dt>
<dd>
<div class="desc"><p>Add im=vipy.image.Scene() into vipy.video.Scene() at given frame. The input image must have been generated using im=self[k] for this to be meaningful, so that trackid can be associated</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3178-L3187" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def addframe(self, im, frame):
    &#34;&#34;&#34;Add im=vipy.image.Scene() into vipy.video.Scene() at given frame. The input image must have been generated using im=self[k] for this to be meaningful, so that trackid can be associated&#34;&#34;&#34;
    assert isinstance(im, vipy.image.Scene), &#34;Invalid input - Must be vipy.image.Scene()&#34;
    assert im.shape() == self.shape(), &#34;Frame input (shape=%s) must be same shape as video (shape=%s)&#34; % (str(im.shape()), str(self.shape()))
    
    # Copy framewise vipy.image.Scene() into vipy.video.Scene(). 
    self.numpy()[frame] = im.array()  # will trigger copy        
    for bb in im.objects():
        self.trackmap(lambda t: t.update(frame, bb) if bb.attributes[&#39;trackid&#39;] == t.id() else t) 
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.annotate"><code class="name flex">
<span>def <span class="ident">annotate</span></span>(<span>self, outfile=None, fontsize=10, captionoffset=(0, 0), textfacecolor='white', textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={'Person': 'green', 'Vehicle': 'blue', 'Object': 'red'}, categories=None, nocaption=False, nocaption_withstring=[], mutator=None, timestamp=None, timestampcolor='black', timestampfacecolor='white', verbose=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a video visualization of all annotated objects and activities in the video.</p>
<p>The annotation video will be at the resolution and framerate of the underlying video, and pixels in this video will now contain the overlay.
This function does not play the video, it only generates an annotation video frames.
Use show() which is equivalent to annotate().saveas().play()</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>outfile</code></strong></dt>
<dd>[str] An optional file to stream the anntation to without storing the annotated video in memory</dd>
<dt><strong><code>fontsize</code></strong></dt>
<dd>[int] The fontsize of bounding box captions, used by matplotlib</dd>
<dt><strong><code>captionoffset</code></strong></dt>
<dd>(tuple) The (x,y) offset relative to the bounding box to place the caption for each box.</dd>
<dt><strong><code>textfacecolor</code></strong></dt>
<dd>[str] The color of the text in the bounding box caption.
Must be in <code><a title="vipy.gui.using_matplotlib.colorlist" href="gui/using_matplotlib.html#vipy.gui.using_matplotlib.colorlist">colorlist()</a></code>.</dd>
<dt><strong><code>textfacealpha</code></strong></dt>
<dd>[float] The transparency of the text in the bounding box caption.
Must be in [0,1], where 0=transparent and 1=opaque.</dd>
<dt><strong><code>shortlabel</code></strong></dt>
<dd>[bool] If true, display the shortlabel for each object in the scene, otherwise show the full category</dd>
<dt><strong><code>boxalpha</code></strong></dt>
<dd>[float]
The transparency of the box face behind the text.
Must be in [0,1], where 0=transparent and 1=opaque.</dd>
<dt><strong><code>d_category2color</code></strong></dt>
<dd>[dict]
A dictionary mapping categories of objects in the scene to their box colors.
Named colors must be in <code><a title="vipy.gui.using_matplotlib.colorlist" href="gui/using_matplotlib.html#vipy.gui.using_matplotlib.colorlist">colorlist()</a></code>. </dd>
<dt><strong><code>categories</code></strong></dt>
<dd>[list]
Only show these categories, or show them all if None</dd>
<dt><strong><code>nocaption_withstring</code></strong></dt>
<dd>[list]:
Do not show captions for those detection categories (or shortlabels) containing any of the strings in the provided list</dd>
<dt><strong><code>nocaption</code></strong></dt>
<dd>[bool] If true, do not show any captions, just boxes</dd>
<dt><strong><code>mutator</code></strong></dt>
<dd>[lambda] A lambda function that will mutate an image to allow for complex visualizations.
This should be a mutator like <code><a title="vipy.image.mutator_show_trackid" href="image.html#vipy.image.mutator_show_trackid">mutator_show_trackid()</a></code>.</dd>
<dt><strong><code>timestamp</code></strong></dt>
<dd>[bool] If true, show a semitransparent timestamp (when the annotation occurs, not when the video was collected) with frame number in the upper left corner of the video</dd>
<dt><strong><code>timestampcolor</code></strong></dt>
<dd>[str] The color of the timstamp text.
Named colors must be in <code><a title="vipy.gui.using_matplotlib.colorlist" href="gui/using_matplotlib.html#vipy.gui.using_matplotlib.colorlist">colorlist()</a></code>.</dd>
<dt><strong><code>timestampfacecolor</code></strong></dt>
<dd>[str]
The color of the timestamp background.
Named colors must be in <code><a title="vipy.gui.using_matplotlib.colorlist" href="gui/using_matplotlib.html#vipy.gui.using_matplotlib.colorlist">colorlist()</a></code>.
</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>[bool] Show more helpful messages if true</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;In general, this function should not be run on very long videos without the outfile kwarg, as it requires loading the video framewise into memory.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3787-L3863" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def annotate(self, outfile=None, fontsize=10, captionoffset=(0,0), textfacecolor=&#39;white&#39;, textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={&#39;Person&#39;:&#39;green&#39;, &#39;Vehicle&#39;:&#39;blue&#39;, &#39;Object&#39;:&#39;red&#39;}, categories=None, nocaption=False, nocaption_withstring=[], mutator=None, timestamp=None, timestampcolor=&#39;black&#39;, timestampfacecolor=&#39;white&#39;, verbose=False):
    &#34;&#34;&#34;Generate a video visualization of all annotated objects and activities in the video.
    
    The annotation video will be at the resolution and framerate of the underlying video, and pixels in this video will now contain the overlay.
    This function does not play the video, it only generates an annotation video frames.  Use show() which is equivalent to annotate().saveas().play()
    
    Args:
        outfile: [str] An optional file to stream the anntation to without storing the annotated video in memory
        fontsize: [int] The fontsize of bounding box captions, used by matplotlib
        captionoffset: (tuple) The (x,y) offset relative to the bounding box to place the caption for each box.
        textfacecolor: [str] The color of the text in the bounding box caption.  Must be in `vipy.gui.using_matplotlib.colorlist`.
        textfacealpha: [float] The transparency of the text in the bounding box caption.  Must be in [0,1], where 0=transparent and 1=opaque.
        shortlabel: [bool] If true, display the shortlabel for each object in the scene, otherwise show the full category
        boxalpha: [float]  The transparency of the box face behind the text.  Must be in [0,1], where 0=transparent and 1=opaque.
        d_category2color: [dict]  A dictionary mapping categories of objects in the scene to their box colors.  Named colors must be in `vipy.gui.using_matplotlib.colorlist`. 
        categories: [list]  Only show these categories, or show them all if None
        nocaption_withstring: [list]:  Do not show captions for those detection categories (or shortlabels) containing any of the strings in the provided list
        nocaption: [bool] If true, do not show any captions, just boxes
        mutator: [lambda] A lambda function that will mutate an image to allow for complex visualizations.  This should be a mutator like `vipy.image.mutator_show_trackid`.
        timestamp: [bool] If true, show a semitransparent timestamp (when the annotation occurs, not when the video was collected) with frame number in the upper left corner of the video
        timestampcolor: [str] The color of the timstamp text.  Named colors must be in `vipy.gui.using_matplotlib.colorlist`.
        timestampfacecolor: [str]  The color of the timestamp background.  Named colors must be in `vipy.gui.using_matplotlib.colorlist`.  
        verbose: [bool] Show more helpful messages if true

    Returns:
        A `vipy.video.Video` with annotations in the pixels.  If outfile is provided, then the returned video will be flushed.  

    .. note::  In general, this function should not be run on very long videos without the outfile kwarg, as it requires loading the video framewise into memory.  
    &#34;&#34;&#34;
    assert outfile is None or vipy.util.isvideofile(outfile), &#34;Invalid filename extension for annotated video&#34;
    
    if verbose:
        print(&#39;[vipy.video.annotate]: Annotating video ...&#39;)  
        
    f_mutator = mutator if mutator is not None else vipy.image.mutator_show_jointlabel()
    f_timestamp = (lambda k: &#39;%s %d&#39; % (vipy.util.clockstamp(), k)) if timestamp is True else timestamp

    if outfile is None:        
        assert self.load().isloaded(), &#34;Load() failed&#34;
        imgs = [f_mutator(self[k].clone(), k).savefig(fontsize=fontsize,
                                              captionoffset=captionoffset,
                                              textfacecolor=textfacecolor,
                                              textfacealpha=textfacealpha,
                                              shortlabel=shortlabel,
                                              boxalpha=boxalpha,
                                              d_category2color=d_category2color,
                                              categories=categories,
                                              nocaption=nocaption,
                                              timestampcolor=timestampcolor,
                                              timestampfacecolor=timestampfacecolor,
                                              timestamp=f_timestamp(k) if timestamp is not None else None,
                                              figure=1 if k&lt;(len(self)-1) else None,  # cleanup on last frame
                                              nocaption_withstring=nocaption_withstring).numpy() for k in range(0, len(self))]
        
        # Replace pixels with annotated pixels and downcast object to vipy.video.Video (since there are no more objects to show)
        return vipy.video.Video(array=np.stack([np.array(PIL.Image.fromarray(img).convert(&#39;RGB&#39;)) for img in imgs], axis=0), framerate=self.framerate(), attributes=self.attributes)  # slow for large videos
    else:
        # Stream to output video without loading all frames into memory
        n = self.duration_in_frames_of_videofile() if not self.isloaded() else len(self)
        vo = vipy.video.Video(filename=outfile, framerate=self.framerate())
        with vo.stream(overwrite=True) as so:
            for (k,im) in enumerate(self.stream()):
                so.write(f_mutator(im.clone(), k).savefig(fontsize=fontsize,
                                                  captionoffset=captionoffset,
                                                  textfacecolor=textfacecolor,
                                                  textfacealpha=textfacealpha,
                                                  shortlabel=shortlabel,
                                                  boxalpha=boxalpha,
                                                  d_category2color=d_category2color,
                                                  categories=categories,
                                                  nocaption=nocaption,
                                                  timestampcolor=timestampcolor,
                                                  timestampfacecolor=timestampfacecolor,
                                                  timestamp=f_timestamp(k) if timestamp is not None else None,
                                                  figure=1 if k&lt;(n-1) else None,  # cleanup on last frame
                                                  nocaption_withstring=nocaption_withstring).rgb())
        return vo</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.annotation"><code class="name flex">
<span>def <span class="ident">annotation</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return an iterator over annotations in each frame.</p>
<pre><code class="language-python">for y in self.annotation():
    for (bb,a) in y:
        print((bb,a))
</code></pre>
<h2 id="yields">Yields</h2>
<dl>
<dt><code>for each frame yield the tuple</code></dt>
<dd>( (<code><a title="vipy.object.Detection" href="object.html#vipy.object.Detection">Detection</a></code>, (tuple of <code><a title="vipy.activity.Activity" href="activity.html#vipy.activity.Activity">Activity</a></code> performed by the actor in this bounding box)), &hellip; )</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;The preferred method for accessing annotations is a frame iterator, which includes pixels.
However, this method provides access to just the annotations without pixels.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3009-L3026" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def annotation(self):
    &#34;&#34;&#34;Return an iterator over annotations in each frame.
    
    ```python
    for y in self.annotation():
        for (bb,a) in y:
            print((bb,a))
    ```

    Yields:
        for each frame yield the tuple:  ( (`vipy.object.Detection`, (tuple of `vipy.activity.Activity` performed by the actor in this bounding box)), ... )

    .. note:: The preferred method for accessing annotations is a frame iterator, which includes pixels.  However, this method provides access to just the annotations without pixels.

    &#34;&#34;&#34;
    endframe = max([a.endframe() for a in self.activitylist()]+[t.endframe() for (tk,t) in self.tracks().items()]) if (len(self._tracks) &gt; 0 or len(self._activities) &gt; 0) else 0
    for k in range(0,endframe):
        yield tuple( [tuple( [t[k] if t.during(k) else None, tuple( [a for a in self.activitylist() if a.during(k) and a.hastrackoverlap(t)] ) ]) for t in self.tracklist()])</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.asfloatmask"><code class="name flex">
<span>def <span class="ident">asfloatmask</span></span>(<span>self, fg=1.0, bg=0.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace all pixels in foreground boxes with fg, and bg in background, return a copy</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3967-L3976" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def asfloatmask(self, fg=1.0, bg=0.0):
    &#34;&#34;&#34;Replace all pixels in foreground boxes with fg, and bg in background, return a copy&#34;&#34;&#34;
    assert self.isloaded()
    self.numpy()  # convert to writeable numpy array, triggers writeable copy        
    array = np.full( (len(self.load()), self.height(), self.width(), 1), dtype=np.float32, fill_value=bg)
    for (k,im) in enumerate(self):
        for bb in im.objects():
            if bb.hasintersection(im.imagebox()):
                array[k, int(round(bb._ymin)):int(round(bb._ymax)), int(round(bb._xmin)):int(round(bb._xmax))] = fg   # does not need imclip
    return vipy.video.Video(array=array, framerate=self.framerate(), colorspace=&#39;float&#39;)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.assign"><code class="name flex">
<span>def <span class="ident">assign</span></span>(<span>self, frame, dets, minconf=0.2, maxhistory=5, activityiou=0.5, trackcover=0.2, trackconfsamples=4, gate=0, activitymerge=True, activitynms=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Assign a list of <code><a title="vipy.object.Detection" href="object.html#vipy.object.Detection">Detection</a></code> object detections and <code><a title="vipy.activity.Activity" href="activity.html#vipy.activity.Activity">Activity</a></code> activity detections at frame k to scene tracks and activities by greedy assignment. In-place update.</p>
<h2 id="approach">Approach</h2>
<ul>
<li>This approach is equivalent to greedy, constant velocity SORT tracking (<a href="https://arxiv.org/abs/1602.00763">https://arxiv.org/abs/1602.00763</a>) </li>
<li>Individual detections are assigned to tracks using a greedy velocity only track propagation, sorted by <code><a title="vipy.geometry.BoundingBox.maxcover" href="geometry.html#vipy.geometry.BoundingBox.maxcover">BoundingBox.maxcover()</a></code> and detection confidence within a spatial tracking gate </li>
<li>New tracks are created if the detection is unassigned and above a minimum confidence </li>
<li>Updated tracks resulting from assignment are stored in <code>vipy.video.tracks</code> </li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>frame</code></strong></dt>
<dd>[int] The frame index to assign the detections into the scene</dd>
<dt><strong><code>dets</code></strong></dt>
<dd>[list] A list of <code><a title="vipy.object.Detection" href="object.html#vipy.object.Detection">Detection</a></code> or <code><a title="vipy.activity.Activity" href="activity.html#vipy.activity.Activity">Activity</a></code> objects as returned from a detector </dd>
<dt><strong><code>miniou</code></strong></dt>
<dd>[float] the minimum temporal IOU for activity assignment</dd>
<dt><strong><code>minconf</code></strong></dt>
<dd>[float] the minimum confidence for a detection to be considered as a new track</dd>
<dt><strong><code>maxhistory</code></strong></dt>
<dd>[int]
the maximum propagation length of a track with no measurements, the frame history used for velocity estimates
</dd>
<dt><strong><code>trackconfsamples</code></strong></dt>
<dd>[int]
the number of uniformly spaced samples along a track to compute a mean track confidence</dd>
<dt><strong><code>gate</code></strong></dt>
<dd>[int] the gating distance in pixels used for assignment of fast moving detections.
Useful for low detection framerates if a detection does not overlap with the track.</dd>
<dt><strong><code>trackcover</code></strong></dt>
<dd>[float] the minimum cover necessary for assignment of a detection to a track</dd>
<dt><strong><code>activitymerge</code></strong></dt>
<dd>[bool] if true, then merge overlapping activity detections of the same track and category, otherwise each activity detection is added as a new detection</dd>
<dt><strong><code>activitynms</code></strong></dt>
<dd>[bool] if true, then perform non-maximum suppression of activity detections of the same actor and category that overlap more than activityiou</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>This video object with each det assigned to corresponding track or activity.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L4026-L4140" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def assign(self, frame, dets, minconf=0.2, maxhistory=5, activityiou=0.5, trackcover=0.2, trackconfsamples=4, gate=0, activitymerge=True, activitynms=False):
    &#34;&#34;&#34;Assign a list of `vipy.object.Detection` object detections and `vipy.activity.Activity` activity detections at frame k to scene tracks and activities by greedy assignment. In-place update.
    
    Approach:

        - This approach is equivalent to greedy, constant velocity SORT tracking (https://arxiv.org/abs/1602.00763) 
        - Individual detections are assigned to tracks using a greedy velocity only track propagation, sorted by `vipy.geometry.BoundingBox.maxcover` and detection confidence within a spatial tracking gate 
        - New tracks are created if the detection is unassigned and above a minimum confidence 
        - Updated tracks resulting from assignment are stored in `vipy.video.tracks` 

    Args:
    
        frame: [int] The frame index to assign the detections into the scene
        dets: [list] A list of `vipy.object.Detection` or `vipy.activity.Activity` objects as returned from a detector 
        miniou: [float] the minimum temporal IOU for activity assignment
        minconf: [float] the minimum confidence for a detection to be considered as a new track
        maxhistory: [int]  the maximum propagation length of a track with no measurements, the frame history used for velocity estimates  
        trackconfsamples: [int]  the number of uniformly spaced samples along a track to compute a mean track confidence
        gate: [int] the gating distance in pixels used for assignment of fast moving detections.  Useful for low detection framerates if a detection does not overlap with the track.
        trackcover: [float] the minimum cover necessary for assignment of a detection to a track
        activitymerge: [bool] if true, then merge overlapping activity detections of the same track and category, otherwise each activity detection is added as a new detection
        activitynms: [bool] if true, then perform non-maximum suppression of activity detections of the same actor and category that overlap more than activityiou

    Returns:

        This video object with each det assigned to corresponding track or activity.

    &#34;&#34;&#34;
    assert dets is None or all([isinstance(d, vipy.object.Detection) or isinstance(d, vipy.activity.Activity) for d in tolist(dets)]), &#34;invalid input&#34;
    assert frame &gt;= 0 and minconf &gt;= 0 and minconf &lt;= 1.0 and maxhistory &gt; 0, &#34;invalid input&#34;
    
    if dets is None or len(tolist(dets)) == 0:
        return self
    dets = tolist(dets)

    if any([d.confidence() is None for d in dets]):
        warnings.warn(&#39;Removing %d detections with no confidence&#39; % len([d.confidence() is None for d in dets]))
        dets = [d for d in dets if d.confidence() is not None]
    objdets = [d for d in dets if isinstance(d, vipy.object.Detection)]
    activitydets = [d for d in dets if isinstance(d, vipy.activity.Activity)]        

    # Object detection to track assignment
    if len(objdets) &gt; 0:
        # Track propagation:  Constant velocity motion model for active tracks 
        t_ref = [(t, t.linear_extrapolation(frame, dt=maxhistory, shape=False)) for (k,t) in self.tracks().items() if ((frame - t.endframe()) &lt;= maxhistory)]
        trackarea = [ti.area() for (t,ti) in t_ref]
        detarea = [d.area() for d in objdets]
        
        # Track assignment:
        #   - Each track is assigned at most one detection
        #   - Each detection is assigned to at most one track.  
        #   - Assignment is the highest confidence maximum overlapping detection by cover within tracking gate
        trackconf = {t.id():t.confidence(samples=trackconfsamples) for (t, ti) in t_ref}
        assignments = [(t, d.confidence(), d.iou(ti, area=detarea[j], otherarea=trackarea[i]), d.shapeiou(ti, area=detarea[j], otherarea=trackarea[i]), d.maxcover(ti, area=detarea[j], otherarea=trackarea[i]), d)
                       for (i, (t, ti)) in enumerate(t_ref)
                       for (j,d) in enumerate(objdets)
                       if (t.category() == d.category() and
                           (((ti._xmax if ti._xmax &lt; d._xmax else d._xmax) - (ti._xmin if ti._xmin &gt; d._xmin else d._xmin)) &gt; 0 and
                            ((ti._ymax if ti._ymax &lt; d._ymax else d._ymax) - (ti._ymin if ti._ymin &gt; d._ymin else d._ymin)) &gt; 0))]
        
        assigned = set([])        
        posconf = min([d.confidence() for d in objdets]) if len(objdets)&gt;0 else 0
        assignments.sort(key=lambda x: (x[1]+posconf)*(x[2]+x[3]+x[4])+trackconf[x[0].id()], reverse=True)  # in-place
        for (t, conf, iou, shapeiou, cover, d) in assignments:
            if cover &gt; (trackcover if len(t)&gt;1 else 0):  # the highest confidence detection within the assignment gate (or any overlap if not yet enough history for velocity estimate) 
                if (t.id() not in assigned and d.id() not in assigned):  # not assigned yet, assign it!
                    self.track(t.id()).update(frame, d.clone())  # track assignment! (clone required)
                    assigned.add(t.id())  # cannot assign again to this track
                    assigned.add(d.id())  # mark detection as assigned
            
        # Track spawn from unassigned and unexplained detections 
        for (j,d) in enumerate(objdets):                
            if (d.id() not in assigned):
                if (d.confidence() &gt;= minconf and not any([t.linear_extrapolation(frame, dt=maxhistory, shape=False).maxcover(d, otherarea=detarea[j]) &gt;= 0.7 for (i,(t,ti)) in enumerate(t_ref) if t.category() == d.category()])):
                    gated = [(t, t.linear_extrapolation(frame, dt=maxhistory, shape=False)) for (t,ti) in t_ref if (t.id() not in assigned and t.category() == d.category())] if gate&gt;0 else []
                    gated = sorted([(t, ti) for (t, ti) in gated if ti.hasintersection(d, gate=gate)], key=lambda x: d.sqdist(x[1]))
                    if len(gated) &gt; 0:
                        self.track(gated[0][0].id()).update(frame, d.clone())  # track assignment! (clone required)
                        assigned.add(gated[0][0].id())
                        assigned.add(d.id())
                    else:
                        assigned.add(self.add(vipy.object.Track(keyframes=[frame], boxes=[d.clone()], category=d.category(), framerate=self.framerate()), rangecheck=False))  # clone required
                        assigned.add(d.id())

    # Activity assignment
    if len(activitydets) &gt; 0:
        assert all([d.actorid() in self.tracks() for d in activitydets]), &#34;Invalid activity&#34;
        assigned = set([])
        if activitymerge:
            minframe = min([a._startframe for a in activitydets]) 
            activities = [a for a in self.activities().values() if a._endframe &gt;= minframe]
            for d in activitydets:
                for a in activities:
                    if (a._label == d._label) and (a._actorid == d._actorid) and a.hasoverlap(d, activityiou): 
                        a.union(d)  # activity assignment 
                        assigned.add(d._id)
                        break  # assigned, early exit
                    
        if activitynms:
            minframe = min([a._startframe for a in activitydets]) 
            activities = sorted([a for a in self.activities().values() if a._endframe &gt;= minframe], key=lambda a: a.confidence(), reverse=True)
            for d in sorted(activitydets, key=lambda x: x.confidence(), reverse=True):
                for a in activities:
                    if (a._label == d._label) and (a._actorid == d._actorid) and a.hasoverlap(d, activityiou):
                        assigned.add(a._id if d.confidence()&gt;a.confidence() else d._id)  # suppressed
            for id in assigned:
                if id in self._activities:
                    del self._activities[id]  # suppression, faster than self.activityfilter(lambda a: a.id() in assigned)
                                
        # Activity construction from unassigned detections
        for d in activitydets:
            if d._id not in assigned:
                self.add(d.clone())  

    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.binarymask"><code class="name flex">
<span>def <span class="ident">binarymask</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace all pixels in foreground boxes with white, zero in background</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3961-L3965" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def binarymask(self):
    &#34;&#34;&#34;Replace all pixels in foreground boxes with white, zero in background&#34;&#34;&#34;
    for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy  
        im.binarymask()  # shared numpy array
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.blurmask"><code class="name flex">
<span>def <span class="ident">blurmask</span></span>(<span>self, radius=7)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace all pixels in foreground boxes with gaussian blurred foreground</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3994-L3998" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def blurmask(self, radius=7):
    &#34;&#34;&#34;Replace all pixels in foreground boxes with gaussian blurred foreground&#34;&#34;&#34;
    for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy                                  
        im.blurmask(radius)  # shared numpy array
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.categories"><code class="name flex">
<span>def <span class="ident">categories</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for labels()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3066-L3068" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def categories(self):
    &#34;&#34;&#34;Alias for labels()&#34;&#34;&#34;
    return self.labels()</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.clear"><code class="name flex">
<span>def <span class="ident">clear</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove all activities and tracks from this object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3189-L3193" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def clear(self):
    &#34;&#34;&#34;Remove all activities and tracks from this object&#34;&#34;&#34;
    self._activities = {}
    self._tracks = {}
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.clearactivities"><code class="name flex">
<span>def <span class="ident">clearactivities</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3199-L3201" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def clearactivities(self):
    self._activities = {}
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.cleartracks"><code class="name flex">
<span>def <span class="ident">cleartracks</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3195-L3197" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def cleartracks(self):
    self._tracks = {}
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.clip"><code class="name flex">
<span>def <span class="ident">clip</span></span>(<span>self, startframe, endframe=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Clip the video to between (startframe, endframe).
This clip is relative to clip() shown by <strong>repr</strong>(). </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>startframe</code></strong></dt>
<dd>[int] the start frame relative to the video framerate() for the clip</dd>
<dt><strong><code>endframe</code></strong></dt>
<dd>[int] the end frame relative to the video framerate for the clip, may be none</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>This video object, clipped so that a load() will result in frame=0 equivalent to startframe.
All tracks and activities updated relative to the new startframe.
.. note:<br>
- This return a clone of the video for idempotence
- This does not load the video.
This updates the ffmpeg filter chain to temporally trim the video.
See self.commandline() for the updated filter chain to run.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3523-L3559" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def clip(self, startframe, endframe=None):
    &#34;&#34;&#34;Clip the video to between (startframe, endframe).  This clip is relative to clip() shown by __repr__(). 

    Args:
        startframe: [int] the start frame relative to the video framerate() for the clip
        endframe: [int] the end frame relative to the video framerate for the clip, may be none
    
    Returns:
        This video object, clipped so that a load() will result in frame=0 equivalent to startframe.  All tracks and activities updated relative to the new startframe.

    .. note:  
        - This return a clone of the video for idempotence
        - This does not load the video.  This updates the ffmpeg filter chain to temporally trim the video.  See self.commandline() for the updated filter chain to run.
    &#34;&#34;&#34;
    assert (endframe is None or startframe &lt;= endframe) and startframe &gt;= 0, &#34;Invalid start and end frames (%s, %s)&#34; % (str(startframe), str(endframe))

    v = self.clone()
    if not v.isloaded():
        # -- Copied from super().clip() to allow for clip on clone (for indempotence)
        # -- This code copy is used to avoid super(Scene, self.clone()) which screws up class inheritance for iPython reload
        assert not v.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;            
        timestamp_in_seconds = ((v._startframe if v._startframe is not None else 0)+startframe)/float(v.framerate())
        v._update_ffmpeg_seek(timestamp_in_seconds)
        if endframe is not None:
            v._ffmpeg = v._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 before trim filter            
            v._ffmpeg = v._ffmpeg.trim(start=0, end=(endframe-startframe)/self.framerate())  # must be in seconds to allow for framerate conversion
        v._ffmpeg = v._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 after trim filter            
        v._startframe = startframe if v._startframe is None else v._startframe + startframe  # for __repr__ only
        v._endframe = (v._startframe + (endframe-startframe)) if endframe is not None else v._endframe  # for __repr__ only
        # -- end copy
    else:
        endframe = endframe if endframe is not None else len(self._array)
        v._array = self._array[startframe:endframe]
        (v._startframe, v._endframe) = (0, endframe-startframe)
    v._tracks = {k:t.offset(dt=-startframe).truncate(startframe=0, endframe=(endframe-startframe) if endframe is not None else None) for (k,t) in v.tracks().items()}   # may be degenerate
    v._activities = {k:a.offset(dt=-startframe).truncate(startframe=0, endframe=(endframe-startframe) if endframe is not None else None) for (k,a) in v.activities().items()}  # may be degenerate
    return v.trackfilter(lambda t: len(t)&gt;0).activityfilter(lambda a: len(a)&gt;0)  # remove degenerate tracks and activities</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.combine"><code class="name flex">
<span>def <span class="ident">combine</span></span>(<span>self, other, tracks=True, activities=True, rekey=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Combine the activities and tracks from both scenes into self. </p>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;This does not perform a union, it simply combines dictionaries.
For deduplication, see <code>vipy.video.union</code></p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3678-L3690" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def combine(self, other, tracks=True, activities=True, rekey=True):
    &#34;&#34;&#34;Combine the activities and tracks from both scenes into self. 
    
    .. note:: This does not perform a union, it simply combines dictionaries.  For deduplication, see `vipy.video.union`
    &#34;&#34;&#34;
    assert isinstance(other, Scene), &#34;Invalid input - must be vipy.video.Scene() object and not type=%s&#34; % str(type(other))
    assert self.framerate() == other.framerate()
    o = other.clone(rekey=True) if rekey else other   # make sure keys are unique
    if activities:
        self.activities().update(o.activities())
    if tracks:
        self.tracks().update(o.tracks())
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.crop"><code class="name flex">
<span>def <span class="ident">crop</span></span>(<span>self, bb, zeropad=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Crop the video using the supplied box, update tracks relative to crop, video is zeropadded if box is outside frame rectangle</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3561-L3572" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def crop(self, bb, zeropad=True):
    &#34;&#34;&#34;Crop the video using the supplied box, update tracks relative to crop, video is zeropadded if box is outside frame rectangle&#34;&#34;&#34;
    assert isinstance(bb, vipy.geometry.BoundingBox), &#34;Invalid input&#34;
    bb = bb.int()
    bbc = bb.clone().imclipshape(self.width(), self.height()).int()
    #if zeropad and bb != bbc:
    #    self.zeropad(bb.width()-bbc.width(), bb.height()-bbc.height())  
    #    bb = bb.offset(bb.width()-bbc.width(), bb.height()-bbc.height())            
    super().crop(bb, zeropad=zeropad)  # range check handled here to correctly apply zeropad
    bb = bb if zeropad else bbc
    self._tracks = {k:t.offset(dx=-bb.xmin(), dy=-bb.ymin()) for (k,t) in self.tracks().items()}
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.csv"><code class="name flex">
<span>def <span class="ident">csv</span></span>(<span>self, outfile=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Export scene to CSV file format with header.
If there are no tracks, this will be empty.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3234-L3246" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def csv(self, outfile=None):
    &#34;&#34;&#34;Export scene to CSV file format with header.  If there are no tracks, this will be empty. &#34;&#34;&#34;
    assert self.load().isloaded()
    csv = [(self.filename(), # video filename
            k,  # frame number (zero indexed)
            d.category(), d.shortlabel(), # track category and shortlabel (displayed in caption)
            &#39;;&#39;.join([self.activities(id=aid).category() for aid in tolist(d.attributes[&#39;activityid&#39;])] if &#39;activityid&#39; in d.attributes else &#39;&#39;), # semicolon separated activity category associated with track
            d.xmin(), d.ymin(), d.width(), d.height(),   # bounding box
            d.attributes[&#39;trackid&#39;],  # globally unique track ID
            &#39;;&#39;.join([aid for aid in tolist(d.attributes[&#39;activityid&#39;])] if &#39;activityid&#39; in d.attributes else &#39;&#39;)) # semicolon separated activity ID associated with track
           for (k,im) in enumerate(self) for d in im.objects()]
    csv = [(&#39;# video_filename&#39;, &#39;frame_number&#39;, &#39;object_category&#39;, &#39;object_shortlabel&#39;, &#39;activity categories(;)&#39;, &#39;xmin&#39;, &#39;ymin&#39;, &#39;width&#39;, &#39;height&#39;, &#39;track_id&#39;, &#39;activity_ids(;)&#39;)] + csv
    return writecsv(csv, outfile) if outfile is not None else csv</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.dedupe"><code class="name flex">
<span>def <span class="ident">dedupe</span></span>(<span>self, spatial_iou_threshold=0.8, dt=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Find and delete duplicate tracks by track segmentiou() overlap.</p>
<p>Algorithm
- For each pair of tracks with the same category, find the larest temporal segment that contains both tracks.
- For this segment, compute the IOU for each box interpolated at a stride of dt frames
- Compute the mean IOU for this segment.
This is the segment IOU.
- If the segment IOU is greater than the threshold, merge the shorter of the two tracks with the current track.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3657-L3676" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def dedupe(self, spatial_iou_threshold=0.8, dt=5):
    &#34;&#34;&#34;Find and delete duplicate tracks by track segmentiou() overlap.
    
    Algorithm
    - For each pair of tracks with the same category, find the larest temporal segment that contains both tracks.
    - For this segment, compute the IOU for each box interpolated at a stride of dt frames
    - Compute the mean IOU for this segment.  This is the segment IOU. 
    - If the segment IOU is greater than the threshold, merge the shorter of the two tracks with the current track.  

    &#34;&#34;&#34;
    deleted = set([])
    for tj in sorted(self.tracklist(), key=lambda t: len(t), reverse=True):  # longest to shortest
        for (s, ti) in sorted([(0,t) if (len(tj) &lt; len(t) or t.id() in deleted or t.id() == tj.id() or t.category() != tj.category()) else (tj.fragmentiou(t, dt=dt), t) for t in self.tracklist()], key=lambda x: x[0], reverse=True):
            if s &gt; spatial_iou_threshold:  # best mean framewise overlap during overlapping segment of two tracks (ti, tj)
                print(&#39;[vipy.video.dedupe]: merging duplicate track &#34;%s&#34; (id=%s) which overlaps with &#34;%s&#34; (id=%s)&#39; % (ti, ti.id(), tj, tj.id()))
                self.tracks()[tj.id()] = tj.union(ti)  # merge
                self.activitymap(lambda a: a.replace(ti, tj))  # replace merged track reference in activity
                deleted.add(ti.id())
    self.trackfilter(lambda t: t.id() not in deleted)  # remove duplicate tracks
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.delete"><code class="name flex">
<span>def <span class="ident">delete</span></span>(<span>self, id)</span>
</code></dt>
<dd>
<div class="desc"><p>Delete a given track or activity by id, if present</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3174-L3176" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def delete(self, id):
    &#34;&#34;&#34;Delete a given track or activity by id, if present&#34;&#34;&#34;
    return self.trackfilter(lambda t: t.id() != id).activityfilter(lambda a: a.id() != id)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.downcast"><code class="name flex">
<span>def <span class="ident">downcast</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Cast the object to a <code><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></code> class</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L4000-L4003" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def downcast(self):
    &#34;&#34;&#34;Cast the object to a `vipy.video.Video` class&#34;&#34;&#34;
    self.__class__ = vipy.video.Video
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.during"><code class="name flex">
<span>def <span class="ident">during</span></span>(<span>self, frameindex)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2710-L2715" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def during(self, frameindex):
    try:
        self.__getitem__(frameindex)  # triggers load
        return True
    except:
        return False</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.extrapolate"><code class="name flex">
<span>def <span class="ident">extrapolate</span></span>(<span>self, f, dt=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Extrapolate the video to frame f and add the extrapolated tracks to the video</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3653-L3655" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def extrapolate(self, f, dt=None):
    &#34;&#34;&#34;Extrapolate the video to frame f and add the extrapolated tracks to the video&#34;&#34;&#34;
    return self.trackmap(lambda t: t.add(f, t.linear_extrapolation(f, dt=dt if dt is not None else self.framerate()), strict=False))</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.fgmask"><code class="name flex">
<span>def <span class="ident">fgmask</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace all pixels in foreground boxes with zero</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3984-L3988" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def fgmask(self):
    &#34;&#34;&#34;Replace all pixels in foreground boxes with zero&#34;&#34;&#34;
    for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy                          
        im.fgmask()  # shared numpy array
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.first_activity"><code class="name flex">
<span>def <span class="ident">first_activity</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the first activity of the video with the earliest start frame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2875-L2877" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def first_activity(self):
    &#34;&#34;&#34;Return the first activity of the video with the earliest start frame&#34;&#34;&#34;
    return sorted(self.activitylist(), key=lambda a: a.startframe())[0] if len(self._activities)&gt;0 else None</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.frame"><code class="name flex">
<span>def <span class="ident">frame</span></span>(<span>self, k=0, img=None, noimage=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Return <code><a title="vipy.image.Scene" href="image.html#vipy.image.Scene">Scene</a></code> object at frame k</p>
<pre><code>    -The attributes of each of the &lt;code&gt;&lt;a title="vipy.image.Scene.objects" href="image.html#vipy.image.Scene.objects"&gt;Scene.objects()&lt;/a&gt;&lt;/code&gt; in the scene contains helpful metadata for the provenance of the detection, including:  
        - 'trackid' of the track this detection
        - 'activityid' associated with this detection 
        - 'jointlabel' of this detection, used for visualization
        - 'noun verb' of this detection, used for visualization

    Args:
        k: [int &gt;=- 0] The frame index requested.  This is relative to the current frame rate of the video.
        img: [numpy, None]  An optional image to be used for this frame.  This is useful to construct frames efficiently for videos if the pixel buffer is already available from a stream rather than a preview.  
        noimage [bool]:  If True, then return only annotations at frame k with empty frame buffer (e.g. no image pixels in the returned image object)

    Return:
        A &lt;code&gt;&lt;a title="vipy.image.Scene" href="image.html#vipy.image.Scene"&gt;Scene&lt;/a&gt;&lt;/code&gt; object for frame k containing all objects in this frame and pixels if img != None or preview=True

    !!! note "Note"
        - Modifying this frame will not affect the source video
        - If multiple objects are associated with an activity and a primary actor is defined, then only the primary actor is displayed as "Noun Verbing", objects are shown as "Noun" with the activityid in the attribute
        - If noun is associated with more than one activity, then this is shown as "Noun Verbing1
</code></pre>
<p>Noun Verbing2", with a newline separator</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2653-L2707" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def frame(self, k=0, img=None, noimage=False):
    &#34;&#34;&#34;Return `vipy.image.Scene` object at frame k

    -The attributes of each of the `vipy.image.Scene.objects` in the scene contains helpful metadata for the provenance of the detection, including:  
        - &#39;trackid&#39; of the track this detection
        - &#39;activityid&#39; associated with this detection 
        - &#39;jointlabel&#39; of this detection, used for visualization
        - &#39;noun verb&#39; of this detection, used for visualization

    Args:
        k: [int &gt;=- 0] The frame index requested.  This is relative to the current frame rate of the video.
        img: [numpy, None]  An optional image to be used for this frame.  This is useful to construct frames efficiently for videos if the pixel buffer is already available from a stream rather than a preview.  
        noimage [bool]:  If True, then return only annotations at frame k with empty frame buffer (e.g. no image pixels in the returned image object)

    Return:
        A `vipy.image.Scene` object for frame k containing all objects in this frame and pixels if img != None or preview=True
    
    .. note::
        - Modifying this frame will not affect the source video
        - If multiple objects are associated with an activity and a primary actor is defined, then only the primary actor is displayed as &#34;Noun Verbing&#34;, objects are shown as &#34;Noun&#34; with the activityid in the attribute
        - If noun is associated with more than one activity, then this is shown as &#34;Noun Verbing1\nNoun Verbing2&#34;, with a newline separator

    &#34;&#34;&#34;
    assert isinstance(k, int) and k&gt;=0, &#34;Frame index must be non-negative integer&#34;
    assert img is not None or (self.isloaded() and k&lt;len(self)) or not self.isloaded(), &#34;Invalid frame index %d - Indexing video by frame must be integer within (0, %d)&#34; % (k, len(self)-1)

    img = img if (img is not None or noimage) else (self._array[k] if self.isloaded() else self.preview(k).array())
    dets = [t[k].clone(deep=True).setattribute(&#39;trackindex&#39;, j) for (j, t) in enumerate(self.tracklist()) if len(t)&gt;0 and (t.during(k) or t.boundary()==&#39;extend&#39;)]  # track interpolation (cloned) with boundary handling
    for d in dets:
        d.attributes[&#39;activityid&#39;] = []  # reset
        jointlabel = [(d.shortlabel(),&#39;&#39;)]  # [(Noun, Verbing1), (Noun, Verbing2), ...], initialized with empty verbs as [(Noun, &#34;&#34;), ... ]
        activityconf = [None]   # for display 

        for (aid, a) in self.activities().items():  # insertion order:  First activity is primary, next is secondary (not in confidence order) 
            if a.hastrack(d.attributes[&#39;trackid&#39;]) and a.during(k):
                # Display assumptions:
                # - Jointlabel is always displayed as &#34;Noun Verbing&#34; during activity (e.g. Person Carrying, Vehicle Turning) using noun=track shortlabel, verb=activity shortlabel
                # - If noun is associated with more than one activity, then this is shown as &#34;Noun Verbing1\nNoun Verbing2&#34;, with a newline separator
                # - If multiple objects are associated with an activity and a primary actor is defined, then only the primary actor is displayed as &#34;Noun Verbing&#34;, objects are shown as &#34;Noun&#34; with the activityid in the attributes
                if (a.actorid() is None or (a.actorid() == d.attributes[&#39;trackid&#39;])) and not any([a.shortlabel() == v for (n,v) in jointlabel]):
                    jointlabel.append( (d.shortlabel(), a.shortlabel()) )  # only show each activity once (even if repeated)
                    activityconf.append(a.confidence())
                d.attributes[&#39;activityid&#39;].append(a.id())  # for activity correspondence (if desired)

        # For display purposes
        # - See `vipy.image.mutator_show_trackindex_verbonly`
        # - Double prepended underscore attributes are private and cleaned using `vipy.image.Image.sanitize`
        d.attributes[&#39;__jointlabel&#39;] = &#39;\n&#39;.join([(&#39;%s %s&#39; % (n,v)).strip() for (n,v) in jointlabel[0 if len(jointlabel)==1 else 1:]])  # to be deprecated
        d.attributes[&#39;__noun verb&#39;] = jointlabel[0 if len(jointlabel)==1 else 1:]
        d.attributes[&#39;__activityconf&#39;] = activityconf[0 if len(jointlabel)==1 else 1:]
        d.attributes[&#39;__trackindex&#39;] = d.attributes[&#39;trackindex&#39;]  # trackindex to be replaced with __trackindex
        d.attributes[&#39;__trackid&#39;] = d.attributes[&#39;trackid&#39;]  # trackid to be replaced with __trackid
        d.attributes[&#39;__activityid&#39;] = d.attributes[&#39;activityid&#39;]  # activityid to be replaced with __activityid            
    dets.sort(key=lambda d: (d.confidence() if d.confidence() is not None else 0, d.shortlabel()))   # layering in video is ordered by decreasing track confidence and alphabetical shortlabel
    return vipy.image.Scene(array=img, colorspace=self.colorspace(), objects=dets, category=self.category())  </code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.framebox"><code class="name flex">
<span>def <span class="ident">framebox</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the bounding box for the image rectangle.</p>
<h2 id="returns">Returns</h2>
<p>A <code><a title="vipy.geometry.BoundingBox" href="geometry.html#vipy.geometry.BoundingBox">BoundingBox</a></code> which defines the image rectangle
.. notes: This requires calling <code><a title="vipy.video.Video.preview" href="#vipy.video.Video.preview">Video.preview()</a></code> to get the frame shape from the current filter chain, which touches the video file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3422-L3429" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def framebox(self):
    &#34;&#34;&#34;Return the bounding box for the image rectangle.

    Returns:
        A `vipy.geometry.BoundingBox` which defines the image rectangle

    .. notes: This requires calling `vipy.video.Video.preview` to get the frame shape from the current filter chain, which touches the video file&#34;&#34;&#34;
    return vipy.geometry.BoundingBox(xmin=0, ymin=0, width=self.width(), height=self.height())</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.framecomposite"><code class="name flex">
<span>def <span class="ident">framecomposite</span></span>(<span>self, n=2, dt=10, mindim=256)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a single composite image with minimum dimension mindim as the uniformly blended composite of n frames each separated by dt frames</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2726-L2732" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def framecomposite(self, n=2, dt=10, mindim=256):
    &#34;&#34;&#34;Generate a single composite image with minimum dimension mindim as the uniformly blended composite of n frames each separated by dt frames&#34;&#34;&#34;
    if not self.isloaded():
        self.mindim(mindim).load()
    imframes = [self.frame(k).maxmatte() for k in range(0, dt*n, dt)]
    img = np.uint8(np.sum([1/float(n)*im.array() for im in imframes], axis=0))
    return imframes[0].clone().array(img)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.framerate"><code class="name flex">
<span>def <span class="ident">framerate</span></span>(<span>self, fps=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Change the input framerate for the video and update frame indexes for all annotations.</p>
<pre><code class="language-python">fps = self.framerate()
self.framerate(fps=15.0)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3249-L3274" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def framerate(self, fps=None):
    &#34;&#34;&#34;Change the input framerate for the video and update frame indexes for all annotations.

    ```python
    fps = self.framerate()
    self.framerate(fps=15.0)
    ```

    &#34;&#34;&#34;
    if fps is None:
        return self._framerate
    elif float(fps) == self._framerate:
        return self
    else:
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        fps = float(fps)
        self._startframe = int(round(self._startframe * (fps/self._framerate))) if self._startframe is not None else self._startframe  # __repr__ only
        self._endframe = int(round(self._endframe * (fps/self._framerate))) if self._endframe is not None else self._endframe  # __repr__only
        self._tracks = {k:t.framerate(fps) for (k,t) in self.tracks().items()}
        self._activities = {k:a.framerate(fps) for (k,a) in self.activities().items()}        
        if &#39;fps=&#39; in self._ffmpeg_commandline():
            self._update_ffmpeg(&#39;fps&#39;, fps)  # replace fps filter, do not add to it
        else:
            self._ffmpeg = self._ffmpeg.filter(&#39;fps&#39;, fps=fps, round=&#39;up&#39;)  # create fps filter first time
        self._framerate = fps
        return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.hasactivities"><code class="name flex">
<span>def <span class="ident">hasactivities</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Does this video have any activities?</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3074-L3076" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def hasactivities(self):
    &#34;&#34;&#34;Does this video have any activities?&#34;&#34;&#34;
    return len(self._activities) &gt; 0</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.hasactivity"><code class="name flex">
<span>def <span class="ident">hasactivity</span></span>(<span>self, activityid)</span>
</code></dt>
<dd>
<div class="desc"><p>Does this video have this activity id?</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3078-L3080" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def hasactivity(self, activityid):
    &#34;&#34;&#34;Does this video have this activity id?&#34;&#34;&#34;
    return activityid in self.activities()</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.hastrack"><code class="name flex">
<span>def <span class="ident">hastrack</span></span>(<span>self, trackid)</span>
</code></dt>
<dd>
<div class="desc"><p>Does the video have this trackid?
</p>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;Track IDs are available as vipy.object.Track().id()</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3086-L3091" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def hastrack(self, trackid):
    &#34;&#34;&#34;Does the video have this trackid?  
    
    .. note:: Track IDs are available as vipy.object.Track().id()
    &#34;&#34;&#34;
    return trackid in self.tracks()</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.hastracks"><code class="name flex">
<span>def <span class="ident">hastracks</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Does this video have any tracks?</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3082-L3084" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def hastracks(self):
    &#34;&#34;&#34;Does this video have any tracks?&#34;&#34;&#34;
    return len(self._tracks) &gt; 0</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.instanceid"><code class="name flex">
<span>def <span class="ident">instanceid</span></span>(<span>self, newid=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return an annotation instance identifier for this video.
</p>
<p>An instance ID is a unique identifier for a ground truth annotation within a video, either a track or an activity.
More than one instance ID may share the same video ID if they are from the same source videofile.
</p>
<p>This is useful when calling <code><a title="vipy.video.Scene.activityclip" href="#vipy.video.Scene.activityclip">Scene.activityclip()</a></code> or <code><a title="vipy.video.Scene.activitysplit" href="#vipy.video.Scene.activitysplit">Scene.activitysplit()</a></code> to clip a video into segments such that each clip has a unique identifier, but all share the same underlying <code><a title="vipy.video.Video.videoid" href="#vipy.video.Video.videoid">Video.videoid()</a></code>.
This is useful when calling <code><a title="vipy.video.Scene.trackclip" href="#vipy.video.Scene.trackclip">Scene.trackclip()</a></code> or <code><a title="vipy.video.Scene.tracksplit" href="#vipy.video.Scene.tracksplit">Scene.tracksplit()</a></code> to clip a video into segments such that each clip has a unique identifier, but all share the same underlying <code><a title="vipy.video.Video.videoid" href="#vipy.video.Video.videoid">Video.videoid()</a></code>.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>INSTANCEID</code></dt>
<dd>if 'instance_id' key is in self.attribute</dd>
<dt><code>VIDEOID_INSTANCEID</code></dt>
<dd>if '_instance_id' key is in self.attribute, as set by activityclip() or trackclip().
This is set using INSTANCE_ID=ACTIVITYID_ACTIVITYINDEX or INSTANCEID=TRACKID_TRACKINDEX, where the index is the temporal order of the annotation in the source video prior to clip().</dd>
<dt><code>VIDEOID_ACTIVITYINDEX</code></dt>
<dd>if 'activityindex' key is in self.attribute, as set by activityclip().
(fallback for legacy datasets).</dd>
<dt><code>VIDEOID</code></dt>
<dd>otherwise</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2626-L2651" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def instanceid(self, newid=None):
    &#34;&#34;&#34;Return an annotation instance identifier for this video.  

    An instance ID is a unique identifier for a ground truth annotation within a video, either a track or an activity.  More than one instance ID may share the same video ID if they are from the same source videofile.  

    This is useful when calling `vipy.video.Scene.activityclip` or `vipy.video.Scene.activitysplit` to clip a video into segments such that each clip has a unique identifier, but all share the same underlying `vipy.video.Video.videoid`.
    This is useful when calling `vipy.video.Scene.trackclip` or `vipy.video.Scene.tracksplit` to clip a video into segments such that each clip has a unique identifier, but all share the same underlying `vipy.video.Video.videoid`.
    
    Returns:
        INSTANCEID: if &#39;instance_id&#39; key is in self.attribute
        VIDEOID_INSTANCEID: if &#39;_instance_id&#39; key is in self.attribute, as set by activityclip() or trackclip().  This is set using INSTANCE_ID=ACTIVITYID_ACTIVITYINDEX or INSTANCEID=TRACKID_TRACKINDEX, where the index is the temporal order of the annotation in the source video prior to clip().
        VIDEOID_ACTIVITYINDEX: if &#39;activityindex&#39; key is in self.attribute, as set by activityclip().  (fallback for legacy datasets).
        VIDEOID: otherwise 
    &#34;&#34;&#34;
    if newid is not None:
        self.setattribute(&#39;instance_id&#39;, newid)
        return self
    else:
        if &#39;instance_id&#39; in self.attributes:
            return self.attributes[&#39;instance_id&#39;]  # set at video creation time (e.g. pycollector)
        elif &#39;_instance_id&#39; in self.attributes:
            return self.attributes[&#39;_instance_id&#39;]  # set at activityclip() time for provenance from clips back to videos
        elif &#39;activityindex&#39; in self.attributes:
            return &#39;%s_%s&#39; % (self.videoid(), str(self.attributes[&#39;activityindex&#39;]))  # set at activityclip() time for provenance from clips back to videos (deprecated)
        else:
            return self.videoid()</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.isdegenerate"><code class="name flex">
<span>def <span class="ident">isdegenerate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Degenerate scene has empty or malformed tracks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2734-L2736" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def isdegenerate(self):
    &#34;&#34;&#34;Degenerate scene has empty or malformed tracks&#34;&#34;&#34;
    return len(self.tracklist()) == 0 or any([t.isempty() or t.isdegenerate() for t in self.tracklist()])</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.json"><code class="name flex">
<span>def <span class="ident">json</span></span>(<span>self, encode=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Return JSON encoded string of this object.
This may fail if attributes contain non-json encodeable object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3210-L3232" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def json(self, encode=True):
    &#34;&#34;&#34;Return JSON encoded string of this object.  This may fail if attributes contain non-json encodeable object&#34;&#34;&#34;
    try:
        json.loads(json.dumps(self.attributes))  # round trip for the attributes dictionary - this can be any arbitrary object and contents may not be json encodable
    except:
        raise ValueError(&#39;Video contains non-JSON encodable object in self.attributes dictionary - Try self.sanitize() or to clear with self.attributes = {} first&#39;)
    d = json.loads(super().json())
    d[&#39;_tracks&#39;] = {k:t.json(encode=False) for (k,t) in self.tracks().items()}
    d[&#39;_activities&#39;] = {k:a.json(encode=False) for (k,a) in self.activities().items()}
    try:
        return json.dumps(d) if encode else d
    except:
        # Legacy support for non JSON serializable objects (&lt;= vipy.1.9.2)
        v = self.clone()
        for (ti, t) in v.tracks().items():
            for o in t._keyboxes:
                vipy.geometry.BoundingBox.cast(o, flush=True)
                o.float().significant_digits(2)

        for (ai, a) in v.activities().items():
            a._startframe = int(a._startframe)
            a._endframe = int(a._endframe)
        return v.json(encode=encode)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.label"><code class="name flex">
<span>def <span class="ident">label</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return an iterator over labels in each frame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3028-L3032" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def label(self):
    &#34;&#34;&#34;Return an iterator over labels in each frame&#34;&#34;&#34;
    endframe = max([a.endframe() for a in self.activitylist()]+[t.endframe() for (tk,t) in self.tracks().items()]) if (len(self._tracks) &gt; 0 or len(self._activities) &gt; 0) else 0
    for k in range(0,endframe):
        yield self.labels(k)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.labeled_frames"><code class="name flex">
<span>def <span class="ident">labeled_frames</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Iterate over frames, yielding tuples (activity+object labelset in scene, vipy.image.Scene())</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2717-L2722" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def labeled_frames(self):
    &#34;&#34;&#34;Iterate over frames, yielding tuples (activity+object labelset in scene, vipy.image.Scene())&#34;&#34;&#34;
    self.load()
    for k in range(0, len(self)):
        #self._currentframe = k    # used only for incremental add()
        yield (self.labels(k), self.__getitem__(k))</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.labels"><code class="name flex">
<span>def <span class="ident">labels</span></span>(<span>self, k=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a set of all object and activity labels in this scene, or at frame int(k)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3034-L3036" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def labels(self, k=None):
    &#34;&#34;&#34;Return a set of all object and activity labels in this scene, or at frame int(k)&#34;&#34;&#34;
    return self.activitylabels(k).union(self.objectlabels(k))</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.last_activity"><code class="name flex">
<span>def <span class="ident">last_activity</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the last activity of the video with the latest end frame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2879-L2881" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def last_activity(self):
    &#34;&#34;&#34;Return the last activity of the video with the latest end frame&#34;&#34;&#34;
    return sorted(self.activitylist(), key=lambda a: a.endframe())[-1] if len(self._activities)&gt;0 else None</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.meanmask"><code class="name flex">
<span>def <span class="ident">meanmask</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace all pixels in foreground boxes with mean color</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3978-L3982" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def meanmask(self):
    &#34;&#34;&#34;Replace all pixels in foreground boxes with mean color&#34;&#34;&#34;
    for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy                  
        im.meanmask()  # shared numpy array
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.merge_tracks"><code class="name flex">
<span>def <span class="ident">merge_tracks</span></span>(<span>self, dilate_height=2.0, dilate_width=2.0, framedist=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Merge tracks if a track endpoint dilated by a fraction overlaps exactly one track startpoint, and the endpoint and startpoint are close enough together temporally.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
</div>
<ul>
<li>This is useful for continuing tracking when the detection framerate was too low and the assignment falls outside the measurement gate.</li>
<li>This will not work for complex scenes, as it assumes that there is exactly one possible continuation for a track.</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L4005-L4024" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def merge_tracks(self, dilate_height=2.0, dilate_width=2.0, framedist=5):
    &#34;&#34;&#34;Merge tracks if a track endpoint dilated by a fraction overlaps exactly one track startpoint, and the endpoint and startpoint are close enough together temporally.
    
    .. note::
    - This is useful for continuing tracking when the detection framerate was too low and the assignment falls outside the measurement gate.
    - This will not work for complex scenes, as it assumes that there is exactly one possible continuation for a track.  
    
    &#34;&#34;&#34;
    merged = set([])
    for ti in sorted(self.tracklist(), key=lambda t: t.startframe()):
        for tj in sorted(self.tracklist(), key=lambda t: t.startframe()):
            if (tj.id() not in merged) and (ti.id() != tj.id()) and (tj.startframe() &gt;= ti.endframe()) and ((tj.startframe()-ti.endframe()) &lt;= framedist) and (ti.category() == tj.category()):
                di = ti[ti.endframe()].dilate_height(dilate_height).dilate_width(dilate_width)
                dj = tj[tj.startframe()]
                if di.iou(dj) &gt; 0 and not any([di.iou(tk[tj.startframe()]) &gt; 0 for tk in self.tracklist() if (tk.id() not in [ti.id(), tj.id()]) and tk.during(tj.startframe())]):
                    self.tracks()[ti.id()] = ti.union(tj)  # Merge tracks that are within gating distance
                    self.delete(tj.id())  # remove merged track
                    merged.add(tj.id())
                    break
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.next_activity"><code class="name flex">
<span>def <span class="ident">next_activity</span></span>(<span>self, id)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the next activity just after the given activityid</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2809-L2814" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def next_activity(self, id):
    &#34;&#34;&#34;Return the next activity just after the given activityid&#34;&#34;&#34;
    assert id in self.activities()
    A = self.activitylist()
    k = [k for (k,a) in enumerate(A) if a.id() == id][0]
    return A[k+1] if k&lt;len(A)-1 else None</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.noactivityclip"><code class="name flex">
<span>def <span class="ident">noactivityclip</span></span>(<span>self, label=None, shortlabel=None, padframes=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a list of vipy.video.Scene() each clipped on a track segment that has no associated activities.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>label</code></strong></dt>
<dd>[str] The activity label to give the background activities.
Defaults to the track category (lowercase)</dd>
<dt><strong><code>shortlabel</code></strong></dt>
<dd>[str] The activity shortlabel to give the background activities when visualized.
Defaults to the track category (lowercase)</dd>
<dt><strong><code>padframes</code></strong></dt>
<dd>[int]
The amount of temporal padding to apply to the clips before and after in frames.
See <code><a title="vipy.video.Scene.activityclip" href="#vipy.video.Scene.activityclip">Scene.activityclip()</a></code> for options.</dd>
</dl>
<div class="admonition notes">
<p class="admonition-title">Notes</p>
<ul>
<li>Each clip will contain exactly one activity "Background" which is the interval for this track where no activities are occurring</li>
<li>Each clip will be at least one frame long</li>
</ul>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3391-L3407" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def noactivityclip(self, label=None, shortlabel=None, padframes=0):
    &#34;&#34;&#34;Return a list of vipy.video.Scene() each clipped on a track segment that has no associated activities.  

    Args:
        label: [str] The activity label to give the background activities.  Defaults to the track category (lowercase)
        shortlabel: [str] The activity shortlabel to give the background activities when visualized.  Defaults to the track category (lowercase)
        padframes: [int]  The amount of temporal padding to apply to the clips before and after in frames.  See `vipy.video.Scene.activityclip` for options.
    
    Returns:
        A list of `vipy.video.Scene` each cloned from the source video and clipped in the temporal region between activities.  The union of activityclip() and noactivityclip() should equal the entire video.

    .. notes::
        - Each clip will contain exactly one activity &#34;Background&#34; which is the interval for this track where no activities are occurring
        - Each clip will be at least one frame long
    &#34;&#34;&#34;
    A = self.clone().activities(self.noactivitylist(label=label, shortlabel=shortlabel)).activityclip(padframes=padframes, multilabel=False)
    return [a.setattribute(&#39;_instance_id&#39;, &#39;%s_bg&#39; % a.getattribute(&#39;_instance_id&#39;)) for a in A]</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.noactivitylist"><code class="name flex">
<span>def <span class="ident">noactivitylist</span></span>(<span>self, label=None, shortlabel=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a list of <code><a title="vipy.activity.Activity" href="activity.html#vipy.activity.Activity">Activity</a></code> which are segments of each track with no associated activities.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>label</code></strong></dt>
<dd>[str] The activity label to give the background activities.
Defaults to the track category (lowercase)</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A list of <code><a title="vipy.activity.Activity" href="activity.html#vipy.activity.Activity">Activity</a></code> such that each activity is associated with a track with temporal support where no activities are performed. The union of activitylist() and noactivitylist() should cover the temporal support of all track</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3363-L3388" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def noactivitylist(self, label=None, shortlabel=None):
    &#34;&#34;&#34;Return a list of `vipy.activity.Activity` which are segments of each track with no associated activities.

    Args:
        label: [str] The activity label to give the background activities.  Defaults to the track category (lowercase)
    
    Returns:
        A list of `vipy.activity.Activity` such that each activity is associated with a track with temporal support where no activities are performed. The union of activitylist() and noactivitylist() should cover the temporal support of all track
    &#34;&#34;&#34;
    A = []
    for t in self.tracklist():
        (startframe, endframe) = (t.startframe(), t.startframe())
        for k in range(t.startframe(), t.endframe()):
            if not any([a.hastrack(t) and a.during(k) for a in self.activitylist()]) and k &lt; (t.endframe()-1):
                endframe = k  # background
            else:
                if startframe &lt; endframe:
                    A.append(vipy.activity.Activity(label=t.category() if label is None else label, 
                                                    shortlabel=&#39;&#39; if label is None else (label if shortlabel is None else shortlabel),
                                                    startframe=startframe,
                                                    endframe=endframe,
                                                    actorid=t.id(),
                                                    framerate=self.framerate(),
                                                    attributes={&#39;_noactivitylist&#39;:True}))
                (startframe, endframe) = (k+1,k+1)                        
    return A</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.objectlabels"><code class="name flex">
<span>def <span class="ident">objectlabels</span></span>(<span>self, k=None, lower=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a python set of all activity categories in this scene, or at frame k.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>k</code></strong></dt>
<dd>[int] The object labels present at frame k.
If k=None, then all object labels in the video</dd>
<dt><strong><code>lower</code></strong></dt>
<dd>[bool] If true, return the object labels in alll lower case for case invariant string comparisonsn</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3057-L3064" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def objectlabels(self, k=None, lower=False):
    &#34;&#34;&#34;Return a python set of all activity categories in this scene, or at frame k.
    
    Args:
        k: [int] The object labels present at frame k.  If k=None, then all object labels in the video
        lower: [bool] If true, return the object labels in alll lower case for case invariant string comparisonsn            
    &#34;&#34;&#34;
    return set([t.category() if not lower else t.category().lower() for t in self.tracks().values() if k is None or t.during(k)])        </code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.objects"><code class="name flex">
<span>def <span class="ident">objects</span></span>(<span>self, casesensitive=True)</span>
</code></dt>
<dd>
<div class="desc"><p>The objects in a scene are the unique categories of tracks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2826-L2828" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def objects(self, casesensitive=True):
    &#34;&#34;&#34;The objects in a scene are the unique categories of tracks&#34;&#34;&#34;
    return sorted(list(set([t.category() if casesensitive else t.category().lower() for t in self.tracklist()])))</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.pack"><code class="name flex">
<span>def <span class="ident">pack</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Packing a scene returns the scene with the annotations JSON serialized.
</p>
<ul>
<li>This is useful for fast garbage collection when there are many objects in memory</li>
<li>This is useful for distributed processing prior to serializing from a scheduler to a client</li>
<li>This is useful for lazy deserialization of complex attributes when loading many videos into memory</li>
<li>Unpacking is transparent to the end user and is performed on the fly when annotations are accessed.
There is no unpack() method.</li>
<li>See the notes in from_json() for why this helps with nested containers and reference cycle tracking with the python garbage collector</li>
</ul></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2588-L2601" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def pack(self):
    &#34;&#34;&#34;Packing a scene returns the scene with the annotations JSON serialized.  
           
    - This is useful for fast garbage collection when there are many objects in memory
    - This is useful for distributed processing prior to serializing from a scheduler to a client
    - This is useful for lazy deserialization of complex attributes when loading many videos into memory
    - Unpacking is transparent to the end user and is performed on the fly when annotations are accessed.  There is no unpack() method.
    - See the notes in from_json() for why this helps with nested containers and reference cycle tracking with the python garbage collector        

    &#34;&#34;&#34;
    d = json.loads(self.json())
    self._tracks = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_tracks&#39;].values()]) # efficient garbage collection: store as a packed string to avoid reference cycle tracking, unpack on demand
    self._activities = tuple([x if isinstance(x, str) else str(json.dumps(x)) for x in d[&#39;_activities&#39;].values()])  # efficient garbage collection: store as a packed string to avoid reference cycle tracking, unpack on demand 
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.pixelate"><code class="name flex">
<span>def <span class="ident">pixelate</span></span>(<span>self, radius=16)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for pixelmask()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3957-L3959" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def pixelate(self, radius=16):
    &#34;&#34;&#34;Alias for pixelmask()&#34;&#34;&#34;
    return self.pixelmask(pixelsize=radius)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.pixelize"><code class="name flex">
<span>def <span class="ident">pixelize</span></span>(<span>self, radius=16)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for pixelmask()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3954-L3956" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def pixelize(self, radius=16):
    &#34;&#34;&#34;Alias for pixelmask()&#34;&#34;&#34;
    return self.pixelmask(pixelsize=radius)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.pixelmask"><code class="name flex">
<span>def <span class="ident">pixelmask</span></span>(<span>self, pixelsize=8)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace all pixels in foreground boxes with pixelation (e.g. bigger pixels, like privacy glass)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3948-L3952" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def pixelmask(self, pixelsize=8):
    &#34;&#34;&#34;Replace all pixels in foreground boxes with pixelation (e.g. bigger pixels, like privacy glass)&#34;&#34;&#34;
    for im in self.mutable():  # convert to writeable numpy array, triggers writeable copy          
        im.pixelmask(pixelsize)  # shared numpy array
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.prev_activity"><code class="name flex">
<span>def <span class="ident">prev_activity</span></span>(<span>self, id)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the previous activity just before the given activityid</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2816-L2821" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def prev_activity(self, id):
    &#34;&#34;&#34;Return the previous activity just before the given activityid&#34;&#34;&#34;
    assert id in self.activities()
    A = self.activitylist()
    k = [k for (k,a) in enumerate(A) if a.id() == id][0]
    return A[k-1] if k&gt;=1 else None</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.primary_activity"><code class="name flex">
<span>def <span class="ident">primary_activity</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the primary activity of the video.</p>
<ul>
<li>The primary activity is the first activity in the activitylist.
</li>
<li>This is useful for activityclip() videos that are centered on a single activity</li>
</ul>
<h2 id="returns">Returns</h2>
<p><code><a title="vipy.activity.Activity" href="activity.html#vipy.activity.Activity">Activity</a></code> that is first in the <code><a title="vipy.video.Scene.activitylist" href="#vipy.video.Scene.activitylist">Scene.activitylist()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2864-L2873" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def primary_activity(self):
    &#34;&#34;&#34;Return the primary activity of the video.

    - The primary activity is the first activity in the activitylist.  
    - This is useful for activityclip() videos that are centered on a single activity
    
    Returns:
        `vipy.activity.Activity` that is first in the `vipy.video.Scene.activitylist`
    &#34;&#34;&#34;
    return next(iter(self.activities().values())) if len(self._activities)&gt;0 else None  # Python &gt;=3.6        </code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.quicklook"><code class="name flex">
<span>def <span class="ident">quicklook</span></span>(<span>self, n=9, dilate=1.5, mindim=256, fontsize=10, context=False, startframe=0, animate=False, dt=30)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a montage of n uniformly spaced annotated frames centered on the union of the labeled boxes in the current frame to show the activity ocurring in this scene at a glance
Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame.
This quicklook is most useful when len(self.activities()==1)
for generating a quicklook from an activityclip().</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong></dt>
<dd>[int]:
Number of images in the quicklook</dd>
<dt><strong><code>dilate</code></strong></dt>
<dd>[float]:
The dilation factor for the bounding box prior to crop for display</dd>
<dt><strong><code>mindim</code></strong></dt>
<dd>[int]:
The minimum dimension of each of the elemnets in the montage</dd>
<dt><strong><code>fontsize</code></strong></dt>
<dd>[int]:
The size of the font for the bounding box label</dd>
<dt><strong><code>context</code></strong></dt>
<dd>[bool]:
If true, replace the first and last frame in the montage with the full frame annotation, to help show the scale of the scene</dd>
<dt><strong><code>animate</code></strong></dt>
<dd>[bool]:
If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames</dd>
<dt><strong><code>dt</code></strong></dt>
<dd>[int]:
The number of frames for animation</dd>
<dt><strong><code>startframe</code></strong></dt>
<dd>[int]:
The initial frame index to start the n uniformly sampled frames for the quicklook</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2738-L2766" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def quicklook(self, n=9, dilate=1.5, mindim=256, fontsize=10, context=False, startframe=0, animate=False, dt=30):
    &#34;&#34;&#34;Generate a montage of n uniformly spaced annotated frames centered on the union of the labeled boxes in the current frame to show the activity ocurring in this scene at a glance
       Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame.  This quicklook is most useful when len(self.activities()==1)
       for generating a quicklook from an activityclip().
    
       Args:
           n: [int]:  Number of images in the quicklook
           dilate: [float]:  The dilation factor for the bounding box prior to crop for display
           mindim: [int]:  The minimum dimension of each of the elemnets in the montage
           fontsize: [int]:  The size of the font for the bounding box label
           context: [bool]:  If true, replace the first and last frame in the montage with the full frame annotation, to help show the scale of the scene
           animate: [bool]:  If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames
           dt: [int]:  The number of frames for animation
           startframe: [int]:  The initial frame index to start the n uniformly sampled frames for the quicklook
    &#34;&#34;&#34;
    if not self.isloaded():
        self.load()  
    if animate:
        return Video(frames=[self.quicklook(n=n, dilate=dilate, mindim=mindim, fontsize=fontsize, context=context, startframe=k, animate=False, dt=dt) for k in range(0, min(dt, len(self)))], framerate=self.framerate())
    f_mutator = vipy.image.mutator_show_jointlabel()
    framelist = [min(int(np.round(f))+startframe, len(self)-1) for f in np.linspace(0, len(self)-1, n)]
    isdegenerate = [self.frame(k).boundingbox() is None or self.frame(k).boundingbox().dilate(dilate).intersection(self.framebox(), strict=False).isdegenerate() for (j,k) in enumerate(framelist)]
    imframes = [self.frame(k).maxmatte()  # letterbox or pillarbox
                if (isdegenerate[j] or (context is True and (j == 0 or j == (n-1)))) else
                self.frame(k).padcrop(self.frame(k).boundingbox().dilate(dilate).imclipshape(self.width(), self.height()).maxsquare().int()).mindim(mindim, interp=&#39;nearest&#39;)
                for (j,k) in enumerate(framelist)]
    imframes = [f_mutator(im) for im in imframes]  # show jointlabel from frame interpolation
    imframes = [im.savefig(fontsize=fontsize, figure=1).rgb() for im in imframes]  # temp storage in memory
    return vipy.visualize.montage(imframes, imgwidth=mindim, imgheight=mindim)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.rekey"><code class="name flex">
<span>def <span class="ident">rekey</span></span>(<span>self, tracks=None, activities=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Change the track and activity IDs to randomly assigned UUIDs.
Useful for cloning unique scenes.</p>
<pre><code class="language-python">v = vipy.video.RandomScene()
v.rekey()  # randomly rekey all track and activity ID
v.rekey(tracks={...})  # rekey tracks (oldkey -&gt; newkey) according to dictionary, randomly rekey activities
v.rekey(tracks={...}, activities={})  #  rekey tracks according to dict, no change to activities
</code></pre>
<h2 id="args">Args</h2>
<p>tracks [dict]: If not None, use this dictionary to remap oldkey-&gt;newkey for tracks.
If None, use random keys. If empty dict, no change (do not rekey tracks)
activities [dict]: If not None, use this dictionary to remap oldkey-&gt;newkey for activities.
If None, use random keys.
If empty dict, no change (do not rekey activities)</p>
<h2 id="returns">Returns</h2>
<p>This object, with all track ID and activity ID rekeyed as specified.
All actor IDs in activities will be updated.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2979-L3007" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def rekey(self, tracks=None, activities=None):
    &#34;&#34;&#34;Change the track and activity IDs to randomly assigned UUIDs.  Useful for cloning unique scenes.
    
    
    ```python
    v = vipy.video.RandomScene()
    v.rekey()  # randomly rekey all track and activity ID
    v.rekey(tracks={...})  # rekey tracks (oldkey -&gt; newkey) according to dictionary, randomly rekey activities
    v.rekey(tracks={...}, activities={})  #  rekey tracks according to dict, no change to activities
    ```

    Args:
        tracks [dict]: If not None, use this dictionary to remap oldkey-&gt;newkey for tracks.  If None, use random keys. If empty dict, no change (do not rekey tracks)
        activities [dict]: If not None, use this dictionary to remap oldkey-&gt;newkey for activities.  If None, use random keys.  If empty dict, no change (do not rekey activities)
    
    Returns:
        This object, with all track ID and activity ID rekeyed as specified.  All actor IDs in activities will be updated.  
    
    &#34;&#34;&#34;
    assert activities is None or isinstance(activities, dict) and all([k in self.activities() for k in activities.keys()])
    assert tracks is None or isinstance(tracks, dict) and all([k in self.tracks() for k in tracks.keys()])

    d_old_to_new = {k:hex(int(uuid.uuid4().hex[0:8], 16))[2:] for (k,a) in self.activities().items()} if activities is None else activities
    self._activities = dict([(d_old_to_new[k], a.id(d_old_to_new[k])) if k in d_old_to_new else (k,a) for (k,a) in self.activities().items()])
    d_old_to_new = {k:hex(int(uuid.uuid4().hex[0:8], 16))[2:] for (k,t) in self.tracks().items()} if tracks is None else tracks
    self._tracks = dict([(d_old_to_new[k], t.id(d_old_to_new[k])) if k in d_old_to_new else (k,t) for (k,t) in self.tracks().items()])
    for (k,v) in d_old_to_new.items():
        self.activitymap(lambda a: a.replaceid(k,v) )
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.replace"><code class="name flex">
<span>def <span class="ident">replace</span></span>(<span>self, other, frame=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace tracks and activities with other if activity/track is during frame</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3203-L3208" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def replace(self, other, frame=None):
    &#34;&#34;&#34;Replace tracks and activities with other if activity/track is during frame&#34;&#34;&#34;
    assert isinstance(other, vipy.video.Scene)
    self.activities([a for a in other.activitylist() if frame is None or a.during(frame)])
    self.tracks([t for t in other.tracklist() if frame is None or t.during(frame)])
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.rescale"><code class="name flex">
<span>def <span class="ident">rescale</span></span>(<span>self, s)</span>
</code></dt>
<dd>
<div class="desc"><p>Spatially rescale the scene by a constant scale factor.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>s</code></strong></dt>
<dd>[float] Scale factor &gt; 0 to isotropically scale the image.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3639-L3648" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def rescale(self, s):
    &#34;&#34;&#34;Spatially rescale the scene by a constant scale factor.

    Args:
        s: [float] Scale factor &gt; 0 to isotropically scale the image.
    &#34;&#34;&#34;
    assert s == 1 or not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;                
    self._tracks = {k:t.rescale(s) for (k,t) in self.tracks().items()}
    super().rescale(s)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.resize"><code class="name flex">
<span>def <span class="ident">resize</span></span>(<span>self, rows=None, cols=None, width=None, height=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Resize the video to (rows, cols), preserving the aspect ratio if only rows or cols is provided</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3612-L3626" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def resize(self, rows=None, cols=None, width=None, height=None):
    &#34;&#34;&#34;Resize the video to (rows, cols), preserving the aspect ratio if only rows or cols is provided&#34;&#34;&#34;
    assert not (rows is not None and height is not None)  # cannot be both
    assert not (cols is not None and width is not None)   # cannot be both
    rows = rows if rows is not None else height
    cols = cols if cols is not None else width        
    
    assert rows is not None or cols is not None, &#34;Invalid input&#34;
    (H,W) = self.shape()  # yuck, need to get image dimensions before filter, manually set this prior to calling resize if known
    sy = rows / float(H) if rows is not None else cols / float(W)
    sx = cols / float(W) if cols is not None else rows / float(H)
    self._tracks = {k:t.scalex(sx) for (k,t) in self.tracks().items()}
    self._tracks = {k:t.scaley(sy) for (k,t) in self.tracks().items()}
    super().resize(rows=rows, cols=cols)        
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.setactorid"><code class="name flex">
<span>def <span class="ident">setactorid</span></span>(<span>self, id)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for <code><a title="vipy.video.Scene.actorid" href="#vipy.video.Scene.actorid">Scene.actorid()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2856-L2858" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def setactorid(self, id):
    &#34;&#34;&#34;Alias for `vipy.video.Scene.actorid`&#34;&#34;&#34;
    return self.actorid(id, fluent=True)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.show"><code class="name flex">
<span>def <span class="ident">show</span></span>(<span>self, outfile=None, verbose=True, fontsize=10, captionoffset=(0, 0), textfacecolor='white', textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={'Person': 'green', 'Vehicle': 'blue', 'Object': 'red'}, categories=None, nocaption=False, nocaption_withstring=[], figure=1, fps=None, timestamp=None, timestampcolor='black', timestampfacecolor='white', mutator=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Faster show using interative image show for annotated videos.
This can visualize videos before video rendering is complete, but it cannot guarantee frame rates. Large videos with complex scenes will slow this down and will render at lower frame rates.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3884-L3913" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def show(self, outfile=None, verbose=True, fontsize=10, captionoffset=(0,0), textfacecolor=&#39;white&#39;, textfacealpha=1.0, shortlabel=True, boxalpha=0.25, d_category2color={&#39;Person&#39;:&#39;green&#39;, &#39;Vehicle&#39;:&#39;blue&#39;, &#39;Object&#39;:&#39;red&#39;}, categories=None, nocaption=False, nocaption_withstring=[], figure=1, fps=None, timestamp=None, timestampcolor=&#39;black&#39;, timestampfacecolor=&#39;white&#39;, mutator=None):
    &#34;&#34;&#34;Faster show using interative image show for annotated videos.  This can visualize videos before video rendering is complete, but it cannot guarantee frame rates. Large videos with complex scenes will slow this down and will render at lower frame rates.&#34;&#34;&#34;
    fps = min(fps, self.framerate()) if fps is not None else self.framerate()
    assert fps &gt; 0, &#34;Invalid display framerate&#34;
    f_timestamp = (lambda k: &#39;%s %d&#39; % (vipy.util.clockstamp(), k)) if timestamp is True else timestamp
    f_mutator = mutator if mutator is not None else vipy.image.mutator_show_jointlabel()        
    if not self.isdownloaded() and self.hasurl():
        self.download()
    with Stopwatch() as sw:            
        for (k,im) in enumerate(self.load() if self.isloaded() else self.stream()):
            time.sleep(max(0, (1.0/self.framerate())*int(np.ceil((self.framerate()/fps)))))
            f_mutator(im,k).show(categories=categories,
                                 figure=figure,
                                 nocaption=nocaption,
                                 nocaption_withstring=nocaption_withstring,
                                 fontsize=fontsize,
                                 boxalpha=boxalpha,
                                 d_category2color=d_category2color,
                                 captionoffset=captionoffset,
                                 textfacecolor=textfacecolor,
                                 textfacealpha=textfacealpha,
                                 timestampcolor=timestampcolor,
                                 timestampfacecolor=timestampfacecolor,
                                 timestamp=f_timestamp(k) if timestamp is not None else None,
                                 shortlabel=shortlabel)
            
            if vipy.globals._user_hit_escape():
                break
    vipy.show.close(figure)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.stabilize"><code class="name flex">
<span>def <span class="ident">stabilize</span></span>(<span>self, padheightfrac=0.125, padwidthfrac=0.25, padheightpx=None, padwidthpx=None, gpu=None, outfile=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Background stablization using flow based stabilization masking foreground region.
</p>
<ul>
<li>This will output a video with all frames aligned to the first frame, such that the background is static.</li>
<li>This uses the flow based approach described in <code><a title="vipy.flow.Flow.stabilize" href="flow.html#vipy.flow.Flow.stabilize">Flow.stabilize()</a></code></li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>padheightfrac</code></strong></dt>
<dd>[float] The height padding (relative to video height) to be applied to output video to allow for vertical stabilization</dd>
<dt><strong><code>padwidthfrac</code></strong></dt>
<dd>[float]
The width padding (relative to video width) to be applied to output video to allow for horizontal stabilization</dd>
<dt><strong><code>padheightpx</code></strong></dt>
<dd>[int]
The height padding to be applied to output video to allow for vertical stabilization.
Overrides padheight.</dd>
<dt><strong><code>padwidthpx</code></strong></dt>
<dd>[int]
The width padding to be applied to output video to allow for horizontal stabilization.
Overrides padwidth.</dd>
<dt><strong><code>gpu</code></strong></dt>
<dd>[int] The GPU index to use, if opencv has been compiled with GPU support (this is rare)</dd>
<dt><strong><code>outfile</code></strong></dt>
<dd>[str]
The output filename to store the stabilized video</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul>
<li>If the camera pans outside the image rectangle, increase the padheight or padwidth to make sure that the actor stays inside the stabilized image rectangle</li>
<li>If there are moving actors in the scene, include bounding boxes for each and these boxes are ignored as keeyouts in the flow stabilization</li>
</ul>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3920-L3946" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def stabilize(self, padheightfrac=0.125, padwidthfrac=0.25, padheightpx=None, padwidthpx=None, gpu=None, outfile=None):
    &#34;&#34;&#34;Background stablization using flow based stabilization masking foreground region.  
    
    - This will output a video with all frames aligned to the first frame, such that the background is static.
    - This uses the flow based approach described in `vipy.flow.Flow.stabilize`

    Args:
    
        padheightfrac: [float] The height padding (relative to video height) to be applied to output video to allow for vertical stabilization
        padwidthfrac: [float]  The width padding (relative to video width) to be applied to output video to allow for horizontal stabilization
        padheightpx: [int]  The height padding to be applied to output video to allow for vertical stabilization.  Overrides padheight.
        padwidthpx: [int]  The width padding to be applied to output video to allow for horizontal stabilization.  Overrides padwidth.
        gpu: [int] The GPU index to use, if opencv has been compiled with GPU support (this is rare)
        outfile: [str]  The output filename to store the stabilized video

    Returns:
    
        A clone of this video with background pixels stabilized to the first frame.  

    .. note::
    
        - If the camera pans outside the image rectangle, increase the padheight or padwidth to make sure that the actor stays inside the stabilized image rectangle
        - If there are moving actors in the scene, include bounding boxes for each and these boxes are ignored as keeyouts in the flow stabilization

    &#34;&#34;&#34;
    from vipy.flow import Flow  # requires opencv
    return Flow(flowdim=256, gpu=gpu).stabilize(self.clone(), residual=True, strict=True, padheightfrac=padheightfrac, padwidthfrac=padwidthfrac, padheightpx=padheightpx, padwidthpx=padwidthpx, outfile=outfile)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.startframe"><code class="name flex">
<span>def <span class="ident">startframe</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3650-L3651" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def startframe(self):
    return self._startframe</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.thumbnail"><code class="name flex">
<span>def <span class="ident">thumbnail</span></span>(<span>self, outfile=None, frame=0, fontsize=10, nocaption=False, boxalpha=0.25, dpi=200, textfacecolor='white', textfacealpha=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Return annotated frame=k of video, save annotation visualization to provided outfile if provided, otherwise return vipy.image.Scene</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3915-L3918" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def thumbnail(self, outfile=None, frame=0, fontsize=10, nocaption=False, boxalpha=0.25, dpi=200, textfacecolor=&#39;white&#39;, textfacealpha=1.0):
    &#34;&#34;&#34;Return annotated frame=k of video, save annotation visualization to provided outfile if provided, otherwise return vipy.image.Scene&#34;&#34;&#34;
    im = self.frame(frame, img=self.preview(framenum=frame).array())
    return im.savefig(outfile=outfile, fontsize=fontsize, nocaption=nocaption, boxalpha=boxalpha, dpi=dpi, textfacecolor=textfacecolor, textfacealpha=textfacealpha) if outfile is not None else im</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.track"><code class="name flex">
<span>def <span class="ident">track</span></span>(<span>self, id)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2794-L2795" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def track(self, id):
    return self.tracks(id=id)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.trackbox"><code class="name flex">
<span>def <span class="ident">trackbox</span></span>(<span>self, dilate=1.0)</span>
</code></dt>
<dd>
<div class="desc"><p>The trackbox is the union of all track bounding boxes in the video, or None if there are no tracks</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>dilate</code></strong></dt>
<dd>[float] A dilation factor to apply to the trackbox before returning.
See <code><a title="vipy.geometry.BoundingBox.dilate" href="geometry.html#vipy.geometry.BoundingBox.dilate">BoundingBox.dilate()</a></code></dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A <code><a title="vipy.geometry.BoundingBox" href="geometry.html#vipy.geometry.BoundingBox">BoundingBox</a></code> which is the union of all boxes in the track (or None if no boxes exist)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3409-L3420" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def trackbox(self, dilate=1.0):
    &#34;&#34;&#34;The trackbox is the union of all track bounding boxes in the video, or None if there are no tracks
    
    Args:
        dilate: [float] A dilation factor to apply to the trackbox before returning.  See `vipy.geometry.BoundingBox.dilate`

    Returns:
        A `vipy.geometry.BoundingBox` which is the union of all boxes in the track (or None if no boxes exist)
    &#34;&#34;&#34;
    boxes = [t.clone().boundingbox() for t in self.tracklist()]
    boxes = [bb.dilate(dilate) for bb in boxes if bb is not None]
    return boxes[0].union(boxes[1:]) if len(boxes) &gt; 0 else None</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.trackclip"><code class="name flex">
<span>def <span class="ident">trackclip</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Split the scene into k separate scenes, one for each track.
Each scene starts and ends when the track starts and ends</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3308-L3310" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def trackclip(self):
    &#34;&#34;&#34;Split the scene into k separate scenes, one for each track.  Each scene starts and ends when the track starts and ends&#34;&#34;&#34;
    return [t.setattribute(&#39;_instance_id&#39;, &#39;%s_%d_trackclip&#39; % (t.videoid(), k)).clip(t.track(t.actorid()).startframe(), t.track(t.actorid()).endframe()) for (k,t) in enumerate(self.tracksplit())]</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.trackcrop"><code class="name flex">
<span>def <span class="ident">trackcrop</span></span>(<span>self, dilate=1.0, maxsquare=False, zeropad=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the trackcrop() of the scene which is the crop of the video using the <code><a title="vipy.video.Scene.trackbox" href="#vipy.video.Scene.trackbox">Scene.trackbox()</a></code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>zeropad</code></strong></dt>
<dd>[bool] If True, the zero pad the crop if it is outside the image rectangle, otherwise return only valid pixels inside the image rectangle</dd>
<dt><strong><code>maxsquare</code></strong></dt>
<dd>[bool] If True, make the bounding box the maximum square before cropping</dd>
<dt><strong><code>dilate</code></strong></dt>
<dd>[float] The dilation factor to apply to the trackbox prior to cropping</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A <code><a title="vipy.video.Scene" href="#vipy.video.Scene">Scene</a></code> object from cropping the video using the trackbox.
If there are no tracks, return None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3431-L3444" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def trackcrop(self, dilate=1.0, maxsquare=False, zeropad=True):
    &#34;&#34;&#34;Return the trackcrop() of the scene which is the crop of the video using the `vipy.video.Scene.trackbox`.
     
    Args:
        zeropad: [bool] If True, the zero pad the crop if it is outside the image rectangle, otherwise return only valid pixels inside the image rectangle
        maxsquare: [bool] If True, make the bounding box the maximum square before cropping
        dilate: [float] The dilation factor to apply to the trackbox prior to cropping
    
    Returns:
       A `vipy.video.Scene` object from cropping the video using the trackbox.  If there are no tracks, return None.  

    &#34;&#34;&#34;
    bb = self.trackbox(dilate)  # may be None if trackbox is degenerate
    return self.crop(bb.maxsquareif(maxsquare), zeropad=zeropad) if bb is not None else None  </code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.trackfilter"><code class="name flex">
<span>def <span class="ident">trackfilter</span></span>(<span>self, f, activitytrack=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply lambda function f to each object and keep if filter is True.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>activitytrack</code></strong></dt>
<dd>[bool] If true, remove track assignment from activities also, may result in activities with no tracks</dd>
<dt><strong><code>f</code></strong></dt>
<dd>[lambda]
The lambda function to apply to each track t, and if f(t) returns True, then keep the track</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;Applying track filter with activitytrack=True may result in activities with no associated tracks.
You should follow up with self.activityfilter(lambda a: len(a.trackids()) &gt; 0).</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2942-L2960" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def trackfilter(self, f, activitytrack=True):
    &#34;&#34;&#34;Apply lambda function f to each object and keep if filter is True.  
    
    Args:
        activitytrack: [bool] If true, remove track assignment from activities also, may result in activities with no tracks
        f: [lambda]  The lambda function to apply to each track t, and if f(t) returns True, then keep the track
    
    Returns:
        self, with tracks removed in-place

    .. note:: Applying track filter with activitytrack=True may result in activities with no associated tracks.  You should follow up with self.activityfilter(lambda a: len(a.trackids()) &gt; 0).
    &#34;&#34;&#34;
    assert callable(f)
    self._tracks = {k:t for (k,t) in self.tracks().items() if f(t) == True}
    if activitytrack:
        self.activitymap(lambda a: a.trackfilter(lambda ti: ti in self._tracks))  # remove track association in activities
        #if any([len(a.tracks()) == 0 for a in self.activitylist()]):
        #    warnings.warn(&#39;trackfilter(..., activitytrack=True) removed tracks which returned at least one degenerate activity with no tracks&#39;)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.trackidx"><code class="name flex">
<span>def <span class="ident">trackidx</span></span>(<span>self, idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the track at the specified index in the tracklist</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2802-L2804" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def trackidx(self, idx):
    &#34;&#34;&#34;Return the track at the specified index in the tracklist&#34;&#34;&#34;
    return self.tracklist()[idx]</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.trackindex"><code class="name flex">
<span>def <span class="ident">trackindex</span></span>(<span>self, id)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the index in the tracklist of the track with the provided track id</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2797-L2800" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def trackindex(self, id):
    &#34;&#34;&#34;Return the index in the tracklist of the track with the provided track id&#34;&#34;&#34;
    assert id in self.tracks()
    return [t.id() for t in self.tracklist()].index(id)</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.tracklist"><code class="name flex">
<span>def <span class="ident">tracklist</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2823-L2824" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tracklist(self):
    return list(self.tracks().values())  # triggers shallow copy</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.trackmap"><code class="name flex">
<span>def <span class="ident">trackmap</span></span>(<span>self, f, strict=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply lambda function f to each activity</p>
<p>-strict=True: enforce that lambda function must return non-degenerate Track() objects</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2962-L2970" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def trackmap(self, f, strict=True):
    &#34;&#34;&#34;Apply lambda function f to each activity

       -strict=True: enforce that lambda function must return non-degenerate Track() objects        
    &#34;&#34;&#34;
    assert callable(f)
    self._tracks = {k:f(t) for (k,t) in self.tracks().items()}
    assert all([isinstance(t, vipy.object.Track) and (strict is False or not t.isdegenerate()) for (tk,t) in self.tracks().items()]), &#34;Lambda function must return non-degenerate vipy.object.Track()&#34;
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.tracks"><code class="name flex">
<span>def <span class="ident">tracks</span></span>(<span>self, tracks=None, id=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return mutable dictionary of tracks,</p>
<h2 id="args">Args</h2>
<p>tracks [dict]: If provided, replace track dictionary with provided track dictionary, and return self
id [str]: If provided, return just the track associated with the provided track id</p>
<h2 id="returns">Returns</h2>
<p>This object if tracks!=None, otherwise the requested track (if id!=None) or trackdict (tracks=None)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2768-L2792" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tracks(self, tracks=None, id=None):
    &#34;&#34;&#34;Return mutable dictionary of tracks,
    
       Args:
           tracks [dict]: If provided, replace track dictionary with provided track dictionary, and return self
           id [str]: If provided, return just the track associated with the provided track id

       Returns:
           This object if tracks!=None, otherwise the requested track (if id!=None) or trackdict (tracks=None)

    &#34;&#34;&#34;        
    if isinstance(self._tracks, tuple):
        self._tracks = {t.id():t for t in [vipy.object.Track.from_json(json.loads(s)) for s in self._tracks]}  # on-demand unpack (efficient garbage collection for large list of objects)
    if tracks is None and id is None:
        return self._tracks  # mutable dict
    elif id is not None:
        return self._tracks[id]
    elif isinstance(tracks, dict):
        assert all([isinstance(t, vipy.object.Track) and k == t.id() for (k,t) in tracks.items()]), &#34;Invalid input - Must be dictionary of vipy.object.Track&#34;
        self._tracks = tracks.copy()  # shallow copy
        return self
    else:
        assert all([isinstance(t, vipy.object.Track) for t in tolist(tracks)]), &#34;Invalid input - Must be vipy.object.Track or list of vipy.object.Track&#34;
        self._tracks = {t.id():t for t in tolist(tracks)}  # insertion order preserved (python &gt;=3.6)
        return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.tracksplit"><code class="name flex">
<span>def <span class="ident">tracksplit</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Split the scene into k separate scenes, one for each track.
Each scene starts at frame 0 and is a shallow copy of self containing exactly one track.
</p>
<ul>
<li>This is useful for visualization by breaking a scene into a list of scenes that contain only one track.</li>
<li>The attribute '_trackindex' is set in the attributes dictionary to provide provenance for the track relative to the source video</li>
</ul>
<div class="admonition notes">
<p class="admonition-title">Notes:&ensp;Use clone() to create a deep copy if needed.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3298-L3306" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tracksplit(self):
    &#34;&#34;&#34;Split the scene into k separate scenes, one for each track.  Each scene starts at frame 0 and is a shallow copy of self containing exactly one track.  

    - This is useful for visualization by breaking a scene into a list of scenes that contain only one track.
    - The attribute &#39;_trackindex&#39; is set in the attributes dictionary to provide provenance for the track relative to the source video

    .. notes:: Use clone() to create a deep copy if needed.
    &#34;&#34;&#34;
    return [self.clone(shallow=True).setattribute(&#39;_trackindex&#39;, k).tracks(t).activityfilter(lambda a: a.hastrack(tk)) for (k,(tk,t)) in enumerate(self.tracks().items())]</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.union"><code class="name flex">
<span>def <span class="ident">union</span></span>(<span>self, other, temporal_iou_threshold=0.5, spatial_iou_threshold=0.6, strict=True, overlap='average', percentilecover=0.8, percentilesamples=100, activity=True, track=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Compute the union two scenes as the set of unique activities and tracks.
</p>
<p>A pair of activities or tracks are non-unique if they overlap spatially and temporally by a given IoU threshold.
Merge overlapping tracks.
Tracks are merged by considering the mean IoU at the overlapping segment of two tracks with the same category greater than the provided spatial_iou_threshold threshold
Activities are merged by considering the temporal IoU of the activities of the same class greater than the provided temporal_iou_threshold threshold</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>Other</code></strong></dt>
<dd>Scene or list of scenes for union.
Other may be a clip of self at a different framerate, spatial isotropic scake, clip offset</dd>
<dt><strong><code>spatial_iou_threshold</code></strong></dt>
<dd>The intersection over union threshold for the mean of the two segments of an overlapping track, Disable by setting to 1.0</dd>
<dt><strong><code>temporal_iou_threshold</code></strong></dt>
<dd>The intersection over union threshold for a temporal bounding box for a pair of activities to be declared duplicates.
Disable by setting to 1.0</dd>
<dt><strong><code>strict</code></strong></dt>
<dd>Require both scenes to share the same underlying video filename</dd>
<dt>overlap=['average', 'replace', 'keep']</dt>
<dt>- average: Merge two tracks by averaging the boxes (average=True) if overlapping</dt>
<dt>- replace:
merge two tracks by replacing overlapping boxes with other (discard self)</dt>
<dt>- keep: merge two tracks by keeping overlapping boxes with other (discard other)</dt>
<dt><strong><code>percentilecover</code></strong></dt>
<dd>[0,1]:
When determining the assignment of two tracks, compute the percentilecover of two tracks by ranking the cover in the overlapping segment and computing the mean of the top-k assignments, where k=len(segment)*percentilecover.</dd>
<dt><strong><code>percentilesamples</code></strong></dt>
<dd>[&gt;1]:
the number of samples along the overlapping scemgne for computing percentile cover</dd>
<dt><strong><code>activity</code></strong></dt>
<dd>[bool]: union() of activities only</dd>
<dt><strong><code>track</code></strong></dt>
<dd>[bool]: union() of tracks only</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul>
<li>This is useful for merging scenes computed using a lower resolution/framerate/clipped
object or activity detector without running the detector on the high-res scene</li>
<li>This function will preserve the invariance for v == v.clear().union(v.rescale(0.5).framerate(5).activityclip()), to within the quantization error of framerate() downsampling.</li>
<li>percentileiou is a robust method of track assignment when boxes for two tracks (e.g. ground truth and detections) where one track may deform due to occlusion.</li>
</ul>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3693-L3784" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def union(self, other, temporal_iou_threshold=0.5, spatial_iou_threshold=0.6, strict=True, overlap=&#39;average&#39;, percentilecover=0.8, percentilesamples=100, activity=True, track=True):
    &#34;&#34;&#34;Compute the union two scenes as the set of unique activities and tracks.  

       A pair of activities or tracks are non-unique if they overlap spatially and temporally by a given IoU threshold.  Merge overlapping tracks. 
       Tracks are merged by considering the mean IoU at the overlapping segment of two tracks with the same category greater than the provided spatial_iou_threshold threshold
       Activities are merged by considering the temporal IoU of the activities of the same class greater than the provided temporal_iou_threshold threshold

       Args:
           Other: Scene or list of scenes for union.  Other may be a clip of self at a different framerate, spatial isotropic scake, clip offset
           spatial_iou_threshold:  The intersection over union threshold for the mean of the two segments of an overlapping track, Disable by setting to 1.0
           temporal_iou_threshold:  The intersection over union threshold for a temporal bounding box for a pair of activities to be declared duplicates.  Disable by setting to 1.0
           strict:  Require both scenes to share the same underlying video filename
           overlap=[&#39;average&#39;, &#39;replace&#39;, &#39;keep&#39;]
               - average: Merge two tracks by averaging the boxes (average=True) if overlapping
               - replace:  merge two tracks by replacing overlapping boxes with other (discard self)
               - keep: merge two tracks by keeping overlapping boxes with other (discard other)
           percentilecover: [0,1]:  When determining the assignment of two tracks, compute the percentilecover of two tracks by ranking the cover in the overlapping segment and computing the mean of the top-k assignments, where k=len(segment)*percentilecover.
           percentilesamples: [&gt;1]:  the number of samples along the overlapping scemgne for computing percentile cover
           activity: [bool]: union() of activities only
           track: [bool]: union() of tracks only

       Returns:
           Updates this scene to include the non-overlapping activities from other.  By default, it takes the strict union of all activities and tracks. 

       .. note::
           - This is useful for merging scenes computed using a lower resolution/framerate/clipped  object or activity detector without running the detector on the high-res scene
           - This function will preserve the invariance for v == v.clear().union(v.rescale(0.5).framerate(5).activityclip()), to within the quantization error of framerate() downsampling.
           - percentileiou is a robust method of track assignment when boxes for two tracks (e.g. ground truth and detections) where one track may deform due to occlusion.
    &#34;&#34;&#34;
    assert overlap in [&#39;average&#39;, &#39;replace&#39;, &#39;keep&#39;], &#34;Invalid input - &#39;overlap&#39; must be in [average, replace, keep]&#34;
    assert spatial_iou_threshold &gt;= 0 and spatial_iou_threshold &lt;= 1, &#34;invalid spatial_iou_threshold, must be between [0,1]&#34;
    assert temporal_iou_threshold &gt;= 0 and temporal_iou_threshold &lt;= 1, &#34;invalid temporal_iou_threshold, must be between [0,1]&#34;        
    assert percentilesamples &gt;= 1, &#34;invalid samples, must be &gt;= 1&#34;
    if not activity and not track:
        return self  # nothing to do

    sc = self.clone()  # do not change self yet, make a copy then merge at the end
    for o in tolist(other):
        assert isinstance(o, Scene), &#34;Invalid input - must be vipy.video.Scene() object and not type=%s&#34; % str(type(o))

        if strict:
            assert sc.filename() == o.filename(), &#34;Invalid input - Scenes must have the same underlying video.  Disable this with strict=False.&#34;
        oc = o.clone()   # do not change other, make a copy

        # Key collision?
        if len(set(sc.tracks().keys()).intersection(set(oc.tracks().keys()))) &gt; 0:
            print(&#39;[vipy.video.union]: track key collision - Rekeying other... Use other.rekey() to suppress this warning.&#39;)
            oc.rekey()
        if len(set(sc.activities().keys()).intersection(set(oc.activities().keys()))) &gt; 0:
            print(&#39;[vipy.video.union]: activity key collision - Rekeying other... Use other.rekey() to suppress this warning.&#39;)                
            oc.rekey()

        # Similarity transform?  Other may differ from self by a temporal scale (framerate), temporal translation (clip) or spatial isotropic scale (rescale)
        assert np.isclose(sc.aspect_ratio(), oc.aspect_ratio(), atol=1E-2), &#34;Invalid input - Scenes must have the same aspect ratio&#34;
        if sc.width() != oc.width():
            oc = oc.rescale(sc.width() / oc.width())   # match spatial scale
        if not np.isclose(sc.framerate(), oc.framerate(), atol=1E-3):
            oc = oc.framerate(sc.framerate())   # match temporal scale (video in oc will not match, only annotations)
        if sc.startframe() != oc.startframe():
            dt = (oc.startframe() if oc.startframe() is not None else 0) - (sc.startframe() if sc.startframe() is not None else 0)
            oc = oc.trackmap(lambda t: t.offset(dt=dt)).activitymap(lambda a: a.offset(dt=dt))  # match temporal translation of tracks and activities
        oc = oc.trackfilter(lambda t: ((not t.isdegenerate()) and len(t)&gt;0), activitytrack=False)  

        # Merge other tracks into selfclone: one-to-many mapping from self to other
        merged = {}  # dictionary mapping trackid in other to the trackid in self, each track in other can be merged at most once
        for ti in sorted(sc.tracklist(), key=lambda t: len(t), reverse=True):  # longest to shortest
            for tj in sorted(oc.tracklist(), key=lambda t: len(t), reverse=True):  
                if ti.category() == tj.category() and (tj.id() not in merged) and tj.segment_percentilecover(sc.track(ti.id()), percentile=percentilecover, samples=percentilesamples) &gt; spatial_iou_threshold:  # mean framewise overlap during overlapping segment of two tracks
                    sc.tracks()[ti.id()] = sc.track(ti.id()).union(tj, overlap=overlap)  # merge duplicate/fragmented tracks from other into self, union() returns clone
                    merged[tj.id()] = ti.id()  
                    print(&#39;[vipy.video.union]: merging track &#34;%s&#34;(id=%s) + &#34;%s&#34;(id=%s) for scene &#34;%s&#34;&#39; % (str(ti), str(ti.id()), str(tj), str(tj.id()), str(sc)))                        
        oc.trackfilter(lambda t: t.id() not in merged, activitytrack=False)  # remove duplicate other track for final union

        # Merge other activities into selfclone: one-to-one mapping
        for (i,j) in merged.items():  # i=id of other, j=id of self
            oc.activitymap(lambda a: a.replaceid(i, j) if a.hastrack(i) else a)  # update track IDs referenced in activities for merged tracks
        for (i,ai) in sc.activities().items():
            for (j,aj) in oc.activities().items():
                if ai.category() == aj.category() and set(ai.trackids()) == set(aj.trackids()) and ai.temporal_iou(aj) &gt; temporal_iou_threshold:
                    oc.activityfilter(lambda a: a.id() != j)  # remove duplicate activity from final union
        oc.activityfilter(lambda a: len(a.tracks())&gt;0)  # remove empty activities not merged

        # Union
        sc.tracks().update(oc.tracks())
        sc.activities().update(oc.activities())

    # Final union of unique tracks/activities
    if track:
        self.tracks(sc.tracklist())  # union of tracks only
    if activity:
        self.activities(sc.activitylist())  # union of activities only: may reference tracks not in self of track=False
    return self        </code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.zeromask"><code class="name flex">
<span>def <span class="ident">zeromask</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for fgmask</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3990-L3992" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def zeromask(self):
    &#34;&#34;&#34;Alias for fgmask&#34;&#34;&#34;
    return self.fgmask()</code></pre>
</details>
</dd>
<dt id="vipy.video.Scene.zeropad"><code class="name flex">
<span>def <span class="ident">zeropad</span></span>(<span>self, padwidth, padheight)</span>
</code></dt>
<dd>
<div class="desc"><p>Zero pad the video with padwidth columns before and after, and padheight rows before and after
Update tracks accordingly.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L3574-L3583" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def zeropad(self, padwidth, padheight):
    &#34;&#34;&#34;Zero pad the video with padwidth columns before and after, and padheight rows before and after
       Update tracks accordingly. 

    &#34;&#34;&#34;
    
    assert isinstance(padwidth, int) and isinstance(padheight, int)
    super().zeropad(padwidth, padheight)  
    self._tracks = {k:t.offset(dx=padwidth, dy=padheight) for (k,t) in self.tracks().items()}
    return self</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="vipy.video.VideoCategory" href="#vipy.video.VideoCategory">VideoCategory</a></b></code>:
<ul class="hlist">
<li><code><a title="vipy.video.VideoCategory.abspath" href="#vipy.video.Video.abspath">abspath</a></code></li>
<li><code><a title="vipy.video.VideoCategory.array" href="#vipy.video.Video.array">array</a></code></li>
<li><code><a title="vipy.video.VideoCategory.aspect_ratio" href="#vipy.video.Video.aspect_ratio">aspect_ratio</a></code></li>
<li><code><a title="vipy.video.VideoCategory.bias" href="#vipy.video.Video.bias">bias</a></code></li>
<li><code><a title="vipy.video.VideoCategory.bytes" href="#vipy.video.Video.bytes">bytes</a></code></li>
<li><code><a title="vipy.video.VideoCategory.canload" href="#vipy.video.Video.canload">canload</a></code></li>
<li><code><a title="vipy.video.VideoCategory.centercrop" href="#vipy.video.Video.centercrop">centercrop</a></code></li>
<li><code><a title="vipy.video.VideoCategory.centersquare" href="#vipy.video.Video.centersquare">centersquare</a></code></li>
<li><code><a title="vipy.video.VideoCategory.channels" href="#vipy.video.Video.channels">channels</a></code></li>
<li><code><a title="vipy.video.VideoCategory.channelshape" href="#vipy.video.Video.channelshape">channelshape</a></code></li>
<li><code><a title="vipy.video.VideoCategory.cliprange" href="#vipy.video.Video.cliprange">cliprange</a></code></li>
<li><code><a title="vipy.video.VideoCategory.clone" href="#vipy.video.Video.clone">clone</a></code></li>
<li><code><a title="vipy.video.VideoCategory.colorspace" href="#vipy.video.Video.colorspace">colorspace</a></code></li>
<li><code><a title="vipy.video.VideoCategory.commandline" href="#vipy.video.Video.commandline">commandline</a></code></li>
<li><code><a title="vipy.video.VideoCategory.concatenate" href="#vipy.video.Video.concatenate">concatenate</a></code></li>
<li><code><a title="vipy.video.VideoCategory.cropeven" href="#vipy.video.Video.cropeven">cropeven</a></code></li>
<li><code><a title="vipy.video.VideoCategory.dict" href="#vipy.video.Video.dict">dict</a></code></li>
<li><code><a title="vipy.video.VideoCategory.download" href="#vipy.video.Video.download">download</a></code></li>
<li><code><a title="vipy.video.VideoCategory.downloadif" href="#vipy.video.Video.downloadif">downloadif</a></code></li>
<li><code><a title="vipy.video.VideoCategory.duration" href="#vipy.video.Video.duration">duration</a></code></li>
<li><code><a title="vipy.video.VideoCategory.duration_in_frames" href="#vipy.video.Video.duration_in_frames">duration_in_frames</a></code></li>
<li><code><a title="vipy.video.VideoCategory.duration_in_frames_of_videofile" href="#vipy.video.Video.duration_in_frames_of_videofile">duration_in_frames_of_videofile</a></code></li>
<li><code><a title="vipy.video.VideoCategory.duration_in_seconds_of_videofile" href="#vipy.video.Video.duration_in_seconds_of_videofile">duration_in_seconds_of_videofile</a></code></li>
<li><code><a title="vipy.video.VideoCategory.fetch" href="#vipy.video.Video.fetch">fetch</a></code></li>
<li><code><a title="vipy.video.VideoCategory.ffplay" href="#vipy.video.Video.ffplay">ffplay</a></code></li>
<li><code><a title="vipy.video.VideoCategory.filename" href="#vipy.video.Video.filename">filename</a></code></li>
<li><code><a title="vipy.video.VideoCategory.filesize" href="#vipy.video.Video.filesize">filesize</a></code></li>
<li><code><a title="vipy.video.VideoCategory.fliplr" href="#vipy.video.Video.fliplr">fliplr</a></code></li>
<li><code><a title="vipy.video.VideoCategory.flipud" href="#vipy.video.Video.flipud">flipud</a></code></li>
<li><code><a title="vipy.video.VideoCategory.flush" href="#vipy.video.Video.flush">flush</a></code></li>
<li><code><a title="vipy.video.VideoCategory.flush_and_return" href="#vipy.video.Video.flush_and_return">flush_and_return</a></code></li>
<li><code><a title="vipy.video.VideoCategory.framerate_of_videofile" href="#vipy.video.Video.framerate_of_videofile">framerate_of_videofile</a></code></li>
<li><code><a title="vipy.video.VideoCategory.frames" href="#vipy.video.Video.frames">frames</a></code></li>
<li><code><a title="vipy.video.VideoCategory.fromarray" href="#vipy.video.Video.fromarray">fromarray</a></code></li>
<li><code><a title="vipy.video.VideoCategory.fromdirectory" href="#vipy.video.Video.fromdirectory">fromdirectory</a></code></li>
<li><code><a title="vipy.video.VideoCategory.fromframes" href="#vipy.video.Video.fromframes">fromframes</a></code></li>
<li><code><a title="vipy.video.VideoCategory.gain" href="#vipy.video.Video.gain">gain</a></code></li>
<li><code><a title="vipy.video.VideoCategory.gif" href="#vipy.video.Video.gif">gif</a></code></li>
<li><code><a title="vipy.video.VideoCategory.hasattribute" href="#vipy.video.Video.hasattribute">hasattribute</a></code></li>
<li><code><a title="vipy.video.VideoCategory.hasfilename" href="#vipy.video.Video.hasfilename">hasfilename</a></code></li>
<li><code><a title="vipy.video.VideoCategory.hasurl" href="#vipy.video.Video.hasurl">hasurl</a></code></li>
<li><code><a title="vipy.video.VideoCategory.height" href="#vipy.video.Video.height">height</a></code></li>
<li><code><a title="vipy.video.VideoCategory.iscolor" href="#vipy.video.Video.iscolor">iscolor</a></code></li>
<li><code><a title="vipy.video.VideoCategory.isdownloaded" href="#vipy.video.Video.isdownloaded">isdownloaded</a></code></li>
<li><code><a title="vipy.video.VideoCategory.isgrayscale" href="#vipy.video.Video.isgrayscale">isgrayscale</a></code></li>
<li><code><a title="vipy.video.VideoCategory.isloadable" href="#vipy.video.Video.isloadable">isloadable</a></code></li>
<li><code><a title="vipy.video.VideoCategory.isloaded" href="#vipy.video.Video.isloaded">isloaded</a></code></li>
<li><code><a title="vipy.video.VideoCategory.issquare" href="#vipy.video.Video.issquare">issquare</a></code></li>
<li><code><a title="vipy.video.VideoCategory.load" href="#vipy.video.Video.load">load</a></code></li>
<li><code><a title="vipy.video.VideoCategory.map" href="#vipy.video.Video.map">map</a></code></li>
<li><code><a title="vipy.video.VideoCategory.maxdim" href="#vipy.video.Video.maxdim">maxdim</a></code></li>
<li><code><a title="vipy.video.VideoCategory.maxmatte" href="#vipy.video.Video.maxmatte">maxmatte</a></code></li>
<li><code><a title="vipy.video.VideoCategory.maxsquare" href="#vipy.video.Video.maxsquare">maxsquare</a></code></li>
<li><code><a title="vipy.video.VideoCategory.metadata" href="#vipy.video.Video.metadata">metadata</a></code></li>
<li><code><a title="vipy.video.VideoCategory.mindim" href="#vipy.video.Video.mindim">mindim</a></code></li>
<li><code><a title="vipy.video.VideoCategory.minsquare" href="#vipy.video.Video.minsquare">minsquare</a></code></li>
<li><code><a title="vipy.video.VideoCategory.mutable" href="#vipy.video.Video.mutable">mutable</a></code></li>
<li><code><a title="vipy.video.VideoCategory.normalize" href="#vipy.video.Video.normalize">normalize</a></code></li>
<li><code><a title="vipy.video.VideoCategory.nourl" href="#vipy.video.Video.nourl">nourl</a></code></li>
<li><code><a title="vipy.video.VideoCategory.numpy" href="#vipy.video.Video.numpy">numpy</a></code></li>
<li><code><a title="vipy.video.VideoCategory.pad" href="#vipy.video.Video.pad">pad</a></code></li>
<li><code><a title="vipy.video.VideoCategory.pkl" href="#vipy.video.Video.pkl">pkl</a></code></li>
<li><code><a title="vipy.video.VideoCategory.pklif" href="#vipy.video.Video.pklif">pklif</a></code></li>
<li><code><a title="vipy.video.VideoCategory.play" href="#vipy.video.Video.play">play</a></code></li>
<li><code><a title="vipy.video.VideoCategory.preview" href="#vipy.video.Video.preview">preview</a></code></li>
<li><code><a title="vipy.video.VideoCategory.print" href="#vipy.video.Video.print">print</a></code></li>
<li><code><a title="vipy.video.VideoCategory.probe" href="#vipy.video.Video.probe">probe</a></code></li>
<li><code><a title="vipy.video.VideoCategory.probeshape" href="#vipy.video.Video.probeshape">probeshape</a></code></li>
<li><code><a title="vipy.video.VideoCategory.randomcrop" href="#vipy.video.Video.randomcrop">randomcrop</a></code></li>
<li><code><a title="vipy.video.VideoCategory.relpath" href="#vipy.video.Video.relpath">relpath</a></code></li>
<li><code><a title="vipy.video.VideoCategory.rename" href="#vipy.video.Video.rename">rename</a></code></li>
<li><code><a title="vipy.video.VideoCategory.resolution_of_videofile" href="#vipy.video.Video.resolution_of_videofile">resolution_of_videofile</a></code></li>
<li><code><a title="vipy.video.VideoCategory.restore" href="#vipy.video.Video.restore">restore</a></code></li>
<li><code><a title="vipy.video.VideoCategory.returns" href="#vipy.video.Video.returns">returns</a></code></li>
<li><code><a title="vipy.video.VideoCategory.rot90ccw" href="#vipy.video.Video.rot90ccw">rot90ccw</a></code></li>
<li><code><a title="vipy.video.VideoCategory.rot90cw" href="#vipy.video.Video.rot90cw">rot90cw</a></code></li>
<li><code><a title="vipy.video.VideoCategory.sanitize" href="#vipy.video.Video.sanitize">sanitize</a></code></li>
<li><code><a title="vipy.video.VideoCategory.saveas" href="#vipy.video.Video.saveas">saveas</a></code></li>
<li><code><a title="vipy.video.VideoCategory.savetemp" href="#vipy.video.Video.savetemp">savetemp</a></code></li>
<li><code><a title="vipy.video.VideoCategory.savetmp" href="#vipy.video.Video.savetmp">savetmp</a></code></li>
<li><code><a title="vipy.video.VideoCategory.shape" href="#vipy.video.Video.shape">shape</a></code></li>
<li><code><a title="vipy.video.VideoCategory.speed" href="#vipy.video.Video.speed">speed</a></code></li>
<li><code><a title="vipy.video.VideoCategory.store" href="#vipy.video.Video.store">store</a></code></li>
<li><code><a title="vipy.video.VideoCategory.stream" href="#vipy.video.Video.stream">stream</a></code></li>
<li><code><a title="vipy.video.VideoCategory.take" href="#vipy.video.Video.take">take</a></code></li>
<li><code><a title="vipy.video.VideoCategory.tonumpy" href="#vipy.video.Video.tonumpy">tonumpy</a></code></li>
<li><code><a title="vipy.video.VideoCategory.torch" href="#vipy.video.Video.torch">torch</a></code></li>
<li><code><a title="vipy.video.VideoCategory.unstore" href="#vipy.video.Video.unstore">unstore</a></code></li>
<li><code><a title="vipy.video.VideoCategory.url" href="#vipy.video.Video.url">url</a></code></li>
<li><code><a title="vipy.video.VideoCategory.videoid" href="#vipy.video.Video.videoid">videoid</a></code></li>
<li><code><a title="vipy.video.VideoCategory.webp" href="#vipy.video.Video.webp">webp</a></code></li>
<li><code><a title="vipy.video.VideoCategory.width" href="#vipy.video.Video.width">width</a></code></li>
<li><code><a title="vipy.video.VideoCategory.zeropadlike" href="#vipy.video.Video.zeropadlike">zeropadlike</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="vipy.video.Stream"><code class="flex name class">
<span>class <span class="ident">Stream</span></span>
<span>(</span><span>v, queuesize, write, overwrite, bitrate=None, buffered=False, bufsize=256, rebuffered=False)</span>
</code></dt>
<dd>
<div class="desc"><p>vipy.video.Stream class. </p>
<p>This class is the primary mechanism for streaming frames and clips from long videos or live video streams.</p>
<ul>
<li>The stream is constructed from a shared underlying video in self._video.
</li>
<li>As the shared video is updated with annotations, the stream can generate frames and clips that contain these annotations</li>
<li>The shared video allows for multiple concurrent iterators all sourced from the same video, iterating over different frames, clips and rates</li>
<li>The iterator leverages a pipe to FFMPEG, reading numpy frames from the video filter chain.
</li>
<li>The pipe is written from a thread which is dedicated to reading frames from ffmpeg</li>
<li>Each numpy frame is added to a queue, with a null termintor when end of stream is reached</li>
<li>The iterator then reads from the queue, and returns annotated frames</li>
</ul>
<p>This iterator can also be used as a buffered stream.
Buffered streams have a primary iterator which saves a fixed stream buffer
of frames so that subsequent iterators can pull temporally aligned frames.
This is useful to avoid having multiple FFMPEG pipes
open simultaneously, and can allow for synchronized access to live video streams without timestamping.
</p>
<ul>
<li>The primary iterator is the first iterator over the video with stream(buffered=True)</li>
<li>The primary iterator creates a private attribute self._video.attributes['__stream_buffer'] which caches frames</li>
<li>The stream buffer saves numpy arrays from the iterator with a fixed buffer length (number of frames)</li>
<li>The secondary iterator (e.g. any iterator that accesses the video after the primary iterator is initially created) will read from the stream buffer</li>
<li>All iterators share the underlying self._video object in the stream so that if the video annotations are updated by an iterator, the annotated frames are accessible in the iterators</li>
<li>The secondary iterators are synchronized to the stream buffer that is read by the primary iterator.
This is useful for synchronizing streams for live camera streams without absolute timestamps.</li>
<li>There can be an unlimited number of secondary iterators, without incurring a penalty on frame access</li>
</ul>
<p>This iterator can iterate over clips, frames or batches.
</p>
<ul>
<li>A clip is a sequence of frames such that each clip is separated by a fixed number of frames.
</li>
<li>Clips are useful for temporal encoding of short atomic activities</li>
<li>A batch is a sequence of n frames with a stride of n.
</li>
<li>A batch is useful for iterating over groups of frames that are operated in parallel on a GPU</li>
</ul>
<pre><code class="language-python">for (im1, im2, v3) in zip(v.stream(buffered=True), v.stream(buffered=True).frame(delay=30), v.stream(buffered=True).clip(n=16,m=1):
    # im1: `vipy.image.Scene` at frame index k
    # im2: `vipy.image.Scene` at frame index k-30
    # v3: `vipy.video.Scene` at frame range [k, k-16]
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul>
<li>This is designed to be accessed as <code><a title="vipy.video.Video.stream" href="#vipy.video.Video.stream">Video.stream()</a></code> and not accessed as a standalone class..</li>
</ul>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L54-L395" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Stream(object):
    &#34;&#34;&#34;vipy.video.Stream class. 

    This class is the primary mechanism for streaming frames and clips from long videos or live video streams.
    
    - The stream is constructed from a shared underlying video in self._video.  
    - As the shared video is updated with annotations, the stream can generate frames and clips that contain these annotations
    - The shared video allows for multiple concurrent iterators all sourced from the same video, iterating over different frames, clips and rates
    - The iterator leverages a pipe to FFMPEG, reading numpy frames from the video filter chain.  
    - The pipe is written from a thread which is dedicated to reading frames from ffmpeg
    - Each numpy frame is added to a queue, with a null termintor when end of stream is reached
    - The iterator then reads from the queue, and returns annotated frames
        
    This iterator can also be used as a buffered stream.  Buffered streams have a primary iterator which saves a fixed stream buffer
    of frames so that subsequent iterators can pull temporally aligned frames.  This is useful to avoid having multiple FFMPEG pipes 
    open simultaneously, and can allow for synchronized access to live video streams without timestamping.  

    - The primary iterator is the first iterator over the video with stream(buffered=True)
    - The primary iterator creates a private attribute self._video.attributes[&#39;__stream_buffer&#39;] which caches frames
    - The stream buffer saves numpy arrays from the iterator with a fixed buffer length (number of frames)
    - The secondary iterator (e.g. any iterator that accesses the video after the primary iterator is initially created) will read from the stream buffer
    - All iterators share the underlying self._video object in the stream so that if the video annotations are updated by an iterator, the annotated frames are accessible in the iterators
    - The secondary iterators are synchronized to the stream buffer that is read by the primary iterator.  This is useful for synchronizing streams for live camera streams without absolute timestamps.
    - There can be an unlimited number of secondary iterators, without incurring a penalty on frame access

    This iterator can iterate over clips, frames or batches.  
        
    - A clip is a sequence of frames such that each clip is separated by a fixed number of frames.  
    - Clips are useful for temporal encoding of short atomic activities
    - A batch is a sequence of n frames with a stride of n.  
    - A batch is useful for iterating over groups of frames that are operated in parallel on a GPU

    ```python
    for (im1, im2, v3) in zip(v.stream(buffered=True), v.stream(buffered=True).frame(delay=30), v.stream(buffered=True).clip(n=16,m=1):
        # im1: `vipy.image.Scene` at frame index k
        # im2: `vipy.image.Scene` at frame index k-30
        # v3: `vipy.video.Scene` at frame range [k, k-16]
    ```

    .. note::
        - This is designed to be accessed as `vipy.video.Video.stream` and not accessed as a standalone class..

    &#34;&#34;&#34;
    def __init__(self, v, queuesize, write, overwrite, bitrate=None, buffered=False, bufsize=256, rebuffered=False):
        self._video = v   # do not clone
        self._write_pipe = None
        self._vcodec = &#39;libx264&#39;
        self._bitrate = bitrate  # e.g. &#39;2000k&#39;, recommended settings for live streaming
        self._framerate = self._video.framerate()
        self._outfile = self._video.filename()
        self._write = write or overwrite               
        assert self._write is False or (overwrite is True or not os.path.exists(self._outfile)), &#34;Output file &#39;%s&#39; exists - Writable stream cannot overwrite existing video file unless overwrite=True&#34; % self._outfile
        if overwrite and os.path.exists(self._outfile):
            os.remove(self._outfile)                
        self._shape = self._video.shape() if (not self._write) or (self._write and self._video.canload()) else None  # shape for write can be defined by first frame
        assert (write is True or overwrite is True) or self._shape is not None, &#34;Invalid video &#39;%s&#39;&#34; % (str(v))
        self._queuesize = queuesize
        self._bufsize = bufsize
        self._buffered = buffered
        self._is_stream_buffer_owner = False                            
        assert self._bufsize &gt;= 1
        if rebuffered:
            self._video.attributes.pop(&#34;__stream_buffer&#34;, None)  # force reinitialization
        
    def __enter__(self):
        &#34;&#34;&#34;Write pipe context manager&#34;&#34;&#34;
        assert self._write, &#34;invalid parameters for write only context manager&#34;

        if self._shape is not None:
            (height, width) = self._shape
            outfile = self._outfile if self._outfile is not None else self._url  # may be youtube/twitch live stream
            outrate = 30 if vipy.util.isRTMPurl(outfile) else self._video.framerate()
            fiv = (ffmpeg.input(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;, s=&#39;{}x{}&#39;.format(width, height), r=self._video.framerate()) 
                   .filter(&#39;pad&#39;, &#39;ceil(iw/2)*2&#39;, &#39;ceil(ih/2)*2&#39;))
            fi = ffmpeg.concat(fiv.filter(&#39;fps&#39;, fps=30, round=&#39;up&#39;), ffmpeg.input(&#39;anullsrc&#39;, f=&#39;lavfi&#39;), v=1, a=1) if isRTMPurl(outfile) else fiv  # empty audio for youtube-live
            kwargs = {&#39;video_bitrate&#39;:self._bitrate} if self._bitrate is not None else {}
            fo = (fi.output(filename=self._outfile if self._outfile is not None else self._url,
                            pix_fmt=&#39;yuv420p&#39;,
                            vcodec=self._vcodec,
                            f=&#39;flv&#39; if vipy.util.isRTMPurl(outfile) else vipy.util.fileext(outfile, withdot=False),
                            g=2*outrate,
                            **kwargs)                              
                  .overwrite_output() 
                  .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;quiet&#39; if not vipy.globals.isdebug() else &#39;debug&#39;))
            self._write_pipe = fo.run_async(pipe_stdin=True)
                    
        self._writeindex = 0
        return self
            
    def __exit__(self, type, value, tb):
        &#34;&#34;&#34;Write pipe context manager
                
        ..note:: This is triggered on ctrl-c as the last step for cleanup
        &#34;&#34;&#34;
        if self._write_pipe is not None:
            self._write_pipe.stdin.close()
            self._write_pipe.wait()
            del self._write_pipe
            self._write_pipe = None
        if type is not None:
            raise
        return self
                
    def __call__(self, im):
        &#34;&#34;&#34;alias for write()&#34;&#34;&#34;
        return self.write(im)

    def _read_pipe(self):
        if not self._video.isloaded():
            p = self._video._ffmpeg.output(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;).global_args(&#39;-nostdin&#39;, &#39;-loglevel&#39;, &#39;debug&#39; if vipy.globals.isdebug() else &#39;quiet&#39;).run_async(pipe_stdout=True, pipe_stderr=True)
            assert p is not None, &#34;Invalid read pipe&#34;
            p.poll()
            return p
        else:
            return None

    def framerate(self):
        return self._video.framerate()
    
    def __iter__(self):
        &#34;&#34;&#34;Stream individual video frames.
        &#34;&#34;&#34;
        try:
            if self._video.isloaded():
                # For loaded video, just use the existing iterator for in-memory video
                for k in range(len(self._video)): 
                    yield self._video[k]

            else:
                # First stream iterator: read from video and store in stream buffer for all other iterators to access
                if self._buffered and not self._video.hasattribute(&#39;__stream_buffer&#39;):
                    self._video.attributes[&#39;__stream_buffer&#39;] = {}  # for synchronized frames with secondary iterator
                    self._is_stream_buffer_owner = True  # track which iterator created the stream buffer for cleanup in &#39;finally&#39;

                # Video pipe thread:
                # - Initialized only if not buffered (the default) or if primary iterator
                # - read numpy frames from the ffmpeg filter chain via a pipe
                # - store the resulting frames in a queue with a null terminated frame when the stream ends
                # - Threading is useful here because there is often time to switch when waiting on GPU I/O 
                if not self._buffered or self._is_stream_buffer_owner:
                    p = self._read_pipe()
                    q = queue.Queue(self._queuesize)
                    (h, w) = self._shape
                    
                    def _f_threadloop(pipe, queue, height, width, event):
                        assert pipe is not None, &#34;Invalid pipe&#34;
                        assert queue is not None, &#34;invalid queue&#34;
                        f = 0
                        while True:
                            in_bytes = pipe.stdout.read(height * width * 3)
                            if not in_bytes:
                                queue.put(None)
                                pipe.poll()
                                pipe.wait()
                                if pipe.returncode != 0:
                                    raise ValueError(&#39;Stream iterator exited with returncode %d&#39; % (pipe.returncode))
                                event.wait()
                                break
                            else:
                                queue.put(np.frombuffer(in_bytes, np.uint8).reshape([height, width, 3]))

                    e = threading.Event()
                    t = threading.Thread(target=_f_threadloop, args=(p, q, h, w, e), daemon=True)
                    t.start()

                    
                # Stream iterator:
                # -read frames from the thread queue and write to the private stream buffer stored as a video attribute with a frame index
                # -Frames are also yielded for the primary iterator
                # -The stream buffer is a dictionary that is n frames long, and if the newest frame from the pipe is frame k, the oldest frame is k-n which is yielded first
                # -If the stream is unbuffered, just read from the queue directly and yield the numpy frame
                b = self._video.attributes[&#39;__stream_buffer&#39;] if self._buffered else None  # buffer (if requested)
                k = 0   # current frame 
                while True:
                    if not self._buffered or self._is_stream_buffer_owner:
                        # Primary iterator: read from thread queue
                        if b is None:
                            (f, img) = (k, q.get())  # unbuffered: to yield latest from thread queue directly
                            k += 1                            
                        else:
                            b[k] = q.get()  # add to stream buffer, cache frames only, annotations are added synchronously on yield
                            (f, img) = (k, b[k])  # primary buffer: yield current frame from pipe
                            k += 1
                    else:
                        # Secondary iterator: read from stream buffer
                        while k not in b:
                            # &#34;Event&#34; wait: wait for primary iterator to start up and fill buffer, after it starts filling, this sleep should be unnecessary
                            time.sleep(0.001)  
                            
                        (f, img) = (k, b[k])  # secondary buffers: yield from stream buffer
                        k += 1
                        
                    if img is not None:
                        yield self._video.frame(f, img)  # yield a vipy.image.Scene object with annotations at frame f, using the latest annotation from the shared video object and shallow copy of img
                        if b is not None and self._is_stream_buffer_owner:
                            if len(b) &gt; self._bufsize:
                                del b[min(b.keys())]  # remove oldest frame from stream buffer
                    else:
                        if not self._buffered or self._is_stream_buffer_owner:
                            e.set()
                        break  # termination
                    
        except:
            raise
        
        finally:
            if self._is_stream_buffer_owner:
                self._video.delattribute(&#39;__stream_buffer&#39;)  # cleanup, or force a reinitialization by passing the rebuffered=True to the primary iterator
            
        
    def __getitem__(self, k):
        &#34;&#34;&#34;Retrieve individual frame index - this is inefficient, use __iter__ instead&#34;&#34;&#34;
        return self._video.preview(frame=k)  # this is inefficient

    def write(self, im, flush=False):
        &#34;&#34;&#34;Write individual frames to write stream&#34;&#34;&#34;
                
        assert isinstance(im, vipy.image.Image)
        if self._shape is None:
            self._shape = im.shape()
            assert im.channels() == 3, &#34;RGB frames required&#34;
            self.__enter__()
        assert self._write_pipe is not None, &#34;Write stream cannot be initialized&#34;                
        assert im.shape() == self._shape, &#34;Shape cannot change during writing&#34;
        self._write_pipe.stdin.write(im.array().astype(np.uint8).tobytes())
        if flush:
            self._write_pipe.stdin.flush()  # do we need this?
        if isinstance(im, vipy.image.Scene) and len(im.objects()) &gt; 0 and isinstance(self._video, vipy.video.Scene):
            for obj in im.objects():
                self._video.add(obj, frame=self._writeindex, rangecheck=False)
        self._writeindex += 1  # assumes that the source image is at the appropriate frame rate for this video

    def clip(self, n, m=1, continuous=False, tracks=True, activities=True, delay=0, ragged=False):
        &#34;&#34;&#34;Stream clips of length n such that the yielded video clip contains frame(0+delay) to frame(n+delay), and next contains frame(m+delay) to frame(n+m+delay). 
            
        Usage examples:
           
        ```python 
        for vc in v.stream().clip(n=16, m=2):
            # yields video vc with frames [0,16] from v
            # then video vc with frames [2,18] from v
            # ... finally video with frames [len(v)-n-1, len(v)-1]
        ```
            
        Introducing a delay so that the clips start at a temporal offset from v

        ```python
        for vc in v.stream().clip(n=8, m=3, delay=1):
            # yields video vc with frames [1,9]
            # then video vc with frames [4,12] ...
        ```

        Args:
            n: [int] the length of the clip in frames
            m: [int] the stride between clips in frames
            delay: [int] The temporal delay in frames for the clip, must be less than n and &gt;= 0
            continuous: [bool]  if true, then yield None for the sequential frames not aligned with a stride so that a clip is yielded on every frame
            activities: [bool]  if false, then activities from the source video are not copied into the clip
            tracks: [bool]  if false, then tracks from the source video are not copied into the clip

        Returns:
            An iterator that yields `vipy.video.Video` objects each of length n with startframe += m, starting at frame=delay, such that each video contains the tracks and activities (if requested) for this clip sourced from the shared stream video.

        .. note:: This iterator runs in a thread to help speed up fetching of frames for GPU I/Oe bound operations

        &#34;&#34;&#34;
        assert isinstance(n, int) and n&gt;0, &#34;Clip length must be a positive integer&#34;
        assert isinstance(m, int) and m&gt;0, &#34;Clip stride must be a positive integer&#34;
        assert isinstance(delay, int) and delay &gt;= 0 and delay &lt; n, &#34;Clip delay must be a positive integer less than n&#34;
        assert not self._buffered or 3*n &lt; self._bufsize, &#34;increase buffered stream size (bufsize) from %d to &gt;%d&#34; % (self._bufsize, 3*n)
        
        def _f_threadloop(v, streamiter, queue, event, ragged, m, n):
            (frames, newframes) = ([], [])            
            for (k,im) in enumerate(streamiter()):
                newframes.append(im)            
                if len(newframes) &gt;= m and len(frames)+len(newframes) &gt;= n:                                
                    # Use frameindex+1 so that we include (0,1), (1,2), (2,3), ... for n=2, m=1
                    # The delay shifts the clip +delay frames (1,2,3), (3,4,5), ... for n=3, m=2, delay=1                
                    frames.extend(newframes)
                    (frames, newframes) = (frames[-n:], [])
                    queue.put( (v.clear().clone(shallow=True).fromframes(frames), k) )  # fromframes() triggers array copy of frames
                elif continuous:
                    queue.put( (None, k) )
            if ragged and len(newframes) &gt; 0:
                queue.put( (v.clear().clone(shallow=True).fromframes(newframes), k) )  # fromframes() triggers array copy of newframes
            queue.put( (None, None) )
            event.wait()            

        vc = self._video.clone(flushfilter=True).clear().nourl().nofilename()
        q = queue.Queue(3)  # warning: if this queuesize*n &gt; buffersize, then there can be a deadlock
        e = threading.Event()        
        t = threading.Thread(target=_f_threadloop, args=(vc, self.__iter__, q, e, ragged, m, n), daemon=True)
        t.start()

        f_copy_annotations = lambda v, k, n: (v.activities([a.clone().offset(-(k-(n-1))).truncate(0,n-1) for (ak,a) in self._video.activities().items() if a.during_interval(k-(n-1), k, inclusive=False)] if activities else [])
                                              .tracks([t.clone(k-(n-1), k).offset(-(k-(n-1))).truncate(0,n-1) for (tk,t) in self._video.tracks().items() if t.during_interval(k-(n-1), k)] if tracks else [])
                                              if (v is not None and isinstance(v, vipy.video.Scene)) else v)
                
        while True:
            # The queue can be filled with more expensive copies and clones to speed up iteration when waiting for GPU I/O
            (v, k) = q.get()
            if k is not None:
                # This copy must be done sychronized at frame k with the current state of the annotations in the shared self._video
                yield f_copy_annotations(v, k, len(v)) if v is not None else None
            else:
                e.set()
                break
                
    def batch(self, n):
        &#34;&#34;&#34;Stream batches of length n such that each batch contains frames [0, n-1], [n, 2n-1], ...  Last batch will be ragged.
            
        The primary use case for batch() is to provide a mechanism for parallel batch processing on a GPU.
        
        ```python
        for im_gpu in myfunc(vi.stream().batch(16))):
            print(im_gpu)
        
        def myfunc(gen):
            for vb in gen:
                # process the batch vb (length n) in parallel by encoding on a GPU with batchsize=n
                for im in f_gpu(vb):
                    yield im_gpu:
        ```
        
        This will then yield the GPU batched processed image im_gpu.
        
        &#34;&#34;&#34;
        return self.clip(n=n, m=n, continuous=False, ragged=True) 


    def frame(self, delay=0):
        &#34;&#34;&#34;Stream individual frames of video with negative offset n frames to the stream head. If delay=30, this will return a frame 30 frames ago&#34;&#34;&#34;
        assert isinstance(delay, int) and delay &gt;= 0, &#34;Frame delay must be non-positive integer&#34;        
        n = -delay
        frames = []
        i = 0
        for (k,im) in enumerate(self):
            frames.append( (k,im) )
            (kout, imout) = frames[0]
            frames.pop(0) if len(frames) &gt; abs(n) else None
            i = k
            yield self._video.frame(kout, imout.array()) if len(frames) == delay  else None   # refetch for track interpolation</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="vipy.video.Stream.batch"><code class="name flex">
<span>def <span class="ident">batch</span></span>(<span>self, n)</span>
</code></dt>
<dd>
<div class="desc"><p>Stream batches of length n such that each batch contains frames [0, n-1], [n, 2n-1], &hellip;
Last batch will be ragged.</p>
<p>The primary use case for batch() is to provide a mechanism for parallel batch processing on a GPU.</p>
<pre><code class="language-python">for im_gpu in myfunc(vi.stream().batch(16))):
    print(im_gpu)

def myfunc(gen):
    for vb in gen:
        # process the batch vb (length n) in parallel by encoding on a GPU with batchsize=n
        for im in f_gpu(vb):
            yield im_gpu:
</code></pre>
<p>This will then yield the GPU batched processed image im_gpu.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L362-L381" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def batch(self, n):
    &#34;&#34;&#34;Stream batches of length n such that each batch contains frames [0, n-1], [n, 2n-1], ...  Last batch will be ragged.
        
    The primary use case for batch() is to provide a mechanism for parallel batch processing on a GPU.
    
    ```python
    for im_gpu in myfunc(vi.stream().batch(16))):
        print(im_gpu)
    
    def myfunc(gen):
        for vb in gen:
            # process the batch vb (length n) in parallel by encoding on a GPU with batchsize=n
            for im in f_gpu(vb):
                yield im_gpu:
    ```
    
    This will then yield the GPU batched processed image im_gpu.
    
    &#34;&#34;&#34;
    return self.clip(n=n, m=n, continuous=False, ragged=True) </code></pre>
</details>
</dd>
<dt id="vipy.video.Stream.clip"><code class="name flex">
<span>def <span class="ident">clip</span></span>(<span>self, n, m=1, continuous=False, tracks=True, activities=True, delay=0, ragged=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Stream clips of length n such that the yielded video clip contains frame(0+delay) to frame(n+delay), and next contains frame(m+delay) to frame(n+m+delay). </p>
<p>Usage examples:</p>
<pre><code class="language-python">for vc in v.stream().clip(n=16, m=2):
    # yields video vc with frames [0,16] from v
    # then video vc with frames [2,18] from v
    # ... finally video with frames [len(v)-n-1, len(v)-1]
</code></pre>
<p>Introducing a delay so that the clips start at a temporal offset from v</p>
<pre><code class="language-python">for vc in v.stream().clip(n=8, m=3, delay=1):
    # yields video vc with frames [1,9]
    # then video vc with frames [4,12] ...
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong></dt>
<dd>[int] the length of the clip in frames</dd>
<dt><strong><code>m</code></strong></dt>
<dd>[int] the stride between clips in frames</dd>
<dt><strong><code>delay</code></strong></dt>
<dd>[int] The temporal delay in frames for the clip, must be less than n and &gt;= 0</dd>
<dt><strong><code>continuous</code></strong></dt>
<dd>[bool]
if true, then yield None for the sequential frames not aligned with a stride so that a clip is yielded on every frame</dd>
<dt><strong><code>activities</code></strong></dt>
<dd>[bool]
if false, then activities from the source video are not copied into the clip</dd>
<dt><strong><code>tracks</code></strong></dt>
<dd>[bool]
if false, then tracks from the source video are not copied into the clip</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;This iterator runs in a thread to help speed up fetching of frames for GPU I/Oe bound operations</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L286-L360" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def clip(self, n, m=1, continuous=False, tracks=True, activities=True, delay=0, ragged=False):
    &#34;&#34;&#34;Stream clips of length n such that the yielded video clip contains frame(0+delay) to frame(n+delay), and next contains frame(m+delay) to frame(n+m+delay). 
        
    Usage examples:
       
    ```python 
    for vc in v.stream().clip(n=16, m=2):
        # yields video vc with frames [0,16] from v
        # then video vc with frames [2,18] from v
        # ... finally video with frames [len(v)-n-1, len(v)-1]
    ```
        
    Introducing a delay so that the clips start at a temporal offset from v

    ```python
    for vc in v.stream().clip(n=8, m=3, delay=1):
        # yields video vc with frames [1,9]
        # then video vc with frames [4,12] ...
    ```

    Args:
        n: [int] the length of the clip in frames
        m: [int] the stride between clips in frames
        delay: [int] The temporal delay in frames for the clip, must be less than n and &gt;= 0
        continuous: [bool]  if true, then yield None for the sequential frames not aligned with a stride so that a clip is yielded on every frame
        activities: [bool]  if false, then activities from the source video are not copied into the clip
        tracks: [bool]  if false, then tracks from the source video are not copied into the clip

    Returns:
        An iterator that yields `vipy.video.Video` objects each of length n with startframe += m, starting at frame=delay, such that each video contains the tracks and activities (if requested) for this clip sourced from the shared stream video.

    .. note:: This iterator runs in a thread to help speed up fetching of frames for GPU I/Oe bound operations

    &#34;&#34;&#34;
    assert isinstance(n, int) and n&gt;0, &#34;Clip length must be a positive integer&#34;
    assert isinstance(m, int) and m&gt;0, &#34;Clip stride must be a positive integer&#34;
    assert isinstance(delay, int) and delay &gt;= 0 and delay &lt; n, &#34;Clip delay must be a positive integer less than n&#34;
    assert not self._buffered or 3*n &lt; self._bufsize, &#34;increase buffered stream size (bufsize) from %d to &gt;%d&#34; % (self._bufsize, 3*n)
    
    def _f_threadloop(v, streamiter, queue, event, ragged, m, n):
        (frames, newframes) = ([], [])            
        for (k,im) in enumerate(streamiter()):
            newframes.append(im)            
            if len(newframes) &gt;= m and len(frames)+len(newframes) &gt;= n:                                
                # Use frameindex+1 so that we include (0,1), (1,2), (2,3), ... for n=2, m=1
                # The delay shifts the clip +delay frames (1,2,3), (3,4,5), ... for n=3, m=2, delay=1                
                frames.extend(newframes)
                (frames, newframes) = (frames[-n:], [])
                queue.put( (v.clear().clone(shallow=True).fromframes(frames), k) )  # fromframes() triggers array copy of frames
            elif continuous:
                queue.put( (None, k) )
        if ragged and len(newframes) &gt; 0:
            queue.put( (v.clear().clone(shallow=True).fromframes(newframes), k) )  # fromframes() triggers array copy of newframes
        queue.put( (None, None) )
        event.wait()            

    vc = self._video.clone(flushfilter=True).clear().nourl().nofilename()
    q = queue.Queue(3)  # warning: if this queuesize*n &gt; buffersize, then there can be a deadlock
    e = threading.Event()        
    t = threading.Thread(target=_f_threadloop, args=(vc, self.__iter__, q, e, ragged, m, n), daemon=True)
    t.start()

    f_copy_annotations = lambda v, k, n: (v.activities([a.clone().offset(-(k-(n-1))).truncate(0,n-1) for (ak,a) in self._video.activities().items() if a.during_interval(k-(n-1), k, inclusive=False)] if activities else [])
                                          .tracks([t.clone(k-(n-1), k).offset(-(k-(n-1))).truncate(0,n-1) for (tk,t) in self._video.tracks().items() if t.during_interval(k-(n-1), k)] if tracks else [])
                                          if (v is not None and isinstance(v, vipy.video.Scene)) else v)
            
    while True:
        # The queue can be filled with more expensive copies and clones to speed up iteration when waiting for GPU I/O
        (v, k) = q.get()
        if k is not None:
            # This copy must be done sychronized at frame k with the current state of the annotations in the shared self._video
            yield f_copy_annotations(v, k, len(v)) if v is not None else None
        else:
            e.set()
            break</code></pre>
</details>
</dd>
<dt id="vipy.video.Stream.frame"><code class="name flex">
<span>def <span class="ident">frame</span></span>(<span>self, delay=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Stream individual frames of video with negative offset n frames to the stream head. If delay=30, this will return a frame 30 frames ago</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L384-L395" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def frame(self, delay=0):
    &#34;&#34;&#34;Stream individual frames of video with negative offset n frames to the stream head. If delay=30, this will return a frame 30 frames ago&#34;&#34;&#34;
    assert isinstance(delay, int) and delay &gt;= 0, &#34;Frame delay must be non-positive integer&#34;        
    n = -delay
    frames = []
    i = 0
    for (k,im) in enumerate(self):
        frames.append( (k,im) )
        (kout, imout) = frames[0]
        frames.pop(0) if len(frames) &gt; abs(n) else None
        i = k
        yield self._video.frame(kout, imout.array()) if len(frames) == delay  else None   # refetch for track interpolation</code></pre>
</details>
</dd>
<dt id="vipy.video.Stream.framerate"><code class="name flex">
<span>def <span class="ident">framerate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L170-L171" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def framerate(self):
    return self._video.framerate()</code></pre>
</details>
</dd>
<dt id="vipy.video.Stream.write"><code class="name flex">
<span>def <span class="ident">write</span></span>(<span>self, im, flush=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Write individual frames to write stream</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L268-L284" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def write(self, im, flush=False):
    &#34;&#34;&#34;Write individual frames to write stream&#34;&#34;&#34;
            
    assert isinstance(im, vipy.image.Image)
    if self._shape is None:
        self._shape = im.shape()
        assert im.channels() == 3, &#34;RGB frames required&#34;
        self.__enter__()
    assert self._write_pipe is not None, &#34;Write stream cannot be initialized&#34;                
    assert im.shape() == self._shape, &#34;Shape cannot change during writing&#34;
    self._write_pipe.stdin.write(im.array().astype(np.uint8).tobytes())
    if flush:
        self._write_pipe.stdin.flush()  # do we need this?
    if isinstance(im, vipy.image.Scene) and len(im.objects()) &gt; 0 and isinstance(self._video, vipy.video.Scene):
        for obj in im.objects():
            self._video.add(obj, frame=self._writeindex, rangecheck=False)
    self._writeindex += 1  # assumes that the source image is at the appropriate frame rate for this video</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="vipy.video.Video"><code class="flex name class">
<span>class <span class="ident">Video</span></span>
<span>(</span><span>filename=None, url=None, framerate=30.0, attributes=None, array=None, colorspace=None, startframe=None, endframe=None, startsec=None, endsec=None, frames=None, probeshape=False)</span>
</code></dt>
<dd>
<div class="desc"><p>vipy.video.Video class</p>
<p>The vipy.video class provides a fluent, lazy interface for representing, transforming and visualizing videos.
The following constructors are supported:</p>
<pre><code class="language-python">vid = vipy.video.Video(filename='/path/to/video.ext')
</code></pre>
<p>Valid video extensions are those that are supported by ffmpeg ['.avi','.mp4','.mov','.wmv','.mpg', 'mkv', 'webm'].</p>
<pre><code class="language-python">vid = vipy.video.Video(url='https://www.youtube.com/watch?v=MrIN959JuV8')
vid = vipy.video.Video(url='http://path/to/video.ext', filename='/path/to/video.ext')
</code></pre>
<p>Youtube URLs are downloaded to a temporary filename, retrievable as vid.download().filename().
If the environment
variable 'VIPY_CACHE' is defined, then videos are saved to this directory rather than the system temporary directory.
If a filename is provided to the constructor, then that filename will be used instead of a temp or cached filename.
URLs can be defined as an absolute URL to a video file, or to a site supported by 'youtube-dl' (<a href="https://ytdl-org.github.io/youtube-dl/supportedsites.html">https://ytdl-org.github.io/youtube-dl/supportedsites.html</a>)</p>
<pre><code class="language-python">vid = vipy.video.Video(url='s3://BUCKET.s3.amazonaws.com/PATH/video.ext')
</code></pre>
<p>If you set the environment variables VIPY_AWS_ACCESS_KEY_ID and VIPY_AWS_SECRET_ACCESS_KEY, then this will download videos directly from S3 using boto3 and store in VIPY_CACHE.
Note that the URL protocol should be 's3' and not 'http' to enable keyed downloads.
</p>
<pre><code class="language-python">vid = vipy.video.Video(array=array, colorspace='rgb')
</code></pre>
<p>The input 'array' is an NxHxWx3 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video
Note that some video transformations are only available prior to load(), and the array() is assumed immutable after load().</p>
<pre><code class="language-python">frames = [im for im in vipy.video.RandomVideo()]
vid = vipy.video.Video(frames=frames)
</code></pre>
<p>The input can be an RTSP video stream.
Note that streaming is most efficiently performed using <code><a title="vipy.video.Scene" href="#vipy.video.Scene">Scene</a></code>.
The URL must contain the 'rtsp://' url scheme.<br>
You can experiment with this using the free Periscope H.264 RTSP App (<a href="https://apps.apple.com/us/app/periscope-hd-h-264-rtsp-cam/id1095600218">https://apps.apple.com/us/app/periscope-hd-h-264-rtsp-cam/id1095600218</a>)</p>
<pre><code class="language-python">vipy.video.Scene(url='rtsp://127.0.0.1:8554/live.sdp').show()
for im in vipy.video.Scene(url='rtsp://127.0.0.1:8554/live.sdp').stream():
    print(im)
</code></pre>
<p>See also 'pip install heyvi' </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong></dt>
<dd>[str] The path to a video file.
</dd>
<dt><strong><code>url</code></strong></dt>
<dd>[str] The URL to a video file.
If filename is not provided, then a random filename is assigned in VIPY_CACHE on download</dd>
<dt><strong><code>framerate</code></strong></dt>
<dd>[float] The framerate of the video file.
This is required.
You can introspect this using ffprobe.</dd>
<dt><strong><code>attributes</code></strong></dt>
<dd>[dict]
A user supplied dictionary of metadata about this video.</dd>
<dt><strong><code>colorspace</code></strong></dt>
<dd>[str] Must be in ['rgb', 'float']</dd>
<dt><strong><code>array</code></strong></dt>
<dd>[numpy] An NxHxWxC numpy array for N frames each HxWxC shape</dd>
<dt><strong><code>startframe</code></strong></dt>
<dd>[int]
A start frame to clip the video</dd>
<dt><strong><code>endframe</code></strong></dt>
<dd>[int] An end frame to clip the video</dd>
<dt><strong><code>startsec</code></strong></dt>
<dd>[float] A start time in seconds to clip the video (this requires setting framerate)</dd>
<dt><strong><code>endsec</code></strong></dt>
<dd>[float] An end time in seconds to clip the video (this requires setting framerate)</dd>
<dt><strong><code>frames</code></strong></dt>
<dd>[list of <code>vipy.image.Image</code>] A list of frames in the video</dd>
<dt><strong><code>probeshape</code></strong></dt>
<dd>[bool] If true, then probe the shape of the video from ffprobe to avoid an explicit preview later.
This can speed up loading in some circumstances.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L399-L2413" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class Video(object):
    &#34;&#34;&#34; vipy.video.Video class

    The vipy.video class provides a fluent, lazy interface for representing, transforming and visualizing videos.
    The following constructors are supported:

    ```python
    vid = vipy.video.Video(filename=&#39;/path/to/video.ext&#39;)
    ```

    Valid video extensions are those that are supported by ffmpeg [&#39;.avi&#39;,&#39;.mp4&#39;,&#39;.mov&#39;,&#39;.wmv&#39;,&#39;.mpg&#39;, &#39;mkv&#39;, &#39;webm&#39;].

    ```python
    vid = vipy.video.Video(url=&#39;https://www.youtube.com/watch?v=MrIN959JuV8&#39;)
    vid = vipy.video.Video(url=&#39;http://path/to/video.ext&#39;, filename=&#39;/path/to/video.ext&#39;)
    ```

    Youtube URLs are downloaded to a temporary filename, retrievable as vid.download().filename().  If the environment
    variable &#39;VIPY_CACHE&#39; is defined, then videos are saved to this directory rather than the system temporary directory.
    If a filename is provided to the constructor, then that filename will be used instead of a temp or cached filename.
    URLs can be defined as an absolute URL to a video file, or to a site supported by &#39;youtube-dl&#39; (https://ytdl-org.github.io/youtube-dl/supportedsites.html)

    ```python
    vid = vipy.video.Video(url=&#39;s3://BUCKET.s3.amazonaws.com/PATH/video.ext&#39;)
    ```

    If you set the environment variables VIPY_AWS_ACCESS_KEY_ID and VIPY_AWS_SECRET_ACCESS_KEY, then this will download videos directly from S3 using boto3 and store in VIPY_CACHE.
    Note that the URL protocol should be &#39;s3&#39; and not &#39;http&#39; to enable keyed downloads.  

    ```python
    vid = vipy.video.Video(array=array, colorspace=&#39;rgb&#39;)
    ```
    
    The input &#39;array&#39; is an NxHxWx3 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video
    Note that some video transformations are only available prior to load(), and the array() is assumed immutable after load().

    ```python
    frames = [im for im in vipy.video.RandomVideo()]
    vid = vipy.video.Video(frames=frames)
    ```

    The input can be an RTSP video stream.  Note that streaming is most efficiently performed using `vipy.video.Scene`.  The URL must contain the &#39;rtsp://&#39; url scheme.  
    You can experiment with this using the free Periscope H.264 RTSP App (https://apps.apple.com/us/app/periscope-hd-h-264-rtsp-cam/id1095600218)

    ```python
    vipy.video.Scene(url=&#39;rtsp://127.0.0.1:8554/live.sdp&#39;).show()
    for im in vipy.video.Scene(url=&#39;rtsp://127.0.0.1:8554/live.sdp&#39;).stream():
        print(im)
    ```

    See also &#39;pip install heyvi&#39; 

    Args:
        filename: [str] The path to a video file.  
        url: [str] The URL to a video file.  If filename is not provided, then a random filename is assigned in VIPY_CACHE on download
        framerate: [float] The framerate of the video file.  This is required.  You can introspect this using ffprobe.
        attributes: [dict]  A user supplied dictionary of metadata about this video.
        colorspace: [str] Must be in [&#39;rgb&#39;, &#39;float&#39;]
        array: [numpy] An NxHxWxC numpy array for N frames each HxWxC shape
        startframe: [int]  A start frame to clip the video
        endframe: [int] An end frame to clip the video
        startsec: [float] A start time in seconds to clip the video (this requires setting framerate)
        endsec: [float] An end time in seconds to clip the video (this requires setting framerate)
        frames: [list of `vipy.image.Image`] A list of frames in the video
        probeshape: [bool] If true, then probe the shape of the video from ffprobe to avoid an explicit preview later.  This can speed up loading in some circumstances.

    &#34;&#34;&#34;
    def __init__(self, filename=None, url=None, framerate=30.0, attributes=None, array=None, colorspace=None, startframe=None, endframe=None, startsec=None, endsec=None, frames=None, probeshape=False):
        self._url = None
        self._filename = None
        self._array = None
        self._colorspace = None
        self._ffmpeg = None
        self._framerate = None

        self.attributes = attributes if attributes is not None else {}
        assert isinstance(self.attributes, dict), &#34;Attributes must be a python dictionary&#34;
        assert filename is not None or url is not None or array is not None or frames is not None, &#39;Invalid constructor - Requires &#34;filename&#34;, &#34;url&#34; or &#34;array&#34; or &#34;frames&#34;&#39;
        assert not isurl(filename)
        
        # FFMPEG installed?
        if not has_ffmpeg:
            warnings.warn(&#39;&#34;ffmpeg&#34; executable not found on path, this is required for vipy.video - Install from http://ffmpeg.org/download.html&#39;)

        # Constructor clips
        startframe = startframe if startframe is not None else (0 if endframe is not None else startframe)
        assert (startsec is not None and endsec is not None) or (startsec is None and endsec is None), &#34;Invalid input - (startsec,endsec) are both required&#34;        
        (self._startframe, self._endframe) = (None, None)  # __repr__ only
        (self._startsec, self._endsec) = (None, None)  # __repr__ only (legacy, no longer used)

        # Input filenames
        if url is not None:
            assert isurl(url), &#39;Invalid URL &#34;%s&#34; &#39; % url
            self._url = url
        if filename is not None:
            self._filename = os.path.normpath(os.path.expanduser(filename))
        elif self._url is not None:
            if isS3url(self._url):
                self._filename = totempdir(self._url)  # Preserve S3 Object ID
            elif isRTSPurl(self._url) or isRTMPurl(self._url):
                # https://ffmpeg.org/ffmpeg-protocols.html#rtsp                
                self._filename = self._url                
            elif isvideourl(self._url):
                self._filename = templike(self._url)
            elif isyoutubeurl(self._url):
                self._filename = os.path.join(tempdir(), &#39;%s&#39; % (self._url.split(&#39;?&#39;)[1].split(&#39;&amp;&#39;)[0] if &#39;?&#39; in self._url else self._url.split(&#39;/&#39;)[-1]))
            else:
                self._filename = totempdir(self._url)  
            if vipy.globals.cache() is not None and self._filename is not None and not isRTSPurl(self._filename) and not isRTMPurl(self._filename):
                self._filename = os.path.join(remkdir(vipy.globals.cache()), filetail(self._filename))

        # Initial video shape: useful to avoid preview()
        self._ffmpeg = ffmpeg.input(self.filename())  # restore, no other filters        
        if probeshape and (frames is None and array is None) and has_ffprobe and self.hasfilename():
            self.shape(self.probeshape())
        else:
            self._shape = None  # preview() on shape()
            
        # Video filter chain
        if framerate is not None:
            if array is None and frames is None:
                self.framerate(framerate)
            self._framerate = framerate        
        if startframe is not None:
            self.clip(startframe, endframe)  
        if startsec is not None:
            # WARNING: if the user does not supply the correct framerate for the video, then this will be wrong since these are converted to frames 
            self.clip(int(round(startsec/self.framerate())), int(round(endsec/self.framerate())) if endsec is not None else None)

        # Array input
        assert not (array is not None and frames is not None)
        if array is not None:
            self.array(array)
            self.colorspace(colorspace)
        elif frames is not None and (isinstance(frames, list) or isinstance(frames, tuple)) and all([isinstance(im, vipy.image.Image) for im in frames]):
            self.fromframes(frames)
        elif frames is not None and (isinstance(frames, list) or isinstance(frames, tuple)) and all([isinstance(im, str) and os.path.exists(im) for im in frames]):
            self.fromframes([vipy.image.Image(filename=f) for f in frames])
        elif frames is not None and (isinstance(frames, str) and os.path.isdir(frames)):
            self.fromdirectory(frames)
            
    @classmethod
    def cast(cls, v):
        &#34;&#34;&#34;Cast a conformal video object to a `vipy.video.Video` object.
        
        This is useful for downcasting superclasses.

        ```python
        vs = vipy.video.RandomScene()
        v = vipy.video.Video.cast(vs)
        ```

        &#34;&#34;&#34;
        assert isinstance(v, vipy.video.Video), &#34;Invalid input - must be derived from vipy.video.Video&#34;
        v.__class__ = vipy.video.Video
        return v
            
    @classmethod
    def from_json(cls, s):
        &#34;&#34;&#34;Import a json string as a `vipy.video.Video` object.

        This will perform a round trip from a video to json and back to a video object.
        This same operation is used for serialization of all vipy objects to JSON for storage.

        ```python
        v = vipy.video.Video.from_json(vipy.video.RandomVideo().json())
        ```

        &#34;&#34;&#34;
        
        d = json.loads(s) if not isinstance(s, dict) else s
        v = cls(filename=d[&#39;_filename&#39;],
                url=d[&#39;_url&#39;],
                framerate=d[&#39;_framerate&#39;],
                array=np.array(d[&#39;_array&#39;]) if d[&#39;_array&#39;] is not None else None,
                colorspace=d[&#39;_colorspace&#39;],
                attributes=d[&#39;attributes&#39;],
                startframe=d[&#39;_startframe&#39;],
                endframe=d[&#39;_endframe&#39;],
                startsec=d[&#39;_startsec&#39;],
                endsec=d[&#39;_endsec&#39;])
        v._ffmpeg = v._from_ffmpeg_commandline(d[&#39;_ffmpeg&#39;])
        return v.filename(d[&#39;_filename&#39;]) if d[&#39;_filename&#39;] is not None else v.nofilename()

    def __repr__(self):
        strlist = []
        if self.isloaded():
            strlist.append(&#34;height=%d, width=%d, frames=%d, color=%s&#34; % (self.height(), self.width(), len(self), self.colorspace()))
        if self.filename() is not None:
            strlist.append(&#39;filename=&#34;%s&#34;&#39; % self.filename())
        if self.hasurl():
            strlist.append(&#39;url=&#34;%s&#34;&#39; % self.url())
        if not self.isloaded() and self._startframe is not None and self._endframe is not None:
            strlist.append(&#39;clip=(%d,%d)&#39; % (self._startframe, self._endframe))
        if not self.isloaded() and self._startframe is not None and self._endframe is None:
            strlist.append(&#39;clip=(%d,)&#39; % (self._startframe))
        if self._framerate is not None:
            strlist.append(&#39;fps=%1.1f&#39; % float(self._framerate))
        return str(&#39;&lt;vipy.video: %s&gt;&#39; % (&#39;, &#39;.join(strlist)))

    def __len__(self):
        &#34;&#34;&#34;Number of frames in the video if loaded, else zero.  
        
        .. notes:: Do not automatically trigger a load, since this can interact in unexpected ways with other tools that depend on fast __len__()
        &#34;&#34;&#34;
        if not self.isloaded():
            warnings.warn(&#39;Load() video to see number of frames - Returning zero&#39;)  # should this just throw an exception?
        return len(self.array()) if self.isloaded() else 0

    def __getitem__(self, k):
        &#34;&#34;&#34;Alias for `vipy.video.Video.frame`&#34;&#34;&#34;
        return self.frame(k)

    def metadata(self):
        &#34;&#34;&#34;Return a dictionary of metadata about this video.

        This is an alias for the &#39;attributes&#39; dictionary. 
        &#34;&#34;&#34;
        return self.attributes

    def sanitize(self):
        &#34;&#34;&#34;Remove all private keys from the attributes dictionary.
        
        The attributes dictionary is useful storage for arbitrary (key,value) pairs.  However, this storage may contain sensitive information that should be scrubbed from the video before serialization.  As a general rule, any key that is of the form &#39;__keyname&#39; prepended by two underscores is a private key.  This is analogous to private or reserved attributes in the python lanugage.  Users should reserve these keynames for those keys that should be sanitized and removed before any seerialization of this object.
        
        ```python
        assert self.setattribute(&#39;__mykey&#39;, 1).sanitize().hasattribute(&#39;__mykey&#39;) == False
        ```

        &#34;&#34;&#34;
        if self._has_private_attribute():
            self.attributes = {k:v for (k,v) in self.attributes.items() if not k.startswith(&#39;__&#39;)}
        return self
        
        
    def videoid(self, newid=None):
        &#34;&#34;&#34;Return a unique video identifier for this video, as specified in the &#39;video_id&#39; attribute, or by SHA1 hash of the `vipy.video.Video.filename` and `vipy.video.Video.url`.

        Args:
            newid: [str] If not None, then update the video_id as newid. 

        Returns:
            The video ID if newid=None else self

        .. note::
            - If the video filename changes (e.g. from transformation), and video_id is not set in self.attributes, then the video ID will change.
            - If a video does not have a filename or URL or a video ID in the attributes, then this will return None
            - To preserve a video ID independent of transformations, set self.setattribute(&#39;video_id&#39;, ${MY_ID}), or pass in newid
        &#34;&#34;&#34;
        if newid is not None:
            self.setattribute(&#39;video_id&#39;, newid)
            return self
        else:
            return self.attributes[&#39;video_id&#39;] if &#39;video_id&#39; in self.attributes else (hashlib.sha1(str(str(self.filename())+str(self.url())).encode(&#34;UTF-8&#34;)).hexdigest() if (self.filename() is not None or self.url() is not None) else None)
        

    def frame(self, k=0, img=None):
        &#34;&#34;&#34;Return the kth frame as an `vipy.image Image` object&#34;&#34;&#34;        
        assert isinstance(k, int) and k&gt;=0, &#34;Frame index must be non-negative integer&#34;
        return Image(array=img if img is not None else (self._array[k] if self.isloaded() else self.preview(k).array()), colorspace=self.colorspace())       
        
    def __iter__(self):
        &#34;&#34;&#34;Iterate over video, yielding read only frames.
        
        ```python
        for im in vipy.video.RandomScene():
            print(im)
        ```

        &#34;&#34;&#34;
        return self.stream().__iter__()
        
    def store(self):
        &#34;&#34;&#34;Store the current video file as an attribute of this object.  

        Useful for archiving an object to be fully self contained without any external references.  

        ```python
        v == v.store().restore(v.filename()) 
        ```
        
        .. note::
        -Remove this stored video using unstore()
        -Unpack this stored video and set up the video chains using restore() 
        -This method is more efficient than load() followed by pkl(), as it stores the encoded video as a byte string.
        -Useful for creating a single self contained object for distributed processing.  
        &#34;&#34;&#34;
        assert self.hasfilename(), &#34;Video file not found.  Try saveas() first to create a video file to store.&#34;
        with open(self.filename(), &#39;rb&#39;) as f:
            self.attributes[&#39;__video__&#39;] = f.read()
        return self

    def unstore(self):
        &#34;&#34;&#34;Delete the currently stored video from `vipy.video.Video.store&#34;&#34;&#34;
        return self.delattribute(&#39;__video__&#39;)

    def restore(self, filename):
        &#34;&#34;&#34;Save the currently stored video as set using `vipy.video.Video.store` to filename, and set up filename&#34;&#34;&#34;
        assert self.hasattribute(&#39;__video__&#39;), &#34;Video not stored&#34;
        with open(filename, &#39;wb&#39;) as f:
            f.write(self.attributes[&#39;__video__&#39;])
        return self.filename(filename)                

    
    @classmethod
    def concatenate(cls, videos, outfile, framerate=30, youtube_chapters=None):
        &#34;&#34;&#34;Temporally concatenate a sequence of videos into a single video stored in outfile.
        
        ```python
        (v1, v2, v3) = (vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32))
        vc = vipy.video.Video.concatenate((v1, v2, v3), &#39;concatenated.mp4&#39;, youtube_chapters=lambda v: v.category())
        ```

        In this example, vc will point to concatenated.mp4 which will contain (v1,v2,v3) concatenated temporally .  

        Args:
            videos: a single video or an iterable of videos of type `vipy.video.Video` or an iterable of video files
            outfile: the output filename to store the concatenation. 
            youtube_chapters: [bool, callable]:  If true, output a string that can be used to define the start and end times of chapters if this video is uploaded to youtube.  The string output should be copied to the youtube video description in order to enable chapters on playback.  This argument will default to the string representation ofo the video, but you may also pass a callable of the form: &#39;youtube_chapters=lambda v: str(v)&#39; which will output the provided string for each video chapter.  A useful lambda is &#39;youtube_chapters=lambda v: v.category()&#39;
            framerate: [float]: The output frame rate of outfile

        Returns:
            A `vipy.video.Video` object with filename()=outfile, such that outfile contains the temporal concatenation of pixels in (self, videos).
        
        .. note::
            - self will not be modified, this will return a new `vipy.video.Video` object.
            - All videos must be the same shape().  If the videos are different shapes, you must pad them to a common size equal to self.shape().  Try `vipy.video.Video.zeropadlike`.
            - The output video will be at the framerate of self.framerate().
            - if you want to concatenate annotations, call `vipy.video.Scene.annotate` first on the videos to save the annotations into the pixels, then concatenate.
        &#34;&#34;&#34;

        assert len(tolist(videos))&gt;0 and (all([isinstance(v, vipy.video.Video) for v in tolist(videos)]) or all([os.path.exists(f) and vipy.util.isvideofile(f) for f in tolist(videos)]))
        vi = tolist(videos) if all([isinstance(v, vipy.video.Video) for v in tolist(videos)]) else [cls(filename=f) for f in tolist(videos)]

        assert all([vij.shape() == vik.shape() for vij in vi for vik in vi]), &#34;Video shapes must all the same, try padding&#34;
        vo = cls(filename=outfile, framerate=vi[0].framerate())
        with vo.stream(overwrite=True) as s:
            for v in vi:
                for im in v.clone().framerate(framerate).stream():
                    s.write(im)

        if youtube_chapters is not None:        
            f = youtube_chapters if callable(youtube_chapters) else lambda v: str(v).replace(&#39;&lt;&#39;,&#39;&#39;).replace(&#39;&gt;&#39;,&#39;&#39;)  # angle brackets not allowed
            print(&#39;[vipy.video.concatenate]: Copy the following into the video Description after uploading the videofile &#34;%s&#34; to YouTube to enable chapters on playback.\n&#39; % outfile)
            print(&#39;\n&#39;.join([&#39;%s  %s&#39; % (vipy.util.seconds_to_MMSS_colon_notation(int(s)), str(f(v))) for (s,v) in zip(np.cumsum([0] + [v.duration() for v in vi][:-1]), vi)])); print(&#39;\n&#39;)
            if any([v.duration() &lt; 10 for v in vi]):
                warnings.warn(&#39;YouTube chapters must be a minimum duration of 10 seconds&#39;)
        return vo
    

    def stream(self, write=False, overwrite=False, queuesize=512, bitrate=None, buffered=False, rebuffered=False, bufsize=256):
        &#34;&#34;&#34;Iterator to yield groups of frames streaming from video.

        A video stream is a real time iterator to read or write from a video.  Streams are useful to group together frames into clips that are operated on as a group.

        The following use cases are supported:
        
        ```python
        v = vipy.video.RandomScene()
        ```

        Stream individual video frames lagged by 10 frames and 20 frames

        ```python
        for (im1, im2) in zip(v.stream().frame(n=-10), v.stream().frame(n=-20)):
            print(im1, im2)
        ```
        
        Stream overlapping clips such that each clip is a video n=16 frames long and starts at frame i, and the next clip is n=16 frames long and starts at frame i=i+m

        ```python
        for vc in v.stream().clip(n=16, m=4):
            print(vc)
        ```

        Stream non-overlapping batches of frames such that each clip is a video of length n and starts at frame i, and the next clip is length n and starts at frame i+n

        ```python
        for vb in v.stream().batch(n=16):
            print(vb)        
        ```

        Create a write stream to incrementally add frames to long video.  

        ```python
        vi = vipy.video.Video(filename=&#39;/path/to/output.mp4&#39;)
        vo = vipy.video.Video(filename=&#39;/path/to/input.mp4&#39;)
        with vo.stream(write=True) as s:
            for im in vi.stream():
                s.write(im)  # manipulate pixels of im, if desired
        ```

        Create a 480p YouTube live stream from an RTSP camera at 5Hz 
        
        ```python
        vo = vipy.video.Scene(url=&#39;rtmp://a.rtmp.youtube.com/live2/$SECRET_STREAM_KEY&#39;)
        vi = vipy.video.Scene(url=&#39;rtsp://URL&#39;).framerate(5)
        with vo.framerate(5).stream(write=True, bitrate=&#39;1000k&#39;) as s:
            for im in vi.framerate(5).resize(cols=854, rows=480):
                s.write(im)
        ```

        Args:
            write: [bool]  If true, create a write stream
            overwrite: [bool]  If true, and the video output filename already exists, overwrite it
            bufsize: [int]  The maximum queue size for the ffmpeg pipe thread in the primary iterator.  The queue size is the maximum size of pre-fetched frames from the ffmpeg pip.  This should be big enough that you are never waiting for queue fills
            bitrate: [str] The ffmpeg bitrate of the output encoder for writing, written like &#39;2000k&#39;
            bufsize: [int]  The maximum size of the stream buffer in frames.  The stream buffer length should be big enough so that all iterators can yield before deleting old frames

        Returns:
            A Stream object

        ..note:: Using this iterator may affect PDB debugging due to stdout/stdin redirection.  Use ipdb instead.

        &#34;&#34;&#34;
        return Stream(self, queuesize=queuesize, write=write, overwrite=overwrite, bitrate=bitrate, buffered=buffered, rebuffered=rebuffered, bufsize=bufsize)  # do not clone


    def clear(self):
        &#34;&#34;&#34;no-op for `vipy.video.Video` object, used only for `vipy.video.Scene`&#34;&#34;&#34;
        return self
    
    def bytes(self):
        &#34;&#34;&#34;Return a bytes representation of the video file&#34;&#34;&#34;
        assert self.hasfilename(), &#34;Invalid filename&#34;
        with open(self.filename(), &#39;rb&#39;) as f:
            data = io.BytesIO(f.read())
        return str(data.read()).encode(&#39;UTF-8&#39;)
    
    def frames(self):
        &#34;&#34;&#34;Alias for __iter__()&#34;&#34;&#34;
        return self.__iter__()
                
    def framelist(self):
        return list(self.frames())

    def _update_ffmpeg_seek(self, timestamp_in_seconds=0, offset=0):
        if timestamp_in_seconds == 0 and offset == 0:
            return self
        nodes = ffmpeg.nodes.get_stream_spec_nodes(self._ffmpeg)
        sorted_nodes, outgoing_edge_maps = ffmpeg.dag.topo_sort(nodes)
        for n in sorted_nodes:
            if &#39;input&#39; == n.__dict__[&#39;name&#39;]:
                if &#39;ss&#39; not in n.__dict__[&#39;kwargs&#39;]:
                    n.__dict__[&#39;kwargs&#39;][&#39;ss&#39;] = 0
                if timestamp_in_seconds == 0:
                    n.__dict__[&#39;kwargs&#39;][&#39;ss&#39;] = n.__dict__[&#39;kwargs&#39;][&#39;ss&#39;] + offset
                else: 
                    n.__dict__[&#39;kwargs&#39;][&#39;ss&#39;] = timestamp_in_seconds + offset                   
                return self
        raise ValueError(&#39;invalid ffmpeg argument &#34;%s&#34; -&gt; &#34;%s&#34;&#39; % (&#39;ss&#39;, timestamp_in_seconds))

        
    def _update_ffmpeg(self, argname, argval, node_name=None):
        &#34;&#34;&#34;Update the ffmpeg filter chain to overwrite the (argname, argval) elements. 

        Useful for fine-tuning a filter chain without rewwriring the whole thing.
        &#34;&#34;&#34;
        nodes = ffmpeg.nodes.get_stream_spec_nodes(self._ffmpeg)
        sorted_nodes, outgoing_edge_maps = ffmpeg.dag.topo_sort(nodes)
        for n in sorted_nodes:
            if argname in n.__dict__[&#39;kwargs&#39;] or node_name == n.__dict__[&#39;name&#39;]:
                n.__dict__[&#39;kwargs&#39;][argname] = argval
                return self
        raise ValueError(&#39;invalid ffmpeg argument &#34;%s&#34; -&gt; &#34;%s&#34;&#39; % (argname, argval))
               
    def _ffmpeg_commandline(self, f=None):
        &#34;&#34;&#34;Return the ffmpeg command line string that will be used to process the video&#34;&#34;&#34;
        cmd = f.compile() if f is not None else self._ffmpeg.output(&#39;dummyfile&#39;).compile()
        for (k,c) in enumerate(cmd):
            if c is None:
                cmd[k] = str(c)
            elif &#39;filter&#39; in c:
                cmd[k+1] = &#39;&#34;%s&#34;&#39; % str(cmd[k+1])
            elif &#39;map&#39; in c:
                cmd[k+1] = &#39;&#34;%s&#34;&#39; % str(cmd[k+1])
        return str(&#39; &#39;).join(cmd)

    def commandline(self):
        &#34;&#34;&#34;Return the equivalent ffmpeg command line string that will be used to transcode the video.
        
           This is useful for introspecting the complex filter chain that will be used to process the video.  You can try to run this command line yourself for debugging purposes, by replacing &#39;dummyfile&#39; with an appropriately named output file.
        &#34;&#34;&#34;        
        return self._ffmpeg_commandline()
    
    def _from_ffmpeg_commandline(self, cmd, strict=False):
        &#34;&#34;&#34;Convert the ffmpeg command line string (e.g. from `vipy.video.Video.commandline`) to the corresponding ffmpeg-python filter chain and update self&#34;&#34;&#34;
        args = copy.copy(cmd).replace(str(self.filename()), &#39;FILENAME&#39;).split(&#39; &#39;)  # filename may contain spaces
        
        assert args[0] == &#39;ffmpeg&#39;, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd
        assert args[1] == &#39;-i&#39; or (args[3] == &#39;-i&#39; and args[1] == &#39;-ss&#39;), &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd
        assert args[-1] == &#39;dummyfile&#39;, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd
        assert len(args) &gt;= 4, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd

        if args[1] == &#39;-ss&#39;:
            timestamp_in_seconds = float(args[2])
            timestamp_in_seconds = int(timestamp_in_seconds) if timestamp_in_seconds == 0 else timestamp_in_seconds  # 0.0 -&gt; 0
            args = [args[0]] + args[3:]
            f = ffmpeg.input(args[2].replace(&#39;FILENAME&#39;, self.filename()), ss=timestamp_in_seconds)   # restore filename, set offset time
            self._startframe = int(round(timestamp_in_seconds*self.framerate()))  # necessary for clip() and __repr__
        else:
            f = ffmpeg.input(args[2].replace(&#39;FILENAME&#39;, self.filename()))  # restore filename

        if len(args) &gt; 4:
            assert args[3] == &#39;-filter_complex&#39;, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd
            assert args[4][0] == &#39;&#34;&#39; and args[4][-1] == &#39;&#34;&#39;, &#34;Invalid FFMEG commmand line &#39;%s&#39;&#34; % cmd

            filterargs = args[4][1:-1].split(&#39;;&#39;)
            for a in filterargs:
                assert a.count(&#39;]&#39;) == 2 and a.count(&#39;[&#39;) == 2
                kwstr = a.split(&#39;]&#39;, maxsplit=1)[1].split(&#39;[&#39;, maxsplit=1)[0]
                if kwstr.count(&#39;=&#39;) == 0:
                    f = f.filter(kwstr)
                else:
                    (a, kw) = ([], {}) 
                    (filtername, kwstr) = kwstr.split(&#39;=&#39;, maxsplit=1)
                    for s in kwstr.split(&#39;:&#39;):
                        if s.count(&#39;=&#39;) &gt; 0:
                            (k,v) = s.split(&#39;=&#39;)
                            kw[k] = v
                        else:
                            a.append(s)

                    if &#39;end&#39; in kw:
                        self._endframe = (self._startframe if self._startframe is not None else 0) + int(round(float(kw[&#39;end&#39;])*self.framerate()))  # for __repr__
                    if &#39;start&#39; in kw:
                        pass
                    if &#39;start_frame&#39; in kw or &#39;end_frame&#39; in kw:
                        f = f.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 before trim filter in seconds
                        if &#39;end_frame&#39; in kw:
                            self._endframe = (self._startframe if self._startframe is not None else 0) + int(kw[&#39;end_frame&#39;])  # for __repr__
                            kw[&#39;end&#39;] = int(kw[&#39;end_frame&#39;])/self.framerate()  # convert end_frame to end (legacy)
                            del kw[&#39;end_frame&#39;]  # use only end and not end frame
                        if &#39;start_frame&#39; in kw:
                            self._startframe = (self._startframe if self._startframe is not None else 0) + int(kw[&#39;start_frame&#39;])  # for __repr__
                            kw[&#39;start&#39;] = int(kw[&#39;start_frame&#39;])/self.framerate()  # convert start_frame to start (legacy)
                            del kw[&#39;start_frame&#39;]  # use only start and not start_frame

                    f = f.filter(filtername, *a, **kw)

        if strict:
            assert self._ffmpeg_commandline(f.output(&#39;dummyfile&#39;)) == cmd, &#34;FFMPEG command line &#39;%s&#39; != &#39;%s&#39;&#34; % (self._ffmpeg_commandline(f.output(&#39;dummyfile&#39;)), cmd)
        return f

    def _isdirty(self):
        &#34;&#34;&#34;Has the FFMPEG filter chain been modified from the default?  If so, then ffplay() on the video file will be different from self.load().play()&#34;&#34;&#34;
        return &#39;-filter_complex&#39; in self._ffmpeg_commandline()

    def probeshape(self):
        &#34;&#34;&#34;Return the (height, width) of underlying video file as determined from ffprobe
        
        .. warning:: this does not take into account any applied ffmpeg filters.  The shape will be the (height, width) of the underlying video file.  
        &#34;&#34;&#34;
        p = self.probe()
        assert len(p[&#39;streams&#39;]) &gt; 0
        return (p[&#39;streams&#39;][0][&#39;height&#39;], p[&#39;streams&#39;][0][&#39;width&#39;])
        
    def duration_in_seconds_of_videofile(self):
        &#34;&#34;&#34;Return video duration of the source filename (NOT the filter chain) in seconds, requires ffprobe.  Fetch once and cache.
        
        .. notes:: This is the duration of the source video and NOT the duration of the filter chain.  If you load(), this may be different duration depending on clip() or framerate() directives.
        &#34;&#34;&#34;
        filehash = hashlib.md5(str(self.downloadif().filename()).encode()).hexdigest()            
        if self.hasattribute(&#39;_duration_in_seconds_of_videofile&#39;) and self.attributes[&#39;__duration_in_seconds_of_videofile&#39;][&#39;filehash&#39;] == filehash:
            return self.attributes[&#39;__duration_in_seconds_of_videofile&#39;][&#39;duration&#39;]
        else:
            d = float(self.probe()[&#39;format&#39;][&#39;duration&#39;])
            self.attributes[&#39;__duration_in_seconds_of_videofile&#39;] = {&#39;duration&#39;:d, &#39;filehash&#39;:filehash}  # for next time, private attribute
            return d

    def duration_in_frames_of_videofile(self):
        &#34;&#34;&#34;Return video duration of the source video file (NOT the filter chain) in frames, requires ffprobe.

        .. notes:: This is the duration of the source video and NOT the duration of the filter chain.  If you load(), this may be different duration depending on clip() or framerate() directives.
        &#34;&#34;&#34;
        return int(np.floor(self.duration_in_seconds_of_videofile()*self.framerate_of_videofile()))
    
    def duration(self, frames=None, seconds=None, minutes=None):
        &#34;&#34;&#34;Return a video clipped with frame indexes between (0, frames) or (0,seconds*self.framerate()) or (0,minutes*60*self.framerate().  Return duration in seconds if no arguments are provided.&#34;&#34;&#34;
        if frames is None and seconds is None and minutes is None:
            return self.duration_in_seconds_of_videofile() if not self.isloaded() else (len(self) / self.framerate())
        assert frames is not None or seconds is not None or minutes is not None
        frames = frames if frames is not None else ((int(seconds*self.framerate()) if seconds is not None else 0) + (int(minutes*60*self.framerate()) if minutes is not None else 0))
        return self.clip(0, frames)

    def duration_in_frames(self):
        &#34;&#34;&#34;Return the duration of the video filter chain in frames, equal to round(self.duration()*self.framerate()).  Requires a probe() of the video to get duration&#34;&#34;&#34;
        return int(round(self.duration()*self.framerate()))
    
    def framerate_of_videofile(self):
        &#34;&#34;&#34;Return video framerate in frames per second of the source video file (NOT the filter chain), requires ffprobe.
        &#34;&#34;&#34;
        p = self.probe()        
        assert &#39;streams&#39; in p and len([&#39;streams&#39;]) &gt; 0
        fps = p[&#39;streams&#39;][0][&#39;avg_frame_rate&#39;]
        return float(fps) if &#39;/&#39; not in fps else (float(fps.split(&#39;/&#39;)[0]) / float(fps.split(&#39;/&#39;)[1]))  # fps=&#39;30/1&#39; or fps=&#39;30.0&#39;

    def resolution_of_videofile(self):
        &#34;&#34;&#34;Return video resolution in (height, width) in pixels (NOT the filter chain), requires ffprobe.
        &#34;&#34;&#34;
        p = self.probe()
        assert &#39;streams&#39; in p and len([&#39;streams&#39;]) &gt; 0
        (H,W) = (p[&#39;streams&#39;][0][&#39;height&#39;], p[&#39;streams&#39;][0][&#39;width&#39;])  # (height, width) in pixels
        return (W,H) if (&#39;tags&#39; in p[&#39;streams&#39;][0] and &#39;rotate&#39; in p[&#39;streams&#39;][0][&#39;tags&#39;] and p[&#39;streams&#39;][0][&#39;tags&#39;][&#39;rotate&#39;] in [&#39;90&#39;,&#39;270&#39;]) else (H,W)
    
    def probe(self):
        &#34;&#34;&#34;Run ffprobe on the filename and return the result as a dictionary&#34;&#34;&#34;
        if not has_ffprobe:
            raise ValueError(&#39;&#34;ffprobe&#34; executable not found on path, this is optional for vipy.video - Install from http://ffmpeg.org/download.html&#39;)            
        assert self.downloadif().hasfilename(), &#34;Invalid video file &#39;%s&#39; for ffprobe&#34; % self.filename() 
        return ffmpeg.probe(self.filename())

    def print(self, prefix=&#39;&#39;, verbose=True, sleep=None):
        &#34;&#34;&#34;Print the representation of the video

        This is useful for debugging in long fluent chains.  Sleep is useful for adding in a delay for distributed processing.

        Args:
            prefix: prepend a string prefix to the video __repr__ when printing.  Useful for logging.
            verbose:  Print out the video __repr__.  Set verbose=False to just sleep
            sleep:  Integer number of seconds to sleep[ before returning
            fluent [bool]:  If true, return self else return None.  This is useful for terminating long fluent chains in lambdas that return None

        Returns:  
            The video object after sleeping 
        &#34;&#34;&#34;
        if verbose:
            print(prefix+self.__repr__())
        if sleep is not None:
            assert isinstance(sleep, int) and sleep &gt; 0, &#34;Sleep must be a non-negative integer number of seconds&#34;
            time.sleep(sleep)
        return self

    def __array__(self):
        &#34;&#34;&#34;Called on np.array(self) for custom array container, (requires numpy &gt;=1.16)&#34;&#34;&#34;
        return self.numpy()

    def dict(self):
        &#34;&#34;&#34;Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding.&#34;&#34;&#34;
        return self.json(encode=False)

    def json(self, encode=True):
        &#34;&#34;&#34;Return a json representation of the video.
        
        Args:
            encode: If true, return a JSON encoded string using json.dumps
        
        Returns:
            A JSON encoded string if encode=True, else returns a dictionary object 

        .. note::  If the video is loaded, then the JSON will not include the pixels.  Try using `vipy.video.Video.store` to serialize videos, or call `vipy.video.Video.flush` first.
        &#34;&#34;&#34;
        
        if self.isloaded():
            warnings.warn(&#34;JSON serialization of video requires flushed buffers, will not include the loaded video.  Try store()/restore()/unstore() instead to serialize videos as standalone objects efficiently, or flush() any loaded videos prior to serialization to quiet this warning.&#34;)
        d = {&#39;_filename&#39;:self._filename,
             &#39;_url&#39;:self._url,
             &#39;_framerate&#39;:self._framerate,
             &#39;_array&#39;:None,
             &#39;_colorspace&#39;:self._colorspace,
             &#39;attributes&#39;:self.attributes,
             &#39;_startframe&#39;:self._startframe,
             &#39;_endframe&#39;:self._endframe,
             &#39;_endsec&#39;:self._endsec,
             &#39;_startsec&#39;:self._startsec,
             &#39;_ffmpeg&#39;:self._ffmpeg_commandline()}
        return json.dumps(d) if encode else d
    

    def take(self, n):
        &#34;&#34;&#34;Return n frames from the clip uniformly spaced as numpy array
        
        Args:
            n: Integer number of uniformly spaced frames to return 
        
        Returns:
            A numpy array of shape (n,W,H)

        .. warning:: This assumes that the entire video is loaded into memory (e.g. call `vipy.video.Video.load`).  Use with caution.
        &#34;&#34;&#34;
        assert self.isloaded(), &#34;load() is required before take()&#34;
        dt = int(np.round(len(self._array) / float(n)))  # stride
        return self._array[::dt][0:n]

    def framerate(self, fps=None):
        &#34;&#34;&#34;Change the input framerate for the video and update frame indexes for all annotations

        Args:
            fps: [Float] frames per second to process the underlying video

        Returns:
            If fps is None, return the current framerate, otherwise set the framerate to fps

        &#34;&#34;&#34;
        if fps is None:
            return self._framerate
        elif float(fps) == self._framerate:
            return self
        else:            
            assert not self.isloaded(), &#34;Filters can only be applied prior to load()&#34;
            if &#39;fps=&#39; in self._ffmpeg_commandline():
                self._update_ffmpeg(&#39;fps&#39;, float(fps))  # replace fps filter, do not add to it
            else:
                self._ffmpeg = self._ffmpeg.filter(&#39;fps&#39;, fps=float(fps), round=&#39;up&#39;)  # create fps filter first time
        
            # if &#39;-ss&#39; in self._ffmpeg_commandline():
            #     No change is needed here.  The seek is in seconds and is independent of the framerate
            # if &#39;trim&#39; in self._ffmpeg_commandline():
            #     No change is needed here.  The trim is in units of seconds which is independent of the framerate

            self._framerate = float(fps)
            return self
            
    def colorspace(self, colorspace=None):
        &#34;&#34;&#34;Return or set the colorspace as [&#39;rgb&#39;, &#39;bgr&#39;, &#39;lum&#39;, &#39;float&#39;].  This will not change pixels, only the colorspace interpretation of pixels.&#34;&#34;&#34;
        if colorspace is None:
            return self._colorspace
        elif self.isloaded():
            assert str(colorspace).lower() in [&#39;rgb&#39;, &#39;bgr&#39;, &#39;lum&#39;, &#39;float&#39;]
            if self.array().dtype == np.float32:
                assert str(colorspace).lower() in [&#39;float&#39;]
            elif self.array().dtype == np.uint8:
                assert str(colorspace).lower() in [&#39;rgb&#39;, &#39;bgr&#39;, &#39;lum&#39;]
                if str(colorspace).lower() in [&#39;lum&#39;]:
                    assert self.channels() == 1, &#34;Luminance colorspace must be one channel uint8&#34;
                elif str(colorspace).lower() in [&#39;rgb&#39;, &#39;bgr&#39;]:
                    assert self.channels() == 3, &#34;RGB or BGR colorspace must be three channel uint8&#34;
            else:
                raise ValueError(&#39;Invalid array() type &#34;%s&#34; - only np.float32 or np.uint8 allowed&#39; % str(self.array().dtype))
            self._colorspace = str(colorspace).lower()
        return self

    def nourl(self):
        &#34;&#34;&#34;Remove the `vipy.video.Video.url` from the video&#34;&#34;&#34;
        (self._url, self._urluser, self._urlpassword, self._urlsha1) = (None, None, None, None)
        return self

    def url(self, url=None, username=None, password=None, sha1=None):
        &#34;&#34;&#34;Video URL and URL download properties&#34;&#34;&#34;
        if url is not None:
            self._url = url  # note that this does not change anything else, better to use the constructor for this
        if url is not None and (isRTSPurl(url) or isRTMPurl(url)):
            self.filename(self._url) 
        if username is not None:
            self._urluser = username  # basic authentication
        if password is not None:
            self._urlpassword = password  # basic authentication
        if sha1 is not None:
            self._urlsha1 = sha1  # file integrity
        if url is None and username is None and password is None and sha1 is None:
            return self._url
        else:
            return self

    def isloaded(self):
        &#34;&#34;&#34;Return True if the video has been loaded&#34;&#34;&#34;
        return self._array is not None

    def isloadable(self, flush=True):
        &#34;&#34;&#34;Return True if the video can be loaded successfully.
        
        This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.
        
        Args:
            flush: [bool] If true, flush the video after it loads.  This will clear the video pixel buffer

        Returns:
            True if load() can be called without FFMPEG exception.  
            If flush=False, then self will contain the loaded video, which is helpful to avoid load() twice in some conditions
        
        .. warning:: This requires loading and flushing the video.  This is an expensive operation when performed on many videos and may result in out of memory conditions with long videos.  Use with caution!  Try `vipy.video.Video.canload` to test if a single frame can be loaded as a less expensive alternative.
        &#34;&#34;&#34;
        if not self.isloaded():
            try:
                self.load()  # try to load the whole thing
                if flush:
                    self.flush()
                return True
            except:
                return False
        else:
            return True
        
        
    def canload(self, frame=0):
        &#34;&#34;&#34;Return True if the video can be previewed at frame=k successfully.
        
        This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.

        .. notes:: This will only try to preview a single frame.  This will not check if the entire video is loadable.  Use `vipy.video.Video.isloadable` in this case
        &#34;&#34;&#34;
        if not self.isloaded():
            try:
                self.preview(framenum=frame)  # try to preview
                return True
            except:
                return False
        else:
            return True

    def iscolor(self):
        &#34;&#34;&#34;Is the video a three channel color video as returned from `vipy.video.Video.channels`?&#34;&#34;&#34;
        return self.channels() == 3

    def isgrayscale(self):
        &#34;&#34;&#34;Is the video a single channel as returned from `vipy.video.Video.channels`?&#34;&#34;&#34;
        return self.channels() == 1

    def hasfilename(self):
        &#34;&#34;&#34;Does the filename returned from `vipy.video.Video.filename` exist?&#34;&#34;&#34;
        return self._filename is not None and (os.path.exists(self._filename) or isRTSPurl(self._filename) or isRTMPurl(self._filename))

    def isdownloaded(self):
        &#34;&#34;&#34;Does the filename returned from `vipy.video.Video.filename` exist, meaning that the url has been downloaded to a local file?&#34;&#34;&#34;
        return self._filename is not None and os.path.exists(self._filename)

    def hasurl(self):
        &#34;&#34;&#34;Is the url returned from `vipy.video.Video.url` a well formed url?&#34;&#34;&#34;
        return self._url is not None and isurl(self._url)

    def islive(self):
        return self.hasurl() and (isRTSPurl(self._url) or isRTMPurl(self._url))
    
    def array(self, array=None, copy=False):
        &#34;&#34;&#34;Set or return the video buffer as a numpy array.
        
        Args:
            array: [np.array] A numpy array of size NxHxWxC = (frames, height, width, channels)  of type uint8 or float32.
            copy: [bool] If true, copy the buffer by value instaed of by reference.  Copied buffers do not share pixels.

        Returns:
            if array=None, return a reference to the pixel buffer as a numpy array, otherwise return the video object.

        &#34;&#34;&#34;
        if array is None:
            return self._array
        elif isnumpy(array):
            assert array.dtype == np.float32 or array.dtype == np.uint8, &#34;Invalid input - array() must be type uint8 or float32&#34;
            assert array.ndim == 4, &#34;Invalid input array() must be of shape NxHxWxC, for N frames, of size HxW with C channels&#34;
            self._array = np.copy(array) if copy else array
            if copy:
                self._array.setflags(write=True)  # mutable iterators, triggers copy
            self.colorspace(None)  # must be set with colorspace() after array() before _convert()
            return self
        else:
            raise ValueError(&#39;Invalid input - array() must be numpy array&#39;)            

    def fromarray(self, array):
        &#34;&#34;&#34;Alias for self.array(..., copy=True), which forces the new array to be a copy&#34;&#34;&#34;
        return self.array(array, copy=True)

    def fromdirectory(self, indir, sortkey=None):
        &#34;&#34;&#34;Create a video from a directory of frames stored as individual image filenames.
        
        Given a directory with files:
        
        framedir/image_0001.jpg
        framedir/image_0002.jpg
        
        ```python
        vipy.video.Video(frames=&#39;/path/to/framedir&#39;)
        ```

        &#34;&#34;&#34;
        return self.fromframes([vipy.image.Image(filename=f) for f in sorted(vipy.util.imlist(indir), key=sortkey)])
                                
    def fromframes(self, framelist, copy=True):
        &#34;&#34;&#34;Create a video from a list of frames&#34;&#34;&#34;
        assert all([isinstance(im, vipy.image.Image) for im in framelist]), &#34;Invalid input&#34;
        return self.array(np.stack([im.load().array() if im.load().array().ndim == 3 else np.expand_dims(im.load().array(), 2) for im in framelist]), copy=copy).colorspace(framelist[0].colorspace())
    
    def tonumpy(self):
        &#34;&#34;&#34;Alias for numpy()&#34;&#34;&#34;
        return self.numpy()

    def mutable(self):
        &#34;&#34;&#34;Return a video object with a writeable mutable frame array.  Video must be loaded, triggers copy of underlying numpy array if the buffer is not writeable.  
        
        Returns:
            This object with a mutable frame buffer in self.array() or self.numpy()
        &#34;&#34;&#34;
        assert self.isloaded()
        self._array = np.copy(self._array) if not self._array.flags[&#39;WRITEABLE&#39;] else self._array  # triggers copy
        self._array.setflags(write=True)  # mutable iterators, torch conversion
        return self        
        
    def numpy(self):
        &#34;&#34;&#34;Convert the video to a writeable numpy array, triggers a load() and copy() as needed.  Returns the numpy array.&#34;&#34;&#34;
        self.load()
        self._array = np.copy(self._array) if not self._array.flags[&#39;WRITEABLE&#39;] else self._array  # triggers copy
        self._array.setflags(write=True)  # mutable iterators, torch conversion
        return self._array
    
    def zeros(self):
        self._array = 0*self.load()._array
        return self

    def reload(self):
        return self.clone(flush=True).load()
                       
    def nofilename(self):
        self._filename = None
        self._update_ffmpeg(&#39;filename&#39;, None)
        return self

    def filename(self, newfile=None, copy=False, symlink=False):
        &#34;&#34;&#34;Update video Filename with optional copy or symlink from existing file (self.filename()) to new file&#34;&#34;&#34;
        if newfile is None:
            return self._filename
        newfile = os.path.normpath(os.path.expanduser(newfile))

        # Copy or symlink from the old filename to the new filename (if requested)
        if copy:
            assert self.hasfilename(), &#34;File not found for copy&#34;
            remkdir(filepath(newfile))
            shutil.copyfile(self._filename, newfile)
        elif symlink:
            assert self.hasfilename(), &#34;File not found for symlink&#34;
            remkdir(filepath(newfile))
            if os.path.islink(newfile) and os.path.abspath(os.readlink(newfile)) == os.path.normpath(os.path.abspath(os.path.expanduser(self.filename()))):
                pass  # already points to the same place, nothing to do
            else:
                os.symlink(self._filename, newfile)                    
                    
        # Update ffmpeg filter chain with new input node filename (this file may not exist yet)
        self._update_ffmpeg(&#39;filename&#39;, newfile)
        self._filename = newfile
        
        return self

    def abspath(self):
        &#34;&#34;&#34;Change the path of the filename from a relative path to an absolute path (not relocatable)&#34;&#34;&#34;
        return self.filename(os.path.normpath(os.path.abspath(os.path.expanduser(self.filename()))))

    def relpath(self, parent=None, start=None):
        &#34;&#34;&#34;Replace the filename with a relative path to parent (or current working directory if none).
        
        Usage:
         
        ```python
        v = vipy.video.Video(filename=&#39;/path/to/dataset/video/category/out.mp4&#39;)
        v.relpath(parent=&#39;/path/to/dataset&#39;)
        v.filename() == &#39;video/category/out.mp4&#39;
        ```

        If the current working directory is /path/to/dataset, and v.load() is called, the filename will be loaded.

        Args:
            parent [str]: A parent path of the current filename to remove and be relative to.  If filename is &#39;/path/to/video.mp4&#39; then filename must start with parent, then parent will be remvoed from filename. 
            start [str]:  Return a relative filename starting from path start=&#39;/path/to/dir&#39; that will create a relative path to this filename.  If start=&#39;/a/b/c&#39; and filename=&#39;/a/b/d/e/f.ext&#39; then return filename &#39;../d/e/f.ext&#39;
        Returns:
            This video object with the filename changed to be a relative path

        &#34;&#34;&#34;
        assert parent is not None or start is not None
        if parent is not None:
            parent = parent if parent is not None else os.getcwd()
            assert parent in os.path.expanduser(self.filename()), &#34;Parent path &#39;%s&#39; not found in abspath &#39;%s&#39;&#34; % (parent, self.filename())
            self.filename(PurePath(os.path.expanduser(self.filename())).relative_to(parent))
        if start is not None: 
            self.filename(os.path.join(os.path.relpath(os.path.expanduser(filepath(self.filename())), start), filetail(self.filename())))
        return self
            
    def rename(self, newname):
        &#34;&#34;&#34;Move the underlying video file preserving the absolute path, such that self.filename() == &#39;/a/b/c.ext&#39; and newname=&#39;d.ext&#39;, then self.filename() -&gt; &#39;/a/b/d.ext&#39;, and move the corresponding file&#34;&#34;&#34;
        newfile = os.path.join(filepath(self.filename()), newname)
        shutil.move(self.filename(), newfile)        
        return self.filename(newfile)
    
    def filesize(self):
        &#34;&#34;&#34;Return the size in bytes of the filename(), None if the filename() is invalid&#34;&#34;&#34;
        return os.path.getsize(self.filename()) if self.hasfilename() else None

    def downloadif(self, ignoreErrors=False, timeout=10, verbose=True, max_filesize=&#39;350m&#39;):
        &#34;&#34;&#34;Download URL to filename if the filename has not already been downloaded&#34;&#34;&#34;
        return self.download(ignoreErrors=ignoreErrors, timeout=timeout, verbose=verbose, max_filesize=max_filesize) if self.hasurl() and not self.isdownloaded() else self
    
    def download(self, ignoreErrors=False, timeout=10, verbose=True, max_filesize=&#39;350m&#39;):
        &#34;&#34;&#34;Download URL to filename provided by constructor, or to temp filename.
        
        Args:
            ignoreErrors: [bool] If true, show a warning and return the video object, otherwise throw an exception
            timeout: [int] An integer timeout in seconds for the download to connect
            verbose: [bool] If trye, show more verbose console output
            max_filesize: [str] A string of the form &#39;NNNg&#39; or &#39;NNNm&#39; for youtube downloads to limit the maximum size of a URL to &#39;350m&#39; 350MB or &#39;12g&#39; for 12GB.

        Returns:
            This video object with the video downloaded to the filename()        
        &#34;&#34;&#34;
        if self._url is None and self._filename is not None:
            return self
        if self._url is None:
            raise ValueError(&#39;[vipy.video.download]: No URL to download&#39;)
        elif not isurl(str(self._url)):
            raise ValueError(&#39;[vipy.video.download]: Invalid URL &#34;%s&#34; &#39; % self._url)

        try:
            url_scheme = urllib.parse.urlparse(self._url)[0]
            if isyoutubeurl(self._url):
                f = self._filename if filefull(self._filename) is None else filefull(self._filename)
                vipy.videosearch.download(self._url, f, writeurlfile=False, skip=ignoreErrors, verbose=verbose, max_filesize=max_filesize)
                for ext in [&#39;mkv&#39;, &#39;mp4&#39;, &#39;webm&#39;]:
                    f = &#39;%s.%s&#39; % (self.filename(), ext)
                    if os.path.exists(f):
                        self.filename(f)  # change the filename to match the youtube extension
                        break    
                if not self.hasfilename():
                    raise ValueError(&#39;Downloaded file not found &#34;%s.*&#34;&#39; % self.filename())
            
            elif url_scheme in [&#39;http&#39;, &#39;https&#39;] and (isvideourl(self._url) or iswebp(self._url)):
                vipy.downloader.download(self._url,
                                         self._filename,
                                         verbose=verbose,
                                         timeout=timeout,
                                         sha1=None,
                                         username=None,
                                         password=None)
                                
            elif url_scheme == &#39;file&#39;:
                shutil.copyfile(self._url, self._filename)
            elif url_scheme == &#39;s3&#39;:
                if self.filename() is None:
                    self.filename(totempdir(self._url))
                    if vipy.globals.cache() is not None:
                        self.filename(os.path.join(remkdir(vipy.globals.cache()), filetail(self._url)))
                vipy.downloader.s3(self.url(), self.filename(), verbose=verbose)
                    
            elif url_scheme == &#39;scp&#39;:                
                if self.filename() is None:
                    self.filename(templike(self._url))                    
                    if vipy.globals.cache() is not None:
                        self.filename(os.path.join(remkdir(vipy.globals.cache()), filetail(self._url)))
                vipy.downloader.scp(self._url, self.filename(), verbose=verbose)
 
            elif not isvideourl(self._url) and vipy.videosearch.is_downloadable_url(self._url):
                vipy.videosearch.download(self._url, filefull(self._filename), writeurlfile=False, skip=ignoreErrors, verbose=verbose, max_filesize=max_filesize)
                for ext in [&#39;mkv&#39;, &#39;mp4&#39;, &#39;webm&#39;]:
                    f = &#39;%s.%s&#39; % (self.filename(), ext)
                    if os.path.exists(f):
                        self.filename(f)
                        break    
                if not self.hasfilename():
                    raise ValueError(&#39;Downloaded filenot found &#34;%s.*&#34;&#39; % self.filename())

            elif url_scheme == &#39;rtsp&#39;:
                # https://ffmpeg.org/ffmpeg-protocols.html#rtsp
                pass

            else:
                raise NotImplementedError(
                    &#39;Invalid URL scheme &#34;%s&#34; for URL &#34;%s&#34;&#39; %
                    (url_scheme, self._url))

        except (httplib.BadStatusLine,
                urllib.error.URLError,
                urllib.error.HTTPError):
            if ignoreErrors:
                warnings.warn(&#39;[vipy.video][WARNING]: download failed - Ignoring Video&#39;)
                self._array = None
            else:
                raise

        except IOError:
            if ignoreErrors:
                warnings.warn(&#39;[vipy.video][WARNING]: IO error - Invalid video file, url or invalid write permissions &#34;%s&#34; - Ignoring video&#39; % self.filename())
                self._array = None
            else:
                raise

        except KeyboardInterrupt:
            raise

        except Exception:
            if ignoreErrors:
                warnings.warn(&#39;[vipy.video][WARNING]: load error for video &#34;%s&#34;&#39; % self.filename())
            else:
                raise
        return self

    def fetch(self, ignoreErrors=False):
        &#34;&#34;&#34;Download only if hasfilename() is not found&#34;&#34;&#34;
        return self.download(ignoreErrors=ignoreErrors) if not self.hasfilename() else self

    def shape(self, shape=None, probe=False):
        &#34;&#34;&#34;Return (height, width) of the frames, requires loading a preview frame from the video if the video is not already loaded, or providing the shape=(height,width) by the user&#34;&#34;&#34;
        if probe:
            # Set the shape of the video from the filename by ffprobe, this should be deprecated
            return self.shape(self.probeshape(), probe=False)
        elif shape is not None:
            # Set the shape of the video using the shape provided by the user (e.g. sometimes the user knows what this will be)
            assert isinstance(shape, tuple), &#34;shape=(height, width) tuple&#34;
            self._shape = shape
            self._channels = self.channels()
            #self._previewhash = hashlib.md5(str(self._ffmpeg_commandline()).encode()).hexdigest() 
            return self
            
        elif not self.isloaded():
            # Preview a frame from the ffmpeg filter chain (more expensive)
            if self._shape is None or len(self._shape) == 0:  # dirty filter chain
                im = self.preview()  # ffmpeg chain changed, load a single frame of video, triggers fetch
                self._shape = (im.height(), im.width())  # cache the shape
                self._channels = im.channels()
                #self._previewhash = previewhash
            return self._shape
        else:
            # Frames already loaded - get shape from numpy array
            return (self._array.shape[1], self._array.shape[2])

    def channelshape(self):
        &#34;&#34;&#34;Return a tuple (channels, height, width) for the video&#34;&#34;&#34;
        return (self.channels(), self.height(), self.width())
    
    def issquare(self):
        &#34;&#34;&#34;Return true if the video has square dimensions (height == width), else false&#34;&#34;&#34;
        s = self.shape()
        return s[0] == s[1]

    def channels(self):
        &#34;&#34;&#34;Return integer number of color channels&#34;&#34;&#34;
        if not self.isloaded():
            self._channels = 3   # always color video
            
            #previewhash = hashlib.md5(str(self._ffmpeg_commandline()).encode()).hexdigest()            
            #if not hasattr(self, &#39;_previewhash&#39;) or previewhash != self._previewhash:
            #    im = self.preview()  # ffmpeg chain changed, load a single frame of video
            #    self._shape = (im.height(), im.width())  # cache the shape                
            #    self._channels = im.channels()  # cache
            #    self._previewhash = previewhash
            
            return self._channels  # cached
        else:
            return 1 if self.load().array().ndim == 3 else self.load().array().shape[3]
        
    def width(self):
        &#34;&#34;&#34;Width (cols) in pixels of the video for the current filter chain&#34;&#34;&#34;
        return self.shape()[1]

    def height(self):
        &#34;&#34;&#34;Height (rows) in pixels of the video for the current filter chain&#34;&#34;&#34;
        return self.shape()[0]

    def aspect_ratio(self):
        &#34;&#34;&#34;The width/height of the video expressed as a fraction&#34;&#34;&#34;
        return self.width() / self.height()

    def preview(self, framenum=0):
        &#34;&#34;&#34;Return selected frame of filtered video, return vipy.image.Image object.  This is useful for previewing the frame shape of a complex filter chain or the frame contents at a particular location without loading the whole video&#34;&#34;&#34;
        if self.isloaded():
            return self[framenum]
        elif self.hasurl() and not self.hasfilename():
            self.download(verbose=True)  
        if not self.hasfilename():
            raise ValueError(&#39;Video file not found&#39;)
        if iswebp(self.filename()) or isgif(self.filename()):
            return self.load().frame(framenum)
        
        # Convert frame to mjpeg and pipe to stdout, used to get dimensions of video
        #   - The MJPEG encoder will generally output lower quality than H.264 encoded frames
        #   - This means that frame indexing from preview() will generate slightly different images than streaming raw
        #   - Beware running convnets, as the pixels will be slightly different (~4 grey levels in uint8) ... 
        try:
            # FFMPEG frame indexing is inefficient for large framenum.  Need to add &#34;-ss sec.msec&#34; flag before input
            #   - the &#34;ss&#34; option must be provided before the input filename, and is supported by ffmpeg-python as &#34;.input(in_filename, ss=time)&#34;
            #   - Seek to the frame before the desired frame in order to pipe the next (desired) frame 
            timestamp_in_seconds = max(0.0, (framenum-1)/float(self.framerate()))
            f_prepipe = self.clone(shallow=True)._update_ffmpeg_seek(offset=timestamp_in_seconds)._ffmpeg.filter(&#39;select&#39;, &#39;gte(n,{})&#39;.format(0))
            f = f_prepipe.output(&#39;pipe:&#39;, vframes=1, format=&#39;image2&#39;, vcodec=&#39;mjpeg&#39;)\
                         .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;debug&#39; if vipy.globals.isdebug() else &#39;error&#39;)
            (out, err) = f.run(capture_stdout=True, capture_stderr=True)
        except Exception as e:            
            raise ValueError(&#39;[vipy.video.load]: Video preview failed with error &#34;%s&#34;\n  - Video: &#34;%s&#34;\n  - FFMPEG command: \&#39;sh&gt; %s\&#39;\n  - Try manually running this ffmpeg command to see errors.  This error usually means that the video is corrupted.&#39; % (str(e), str(self), str(self._ffmpeg_commandline(f_prepipe.output(&#39;preview.jpg&#39;, vframes=1)))))

        # [EXCEPTION]:  UnidentifiedImageError: cannot identify image file, means usually that FFMPEG piped a zero length image
        try:
            return Image(array=np.array(PIL.Image.open(BytesIO(out))))
        except Exception as e:
            print(&#39;[vipy.video.Video.preview][ERROR]:  %s&#39; % str(e))
            print(&#39;  - FFMPEG attempted to extract a single frame from the following video and failed:\n    %s&#39; % str(self))
            print(&#39;  - This may occur after calling clip() with too short a duration, try increasing the clip to be &gt; 1 sec&#39;)
            print(&#39;  - This may occur after calling clip() with a startframe or endframe outside the duration of the video&#39;)
            print(&#39;  - This may occur if requesting a frame number greater than the length of the video.  At this point, we do not know the video length, and cannot fail gracefully&#39;)
            print(&#39;  - This may occur when the framerate of the video from ffprobe (tbr) does not match that passed to fps filter, resulting in a zero length image preview piped to stdout&#39;)
            print(&#39;  - This may occur if the filter chain fails for some unknown reason on this video.  Try running this ffmpeg command manually and inspect the FFMPEG console output:\n     sh&gt; %s&#39; % str(self._ffmpeg_commandline(f_prepipe.output(&#39;preview.jpg&#39;, vframes=1))))
            raise

    def thumbnail(self, outfile=None, frame=0):
        &#34;&#34;&#34;Return annotated frame=k of video, save annotation visualization to provided outfile.

        This is functionally equivalent to `vipy.video.Video.frame` with an additional outfile argument to easily save an annotated thumbnail image.

        Args:
            outfile: [str] an optional outfile to save the annotated frame 
            frame: [int &gt;= 0] The frame to output the thumbnail

        Returns:
            A `vipy.image.Image` object for frame k.  
        &#34;&#34;&#34;
        im = self.frame(frame, img=self.preview(frame).array())
        return im.savefig(outfile) if outfile is not None else im
    
    def load(self, verbose=False, ignoreErrors=False, shape=None):
        &#34;&#34;&#34;Load a video using ffmpeg, applying the requested filter chain.  
           
        Args:
            verbose: [bool] if True. then ffmpeg console output will be displayed. 
            ignoreErrors: [bool] if True, then all load errors are warned and skipped.  Be sure to call isloaded() to confirm loading was successful.
            shape: [tuple (height, width, channels)]  If provided, use this shape for reading and reshaping the byte stream from ffmpeg.  This is useful for efficient loading in some scenarios. Knowing the final output shape can speed up loads by avoiding a preview() of the filter chain to get the frame size

        Returns:
            this video object, with the pixels loaded in self.array()

        .. warning:: Loading long videos can result in out of memory conditions.  Try to call clip() first to extract a video segment to load().
        &#34;&#34;&#34;
        if self.isloaded():
            return self
        elif not self.hasfilename() and self.hasurl():
            self.download(ignoreErrors=ignoreErrors)
        elif not self.hasfilename() and not ignoreErrors:
            raise ValueError(&#39;Invalid input - load() requires a valid URL, filename or array&#39;)
        if not self.hasfilename() and ignoreErrors:
            print(&#39;[vipy.video.load]: Video file &#34;%s&#34; not found - Ignoring&#39; % self.filename())
            return self
        if iswebp(self.filename()) or isgif(self.filename()):
            frames = []
            pil = PIL.Image.open(self.filename())
            self._framerate = (1000.0 / pil.info[&#39;duration&#39;]) if &#39;duration&#39; in pil.info else self._framerate
            for k in range(pil.n_frames):
                pil.seek(k)
                frames.append(np.array(pil.convert(&#39;RGB&#39;)))
            return self.array(np.stack(frames)).colorspace(&#39;RGB&#39;)
                        
        # Load the video with ffmpeg
        # 
        # [EXCEPTION]:  older ffmpeg versions may segfault on complex crop filter chains
        #    -On some versions of ffmpeg setting -cpuflags=0 fixes it, but the right solution is to rebuild from the head (30APR20)
        if verbose:
            print(&#39;[vipy.video.load]: Loading &#34;%s&#34;&#39; % self.filename())                    
        try:
            
            f_prepipe = copy.deepcopy(self._ffmpeg)
            f = self._ffmpeg.output(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;)\
                            .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;debug&#39; if vipy.globals.isdebug() else &#39;quiet&#39;)
            (out, err) = f.run(capture_stdout=True, capture_stderr=True)
        except Exception as e:
            if not ignoreErrors:
                raise ValueError(&#39;[vipy.video.load]: Load failed with error &#34;%s&#34;\n\n  - Video: &#34;%s&#34;\n  - FFMPEG command: \&#39;sh&gt; %s\&#39;\n  - This error usually means that the video is corrupted or that you need to upgrade your FFMPEG distribution to the latest stable version.\n  - Try running the output of the ffmpeg command for debugging.&#39; % (str(e), str(self), str(self._ffmpeg_commandline(f_prepipe.output(&#39;preview.mp4&#39;)))))
            else:
                return self  # Failed, return immediately, useful for calling canload() 

        # Video shape:
        #   - due to complex filter chains, we may not know the final video size without executing it
        #   - However, this introduces extra cost by calling preview() on each filter chain
        #   - If we know what the shape will be (e.g. we made the video square with a known size), then use it here directly
        (height, width, channels) = (self.height(), self.width(), self.channels()) if shape is None else shape
        
        # [EXCEPTION]:  older ffmpeg versions may be off by one on the size returned from self.preview() which uses an image decoder vs. f.run() which uses a video decoder
        #    -Try to correct this manually by searching for a off-by-one-pixel decoding that works.  The right way is to upgrade your FFMPEG version to the FFMPEG head (11JUN20)
        #    -We cannot tell which is the one that the end-user wanted, so we leave it up to the calling function to check dimensions (see self.resize())
        if (len(out) % (height*width*channels)) != 0:
            #warnings.warn(&#39;Your FFMPEG version is triggering a known bug that is being worked around in an inefficient manner.  Consider upgrading your FFMPEG distribution.&#39;)
            if (len(out) % ((height-1)*(width-1)*channels) == 0):
                (newwidth, newheight) = (width-1, height-1)
            elif (len(out) % ((height-1)*(width)*channels) == 0):
                (newwidth, newheight) = (width, height-1)
            elif (len(out) % ((height-1)*(width+1)*channels) == 0):
                (newwidth, newheight) = (width+1, height-1)
            elif (len(out) % ((height)*(width-1)*channels) == 0):
                (newwidth, newheight) = (width-1, height)
            elif (len(out) % ((height)*(width+1)*channels) == 0):
                (newwidth, newheight) = (width+1, height)
            elif (len(out) % ((height+1)*(width-1)*channels) == 0):
                (newwidth, newheight) = (width-1, height+1)
            elif (len(out) % ((height+1)*(width)*channels) == 0):
                (newwidth, newheight) = (width, height+1)
            elif (len(out) % ((height+1)*(width+1)*channels) == 0):
                (newwidth, newheight) = (width+1, height+1)
            else:
                (newwidth, newheight) = (width, height)

            is_loadable = (len(out) % (newheight*newwidth*channels)) == 0

            if not is_loadable:
                im = self.preview()  # get the real shape...
                (newheight, newwidth, newchannels) = (im.height(), im.width(), im.channels()) 
                        
            assert is_loadable or ignoreErrors, &#34;Load failed for video &#39;%s&#39;, and FFMPEG command line: &#39;%s&#39;&#34; % (str(self), str(self._ffmpeg_commandline(f)))
            self._array = np.frombuffer(out, np.uint8).reshape([-1, newheight, newwidth, channels]) if is_loadable else None  # read-only                        
            self.colorspace(&#39;rgb&#39; if channels == 3 else &#39;lum&#39;)
            self.resize(rows=height, cols=width)  # Very expensive framewise resizing so that the loaded video is identical shape to preview
        else:
            self._array = np.frombuffer(out, np.uint8).reshape([-1, height, width, channels])  # read-only            
            self.colorspace(&#39;rgb&#39; if channels == 3 else &#39;lum&#39;)
        return self

    def speed(self, s):
        &#34;&#34;&#34;Change the speed by a multiplier s.  If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)&#34;&#34;&#34;
        assert s &gt; 0, &#34;Invalid input&#34;
        self._ffmpeg = self._ffmpeg.setpts(&#39;%1.3f*PTS&#39; % float(1.0/float(s)))
        return self
        
    def clip(self, startframe, endframe=None):
        &#34;&#34;&#34;Load a video clip betweeen start and end frames&#34;&#34;&#34;
        assert (endframe is None or startframe &lt;= endframe) and startframe &gt;= 0, &#34;Invalid start and end frames (%s, %s)&#34; % (str(startframe), str(endframe))
        if not self.isloaded():
            timestamp_in_seconds = ((self._startframe if self._startframe is not None else 0)+startframe)/float(self.framerate())            
            self._update_ffmpeg_seek(timestamp_in_seconds)
            if endframe is not None:
                self._ffmpeg = self._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 before trim filter            
                self._ffmpeg = self._ffmpeg.trim(start=0, end=(endframe-startframe)/self.framerate())  # must be in seconds to allow for framerate conversion
            self._ffmpeg = self._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 after trim filter            
            self._startframe = startframe if self._startframe is None else self._startframe + startframe  # for __repr__ only
            self._endframe = (self._startframe + (endframe-startframe)) if endframe is not None else endframe  # for __repr__ only
        else:
            endframe = endframe if endframe is not None else len(self._array)
            self._array = self._array[startframe:endframe]
            (self._startframe, self._endframe) = (0, endframe-startframe)
        return self

    def cliprange(self):
        &#34;&#34;&#34;Return the planned clip (startframe, endframe) range.
        
        This is useful for introspection of the planned clip() before load(), such as for data augmentation purposes without triggering a load. 
        
        Returns:
            (startframe, endframe) of the video() such that after load(), the pixel buffer will contain frame=0 equivalent to startframe in the source video, and frame=endframe-startframe-1 equivalent to endframe in the source video.
            (0, None) If a video does not have a clip() (e.g. clip() was never called, the filter chain does not include a &#39;trim&#39;)

        .. notes:: The endframe can be retrieved (inefficiently) using:

        ```python
        int(round(self.duration_in_frames_of_videofile() * (self.framerate() / self.framerate_of_videofile())))
        ```

        &#34;&#34;&#34;
        return (self._startframe if self._startframe is not None else 0, self._endframe)

    #def cliptime(self, startsec, endsec):
    #    &#34;&#34;&#34;Load a video clip betweeen start seconds and end seconds, should be initialized by constructor, which will work but will not set __repr__ correctly&#34;&#34;&#34;
    #    assert startsec &lt;= endsec and startsec &gt;= 0, &#34;Invalid start and end seconds (%s, %s)&#34; % (str(startsec), str(endsec))
    #    assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
    #    self._ffmpeg = self._ffmpeg.trim(start=startsec, end=endsec)\
    #                               .setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 after trim filter
    #    self._startsec = startsec if self._startsec is None else self._startsec + startsec  # for __repr__ only
    #    self._endsec = endsec if self._endsec is None else self._startsec + (endsec-startsec)  # for __repr__ only
    #    return self
    
    def rot90cw(self):
        &#34;&#34;&#34;Rotate the video 90 degrees clockwise, can only be applied prior to load()&#34;&#34;&#34;
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        self.shape(shape=(self.width(), self.height()))  # transposed        
        self._ffmpeg = self._ffmpeg.filter(&#39;transpose&#39;, 1)
        return self

    def rot90ccw(self):
        &#34;&#34;&#34;Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()&#34;&#34;&#34;        
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        self.shape(shape=(self.width(), self.height()))  # transposed                
        self._ffmpeg = self._ffmpeg.filter(&#39;transpose&#39;, 2)
        return self

    def fliplr(self):
        &#34;&#34;&#34;Mirror the video left/right by flipping horizontally&#34;&#34;&#34;
        if not self.isloaded():
            self._ffmpeg = self._ffmpeg.filter(&#39;hflip&#39;)
        else:
            self.array(np.stack([np.fliplr(f) for f in self._array]), copy=False)
        return self

    def flipud(self):
        &#34;&#34;&#34;Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()&#34;&#34;&#34;        
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        self._ffmpeg = self._ffmpeg.filter(&#39;vflip&#39;)
        return self

    def rescale(self, s):
        &#34;&#34;&#34;Rescale the video by factor s, such that the new dimensions are (s*H, s*W), can only be applied prior to load()&#34;&#34;&#34;
        if s == 1:
            return self
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        self.shape(shape=(int(np.round(self.height()*float(np.ceil(s*1e6)/1e6))), int(np.round(self.width()*float(np.ceil(s*1e6)/1e6)))))  # update the known shape        
        self._ffmpeg = self._ffmpeg.filter(&#39;scale&#39;, &#39;iw*%1.6f&#39; % float(np.ceil(s*1e6)/1e6), &#39;ih*%1.6f&#39; % float(np.ceil(s*1e6)/1e6))  # ceil last significant digit to avoid off by one
        return self

    def resize(self, rows=None, cols=None, width=None, height=None):
        &#34;&#34;&#34;Resize the video to be (rows=height, cols=width)&#34;&#34;&#34;
        assert not (rows is not None and height is not None)
        assert not (cols is not None and width is not None)
        rows = rows if rows is not None else height
        cols = cols if cols is not None else width
                
        newshape = (rows if rows is not None else int(np.round(self.height()*(cols/self.width()))),
                    cols if cols is not None else int(np.round(self.width()*(rows/self.height()))))
                            
        if (rows is None and cols is None):
            return self  # only if strictly necessary
        if not self.isloaded():
            self._ffmpeg = self._ffmpeg.filter(&#39;scale&#39;, cols if cols is not None else -1, rows if rows is not None else -1)
        else:            
            # Do not use self.__iter__() which triggers copy for mutable arrays
            #self.array(np.stack([Image(array=self._array[k]).resize(rows=rows, cols=cols).array() for k in range(len(self))]), copy=False)
            
            # Faster: RGB-&gt;RGBX to allow for PIL.Image.fromarray() without tobytes() copy, padding faster than np.concatenate()
            #self.array(np.stack([PIL.Image.fromarray(x, mode=&#39;RGBX&#39;).resize( (cols, rows), resample=PIL.Image.BILINEAR) for x in np.pad(self._array, ((0,0),(0,0),(0,0),(0,1)))])[:,:,:,:-1], copy=False)  # RGB-&gt;RGBX-&gt;RGB
            
            # Fastest: padding introduces more overhead than just accepting tobytes(), image size dependent?
            self.array(np.stack([PIL.Image.fromarray(x).resize( (newshape[1], newshape[0]), resample=PIL.Image.BILINEAR) for x in np.ascontiguousarray(self._array)]), copy=False)
        self.shape(shape=newshape)  # manually set newshape
        return self

    def mindim(self, dim=None):
        &#34;&#34;&#34;Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        return min(self.shape()) if dim is None else (self if min(H,W)==dim else (self.resize(cols=dim) if W&lt;H else self.resize(rows=dim)))

    def maxdim(self, dim=None):
        &#34;&#34;&#34;Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
        assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
        (H,W) = self.shape()  # yuck, need to get image dimensions before filter
        return max(H,W) if dim is None else (self.resize(cols=dim) if W&gt;H else self.resize(rows=dim))
    
    def randomcrop(self, shape, withbox=False):
        &#34;&#34;&#34;Crop the video to shape=(H,W) with random position such that the crop contains only valid pixels, and optionally return the box&#34;&#34;&#34;
        assert shape[0] &lt;= self.height() and shape[1] &lt;= self.width()  # triggers preview()
        (xmin, ymin) = (np.random.randint(self.height()-shape[0]), np.random.randint(self.width()-shape[1]))
        bb = vipy.geometry.BoundingBox(xmin=int(xmin), ymin=int(ymin), width=int(shape[1]), height=int(shape[0]))  # may be outside frame
        self.crop(bb, zeropad=True)
        return self if not withbox else (self, bb)

    def centercrop(self, shape, withbox=False):
        &#34;&#34;&#34;Crop the video to shape=(H,W) preserving the integer centroid position, and optionally return the box&#34;&#34;&#34;
        assert shape[0] &lt;= self.height() and shape[1] &lt;= self.width()  # triggers preview()
        bb = vipy.geometry.BoundingBox(xcentroid=float(self.width()/2.0), ycentroid=float(self.height()/2.0), width=float(shape[1]), height=float(shape[0])).int()  # may be outside frame
        self.crop(bb, zeropad=True)
        return self if not withbox else (self, bb)

    def centersquare(self):
        &#34;&#34;&#34;Crop video of size (NxN) in the center, such that N=min(width,height), keeping the video centroid constant&#34;&#34;&#34;
        return self.centercrop( (min(self.height(), self.width()), min(self.height(), self.width())))

    def cropeven(self):
        &#34;&#34;&#34;Crop the video to the largest even (width,height) less than or equal to current (width,height).  This is useful for some codecs or filters which require even shape.&#34;&#34;&#34;
        return self.crop(vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(vipy.math.even(self.width())), height=int(vipy.math.even(self.height()))))
    
    def maxsquare(self):
        &#34;&#34;&#34;Pad the video to be square, preserving the upper left corner of the video&#34;&#34;&#34;
        # This ffmpeg filter can throw the error:  &#34;Padded dimensions cannot be smaller than input dimensions.&#34; since the preview is off by one.  Add one here to make sure.
        # FIXME: not sure where in some filter chains this off-by-one error is being introduced, but probably does not matter since it does not affect any annotations 
        # and since the max square always preserves the scale and the upper left corner of the source video. 
        # FIXME: this may trigger an inefficient resizing operation during load()
        if not self.issquare():
            d = max(self.shape())
            self._ffmpeg = self._ffmpeg.filter(&#39;pad&#39;, d+1, d+1, 0, 0)
            self.shape(shape=(d+1, d+1))
            return self.crop(vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(d), height=int(d)))
        else:
            return self

    def minsquare(self):
        &#34;&#34;&#34;Return a square crop of the video, preserving the upper left corner of the video&#34;&#34;&#34;
        d = min(self.shape())
        self.shape(shape=(d, d))
        return self.crop(vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(d), height=int(d)))
    
    def maxmatte(self):
        &#34;&#34;&#34;Return a square video with dimensions (self.maxdim(), self.maxdim()) with zeropadded lack bars or mattes above or below the video forming a letterboxed video.&#34;&#34;&#34;
        return self.zeropad(max(1, int((max(self.shape()) - self.width())/2)), max(int((max(self.shape()) - self.height())/2), 1)).maxsquare()
    
    def zeropad(self, padwidth, padheight):
        &#34;&#34;&#34;Zero pad the video with padwidth columns before and after, and padheight rows before and after
           
        .. notes:: Older FFMPEG implementations can throw the error &#34;Input area #:#:#:# not within the padded area #:#:#:# or zero-sized, this is often caused by odd sized padding. 
             Recommend calling self.cropeven().zeropad(...) to avoid this

        &#34;&#34;&#34;
        assert isinstance(padwidth, int) and isinstance(padheight, int)        
        if not self.isloaded():
            self.shape(shape=(self.height()+2*padheight, self.width()+2*padwidth))  # manually set shape to avoid preview            
            self._ffmpeg = self._ffmpeg.filter(&#39;pad&#39;, &#39;iw+%d&#39; % (2*padwidth), &#39;ih+%d&#39; % (2*padheight), &#39;%d&#39;%padwidth, &#39;%d&#39;%padheight)
        elif padwidth &gt; 0 or padheight &gt; 0:
            self.array( np.pad(self.array(), ((0,0), (padheight,padheight), (padwidth,padwidth), (0,0)), mode=&#39;constant&#39;), copy=False)  # this is very expensive, since np.pad() must copy (once in np.pad &gt;=1.17)            
        return self

    def pad(self, padwidth=0, padheight=0):
        &#34;&#34;&#34;Alias for zeropad&#34;&#34;&#34;
        return self.zeropad(padwidth=padwidth, padheight=padheight)

    def zeropadlike(self, width, height):
        &#34;&#34;&#34;Zero pad the video balancing the border so that the resulting video size is (width, height).&#34;&#34;&#34;
        assert width &gt;= self.width() and height &gt;= self.height(), &#34;Invalid input - final (width=%d, height=%d) must be greater than current image size (width=%d, height=%d)&#34; % (width, height, self.width(), self.height())
        assert int(np.floor((width - self.width())/2)) == int(np.ceil((width - self.width())/2)), &#34;Zero pad must be symmetric, this is often due to odd zeropadding which ffmpeg doesn&#39;t like.  Try changing the width +/- 1 pixel&#34;
        assert int(np.floor((height - self.height())/2)) == int(np.ceil((height - self.height())/2)), &#34;Zero pad must be symmetric, this is often due to odd zeropadding which ffmpeg doesn&#39;t like.  Try changing the height +/- 1 pixel&#34;        
        return self.zeropad(int(np.floor((width - self.width())/2)),
                            int(np.floor((height - self.height())/2)))
    
    def crop(self, bbi, zeropad=True):
        &#34;&#34;&#34;Spatially crop the video using the supplied vipy.geometry.BoundingBox, can only be applied prior to load().
        
        .. note:: Crop is performed in place overwriting pixels of self.array().  Clone() before crop() if array() must be preserved.
        &#34;&#34;&#34;
        assert isinstance(bbi, vipy.geometry.BoundingBox), &#34;Invalid input&#34;
        bbc = bbi.clone().imclipshape(self.width(), self.height()).int()  # clipped box to image rectangle
        bb = bbi.int() if zeropad else bbc  # use clipped box if not zeropad 

        if bb.isdegenerate():
            return None
        elif not self.isloaded():
            if zeropad and bb != bbc:
                # Crop outside the image rectangle will segfault ffmpeg, pad video first (if zeropad=False, then rangecheck will not occur!)
                self.zeropad(int(np.ceil(bb.width()-bbc.width())), int(np.ceil(bb.height()-bbc.height())))     # cannot be called in derived classes
                bb = bb.offset(int(np.ceil(bb.width()-bbc.width())), int(np.ceil(bb.height()-bbc.height())))   # Shift boundingbox by padding (integer coordinates)
            self._ffmpeg = self._ffmpeg.filter(&#39;crop&#39;, &#39;%d&#39; % bb.width(), &#39;%d&#39; % bb.height(), &#39;%d&#39; % bb.xmin(), &#39;%d&#39; % bb.ymin(), keep_aspect=0)  # keep_aspect=False (disable exact=True, this is not present in older ffmpeg)
        else:
            self.array( bbc.crop(self.array()), copy=False )  # crop first, in-place, valid pixels only
            if zeropad and bb != bbc:
                ((dyb, dya), (dxb, dxa)) = ((max(0, int(abs(np.ceil(bb.ymin() - bbc.ymin())))), max(0, int(abs(np.ceil(bb.ymax() - bbc.ymax()))))),
                                            (max(0, int(abs(np.ceil(bb.xmin() - bbc.xmin())))), max(0, int(abs(np.ceil(bb.xmax() - bbc.xmax()))))))
                self._array = np.pad(self.load().array(), ((0,0), (dyb, dya), (dxb, dxa), (0, 0)), mode=&#39;constant&#39;)
        self.shape(shape=(bb.height(), bb.width()))  # manually set shape
        return self

    def pkl(self, pklfile=None):
        &#34;&#34;&#34;save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains&#34;&#34;&#34;
        pklfile = pklfile if pklfile is not None else toextension(self.filename(), &#39;.pkl&#39;)
        remkdir(filepath(pklfile))
        vipy.util.save(self, pklfile)
        return self

    def pklif(self, b, pklfile=None):
        &#34;&#34;&#34;Save the object to the provided pickle file only if b=True. Uuseful for conditional intermediate saving in long fluent chains&#34;&#34;&#34;
        assert isinstance(b, bool)
        return self.pkl(pklfile) if b else self

    def webp(self, outfile=None, pause=3, strict=True, smallest=False, smaller=False, framerate=None):
        &#34;&#34;&#34;Save a video to an animated WEBP file, with pause=N seconds on the last frame between loops.  
        
        Args:
            strict: If true, assert that the filename must have an .webp extension
            pause: Integer seconds to pause between loops of the animation
            smallest:  if true, create the smallest possible file but takes much longer to run
            smaller:  If true, create a smaller file, which takes a little longer to run 
            framerate [float]:  The output framerate of the webp file.  The default is the framerate of the video. 

        Returns:
            The filename of the webp file for this video

        .. warning::  This may be slow for very long or large videos
        &#34;&#34;&#34;
        outfile = vipy.util.tempWEBP() if outfile is None else outfile        
        assert strict is False or iswebp(outfile)
        outfile = os.path.normpath(os.path.abspath(os.path.expanduser(outfile)))
        framerate = framerate if framerate is not None else self._framerate
        self.load().frame(0).pil().save(outfile, loop=0, save_all=True, method=6 if smallest else 3 if smaller else 0,
                                        append_images=[self.frame(k).pil() for k in range(1, len(self))],
                                        duration=[int(1000.0/framerate) for k in range(0, len(self)-1)] + [pause*1000])
        return outfile

    def gif(self, outfile, pause=3, smallest=False, smaller=False, framerate=None):
        &#34;&#34;&#34;Save a video to an animated GIF file, with pause=N seconds between loops.  

        Args:
            pause: Integer seconds to pause between loops of the animation
            smallest:  If true, create the smallest possible file but takes much longer to run
            smaller:  if trye, create a smaller file, which takes a little longer to run 
            framerate [float]:  The output framerate of the webp file.  The default is the framerate of the video. 

        Returns:
            The filename of the animated GIF of this video

        .. warning::  This will be very large for big videos, consider using `vipy.video.Video.webp` instead.
        &#34;&#34;&#34;        
        assert isgif(outfile)
        return self.webp(outfile, pause, strict=False, smallest=smallest, smaller=True, framerate=framerate)
        
    def saveas(self, outfile=None, framerate=None, vcodec=&#39;libx264&#39;, verbose=False, ignoreErrors=False, flush=False, pause=5):
        &#34;&#34;&#34;Save video to new output video file.  This function does not draw boxes, it saves pixels to a new video file.

        Args:
            outfile: the absolute path to the output video file.  This extension can be .mp4 (for video) or [&#34;.webp&#34;,&#34;.gif&#34;]  (for animated image)
            ignoreErrors:  if True, then exit gracefully without throwing an exception.  Useful for chaining download().saveas() on parallel dataset downloads
            flush:  If true, then flush the buffer for this object right after saving the new video. This is useful for transcoding in parallel
            framerate:  input framerate of the frames in the buffer, or the output framerate of the transcoded video.  If not provided, use framerate of source video
            pause:  an integer in seconds to pause between loops of animated images if the outfile is webp or animated gif

        Returns:
            a new video object with this video filename, and a clean video filter chain

        .. note:: 
            - If self.array() is loaded, then export the contents of self._array to the video file
            - If self.array() is not loaded, and there exists a valid video file, apply the filter chain directly to the input video
            - If outfile==None or outfile==self.filename(), then overwrite the current filename 

        &#34;&#34;&#34;        
        outfile = tocache(tempMP4()) if outfile is None else os.path.normpath(os.path.abspath(os.path.expanduser(outfile)))
        premkdir(outfile)  # create output directory for this file if not exists
        framerate = framerate if framerate is not None else self._framerate
        assert vipy.util.isvideofile(outfile), &#34;Invalid filename extension for video filename&#34;

        if verbose:
            print(&#39;[vipy.video.saveas]: Saving video &#34;%s&#34; ...&#39; % outfile)                      
        try:
            if iswebp(outfile):
                return self.webp(outfile, pause)
            elif isgif(outfile):
                return self.gif(outfile, pause)
            elif isjsonfile(outfile):
                with open(outfile) as f:
                    f.write(self.json(encode=True))
                return outfile
            elif self.isloaded():
                # Save numpy() from load() to video, forcing to be even shape
                (n, height, width, channels) = self._array.shape
                process = ffmpeg.input(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;, s=&#39;{}x{}&#39;.format(width, height), r=framerate) \
                                .filter(&#39;pad&#39;, &#39;ceil(iw/2)*2&#39;, &#39;ceil(ih/2)*2&#39;) \
                                .output(filename=outfile, pix_fmt=&#39;yuv420p&#39;, vcodec=vcodec) \
                                .overwrite_output() \
                                .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;quiet&#39; if not vipy.globals.isdebug() else &#39;debug&#39;) \
                                .run_async(pipe_stdin=True)                
                for frame in self._array:
                    process.stdin.write(frame.astype(np.uint8).tobytes())
                process.stdin.close()
                process.wait()
            
            elif (self.isdownloaded() and self._isdirty()) or isRTSPurl(self.filename()) or isRTMPurl(self.filename()):
                # Transcode the video file directly, do not load() then export
                # Requires saving to a tmpfile if the output filename is the same as the input filename
                tmpfile = &#39;%s.tmp%s&#39; % (filefull(outfile), fileext(outfile)) if outfile == self.filename() else outfile
                self._ffmpeg.filter(&#39;pad&#39;, &#39;ceil(iw/2)*2&#39;, &#39;ceil(ih/2)*2&#39;) \
                            .output(filename=tmpfile, pix_fmt=&#39;yuv420p&#39;, vcodec=vcodec, r=framerate) \
                            .overwrite_output() \
                            .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;quiet&#39; if not vipy.globals.isdebug() else &#39;debug&#39;) \
                            .run()
                if outfile == self.filename():
                    if os.path.exists(self.filename()):
                        os.remove(self.filename())
                    shutil.move(tmpfile, self.filename())
            elif self.hasfilename() and not self._isdirty():
                shutil.copyfile(self.filename(), outfile)
            elif self.hasurl() and not self.hasfilename():
                raise ValueError(&#39;Input video url &#34;%s&#34; not downloaded, call download() first&#39; % self.url())
            elif not self.hasfilename():
                raise ValueError(&#39;Input video file not found &#34;%s&#34;&#39; % self.filename())
            else: 
                raise ValueError(&#39;saveas() failed&#39;)
        except Exception as e:
            if ignoreErrors:
                # useful for saving a large number of videos in parallel where some failed download
                print(&#39;[vipy.video.saveas]:  Failed with error &#34;%s&#34; - Returning empty video&#39; % str(repr(e)))
            else:
                raise

        # Return a new video, cloned from this video with the new video file, optionally flush the video we loaded before returning
        return self.clone(flushforward=True, flushfilter=True, flushbackward=flush).filename(outfile).nourl()
    
    def savetmp(self):
        &#34;&#34;&#34;Call `vipy.video.Video.saveas` using a new temporary video file, and return the video object with this new filename&#34;&#34;&#34;
        return self.saveas(outfile=tempMP4())
    def savetemp(self):
        &#34;&#34;&#34;Alias for `vipy.video.Video.savetmp`&#34;&#34;&#34;
        return self.savetmp()

    def ffplay(self):
        &#34;&#34;&#34;Play the video file using ffplay&#34;&#34;&#34;
        assert self.hasfilename() or (self.hasurl() and self.download().hasfilename())  # triggers download if needed
        cmd = &#39;ffplay &#34;%s&#34;&#39; % self.filename()
        print(&#39;[vipy.video.play]: Executing &#34;%s&#34;&#39; % cmd)
        os.system(cmd)
        return self
        
    def play(self, verbose=False, notebook=False):
        &#34;&#34;&#34;Play the saved video filename in self.filename()

        If there is no filename, try to download it.  If the filter chain is dirty or the pixels are loaded, dump to temp video file first then play it.  This uses &#39;ffplay&#39; on the PATH if available, otherwise uses a fallback player by showing a sequence of matplotlib frames.
        If the output of the ffmpeg filter chain has modified this video, then this will be saved to a temporary video file.  To play the original video (indepenedent of the filter chain of this video), use `vipy.video.Video.ffplay`.
        
        Args:
            verbose: If true, show more verbose output 
            notebook:  If true, play in a jupyter notebook

        Returns:
            The unmodified video object
        &#34;&#34;&#34;
        

        if not self.isdownloaded() and self.hasurl():
            self.download()
        if iswebp(self.filename()) or isgif(self.filename()):
            self.load()
            
        if notebook:
            # save to temporary video, this video is not cleaned up and may accumulate            
            try_import(&#34;IPython.display&#34;, &#34;ipython&#34;); import IPython.display
            if not self.hasfilename() or self.isloaded() or self._isdirty():
                v = self.saveas(tempMP4())                 
                warnings.warn(&#39;Saving video to temporary file &#34;%s&#34; for notebook viewer ... &#39; % v.filename())
                return IPython.display.Video(v.filename(), embed=True)
            return IPython.display.Video(self.filename(), embed=True)
        elif has_ffplay:
            if self.isloaded() or self._isdirty():
                f = tempMP4()
                if verbose:
                    warnings.warn(&#39;%s - Saving video to temporary file &#34;%s&#34; for ffplay ... &#39; % (&#39;Video loaded into memory&#39; if self.isloaded() else &#39;Dirty FFMPEG filter chain&#39;, f))
                v = self.saveas(f)
                cmd = &#39;ffplay &#34;%s&#34;&#39; % v.filename()
                if verbose:
                    print(&#39;[vipy.video.play]: Executing &#34;%s&#34;&#39; % cmd)
                os.system(cmd)
                if verbose:
                    print(&#39;[vipy.video.play]:  Removing temporary file &#34;%s&#34;&#39; % v.filename())                    
                os.remove(v.filename())  # cleanup
            elif self.hasfilename() or (self.hasurl() and self.download().hasfilename()):  # triggers download
                self.ffplay()
            else:
                raise ValueError(&#39;Invalid video file &#34;%s&#34; - ffplay requires a video filename&#39; % self.filename())
            return self

        else:
            &#34;&#34;&#34;Fallback player.  This can visualize videos without ffplay, but it cannot guarantee frame rates. Large videos with complex scenes will slow this down and will render at lower frame rates.&#34;&#34;&#34;
            fps = self.framerate()
            assert fps &gt; 0, &#34;Invalid display framerate&#34;
            with Stopwatch() as sw:            
                for (k,im) in enumerate(self.load() if self.isloaded() else self.stream()):
                    time.sleep(max(0, (1.0/self.framerate())*int(np.ceil((self.framerate()/fps))) - sw.since()))                                
                    im.show(figure=figure)
                    if vipy.globals._user_hit_escape():
                        break                    
            vipy.show.close(figure)
            return self

    def show(self):
        &#34;&#34;&#34;Alias for play&#34;&#34;&#34;
        return self.play()
    
    def quicklook(self, n=9, mindim=256, startframe=0, animate=False, dt=30):
        &#34;&#34;&#34;Generate a montage of n uniformly spaced frames.
           Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame.
        
           Input:
               n:  Number of images in the quicklook
               mindim:  The minimum dimension of each of the elements in the montage
               animate:  If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames
               dt:  The number of frames for animation
               startframe:  The initial frame index to start the n uniformly sampled frames for the quicklook

           ..note:: The first frame in the upper left is guaranteed to be the start frame of the labeled activity, but the last frame in the bottom right may not be precisely the end frame and may be off by at most len(video)/9.
        &#34;&#34;&#34;
        if not self.isloaded():
            self.load()  
        if animate:
            return Video(frames=[self.quicklook(n=n, startframe=k, animate=False, dt=dt) for k in range(0, min(dt, len(self)))], framerate=self.framerate())
        framelist = [min(int(np.round(f))+startframe, len(self)-1) for f in np.linspace(0, len(self)-1, n)]
        imframes = [self.frame(k).maxmatte()  # letterbox or pillarbox
                    for (j,k) in enumerate(framelist)]
        imframes = [im.savefig(figure=1).rgb() for im in imframes]  # temp storage in memory
        return vipy.visualize.montage(imframes, imgwidth=mindim, imgheight=mindim)

    def torch(self, startframe=0, endframe=None, length=None, stride=1, take=None, boundary=&#39;repeat&#39;, order=&#39;nchw&#39;, verbose=False, withslice=False, scale=1.0, withlabel=False, nonelabel=False):
        &#34;&#34;&#34;Convert the loaded video of shape NxHxWxC frames to an MxCxHxW torch tensor/

        Args:
            startframe: [int &gt;= 0] The start frame of the loaded video to use for constructig the torch tensor
            endframe: [int &gt;= 0] The end frame of the loaded video to use for constructing the torch tensor
            length: [int &gt;= 0] The length of the torch tensor if endframe is not provided. 
            stride: [int &gt;= 1] The temporal stride in frames.  This is the number of frames to skip.
            take: [int &gt;= 0]  The number of uniformly spaced frames to include in the tensor.  
            boundary: [&#39;repeat&#39;, &#39;cyclic&#39;] The boundary handling for when the requested tensor slice goes beyond the end of the video
            order: [&#39;nchw&#39;, &#39;nhwc&#39;, &#39;chwn&#39;, &#39;cnhw&#39;]  The axis ordering of the returned torch tensor N=number of frames (batchsize), C=channels, H=height, W=width
            verbose [bool]: Print out the slice used for contructing tensor
            withslice: [bool] Return a tuple (tensor, slice) that includes the slice used to construct the tensor.  Useful for data provenance.
            scale: [float] An optional scale factor to apply to the tensor. Useful for converting [0,255] -&gt; [0,1]
            withlabel: [bool] Return a tuple (tensor, labels) that includes the N framewise activity labels.  
            nonelabel: [bool] returns tuple (t, None) if withlabel=False

        Returns
            Returns torch float tensor, analogous to torchvision.transforms.ToTensor()           
            Return (tensor, slice) if withslice=True (withslice takes precedence)
            Returns (tensor, labellist) if withlabel=True

        .. notes::
            - This triggers a load() of the video
            - The precedence of arguments is (startframe, endframe) or (startframe, startframe+length), then stride and take.
            - Follows numpy slicing rules.  Optionally return the slice used if withslice=True
        &#34;&#34;&#34;
        try_import(&#39;torch&#39;); import torch
        frames = self.load().numpy() if self.load().numpy().ndim == 4 else np.expand_dims(self.load().numpy(), 3)  # NxHxWx(C=1, C=3)
        assert boundary in [&#39;repeat&#39;, &#39;strict&#39;, &#39;cyclic&#39;], &#34;Invalid boundary mode - must be in [&#39;repeat&#39;, &#39;strict&#39;, &#39;cyclic&#39;]&#34;

        # Slice index (i=start (zero-indexed), j=end (non-inclusive), k=step)
        (i,j,k) = (startframe, endframe, stride)
        if startframe == &#39;random&#39;:
            assert length is not None, &#34;Random start frame requires fixed length&#34;
            i = max(0, np.random.randint(len(frames)-length+1))
        if endframe is not None:
            assert length is None, &#34;Cannot specify both endframe and length&#34;                        
            assert endframe &gt; startframe, &#34;End frame must be greater than start frame&#34;
            (j,k) = (endframe, 1)
        if length is not None:
            assert endframe is None, &#34;Cannot specify both endframe and length&#34;
            assert length &gt;= 0, &#34;Length must be positive&#34;
            (j,k) = (i+length, 1)
        if length is None and endframe is None:
            j = len(frames)  # use them all
        if stride != 1:
            assert take is None, &#34;Cannot specify both take and stride&#34;
            assert stride &gt;= 1, &#34;Stride must be &gt;= 1&#34;
            k = stride
        if take is not None:
            # Uniformly sampled frames to result in len(frames)=take
            assert stride == 1, &#34;Cannot specify both take and stride&#34;
            assert take &lt;= len(frames), &#34;Take must be less than the number of frames&#34;
            k = int(np.ceil(len(frames)/float(take)))

        # Boundary handling
        assert i &gt;= 0, &#34;Start frame must be &gt;= 0&#34;
        assert i &lt; j, &#34;Start frame must be less then end frame&#34;
        assert k &lt;= len(frames), &#34;Stride must be &lt;= len(frames)&#34;
        n = len(frames)  # true video length for labels
        if boundary == &#39;repeat&#39; and j &gt; len(frames):
            for d in range(j-len(frames)):
                frames = np.concatenate( (frames, np.expand_dims(frames[-1], 0) ))
        elif boundary == &#39;cyclic&#39; and j &gt; len(frames):
            for d in range(j-len(frames)):
                frames = np.concatenate( (frames, np.expand_dims(frames[j % len(frames)], 0) ))
        assert j &lt;= len(frames), &#34;invalid slice=%s for frame shape=%s&#34; % (str((i,j,k)), str(frames.shape))
        if verbose:
            print(&#39;[vipy.video.torch]: slice (start,end,step)=%s for frame shape (N,C,H,W)=%s&#39; % (str((i,j,k)), str(frames.shape)))

        # Slice and transpose to torch tensor axis ordering
        t = torch.from_numpy(frames[i:j:k] if (k!=1 or i!=0 or j!=len(frames)) else frames)  # do not copy - This shares the numpy buffer of the video, be careful!
        if t.dim() == 2:
            t = t.unsqueeze(0).unsqueeze(-1)  # HxW -&gt; (N=1)xHxWx(C=1)
        if order == &#39;nchw&#39;:
            t = t.permute(0,3,1,2)  # NxCxHxW, view
        elif order == &#39;nhwc&#39;:
            pass  # NxHxWxC  (native numpy order)
        elif order == &#39;cnhw&#39; or order == &#39;cdhw&#39;:
            t = t.permute(3,0,1,2)  # CxNxHxW == CxDxHxW (for torch conv3d), view
        elif order == &#39;chwn&#39;:
            t = t.permute(3,1,2,0)  # CxHxWxN, view
        else:
            raise ValueError(&#34;Invalid order = must be in [&#39;nchw&#39;, &#39;nhwc&#39;, &#39;chwn&#39;, &#39;cnhw&#39;]&#34;)
            
        # Scaling (optional)
        if scale is not None and self.colorspace() != &#39;float&#39;:
            t = (1.0/255.0)*t  # [0,255] -&gt; [0,1]
        elif scale is not None and scale != 1.0:
            t = scale*t

        # Return tensor or (tensor, slice) or (tensor, labels)
        if withslice:
            return (t, (i,j,k))
        elif withlabel:            
            labels = [sorted(tuple(self.activitylabels( (f%n) if boundary == &#39;cyclic&#39; else min(f, n-1) ))) for f in range(i,j,k)]
            return (t, labels)
        elif nonelabel:
            return (t, None)
        else:
            return t

    def clone(self, flushforward=False, flushbackward=False, flush=False, flushfilter=False, rekey=False, flushfile=False, shallow=False, sharedarray=False, sanitize=True):
        &#34;&#34;&#34;Create deep copy of video object, flushing the original buffer if requested and returning the cloned object.

        Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned 
        object which can be used for encoding and will be garbage collected.
        
        Args:
            flushforward: copy the object, and set the cloned object `vipy.video.Video.array` to None.  This flushes the video buffer for the clone, not the object
            flushbackward:  copy the object, and set the object array() to None.  This flushes the video buffer for the object, not the clone.
            flush:  set the object array() to None and clone the object.  This flushes the video buffer for both the clone and the object.
            flushfilter:  Set the ffmpeg filter chain to the default in the new object, useful for saving new videos
            flushfile:  Remove the filename and the URL from the video object.  Useful for creating new video objects from loaded pixels.  
            rekey: Generate new unique track ID and activity ID keys for this scene
            shallow:  shallow copy everything (copy by reference), except for ffmpeg object.  attributes dictionary is shallow copied
            sharedarray:  deep copy of everything, except for pixel buffer which is shared.  Changing the pixel buffer on self is reflected in the clone.
            sanitize:  remove private attributes from self.attributes dictionary.  A private attribute is any key with two leading underscores &#39;__&#39; which should not be propagated to clone

        Returns:
            A deepcopy of the video object such that changes to self are not reflected in the copy

        .. note:: Cloning videos is an expensive operation and can slow down real time code. Use sparingly. 

        &#34;&#34;&#34;
        if sanitize:
            a = self.attributes  # copy reference to attributes to restore 
            self.attributes = {}  # remove attributes on self for fast clone() since private attributes will be filtered anyway
        if flush or (flushforward and flushbackward):
            self._array = None  # flushes buffer on object and clone
            #self._previewhash = None
            self._shape = None
            v = copy.deepcopy(self)  # object and clone are flushed
        elif flushbackward:
            v = copy.deepcopy(self)  # propagates _array to clone
            self._array = None   # object flushed, clone not flushed
            #self._previewhash = None
            self._shape = None
        elif flushforward:
            array = self._array;
            self._array = None
            #self._previewhash = None
            self._shape = None
            v = copy.deepcopy(self)   # does not propagate _array to clone
            self._array = array    # object not flushed
            v._array = None   # clone flushed
        elif shallow:
            v = copy.copy(self)  # shallow copy
            v._ffmpeg = copy.deepcopy(self._ffmpeg)  # except for ffmpeg object
            v.attributes = {k:v for (k,v) in self.attributes.items()}  # shallow copy of keys
            v._array = np.asarray(self._array) if self._array is not None else None  # shared pixels
        elif sharedarray:
            array = self._array
            self._array = None
            v = copy.deepcopy(self)  # deep copy of everything but pixels
            v._array = np.asarray(array) if array is not None else None  # shared pixels
            self._array = array # restore
        else:
            v = copy.deepcopy(self)            

        if flushfilter:
            v._ffmpeg = ffmpeg.input(v.filename())  # no other filters
            #v._previewhash = None
            v._shape = None
            (v._startframe, v._endframe) = (None, None)
            (v._startsec, v._endsec) = (None, None)
        if rekey:
            v.rekey()
        if flushfile:
            v.nofilename().nourl()
        if sanitize:
            self.attributes = a  # restore attributes            
            v.attributes = {k:v for (k,v) in self.attributes.items()}  # shallow copy
            v.sanitize()  # remove private attributes
        return v

    def flush(self):
        &#34;&#34;&#34;Alias for clone(flush=True), returns self not clone&#34;&#34;&#34;
        self._array = None  # flushes buffer on object and clone
        #self._previewhash = None
        self._shape = None
        return self

    def returns(self, r=None):
        &#34;&#34;&#34;Return the provided value, useful for terminating long fluent chains without returning self&#34;&#34;&#34;
        return r

    def flush_and_return(self, retval):
        &#34;&#34;&#34;Flush the video and return the parameter supplied, useful for long fluent chains&#34;&#34;&#34;
        self.flush()
        return retval

    def map(self, func):
        &#34;&#34;&#34;Apply lambda function to the loaded numpy array img, changes pixels not shape
        
        Lambda function must have the following signature:
            * newimg = func(img)
            * img: HxWxC numpy array for a single frame of video
            * newimg:  HxWxC modified numpy array for this frame.  Change only the pixels, not the shape

        The lambda function will be applied to every frame in the video in frame index order.
        &#34;&#34;&#34;
        assert isinstance(func, types.LambdaType), &#34;Input must be lambda function with np.array() input and np.array() output&#34;
        oldimgs = self.load().array()
        self.array(np.apply_along_axis(func, 0, self._array))   # FIXME: in-place operation?
        if (any([oldimg.dtype != newimg.dtype for (oldimg, newimg) in zip(oldimgs, self.array())]) or
            any([oldimg.shape != newimg.shape for (oldimg, newimg) in zip(oldimgs, self.array())])):            
            self.colorspace(&#39;float&#39;)  # unknown colorspace after shape or type transformation, set generic
        return self

    def gain(self, g):
        &#34;&#34;&#34;Pixelwise multiplicative gain, such that each pixel p_{ij} = g * p_{ij}&#34;&#34;&#34;
        return self.normalize(0, 1, scale=g)

    def bias(self, b):
        &#34;&#34;&#34;Pixelwise additive bias, such that each pixel p_{ij} = b + p_{ij}&#34;&#34;&#34;
        return self.normalize(mean=0, std=1, scale=1.0, bias=b)
    
    def float(self):
        self.load()
        self._array = self._array.astype(np.float32) if self._array is not None else self._array
        return self

    def channel(self, c):
        self.load()
        assert c &gt;= 0 and c &lt; self.channels()
        self._array = self._array[:,:,:,c] if self._array is not None else self._array
        return self

    def normalize(self, mean, std, scale=1, bias=0):
        &#34;&#34;&#34;Pixelwise whitening, out = ((scale*in) - mean) / std); triggers load().  All computations float32&#34;&#34;&#34;
        assert scale &gt;= 0, &#34;Invalid input&#34;
        assert all([s &gt; 0 for s in tolist(std)]), &#34;Invalid input&#34;
        self._array = vipy.math.normalize(self._array, np.array(mean, dtype=np.float32), np.array(std, dtype=np.float32), np.float32(scale))
        if bias != 0:
            self._array = self._array + np.array(bias, dtype=np.float32)
        return self.colorspace(&#39;float&#39;)

    def setattribute(self, k, v=None):
        if self.attributes is None:
            self.attributes = {}
        self.attributes[k] = v
        return self

    def _has_private_attribute(self):
        &#34;&#34;&#34;Does the attributes dictionary contain any private attributes (e.g. those keys prepended with &#39;__&#39;)&#34;&#34;&#34;
        return isinstance(self.attributes, dict) and any([k.startswith(&#39;__&#39;) for k in self.attributes.keys()])      
    
    def hasattribute(self, k):
        &#34;&#34;&#34;Does the attributes dictionary (self.attributes) contain the provided key&#34;&#34;&#34;
        return isinstance(self.attributes, dict) and k in self.attributes

    def delattribute(self, k):
        if k in self.attributes:
            self.attributes.pop(k)
        return self

    def getattribute(self, k):
        return self.attributes[k]</code></pre>
</details>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="vipy.flow.Video" href="flow.html#vipy.flow.Video">Video</a></li>
<li><a title="vipy.video.VideoCategory" href="#vipy.video.VideoCategory">VideoCategory</a></li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="vipy.video.Video.cast"><code class="name flex">
<span>def <span class="ident">cast</span></span>(<span>v)</span>
</code></dt>
<dd>
<div class="desc"><p>Cast a conformal video object to a <code><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></code> object.</p>
<p>This is useful for downcasting superclasses.</p>
<pre><code class="language-python">vs = vipy.video.RandomScene()
v = vipy.video.Video.cast(vs)
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L540-L554" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@classmethod
def cast(cls, v):
    &#34;&#34;&#34;Cast a conformal video object to a `vipy.video.Video` object.
    
    This is useful for downcasting superclasses.

    ```python
    vs = vipy.video.RandomScene()
    v = vipy.video.Video.cast(vs)
    ```

    &#34;&#34;&#34;
    assert isinstance(v, vipy.video.Video), &#34;Invalid input - must be derived from vipy.video.Video&#34;
    v.__class__ = vipy.video.Video
    return v</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.concatenate"><code class="name flex">
<span>def <span class="ident">concatenate</span></span>(<span>videos, outfile, framerate=30, youtube_chapters=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Temporally concatenate a sequence of videos into a single video stored in outfile.</p>
<pre><code class="language-python">(v1, v2, v3) = (vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32))
vc = vipy.video.Video.concatenate((v1, v2, v3), 'concatenated.mp4', youtube_chapters=lambda v: v.category())
</code></pre>
<p>In this example, vc will point to concatenated.mp4 which will contain (v1,v2,v3) concatenated temporally .
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>videos</code></strong></dt>
<dd>a single video or an iterable of videos of type <code><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></code> or an iterable of video files</dd>
<dt><strong><code>outfile</code></strong></dt>
<dd>the output filename to store the concatenation. </dd>
<dt><strong><code>youtube_chapters</code></strong></dt>
<dd>[bool, callable]:
If true, output a string that can be used to define the start and end times of chapters if this video is uploaded to youtube.
The string output should be copied to the youtube video description in order to enable chapters on playback.
This argument will default to the string representation ofo the video, but you may also pass a callable of the form: 'youtube_chapters=lambda v: str(v)' which will output the provided string for each video chapter.
A useful lambda is 'youtube_chapters=lambda v: v.category()'</dd>
<dt><strong><code>framerate</code></strong></dt>
<dd>[float]: The output frame rate of outfile</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul>
<li>self will not be modified, this will return a new <code><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></code> object.</li>
<li>All videos must be the same shape().
If the videos are different shapes, you must pad them to a common size equal to self.shape().
Try <code><a title="vipy.video.Video.zeropadlike" href="#vipy.video.Video.zeropadlike">Video.zeropadlike()</a></code>.</li>
<li>The output video will be at the framerate of self.framerate().</li>
<li>if you want to concatenate annotations, call <code><a title="vipy.video.Scene.annotate" href="#vipy.video.Scene.annotate">Scene.annotate()</a></code> first on the videos to save the annotations into the pixels, then concatenate.</li>
</ul>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L703-L746" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@classmethod
def concatenate(cls, videos, outfile, framerate=30, youtube_chapters=None):
    &#34;&#34;&#34;Temporally concatenate a sequence of videos into a single video stored in outfile.
    
    ```python
    (v1, v2, v3) = (vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32))
    vc = vipy.video.Video.concatenate((v1, v2, v3), &#39;concatenated.mp4&#39;, youtube_chapters=lambda v: v.category())
    ```

    In this example, vc will point to concatenated.mp4 which will contain (v1,v2,v3) concatenated temporally .  

    Args:
        videos: a single video or an iterable of videos of type `vipy.video.Video` or an iterable of video files
        outfile: the output filename to store the concatenation. 
        youtube_chapters: [bool, callable]:  If true, output a string that can be used to define the start and end times of chapters if this video is uploaded to youtube.  The string output should be copied to the youtube video description in order to enable chapters on playback.  This argument will default to the string representation ofo the video, but you may also pass a callable of the form: &#39;youtube_chapters=lambda v: str(v)&#39; which will output the provided string for each video chapter.  A useful lambda is &#39;youtube_chapters=lambda v: v.category()&#39;
        framerate: [float]: The output frame rate of outfile

    Returns:
        A `vipy.video.Video` object with filename()=outfile, such that outfile contains the temporal concatenation of pixels in (self, videos).
    
    .. note::
        - self will not be modified, this will return a new `vipy.video.Video` object.
        - All videos must be the same shape().  If the videos are different shapes, you must pad them to a common size equal to self.shape().  Try `vipy.video.Video.zeropadlike`.
        - The output video will be at the framerate of self.framerate().
        - if you want to concatenate annotations, call `vipy.video.Scene.annotate` first on the videos to save the annotations into the pixels, then concatenate.
    &#34;&#34;&#34;

    assert len(tolist(videos))&gt;0 and (all([isinstance(v, vipy.video.Video) for v in tolist(videos)]) or all([os.path.exists(f) and vipy.util.isvideofile(f) for f in tolist(videos)]))
    vi = tolist(videos) if all([isinstance(v, vipy.video.Video) for v in tolist(videos)]) else [cls(filename=f) for f in tolist(videos)]

    assert all([vij.shape() == vik.shape() for vij in vi for vik in vi]), &#34;Video shapes must all the same, try padding&#34;
    vo = cls(filename=outfile, framerate=vi[0].framerate())
    with vo.stream(overwrite=True) as s:
        for v in vi:
            for im in v.clone().framerate(framerate).stream():
                s.write(im)

    if youtube_chapters is not None:        
        f = youtube_chapters if callable(youtube_chapters) else lambda v: str(v).replace(&#39;&lt;&#39;,&#39;&#39;).replace(&#39;&gt;&#39;,&#39;&#39;)  # angle brackets not allowed
        print(&#39;[vipy.video.concatenate]: Copy the following into the video Description after uploading the videofile &#34;%s&#34; to YouTube to enable chapters on playback.\n&#39; % outfile)
        print(&#39;\n&#39;.join([&#39;%s  %s&#39; % (vipy.util.seconds_to_MMSS_colon_notation(int(s)), str(f(v))) for (s,v) in zip(np.cumsum([0] + [v.duration() for v in vi][:-1]), vi)])); print(&#39;\n&#39;)
        if any([v.duration() &lt; 10 for v in vi]):
            warnings.warn(&#39;YouTube chapters must be a minimum duration of 10 seconds&#39;)
    return vo</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.from_json"><code class="name flex">
<span>def <span class="ident">from_json</span></span>(<span>s)</span>
</code></dt>
<dd>
<div class="desc"><p>Import a json string as a <code><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></code> object.</p>
<p>This will perform a round trip from a video to json and back to a video object.
This same operation is used for serialization of all vipy objects to JSON for storage.</p>
<pre><code class="language-python">v = vipy.video.Video.from_json(vipy.video.RandomVideo().json())
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L556-L581" class="git-link">Browse git</a>
</summary>
<pre><code class="python">@classmethod
def from_json(cls, s):
    &#34;&#34;&#34;Import a json string as a `vipy.video.Video` object.

    This will perform a round trip from a video to json and back to a video object.
    This same operation is used for serialization of all vipy objects to JSON for storage.

    ```python
    v = vipy.video.Video.from_json(vipy.video.RandomVideo().json())
    ```

    &#34;&#34;&#34;
    
    d = json.loads(s) if not isinstance(s, dict) else s
    v = cls(filename=d[&#39;_filename&#39;],
            url=d[&#39;_url&#39;],
            framerate=d[&#39;_framerate&#39;],
            array=np.array(d[&#39;_array&#39;]) if d[&#39;_array&#39;] is not None else None,
            colorspace=d[&#39;_colorspace&#39;],
            attributes=d[&#39;attributes&#39;],
            startframe=d[&#39;_startframe&#39;],
            endframe=d[&#39;_endframe&#39;],
            startsec=d[&#39;_startsec&#39;],
            endsec=d[&#39;_endsec&#39;])
    v._ffmpeg = v._from_ffmpeg_commandline(d[&#39;_ffmpeg&#39;])
    return v.filename(d[&#39;_filename&#39;]) if d[&#39;_filename&#39;] is not None else v.nofilename()</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="vipy.video.Video.abspath"><code class="name flex">
<span>def <span class="ident">abspath</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Change the path of the filename from a relative path to an absolute path (not relocatable)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1329-L1331" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def abspath(self):
    &#34;&#34;&#34;Change the path of the filename from a relative path to an absolute path (not relocatable)&#34;&#34;&#34;
    return self.filename(os.path.normpath(os.path.abspath(os.path.expanduser(self.filename()))))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.array"><code class="name flex">
<span>def <span class="ident">array</span></span>(<span>self, array=None, copy=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Set or return the video buffer as a numpy array.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>array</code></strong></dt>
<dd>[np.array] A numpy array of size NxHxWxC = (frames, height, width, channels)
of type uint8 or float32.</dd>
<dt><strong><code>copy</code></strong></dt>
<dd>[bool] If true, copy the buffer by value instaed of by reference.
Copied buffers do not share pixels.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>if array=None, return a reference to the pixel buffer as a numpy array, otherwise return the video object.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1222-L1244" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def array(self, array=None, copy=False):
    &#34;&#34;&#34;Set or return the video buffer as a numpy array.
    
    Args:
        array: [np.array] A numpy array of size NxHxWxC = (frames, height, width, channels)  of type uint8 or float32.
        copy: [bool] If true, copy the buffer by value instaed of by reference.  Copied buffers do not share pixels.

    Returns:
        if array=None, return a reference to the pixel buffer as a numpy array, otherwise return the video object.

    &#34;&#34;&#34;
    if array is None:
        return self._array
    elif isnumpy(array):
        assert array.dtype == np.float32 or array.dtype == np.uint8, &#34;Invalid input - array() must be type uint8 or float32&#34;
        assert array.ndim == 4, &#34;Invalid input array() must be of shape NxHxWxC, for N frames, of size HxW with C channels&#34;
        self._array = np.copy(array) if copy else array
        if copy:
            self._array.setflags(write=True)  # mutable iterators, triggers copy
        self.colorspace(None)  # must be set with colorspace() after array() before _convert()
        return self
    else:
        raise ValueError(&#39;Invalid input - array() must be numpy array&#39;)            </code></pre>
</details>
</dd>
<dt id="vipy.video.Video.aspect_ratio"><code class="name flex">
<span>def <span class="ident">aspect_ratio</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>The width/height of the video expressed as a fraction</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1540-L1542" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def aspect_ratio(self):
    &#34;&#34;&#34;The width/height of the video expressed as a fraction&#34;&#34;&#34;
    return self.width() / self.height()</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.bias"><code class="name flex">
<span>def <span class="ident">bias</span></span>(<span>self, b)</span>
</code></dt>
<dd>
<div class="desc"><p>Pixelwise additive bias, such that each pixel p_{ij} = b + p_{ij}</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2369-L2371" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def bias(self, b):
    &#34;&#34;&#34;Pixelwise additive bias, such that each pixel p_{ij} = b + p_{ij}&#34;&#34;&#34;
    return self.normalize(mean=0, std=1, scale=1.0, bias=b)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.bytes"><code class="name flex">
<span>def <span class="ident">bytes</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a bytes representation of the video file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L821-L826" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def bytes(self):
    &#34;&#34;&#34;Return a bytes representation of the video file&#34;&#34;&#34;
    assert self.hasfilename(), &#34;Invalid filename&#34;
    with open(self.filename(), &#39;rb&#39;) as f:
        data = io.BytesIO(f.read())
    return str(data.read()).encode(&#39;UTF-8&#39;)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.canload"><code class="name flex">
<span>def <span class="ident">canload</span></span>(<span>self, frame=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Return True if the video can be previewed at frame=k successfully.</p>
<p>This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.</p>
<div class="admonition notes">
<p class="admonition-title">Notes:&ensp;This will only try to preview a single frame.
This will not check if the entire video is loadable.
Use <code><a title="vipy.video.Video.isloadable" href="#vipy.video.Video.isloadable">Video.isloadable()</a></code> in this case</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1183-L1197" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def canload(self, frame=0):
    &#34;&#34;&#34;Return True if the video can be previewed at frame=k successfully.
    
    This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.

    .. notes:: This will only try to preview a single frame.  This will not check if the entire video is loadable.  Use `vipy.video.Video.isloadable` in this case
    &#34;&#34;&#34;
    if not self.isloaded():
        try:
            self.preview(framenum=frame)  # try to preview
            return True
        except:
            return False
    else:
        return True</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.centercrop"><code class="name flex">
<span>def <span class="ident">centercrop</span></span>(<span>self, shape, withbox=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Crop the video to shape=(H,W) preserving the integer centroid position, and optionally return the box</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1827-L1832" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def centercrop(self, shape, withbox=False):
    &#34;&#34;&#34;Crop the video to shape=(H,W) preserving the integer centroid position, and optionally return the box&#34;&#34;&#34;
    assert shape[0] &lt;= self.height() and shape[1] &lt;= self.width()  # triggers preview()
    bb = vipy.geometry.BoundingBox(xcentroid=float(self.width()/2.0), ycentroid=float(self.height()/2.0), width=float(shape[1]), height=float(shape[0])).int()  # may be outside frame
    self.crop(bb, zeropad=True)
    return self if not withbox else (self, bb)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.centersquare"><code class="name flex">
<span>def <span class="ident">centersquare</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Crop video of size (NxN) in the center, such that N=min(width,height), keeping the video centroid constant</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1834-L1836" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def centersquare(self):
    &#34;&#34;&#34;Crop video of size (NxN) in the center, such that N=min(width,height), keeping the video centroid constant&#34;&#34;&#34;
    return self.centercrop( (min(self.height(), self.width()), min(self.height(), self.width())))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.channel"><code class="name flex">
<span>def <span class="ident">channel</span></span>(<span>self, c)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2378-L2382" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def channel(self, c):
    self.load()
    assert c &gt;= 0 and c &lt; self.channels()
    self._array = self._array[:,:,:,c] if self._array is not None else self._array
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.channels"><code class="name flex">
<span>def <span class="ident">channels</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return integer number of color channels</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1516-L1530" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def channels(self):
    &#34;&#34;&#34;Return integer number of color channels&#34;&#34;&#34;
    if not self.isloaded():
        self._channels = 3   # always color video
        
        #previewhash = hashlib.md5(str(self._ffmpeg_commandline()).encode()).hexdigest()            
        #if not hasattr(self, &#39;_previewhash&#39;) or previewhash != self._previewhash:
        #    im = self.preview()  # ffmpeg chain changed, load a single frame of video
        #    self._shape = (im.height(), im.width())  # cache the shape                
        #    self._channels = im.channels()  # cache
        #    self._previewhash = previewhash
        
        return self._channels  # cached
    else:
        return 1 if self.load().array().ndim == 3 else self.load().array().shape[3]</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.channelshape"><code class="name flex">
<span>def <span class="ident">channelshape</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a tuple (channels, height, width) for the video</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1507-L1509" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def channelshape(self):
    &#34;&#34;&#34;Return a tuple (channels, height, width) for the video&#34;&#34;&#34;
    return (self.channels(), self.height(), self.width())</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.clear"><code class="name flex">
<span>def <span class="ident">clear</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>no-op for <code><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></code> object, used only for <code><a title="vipy.video.Scene" href="#vipy.video.Scene">Scene</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L817-L819" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def clear(self):
    &#34;&#34;&#34;no-op for `vipy.video.Video` object, used only for `vipy.video.Scene`&#34;&#34;&#34;
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.clip"><code class="name flex">
<span>def <span class="ident">clip</span></span>(<span>self, startframe, endframe=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a video clip betweeen start and end frames</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1699-L1715" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def clip(self, startframe, endframe=None):
    &#34;&#34;&#34;Load a video clip betweeen start and end frames&#34;&#34;&#34;
    assert (endframe is None or startframe &lt;= endframe) and startframe &gt;= 0, &#34;Invalid start and end frames (%s, %s)&#34; % (str(startframe), str(endframe))
    if not self.isloaded():
        timestamp_in_seconds = ((self._startframe if self._startframe is not None else 0)+startframe)/float(self.framerate())            
        self._update_ffmpeg_seek(timestamp_in_seconds)
        if endframe is not None:
            self._ffmpeg = self._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 before trim filter            
            self._ffmpeg = self._ffmpeg.trim(start=0, end=(endframe-startframe)/self.framerate())  # must be in seconds to allow for framerate conversion
        self._ffmpeg = self._ffmpeg.setpts(&#39;PTS-STARTPTS&#39;)  # reset timestamp to 0 after trim filter            
        self._startframe = startframe if self._startframe is None else self._startframe + startframe  # for __repr__ only
        self._endframe = (self._startframe + (endframe-startframe)) if endframe is not None else endframe  # for __repr__ only
    else:
        endframe = endframe if endframe is not None else len(self._array)
        self._array = self._array[startframe:endframe]
        (self._startframe, self._endframe) = (0, endframe-startframe)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.cliprange"><code class="name flex">
<span>def <span class="ident">cliprange</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the planned clip (startframe, endframe) range.</p>
<p>This is useful for introspection of the planned clip() before load(), such as for data augmentation purposes without triggering a load. </p>
<div class="admonition notes">
<p class="admonition-title">Notes:&ensp;The endframe can be retrieved (inefficiently) using:</p>
</div>
<pre><code class="language-python">int(round(self.duration_in_frames_of_videofile() * (self.framerate() / self.framerate_of_videofile())))
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1717-L1733" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def cliprange(self):
    &#34;&#34;&#34;Return the planned clip (startframe, endframe) range.
    
    This is useful for introspection of the planned clip() before load(), such as for data augmentation purposes without triggering a load. 
    
    Returns:
        (startframe, endframe) of the video() such that after load(), the pixel buffer will contain frame=0 equivalent to startframe in the source video, and frame=endframe-startframe-1 equivalent to endframe in the source video.
        (0, None) If a video does not have a clip() (e.g. clip() was never called, the filter chain does not include a &#39;trim&#39;)

    .. notes:: The endframe can be retrieved (inefficiently) using:

    ```python
    int(round(self.duration_in_frames_of_videofile() * (self.framerate() / self.framerate_of_videofile())))
    ```

    &#34;&#34;&#34;
    return (self._startframe if self._startframe is not None else 0, self._endframe)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.clone"><code class="name flex">
<span>def <span class="ident">clone</span></span>(<span>self, flushforward=False, flushbackward=False, flush=False, flushfilter=False, rekey=False, flushfile=False, shallow=False, sharedarray=False, sanitize=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Create deep copy of video object, flushing the original buffer if requested and returning the cloned object.</p>
<p>Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned
object which can be used for encoding and will be garbage collected.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>flushforward</code></strong></dt>
<dd>copy the object, and set the cloned object <code><a title="vipy.video.Video.array" href="#vipy.video.Video.array">Video.array()</a></code> to None.
This flushes the video buffer for the clone, not the object</dd>
<dt><strong><code>flushbackward</code></strong></dt>
<dd>copy the object, and set the object array() to None.
This flushes the video buffer for the object, not the clone.</dd>
<dt><strong><code>flush</code></strong></dt>
<dd>set the object array() to None and clone the object.
This flushes the video buffer for both the clone and the object.</dd>
<dt><strong><code>flushfilter</code></strong></dt>
<dd>Set the ffmpeg filter chain to the default in the new object, useful for saving new videos</dd>
<dt><strong><code>flushfile</code></strong></dt>
<dd>Remove the filename and the URL from the video object.
Useful for creating new video objects from loaded pixels.
</dd>
<dt><strong><code>rekey</code></strong></dt>
<dd>Generate new unique track ID and activity ID keys for this scene</dd>
<dt><strong><code>shallow</code></strong></dt>
<dd>shallow copy everything (copy by reference), except for ffmpeg object.
attributes dictionary is shallow copied</dd>
<dt><strong><code>sharedarray</code></strong></dt>
<dd>deep copy of everything, except for pixel buffer which is shared.
Changing the pixel buffer on self is reflected in the clone.</dd>
<dt><strong><code>sanitize</code></strong></dt>
<dd>remove private attributes from self.attributes dictionary.
A private attribute is any key with two leading underscores '__' which should not be propagated to clone</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;Cloning videos is an expensive operation and can slow down real time code. Use sparingly.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2257-L2329" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def clone(self, flushforward=False, flushbackward=False, flush=False, flushfilter=False, rekey=False, flushfile=False, shallow=False, sharedarray=False, sanitize=True):
    &#34;&#34;&#34;Create deep copy of video object, flushing the original buffer if requested and returning the cloned object.

    Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned 
    object which can be used for encoding and will be garbage collected.
    
    Args:
        flushforward: copy the object, and set the cloned object `vipy.video.Video.array` to None.  This flushes the video buffer for the clone, not the object
        flushbackward:  copy the object, and set the object array() to None.  This flushes the video buffer for the object, not the clone.
        flush:  set the object array() to None and clone the object.  This flushes the video buffer for both the clone and the object.
        flushfilter:  Set the ffmpeg filter chain to the default in the new object, useful for saving new videos
        flushfile:  Remove the filename and the URL from the video object.  Useful for creating new video objects from loaded pixels.  
        rekey: Generate new unique track ID and activity ID keys for this scene
        shallow:  shallow copy everything (copy by reference), except for ffmpeg object.  attributes dictionary is shallow copied
        sharedarray:  deep copy of everything, except for pixel buffer which is shared.  Changing the pixel buffer on self is reflected in the clone.
        sanitize:  remove private attributes from self.attributes dictionary.  A private attribute is any key with two leading underscores &#39;__&#39; which should not be propagated to clone

    Returns:
        A deepcopy of the video object such that changes to self are not reflected in the copy

    .. note:: Cloning videos is an expensive operation and can slow down real time code. Use sparingly. 

    &#34;&#34;&#34;
    if sanitize:
        a = self.attributes  # copy reference to attributes to restore 
        self.attributes = {}  # remove attributes on self for fast clone() since private attributes will be filtered anyway
    if flush or (flushforward and flushbackward):
        self._array = None  # flushes buffer on object and clone
        #self._previewhash = None
        self._shape = None
        v = copy.deepcopy(self)  # object and clone are flushed
    elif flushbackward:
        v = copy.deepcopy(self)  # propagates _array to clone
        self._array = None   # object flushed, clone not flushed
        #self._previewhash = None
        self._shape = None
    elif flushforward:
        array = self._array;
        self._array = None
        #self._previewhash = None
        self._shape = None
        v = copy.deepcopy(self)   # does not propagate _array to clone
        self._array = array    # object not flushed
        v._array = None   # clone flushed
    elif shallow:
        v = copy.copy(self)  # shallow copy
        v._ffmpeg = copy.deepcopy(self._ffmpeg)  # except for ffmpeg object
        v.attributes = {k:v for (k,v) in self.attributes.items()}  # shallow copy of keys
        v._array = np.asarray(self._array) if self._array is not None else None  # shared pixels
    elif sharedarray:
        array = self._array
        self._array = None
        v = copy.deepcopy(self)  # deep copy of everything but pixels
        v._array = np.asarray(array) if array is not None else None  # shared pixels
        self._array = array # restore
    else:
        v = copy.deepcopy(self)            

    if flushfilter:
        v._ffmpeg = ffmpeg.input(v.filename())  # no other filters
        #v._previewhash = None
        v._shape = None
        (v._startframe, v._endframe) = (None, None)
        (v._startsec, v._endsec) = (None, None)
    if rekey:
        v.rekey()
    if flushfile:
        v.nofilename().nourl()
    if sanitize:
        self.attributes = a  # restore attributes            
        v.attributes = {k:v for (k,v) in self.attributes.items()}  # shallow copy
        v.sanitize()  # remove private attributes
    return v</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.colorspace"><code class="name flex">
<span>def <span class="ident">colorspace</span></span>(<span>self, colorspace=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return or set the colorspace as ['rgb', 'bgr', 'lum', 'float'].
This will not change pixels, only the colorspace interpretation of pixels.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1112-L1129" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def colorspace(self, colorspace=None):
    &#34;&#34;&#34;Return or set the colorspace as [&#39;rgb&#39;, &#39;bgr&#39;, &#39;lum&#39;, &#39;float&#39;].  This will not change pixels, only the colorspace interpretation of pixels.&#34;&#34;&#34;
    if colorspace is None:
        return self._colorspace
    elif self.isloaded():
        assert str(colorspace).lower() in [&#39;rgb&#39;, &#39;bgr&#39;, &#39;lum&#39;, &#39;float&#39;]
        if self.array().dtype == np.float32:
            assert str(colorspace).lower() in [&#39;float&#39;]
        elif self.array().dtype == np.uint8:
            assert str(colorspace).lower() in [&#39;rgb&#39;, &#39;bgr&#39;, &#39;lum&#39;]
            if str(colorspace).lower() in [&#39;lum&#39;]:
                assert self.channels() == 1, &#34;Luminance colorspace must be one channel uint8&#34;
            elif str(colorspace).lower() in [&#39;rgb&#39;, &#39;bgr&#39;]:
                assert self.channels() == 3, &#34;RGB or BGR colorspace must be three channel uint8&#34;
        else:
            raise ValueError(&#39;Invalid array() type &#34;%s&#34; - only np.float32 or np.uint8 allowed&#39; % str(self.array().dtype))
        self._colorspace = str(colorspace).lower()
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.commandline"><code class="name flex">
<span>def <span class="ident">commandline</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the equivalent ffmpeg command line string that will be used to transcode the video.</p>
<p>This is useful for introspecting the complex filter chain that will be used to process the video.
You can try to run this command line yourself for debugging purposes, by replacing 'dummyfile' with an appropriately named output file.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L877-L882" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def commandline(self):
    &#34;&#34;&#34;Return the equivalent ffmpeg command line string that will be used to transcode the video.
    
       This is useful for introspecting the complex filter chain that will be used to process the video.  You can try to run this command line yourself for debugging purposes, by replacing &#39;dummyfile&#39; with an appropriately named output file.
    &#34;&#34;&#34;        
    return self._ffmpeg_commandline()</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.crop"><code class="name flex">
<span>def <span class="ident">crop</span></span>(<span>self, bbi, zeropad=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Spatially crop the video using the supplied vipy.geometry.BoundingBox, can only be applied prior to load().</p>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;Crop is performed in place overwriting pixels of self.array().
Clone() before crop() if array() must be preserved.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1893-L1917" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def crop(self, bbi, zeropad=True):
    &#34;&#34;&#34;Spatially crop the video using the supplied vipy.geometry.BoundingBox, can only be applied prior to load().
    
    .. note:: Crop is performed in place overwriting pixels of self.array().  Clone() before crop() if array() must be preserved.
    &#34;&#34;&#34;
    assert isinstance(bbi, vipy.geometry.BoundingBox), &#34;Invalid input&#34;
    bbc = bbi.clone().imclipshape(self.width(), self.height()).int()  # clipped box to image rectangle
    bb = bbi.int() if zeropad else bbc  # use clipped box if not zeropad 

    if bb.isdegenerate():
        return None
    elif not self.isloaded():
        if zeropad and bb != bbc:
            # Crop outside the image rectangle will segfault ffmpeg, pad video first (if zeropad=False, then rangecheck will not occur!)
            self.zeropad(int(np.ceil(bb.width()-bbc.width())), int(np.ceil(bb.height()-bbc.height())))     # cannot be called in derived classes
            bb = bb.offset(int(np.ceil(bb.width()-bbc.width())), int(np.ceil(bb.height()-bbc.height())))   # Shift boundingbox by padding (integer coordinates)
        self._ffmpeg = self._ffmpeg.filter(&#39;crop&#39;, &#39;%d&#39; % bb.width(), &#39;%d&#39; % bb.height(), &#39;%d&#39; % bb.xmin(), &#39;%d&#39; % bb.ymin(), keep_aspect=0)  # keep_aspect=False (disable exact=True, this is not present in older ffmpeg)
    else:
        self.array( bbc.crop(self.array()), copy=False )  # crop first, in-place, valid pixels only
        if zeropad and bb != bbc:
            ((dyb, dya), (dxb, dxa)) = ((max(0, int(abs(np.ceil(bb.ymin() - bbc.ymin())))), max(0, int(abs(np.ceil(bb.ymax() - bbc.ymax()))))),
                                        (max(0, int(abs(np.ceil(bb.xmin() - bbc.xmin())))), max(0, int(abs(np.ceil(bb.xmax() - bbc.xmax()))))))
            self._array = np.pad(self.load().array(), ((0,0), (dyb, dya), (dxb, dxa), (0, 0)), mode=&#39;constant&#39;)
    self.shape(shape=(bb.height(), bb.width()))  # manually set shape
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.cropeven"><code class="name flex">
<span>def <span class="ident">cropeven</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Crop the video to the largest even (width,height) less than or equal to current (width,height).
This is useful for some codecs or filters which require even shape.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1838-L1840" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def cropeven(self):
    &#34;&#34;&#34;Crop the video to the largest even (width,height) less than or equal to current (width,height).  This is useful for some codecs or filters which require even shape.&#34;&#34;&#34;
    return self.crop(vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(vipy.math.even(self.width())), height=int(vipy.math.even(self.height()))))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.delattribute"><code class="name flex">
<span>def <span class="ident">delattribute</span></span>(<span>self, k)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2407-L2410" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def delattribute(self, k):
    if k in self.attributes:
        self.attributes.pop(k)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.dict"><code class="name flex">
<span>def <span class="ident">dict</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1036-L1038" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def dict(self):
    &#34;&#34;&#34;Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding.&#34;&#34;&#34;
    return self.json(encode=False)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.download"><code class="name flex">
<span>def <span class="ident">download</span></span>(<span>self, ignoreErrors=False, timeout=10, verbose=True, max_filesize='350m')</span>
</code></dt>
<dd>
<div class="desc"><p>Download URL to filename provided by constructor, or to temp filename.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>ignoreErrors</code></strong></dt>
<dd>[bool] If true, show a warning and return the video object, otherwise throw an exception</dd>
<dt><strong><code>timeout</code></strong></dt>
<dd>[int] An integer timeout in seconds for the download to connect</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>[bool] If trye, show more verbose console output</dd>
<dt><strong><code>max_filesize</code></strong></dt>
<dd>[str] A string of the form 'NNNg' or 'NNNm' for youtube downloads to limit the maximum size of a URL to '350m' 350MB or '12g' for 12GB.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>This video object with the video downloaded to the filename()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1376-L1476" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def download(self, ignoreErrors=False, timeout=10, verbose=True, max_filesize=&#39;350m&#39;):
    &#34;&#34;&#34;Download URL to filename provided by constructor, or to temp filename.
    
    Args:
        ignoreErrors: [bool] If true, show a warning and return the video object, otherwise throw an exception
        timeout: [int] An integer timeout in seconds for the download to connect
        verbose: [bool] If trye, show more verbose console output
        max_filesize: [str] A string of the form &#39;NNNg&#39; or &#39;NNNm&#39; for youtube downloads to limit the maximum size of a URL to &#39;350m&#39; 350MB or &#39;12g&#39; for 12GB.

    Returns:
        This video object with the video downloaded to the filename()        
    &#34;&#34;&#34;
    if self._url is None and self._filename is not None:
        return self
    if self._url is None:
        raise ValueError(&#39;[vipy.video.download]: No URL to download&#39;)
    elif not isurl(str(self._url)):
        raise ValueError(&#39;[vipy.video.download]: Invalid URL &#34;%s&#34; &#39; % self._url)

    try:
        url_scheme = urllib.parse.urlparse(self._url)[0]
        if isyoutubeurl(self._url):
            f = self._filename if filefull(self._filename) is None else filefull(self._filename)
            vipy.videosearch.download(self._url, f, writeurlfile=False, skip=ignoreErrors, verbose=verbose, max_filesize=max_filesize)
            for ext in [&#39;mkv&#39;, &#39;mp4&#39;, &#39;webm&#39;]:
                f = &#39;%s.%s&#39; % (self.filename(), ext)
                if os.path.exists(f):
                    self.filename(f)  # change the filename to match the youtube extension
                    break    
            if not self.hasfilename():
                raise ValueError(&#39;Downloaded file not found &#34;%s.*&#34;&#39; % self.filename())
        
        elif url_scheme in [&#39;http&#39;, &#39;https&#39;] and (isvideourl(self._url) or iswebp(self._url)):
            vipy.downloader.download(self._url,
                                     self._filename,
                                     verbose=verbose,
                                     timeout=timeout,
                                     sha1=None,
                                     username=None,
                                     password=None)
                            
        elif url_scheme == &#39;file&#39;:
            shutil.copyfile(self._url, self._filename)
        elif url_scheme == &#39;s3&#39;:
            if self.filename() is None:
                self.filename(totempdir(self._url))
                if vipy.globals.cache() is not None:
                    self.filename(os.path.join(remkdir(vipy.globals.cache()), filetail(self._url)))
            vipy.downloader.s3(self.url(), self.filename(), verbose=verbose)
                
        elif url_scheme == &#39;scp&#39;:                
            if self.filename() is None:
                self.filename(templike(self._url))                    
                if vipy.globals.cache() is not None:
                    self.filename(os.path.join(remkdir(vipy.globals.cache()), filetail(self._url)))
            vipy.downloader.scp(self._url, self.filename(), verbose=verbose)

        elif not isvideourl(self._url) and vipy.videosearch.is_downloadable_url(self._url):
            vipy.videosearch.download(self._url, filefull(self._filename), writeurlfile=False, skip=ignoreErrors, verbose=verbose, max_filesize=max_filesize)
            for ext in [&#39;mkv&#39;, &#39;mp4&#39;, &#39;webm&#39;]:
                f = &#39;%s.%s&#39; % (self.filename(), ext)
                if os.path.exists(f):
                    self.filename(f)
                    break    
            if not self.hasfilename():
                raise ValueError(&#39;Downloaded filenot found &#34;%s.*&#34;&#39; % self.filename())

        elif url_scheme == &#39;rtsp&#39;:
            # https://ffmpeg.org/ffmpeg-protocols.html#rtsp
            pass

        else:
            raise NotImplementedError(
                &#39;Invalid URL scheme &#34;%s&#34; for URL &#34;%s&#34;&#39; %
                (url_scheme, self._url))

    except (httplib.BadStatusLine,
            urllib.error.URLError,
            urllib.error.HTTPError):
        if ignoreErrors:
            warnings.warn(&#39;[vipy.video][WARNING]: download failed - Ignoring Video&#39;)
            self._array = None
        else:
            raise

    except IOError:
        if ignoreErrors:
            warnings.warn(&#39;[vipy.video][WARNING]: IO error - Invalid video file, url or invalid write permissions &#34;%s&#34; - Ignoring video&#39; % self.filename())
            self._array = None
        else:
            raise

    except KeyboardInterrupt:
        raise

    except Exception:
        if ignoreErrors:
            warnings.warn(&#39;[vipy.video][WARNING]: load error for video &#34;%s&#34;&#39; % self.filename())
        else:
            raise
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.downloadif"><code class="name flex">
<span>def <span class="ident">downloadif</span></span>(<span>self, ignoreErrors=False, timeout=10, verbose=True, max_filesize='350m')</span>
</code></dt>
<dd>
<div class="desc"><p>Download URL to filename if the filename has not already been downloaded</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1372-L1374" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def downloadif(self, ignoreErrors=False, timeout=10, verbose=True, max_filesize=&#39;350m&#39;):
    &#34;&#34;&#34;Download URL to filename if the filename has not already been downloaded&#34;&#34;&#34;
    return self.download(ignoreErrors=ignoreErrors, timeout=timeout, verbose=verbose, max_filesize=max_filesize) if self.hasurl() and not self.isdownloaded() else self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.duration"><code class="name flex">
<span>def <span class="ident">duration</span></span>(<span>self, frames=None, seconds=None, minutes=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a video clipped with frame indexes between (0, frames) or (0,seconds<em>self.framerate()) or (0,minutes</em>60*self.framerate().
Return duration in seconds if no arguments are provided.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L976-L982" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def duration(self, frames=None, seconds=None, minutes=None):
    &#34;&#34;&#34;Return a video clipped with frame indexes between (0, frames) or (0,seconds*self.framerate()) or (0,minutes*60*self.framerate().  Return duration in seconds if no arguments are provided.&#34;&#34;&#34;
    if frames is None and seconds is None and minutes is None:
        return self.duration_in_seconds_of_videofile() if not self.isloaded() else (len(self) / self.framerate())
    assert frames is not None or seconds is not None or minutes is not None
    frames = frames if frames is not None else ((int(seconds*self.framerate()) if seconds is not None else 0) + (int(minutes*60*self.framerate()) if minutes is not None else 0))
    return self.clip(0, frames)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.duration_in_frames"><code class="name flex">
<span>def <span class="ident">duration_in_frames</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the duration of the video filter chain in frames, equal to round(self.duration()*self.framerate()).
Requires a probe() of the video to get duration</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L984-L986" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def duration_in_frames(self):
    &#34;&#34;&#34;Return the duration of the video filter chain in frames, equal to round(self.duration()*self.framerate()).  Requires a probe() of the video to get duration&#34;&#34;&#34;
    return int(round(self.duration()*self.framerate()))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.duration_in_frames_of_videofile"><code class="name flex">
<span>def <span class="ident">duration_in_frames_of_videofile</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return video duration of the source video file (NOT the filter chain) in frames, requires ffprobe.</p>
<div class="admonition notes">
<p class="admonition-title">Notes:&ensp;This is the duration of the source video and NOT the duration of the filter chain.
If you load(), this may be different duration depending on clip() or framerate() directives.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L969-L974" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def duration_in_frames_of_videofile(self):
    &#34;&#34;&#34;Return video duration of the source video file (NOT the filter chain) in frames, requires ffprobe.

    .. notes:: This is the duration of the source video and NOT the duration of the filter chain.  If you load(), this may be different duration depending on clip() or framerate() directives.
    &#34;&#34;&#34;
    return int(np.floor(self.duration_in_seconds_of_videofile()*self.framerate_of_videofile()))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.duration_in_seconds_of_videofile"><code class="name flex">
<span>def <span class="ident">duration_in_seconds_of_videofile</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return video duration of the source filename (NOT the filter chain) in seconds, requires ffprobe.
Fetch once and cache.</p>
<div class="admonition notes">
<p class="admonition-title">Notes:&ensp;This is the duration of the source video and NOT the duration of the filter chain.
If you load(), this may be different duration depending on clip() or framerate() directives.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L956-L967" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def duration_in_seconds_of_videofile(self):
    &#34;&#34;&#34;Return video duration of the source filename (NOT the filter chain) in seconds, requires ffprobe.  Fetch once and cache.
    
    .. notes:: This is the duration of the source video and NOT the duration of the filter chain.  If you load(), this may be different duration depending on clip() or framerate() directives.
    &#34;&#34;&#34;
    filehash = hashlib.md5(str(self.downloadif().filename()).encode()).hexdigest()            
    if self.hasattribute(&#39;_duration_in_seconds_of_videofile&#39;) and self.attributes[&#39;__duration_in_seconds_of_videofile&#39;][&#39;filehash&#39;] == filehash:
        return self.attributes[&#39;__duration_in_seconds_of_videofile&#39;][&#39;duration&#39;]
    else:
        d = float(self.probe()[&#39;format&#39;][&#39;duration&#39;])
        self.attributes[&#39;__duration_in_seconds_of_videofile&#39;] = {&#39;duration&#39;:d, &#39;filehash&#39;:filehash}  # for next time, private attribute
        return d</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.fetch"><code class="name flex">
<span>def <span class="ident">fetch</span></span>(<span>self, ignoreErrors=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Download only if hasfilename() is not found</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1478-L1480" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def fetch(self, ignoreErrors=False):
    &#34;&#34;&#34;Download only if hasfilename() is not found&#34;&#34;&#34;
    return self.download(ignoreErrors=ignoreErrors) if not self.hasfilename() else self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.ffplay"><code class="name flex">
<span>def <span class="ident">ffplay</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Play the video file using ffplay</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2059-L2065" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def ffplay(self):
    &#34;&#34;&#34;Play the video file using ffplay&#34;&#34;&#34;
    assert self.hasfilename() or (self.hasurl() and self.download().hasfilename())  # triggers download if needed
    cmd = &#39;ffplay &#34;%s&#34;&#39; % self.filename()
    print(&#39;[vipy.video.play]: Executing &#34;%s&#34;&#39; % cmd)
    os.system(cmd)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.filename"><code class="name flex">
<span>def <span class="ident">filename</span></span>(<span>self, newfile=None, copy=False, symlink=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Update video Filename with optional copy or symlink from existing file (self.filename()) to new file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1304-L1327" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def filename(self, newfile=None, copy=False, symlink=False):
    &#34;&#34;&#34;Update video Filename with optional copy or symlink from existing file (self.filename()) to new file&#34;&#34;&#34;
    if newfile is None:
        return self._filename
    newfile = os.path.normpath(os.path.expanduser(newfile))

    # Copy or symlink from the old filename to the new filename (if requested)
    if copy:
        assert self.hasfilename(), &#34;File not found for copy&#34;
        remkdir(filepath(newfile))
        shutil.copyfile(self._filename, newfile)
    elif symlink:
        assert self.hasfilename(), &#34;File not found for symlink&#34;
        remkdir(filepath(newfile))
        if os.path.islink(newfile) and os.path.abspath(os.readlink(newfile)) == os.path.normpath(os.path.abspath(os.path.expanduser(self.filename()))):
            pass  # already points to the same place, nothing to do
        else:
            os.symlink(self._filename, newfile)                    
                
    # Update ffmpeg filter chain with new input node filename (this file may not exist yet)
    self._update_ffmpeg(&#39;filename&#39;, newfile)
    self._filename = newfile
    
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.filesize"><code class="name flex">
<span>def <span class="ident">filesize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the size in bytes of the filename(), None if the filename() is invalid</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1368-L1370" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def filesize(self):
    &#34;&#34;&#34;Return the size in bytes of the filename(), None if the filename() is invalid&#34;&#34;&#34;
    return os.path.getsize(self.filename()) if self.hasfilename() else None</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.fliplr"><code class="name flex">
<span>def <span class="ident">fliplr</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Mirror the video left/right by flipping horizontally</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1759-L1765" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def fliplr(self):
    &#34;&#34;&#34;Mirror the video left/right by flipping horizontally&#34;&#34;&#34;
    if not self.isloaded():
        self._ffmpeg = self._ffmpeg.filter(&#39;hflip&#39;)
    else:
        self.array(np.stack([np.fliplr(f) for f in self._array]), copy=False)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.flipud"><code class="name flex">
<span>def <span class="ident">flipud</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1767-L1771" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def flipud(self):
    &#34;&#34;&#34;Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()&#34;&#34;&#34;        
    assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
    self._ffmpeg = self._ffmpeg.filter(&#39;vflip&#39;)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.float"><code class="name flex">
<span>def <span class="ident">float</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2373-L2376" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def float(self):
    self.load()
    self._array = self._array.astype(np.float32) if self._array is not None else self._array
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.flush"><code class="name flex">
<span>def <span class="ident">flush</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for clone(flush=True), returns self not clone</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2331-L2336" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def flush(self):
    &#34;&#34;&#34;Alias for clone(flush=True), returns self not clone&#34;&#34;&#34;
    self._array = None  # flushes buffer on object and clone
    #self._previewhash = None
    self._shape = None
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.flush_and_return"><code class="name flex">
<span>def <span class="ident">flush_and_return</span></span>(<span>self, retval)</span>
</code></dt>
<dd>
<div class="desc"><p>Flush the video and return the parameter supplied, useful for long fluent chains</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2342-L2345" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def flush_and_return(self, retval):
    &#34;&#34;&#34;Flush the video and return the parameter supplied, useful for long fluent chains&#34;&#34;&#34;
    self.flush()
    return retval</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.frame"><code class="name flex">
<span>def <span class="ident">frame</span></span>(<span>self, k=0, img=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the kth frame as an <code><a title="vipy.image" href="image.html">vipy.image</a> Image</code> object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L655-L658" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def frame(self, k=0, img=None):
    &#34;&#34;&#34;Return the kth frame as an `vipy.image Image` object&#34;&#34;&#34;        
    assert isinstance(k, int) and k&gt;=0, &#34;Frame index must be non-negative integer&#34;
    return Image(array=img if img is not None else (self._array[k] if self.isloaded() else self.preview(k).array()), colorspace=self.colorspace())       </code></pre>
</details>
</dd>
<dt id="vipy.video.Video.framelist"><code class="name flex">
<span>def <span class="ident">framelist</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L832-L833" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def framelist(self):
    return list(self.frames())</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.framerate"><code class="name flex">
<span>def <span class="ident">framerate</span></span>(<span>self, fps=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Change the input framerate for the video and update frame indexes for all annotations</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fps</code></strong></dt>
<dd>[Float] frames per second to process the underlying video</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>If fps is None, return the current framerate, otherwise set the framerate to fps</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1083-L1110" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def framerate(self, fps=None):
    &#34;&#34;&#34;Change the input framerate for the video and update frame indexes for all annotations

    Args:
        fps: [Float] frames per second to process the underlying video

    Returns:
        If fps is None, return the current framerate, otherwise set the framerate to fps

    &#34;&#34;&#34;
    if fps is None:
        return self._framerate
    elif float(fps) == self._framerate:
        return self
    else:            
        assert not self.isloaded(), &#34;Filters can only be applied prior to load()&#34;
        if &#39;fps=&#39; in self._ffmpeg_commandline():
            self._update_ffmpeg(&#39;fps&#39;, float(fps))  # replace fps filter, do not add to it
        else:
            self._ffmpeg = self._ffmpeg.filter(&#39;fps&#39;, fps=float(fps), round=&#39;up&#39;)  # create fps filter first time
    
        # if &#39;-ss&#39; in self._ffmpeg_commandline():
        #     No change is needed here.  The seek is in seconds and is independent of the framerate
        # if &#39;trim&#39; in self._ffmpeg_commandline():
        #     No change is needed here.  The trim is in units of seconds which is independent of the framerate

        self._framerate = float(fps)
        return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.framerate_of_videofile"><code class="name flex">
<span>def <span class="ident">framerate_of_videofile</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return video framerate in frames per second of the source video file (NOT the filter chain), requires ffprobe.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L988-L994" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def framerate_of_videofile(self):
    &#34;&#34;&#34;Return video framerate in frames per second of the source video file (NOT the filter chain), requires ffprobe.
    &#34;&#34;&#34;
    p = self.probe()        
    assert &#39;streams&#39; in p and len([&#39;streams&#39;]) &gt; 0
    fps = p[&#39;streams&#39;][0][&#39;avg_frame_rate&#39;]
    return float(fps) if &#39;/&#39; not in fps else (float(fps.split(&#39;/&#39;)[0]) / float(fps.split(&#39;/&#39;)[1]))  # fps=&#39;30/1&#39; or fps=&#39;30.0&#39;</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.frames"><code class="name flex">
<span>def <span class="ident">frames</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for <strong>iter</strong>()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L828-L830" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def frames(self):
    &#34;&#34;&#34;Alias for __iter__()&#34;&#34;&#34;
    return self.__iter__()</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.fromarray"><code class="name flex">
<span>def <span class="ident">fromarray</span></span>(<span>self, array)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for self.array(&hellip;, copy=True), which forces the new array to be a copy</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1246-L1248" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def fromarray(self, array):
    &#34;&#34;&#34;Alias for self.array(..., copy=True), which forces the new array to be a copy&#34;&#34;&#34;
    return self.array(array, copy=True)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.fromdirectory"><code class="name flex">
<span>def <span class="ident">fromdirectory</span></span>(<span>self, indir, sortkey=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a video from a directory of frames stored as individual image filenames.</p>
<p>Given a directory with files:</p>
<p>framedir/image_0001.jpg
framedir/image_0002.jpg</p>
<pre><code class="language-python">vipy.video.Video(frames='/path/to/framedir')
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1250-L1263" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def fromdirectory(self, indir, sortkey=None):
    &#34;&#34;&#34;Create a video from a directory of frames stored as individual image filenames.
    
    Given a directory with files:
    
    framedir/image_0001.jpg
    framedir/image_0002.jpg
    
    ```python
    vipy.video.Video(frames=&#39;/path/to/framedir&#39;)
    ```

    &#34;&#34;&#34;
    return self.fromframes([vipy.image.Image(filename=f) for f in sorted(vipy.util.imlist(indir), key=sortkey)])</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.fromframes"><code class="name flex">
<span>def <span class="ident">fromframes</span></span>(<span>self, framelist, copy=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a video from a list of frames</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1265-L1268" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def fromframes(self, framelist, copy=True):
    &#34;&#34;&#34;Create a video from a list of frames&#34;&#34;&#34;
    assert all([isinstance(im, vipy.image.Image) for im in framelist]), &#34;Invalid input&#34;
    return self.array(np.stack([im.load().array() if im.load().array().ndim == 3 else np.expand_dims(im.load().array(), 2) for im in framelist]), copy=copy).colorspace(framelist[0].colorspace())</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.gain"><code class="name flex">
<span>def <span class="ident">gain</span></span>(<span>self, g)</span>
</code></dt>
<dd>
<div class="desc"><p>Pixelwise multiplicative gain, such that each pixel p_{ij} = g * p_{ij}</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2365-L2367" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def gain(self, g):
    &#34;&#34;&#34;Pixelwise multiplicative gain, such that each pixel p_{ij} = g * p_{ij}&#34;&#34;&#34;
    return self.normalize(0, 1, scale=g)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.getattribute"><code class="name flex">
<span>def <span class="ident">getattribute</span></span>(<span>self, k)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2412-L2413" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def getattribute(self, k):
    return self.attributes[k]</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.gif"><code class="name flex">
<span>def <span class="ident">gif</span></span>(<span>self, outfile, pause=3, smallest=False, smaller=False, framerate=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Save a video to an animated GIF file, with pause=N seconds between loops.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>pause</code></strong></dt>
<dd>Integer seconds to pause between loops of the animation</dd>
<dt><strong><code>smallest</code></strong></dt>
<dd>If true, create the smallest possible file but takes much longer to run</dd>
<dt><strong><code>smaller</code></strong></dt>
<dd>if trye, create a smaller file, which takes a little longer to run </dd>
</dl>
<p>framerate [float]:
The output framerate of the webp file.
The default is the framerate of the video. </p>
<div class="admonition warning">
<p class="admonition-title">Warning:&ensp;This will be very large for big videos, consider using <code><a title="vipy.video.Video.webp" href="#vipy.video.Video.webp">Video.webp()</a></code> instead.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1955-L1970" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def gif(self, outfile, pause=3, smallest=False, smaller=False, framerate=None):
    &#34;&#34;&#34;Save a video to an animated GIF file, with pause=N seconds between loops.  

    Args:
        pause: Integer seconds to pause between loops of the animation
        smallest:  If true, create the smallest possible file but takes much longer to run
        smaller:  if trye, create a smaller file, which takes a little longer to run 
        framerate [float]:  The output framerate of the webp file.  The default is the framerate of the video. 

    Returns:
        The filename of the animated GIF of this video

    .. warning::  This will be very large for big videos, consider using `vipy.video.Video.webp` instead.
    &#34;&#34;&#34;        
    assert isgif(outfile)
    return self.webp(outfile, pause, strict=False, smallest=smallest, smaller=True, framerate=framerate)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.hasattribute"><code class="name flex">
<span>def <span class="ident">hasattribute</span></span>(<span>self, k)</span>
</code></dt>
<dd>
<div class="desc"><p>Does the attributes dictionary (self.attributes) contain the provided key</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2403-L2405" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def hasattribute(self, k):
    &#34;&#34;&#34;Does the attributes dictionary (self.attributes) contain the provided key&#34;&#34;&#34;
    return isinstance(self.attributes, dict) and k in self.attributes</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.hasfilename"><code class="name flex">
<span>def <span class="ident">hasfilename</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Does the filename returned from <code><a title="vipy.video.Video.filename" href="#vipy.video.Video.filename">Video.filename()</a></code> exist?</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1207-L1209" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def hasfilename(self):
    &#34;&#34;&#34;Does the filename returned from `vipy.video.Video.filename` exist?&#34;&#34;&#34;
    return self._filename is not None and (os.path.exists(self._filename) or isRTSPurl(self._filename) or isRTMPurl(self._filename))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.hasurl"><code class="name flex">
<span>def <span class="ident">hasurl</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Is the url returned from <code><a title="vipy.video.Video.url" href="#vipy.video.Video.url">Video.url()</a></code> a well formed url?</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1215-L1217" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def hasurl(self):
    &#34;&#34;&#34;Is the url returned from `vipy.video.Video.url` a well formed url?&#34;&#34;&#34;
    return self._url is not None and isurl(self._url)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.height"><code class="name flex">
<span>def <span class="ident">height</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Height (rows) in pixels of the video for the current filter chain</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1536-L1538" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def height(self):
    &#34;&#34;&#34;Height (rows) in pixels of the video for the current filter chain&#34;&#34;&#34;
    return self.shape()[0]</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.iscolor"><code class="name flex">
<span>def <span class="ident">iscolor</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Is the video a three channel color video as returned from <code><a title="vipy.video.Video.channels" href="#vipy.video.Video.channels">Video.channels()</a></code>?</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1199-L1201" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def iscolor(self):
    &#34;&#34;&#34;Is the video a three channel color video as returned from `vipy.video.Video.channels`?&#34;&#34;&#34;
    return self.channels() == 3</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.isdownloaded"><code class="name flex">
<span>def <span class="ident">isdownloaded</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Does the filename returned from <code><a title="vipy.video.Video.filename" href="#vipy.video.Video.filename">Video.filename()</a></code> exist, meaning that the url has been downloaded to a local file?</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1211-L1213" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def isdownloaded(self):
    &#34;&#34;&#34;Does the filename returned from `vipy.video.Video.filename` exist, meaning that the url has been downloaded to a local file?&#34;&#34;&#34;
    return self._filename is not None and os.path.exists(self._filename)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.isgrayscale"><code class="name flex">
<span>def <span class="ident">isgrayscale</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Is the video a single channel as returned from <code><a title="vipy.video.Video.channels" href="#vipy.video.Video.channels">Video.channels()</a></code>?</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1203-L1205" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def isgrayscale(self):
    &#34;&#34;&#34;Is the video a single channel as returned from `vipy.video.Video.channels`?&#34;&#34;&#34;
    return self.channels() == 1</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.islive"><code class="name flex">
<span>def <span class="ident">islive</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1219-L1220" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def islive(self):
    return self.hasurl() and (isRTSPurl(self._url) or isRTMPurl(self._url))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.isloadable"><code class="name flex">
<span>def <span class="ident">isloadable</span></span>(<span>self, flush=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Return True if the video can be loaded successfully.</p>
<p>This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>flush</code></strong></dt>
<dd>[bool] If true, flush the video after it loads.
This will clear the video pixel buffer</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning:&ensp;This requires loading and flushing the video.
This is an expensive operation when performed on many videos and may result in out of memory conditions with long videos.
Use with caution!
Try <code><a title="vipy.video.Video.canload" href="#vipy.video.Video.canload">Video.canload()</a></code> to test if a single frame can be loaded as a less expensive alternative.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1157-L1180" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def isloadable(self, flush=True):
    &#34;&#34;&#34;Return True if the video can be loaded successfully.
    
    This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.
    
    Args:
        flush: [bool] If true, flush the video after it loads.  This will clear the video pixel buffer

    Returns:
        True if load() can be called without FFMPEG exception.  
        If flush=False, then self will contain the loaded video, which is helpful to avoid load() twice in some conditions
    
    .. warning:: This requires loading and flushing the video.  This is an expensive operation when performed on many videos and may result in out of memory conditions with long videos.  Use with caution!  Try `vipy.video.Video.canload` to test if a single frame can be loaded as a less expensive alternative.
    &#34;&#34;&#34;
    if not self.isloaded():
        try:
            self.load()  # try to load the whole thing
            if flush:
                self.flush()
            return True
        except:
            return False
    else:
        return True</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.isloaded"><code class="name flex">
<span>def <span class="ident">isloaded</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return True if the video has been loaded</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1153-L1155" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def isloaded(self):
    &#34;&#34;&#34;Return True if the video has been loaded&#34;&#34;&#34;
    return self._array is not None</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.issquare"><code class="name flex">
<span>def <span class="ident">issquare</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return true if the video has square dimensions (height == width), else false</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1511-L1514" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def issquare(self):
    &#34;&#34;&#34;Return true if the video has square dimensions (height == width), else false&#34;&#34;&#34;
    s = self.shape()
    return s[0] == s[1]</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.json"><code class="name flex">
<span>def <span class="ident">json</span></span>(<span>self, encode=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a json representation of the video.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>encode</code></strong></dt>
<dd>If true, return a JSON encoded string using json.dumps</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;If the video is loaded, then the JSON will not include the pixels.
Try using <code><a title="vipy.video.Video.store" href="#vipy.video.Video.store">Video.store()</a></code> to serialize videos, or call <code><a title="vipy.video.Video.flush" href="#vipy.video.Video.flush">Video.flush()</a></code> first.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1040-L1065" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def json(self, encode=True):
    &#34;&#34;&#34;Return a json representation of the video.
    
    Args:
        encode: If true, return a JSON encoded string using json.dumps
    
    Returns:
        A JSON encoded string if encode=True, else returns a dictionary object 

    .. note::  If the video is loaded, then the JSON will not include the pixels.  Try using `vipy.video.Video.store` to serialize videos, or call `vipy.video.Video.flush` first.
    &#34;&#34;&#34;
    
    if self.isloaded():
        warnings.warn(&#34;JSON serialization of video requires flushed buffers, will not include the loaded video.  Try store()/restore()/unstore() instead to serialize videos as standalone objects efficiently, or flush() any loaded videos prior to serialization to quiet this warning.&#34;)
    d = {&#39;_filename&#39;:self._filename,
         &#39;_url&#39;:self._url,
         &#39;_framerate&#39;:self._framerate,
         &#39;_array&#39;:None,
         &#39;_colorspace&#39;:self._colorspace,
         &#39;attributes&#39;:self.attributes,
         &#39;_startframe&#39;:self._startframe,
         &#39;_endframe&#39;:self._endframe,
         &#39;_endsec&#39;:self._endsec,
         &#39;_startsec&#39;:self._startsec,
         &#39;_ffmpeg&#39;:self._ffmpeg_commandline()}
    return json.dumps(d) if encode else d</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>self, verbose=False, ignoreErrors=False, shape=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a video using ffmpeg, applying the requested filter chain.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>verbose</code></strong></dt>
<dd>[bool] if True. then ffmpeg console output will be displayed. </dd>
<dt><strong><code>ignoreErrors</code></strong></dt>
<dd>[bool] if True, then all load errors are warned and skipped.
Be sure to call isloaded() to confirm loading was successful.</dd>
<dt><strong><code>shape</code></strong></dt>
<dd>[tuple (height, width, channels)]
If provided, use this shape for reading and reshaping the byte stream from ffmpeg.
This is useful for efficient loading in some scenarios. Knowing the final output shape can speed up loads by avoiding a preview() of the filter chain to get the frame size</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning:&ensp;Loading long videos can result in out of memory conditions.
Try to call clip() first to extract a video segment to load().</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1599-L1691" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def load(self, verbose=False, ignoreErrors=False, shape=None):
    &#34;&#34;&#34;Load a video using ffmpeg, applying the requested filter chain.  
       
    Args:
        verbose: [bool] if True. then ffmpeg console output will be displayed. 
        ignoreErrors: [bool] if True, then all load errors are warned and skipped.  Be sure to call isloaded() to confirm loading was successful.
        shape: [tuple (height, width, channels)]  If provided, use this shape for reading and reshaping the byte stream from ffmpeg.  This is useful for efficient loading in some scenarios. Knowing the final output shape can speed up loads by avoiding a preview() of the filter chain to get the frame size

    Returns:
        this video object, with the pixels loaded in self.array()

    .. warning:: Loading long videos can result in out of memory conditions.  Try to call clip() first to extract a video segment to load().
    &#34;&#34;&#34;
    if self.isloaded():
        return self
    elif not self.hasfilename() and self.hasurl():
        self.download(ignoreErrors=ignoreErrors)
    elif not self.hasfilename() and not ignoreErrors:
        raise ValueError(&#39;Invalid input - load() requires a valid URL, filename or array&#39;)
    if not self.hasfilename() and ignoreErrors:
        print(&#39;[vipy.video.load]: Video file &#34;%s&#34; not found - Ignoring&#39; % self.filename())
        return self
    if iswebp(self.filename()) or isgif(self.filename()):
        frames = []
        pil = PIL.Image.open(self.filename())
        self._framerate = (1000.0 / pil.info[&#39;duration&#39;]) if &#39;duration&#39; in pil.info else self._framerate
        for k in range(pil.n_frames):
            pil.seek(k)
            frames.append(np.array(pil.convert(&#39;RGB&#39;)))
        return self.array(np.stack(frames)).colorspace(&#39;RGB&#39;)
                    
    # Load the video with ffmpeg
    # 
    # [EXCEPTION]:  older ffmpeg versions may segfault on complex crop filter chains
    #    -On some versions of ffmpeg setting -cpuflags=0 fixes it, but the right solution is to rebuild from the head (30APR20)
    if verbose:
        print(&#39;[vipy.video.load]: Loading &#34;%s&#34;&#39; % self.filename())                    
    try:
        
        f_prepipe = copy.deepcopy(self._ffmpeg)
        f = self._ffmpeg.output(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;)\
                        .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;debug&#39; if vipy.globals.isdebug() else &#39;quiet&#39;)
        (out, err) = f.run(capture_stdout=True, capture_stderr=True)
    except Exception as e:
        if not ignoreErrors:
            raise ValueError(&#39;[vipy.video.load]: Load failed with error &#34;%s&#34;\n\n  - Video: &#34;%s&#34;\n  - FFMPEG command: \&#39;sh&gt; %s\&#39;\n  - This error usually means that the video is corrupted or that you need to upgrade your FFMPEG distribution to the latest stable version.\n  - Try running the output of the ffmpeg command for debugging.&#39; % (str(e), str(self), str(self._ffmpeg_commandline(f_prepipe.output(&#39;preview.mp4&#39;)))))
        else:
            return self  # Failed, return immediately, useful for calling canload() 

    # Video shape:
    #   - due to complex filter chains, we may not know the final video size without executing it
    #   - However, this introduces extra cost by calling preview() on each filter chain
    #   - If we know what the shape will be (e.g. we made the video square with a known size), then use it here directly
    (height, width, channels) = (self.height(), self.width(), self.channels()) if shape is None else shape
    
    # [EXCEPTION]:  older ffmpeg versions may be off by one on the size returned from self.preview() which uses an image decoder vs. f.run() which uses a video decoder
    #    -Try to correct this manually by searching for a off-by-one-pixel decoding that works.  The right way is to upgrade your FFMPEG version to the FFMPEG head (11JUN20)
    #    -We cannot tell which is the one that the end-user wanted, so we leave it up to the calling function to check dimensions (see self.resize())
    if (len(out) % (height*width*channels)) != 0:
        #warnings.warn(&#39;Your FFMPEG version is triggering a known bug that is being worked around in an inefficient manner.  Consider upgrading your FFMPEG distribution.&#39;)
        if (len(out) % ((height-1)*(width-1)*channels) == 0):
            (newwidth, newheight) = (width-1, height-1)
        elif (len(out) % ((height-1)*(width)*channels) == 0):
            (newwidth, newheight) = (width, height-1)
        elif (len(out) % ((height-1)*(width+1)*channels) == 0):
            (newwidth, newheight) = (width+1, height-1)
        elif (len(out) % ((height)*(width-1)*channels) == 0):
            (newwidth, newheight) = (width-1, height)
        elif (len(out) % ((height)*(width+1)*channels) == 0):
            (newwidth, newheight) = (width+1, height)
        elif (len(out) % ((height+1)*(width-1)*channels) == 0):
            (newwidth, newheight) = (width-1, height+1)
        elif (len(out) % ((height+1)*(width)*channels) == 0):
            (newwidth, newheight) = (width, height+1)
        elif (len(out) % ((height+1)*(width+1)*channels) == 0):
            (newwidth, newheight) = (width+1, height+1)
        else:
            (newwidth, newheight) = (width, height)

        is_loadable = (len(out) % (newheight*newwidth*channels)) == 0

        if not is_loadable:
            im = self.preview()  # get the real shape...
            (newheight, newwidth, newchannels) = (im.height(), im.width(), im.channels()) 
                    
        assert is_loadable or ignoreErrors, &#34;Load failed for video &#39;%s&#39;, and FFMPEG command line: &#39;%s&#39;&#34; % (str(self), str(self._ffmpeg_commandline(f)))
        self._array = np.frombuffer(out, np.uint8).reshape([-1, newheight, newwidth, channels]) if is_loadable else None  # read-only                        
        self.colorspace(&#39;rgb&#39; if channels == 3 else &#39;lum&#39;)
        self.resize(rows=height, cols=width)  # Very expensive framewise resizing so that the loaded video is identical shape to preview
    else:
        self._array = np.frombuffer(out, np.uint8).reshape([-1, height, width, channels])  # read-only            
        self.colorspace(&#39;rgb&#39; if channels == 3 else &#39;lum&#39;)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.map"><code class="name flex">
<span>def <span class="ident">map</span></span>(<span>self, func)</span>
</code></dt>
<dd>
<div class="desc"><p>Apply lambda function to the loaded numpy array img, changes pixels not shape</p>
<p>Lambda function must have the following signature:
* newimg = func(img)
* img: HxWxC numpy array for a single frame of video
* newimg:
HxWxC modified numpy array for this frame.
Change only the pixels, not the shape</p>
<p>The lambda function will be applied to every frame in the video in frame index order.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2347-L2363" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def map(self, func):
    &#34;&#34;&#34;Apply lambda function to the loaded numpy array img, changes pixels not shape
    
    Lambda function must have the following signature:
        * newimg = func(img)
        * img: HxWxC numpy array for a single frame of video
        * newimg:  HxWxC modified numpy array for this frame.  Change only the pixels, not the shape

    The lambda function will be applied to every frame in the video in frame index order.
    &#34;&#34;&#34;
    assert isinstance(func, types.LambdaType), &#34;Input must be lambda function with np.array() input and np.array() output&#34;
    oldimgs = self.load().array()
    self.array(np.apply_along_axis(func, 0, self._array))   # FIXME: in-place operation?
    if (any([oldimg.dtype != newimg.dtype for (oldimg, newimg) in zip(oldimgs, self.array())]) or
        any([oldimg.shape != newimg.shape for (oldimg, newimg) in zip(oldimgs, self.array())])):            
        self.colorspace(&#39;float&#39;)  # unknown colorspace after shape or type transformation, set generic
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.maxdim"><code class="name flex">
<span>def <span class="ident">maxdim</span></span>(<span>self, dim=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1813-L1817" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def maxdim(self, dim=None):
    &#34;&#34;&#34;Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
    assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
    (H,W) = self.shape()  # yuck, need to get image dimensions before filter
    return max(H,W) if dim is None else (self.resize(cols=dim) if W&gt;H else self.resize(rows=dim))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.maxmatte"><code class="name flex">
<span>def <span class="ident">maxmatte</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a square video with dimensions (self.maxdim(), self.maxdim()) with zeropadded lack bars or mattes above or below the video forming a letterboxed video.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1862-L1864" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def maxmatte(self):
    &#34;&#34;&#34;Return a square video with dimensions (self.maxdim(), self.maxdim()) with zeropadded lack bars or mattes above or below the video forming a letterboxed video.&#34;&#34;&#34;
    return self.zeropad(max(1, int((max(self.shape()) - self.width())/2)), max(int((max(self.shape()) - self.height())/2), 1)).maxsquare()</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.maxsquare"><code class="name flex">
<span>def <span class="ident">maxsquare</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Pad the video to be square, preserving the upper left corner of the video</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1842-L1854" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def maxsquare(self):
    &#34;&#34;&#34;Pad the video to be square, preserving the upper left corner of the video&#34;&#34;&#34;
    # This ffmpeg filter can throw the error:  &#34;Padded dimensions cannot be smaller than input dimensions.&#34; since the preview is off by one.  Add one here to make sure.
    # FIXME: not sure where in some filter chains this off-by-one error is being introduced, but probably does not matter since it does not affect any annotations 
    # and since the max square always preserves the scale and the upper left corner of the source video. 
    # FIXME: this may trigger an inefficient resizing operation during load()
    if not self.issquare():
        d = max(self.shape())
        self._ffmpeg = self._ffmpeg.filter(&#39;pad&#39;, d+1, d+1, 0, 0)
        self.shape(shape=(d+1, d+1))
        return self.crop(vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(d), height=int(d)))
    else:
        return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.metadata"><code class="name flex">
<span>def <span class="ident">metadata</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a dictionary of metadata about this video.</p>
<p>This is an alias for the 'attributes' dictionary.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L612-L617" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def metadata(self):
    &#34;&#34;&#34;Return a dictionary of metadata about this video.

    This is an alias for the &#39;attributes&#39; dictionary. 
    &#34;&#34;&#34;
    return self.attributes</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.mindim"><code class="name flex">
<span>def <span class="ident">mindim</span></span>(<span>self, dim=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1808-L1811" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def mindim(self, dim=None):
    &#34;&#34;&#34;Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio&#34;&#34;&#34;
    (H,W) = self.shape()  # yuck, need to get image dimensions before filter
    return min(self.shape()) if dim is None else (self if min(H,W)==dim else (self.resize(cols=dim) if W&lt;H else self.resize(rows=dim)))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.minsquare"><code class="name flex">
<span>def <span class="ident">minsquare</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a square crop of the video, preserving the upper left corner of the video</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1856-L1860" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def minsquare(self):
    &#34;&#34;&#34;Return a square crop of the video, preserving the upper left corner of the video&#34;&#34;&#34;
    d = min(self.shape())
    self.shape(shape=(d, d))
    return self.crop(vipy.geometry.BoundingBox(xmin=0, ymin=0, width=int(d), height=int(d)))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.mutable"><code class="name flex">
<span>def <span class="ident">mutable</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a video object with a writeable mutable frame array.
Video must be loaded, triggers copy of underlying numpy array if the buffer is not writeable.
</p>
<h2 id="returns">Returns</h2>
<p>This object with a mutable frame buffer in self.array() or self.numpy()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1274-L1283" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def mutable(self):
    &#34;&#34;&#34;Return a video object with a writeable mutable frame array.  Video must be loaded, triggers copy of underlying numpy array if the buffer is not writeable.  
    
    Returns:
        This object with a mutable frame buffer in self.array() or self.numpy()
    &#34;&#34;&#34;
    assert self.isloaded()
    self._array = np.copy(self._array) if not self._array.flags[&#39;WRITEABLE&#39;] else self._array  # triggers copy
    self._array.setflags(write=True)  # mutable iterators, torch conversion
    return self        </code></pre>
</details>
</dd>
<dt id="vipy.video.Video.nofilename"><code class="name flex">
<span>def <span class="ident">nofilename</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1299-L1302" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def nofilename(self):
    self._filename = None
    self._update_ffmpeg(&#39;filename&#39;, None)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.normalize"><code class="name flex">
<span>def <span class="ident">normalize</span></span>(<span>self, mean, std, scale=1, bias=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Pixelwise whitening, out = ((scale*in) - mean) / std); triggers load().
All computations float32</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2384-L2391" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def normalize(self, mean, std, scale=1, bias=0):
    &#34;&#34;&#34;Pixelwise whitening, out = ((scale*in) - mean) / std); triggers load().  All computations float32&#34;&#34;&#34;
    assert scale &gt;= 0, &#34;Invalid input&#34;
    assert all([s &gt; 0 for s in tolist(std)]), &#34;Invalid input&#34;
    self._array = vipy.math.normalize(self._array, np.array(mean, dtype=np.float32), np.array(std, dtype=np.float32), np.float32(scale))
    if bias != 0:
        self._array = self._array + np.array(bias, dtype=np.float32)
    return self.colorspace(&#39;float&#39;)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.nourl"><code class="name flex">
<span>def <span class="ident">nourl</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove the <code><a title="vipy.video.Video.url" href="#vipy.video.Video.url">Video.url()</a></code> from the video</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1131-L1134" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def nourl(self):
    &#34;&#34;&#34;Remove the `vipy.video.Video.url` from the video&#34;&#34;&#34;
    (self._url, self._urluser, self._urlpassword, self._urlsha1) = (None, None, None, None)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.numpy"><code class="name flex">
<span>def <span class="ident">numpy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert the video to a writeable numpy array, triggers a load() and copy() as needed.
Returns the numpy array.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1285-L1290" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def numpy(self):
    &#34;&#34;&#34;Convert the video to a writeable numpy array, triggers a load() and copy() as needed.  Returns the numpy array.&#34;&#34;&#34;
    self.load()
    self._array = np.copy(self._array) if not self._array.flags[&#39;WRITEABLE&#39;] else self._array  # triggers copy
    self._array.setflags(write=True)  # mutable iterators, torch conversion
    return self._array</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.pad"><code class="name flex">
<span>def <span class="ident">pad</span></span>(<span>self, padwidth=0, padheight=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for zeropad</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1881-L1883" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def pad(self, padwidth=0, padheight=0):
    &#34;&#34;&#34;Alias for zeropad&#34;&#34;&#34;
    return self.zeropad(padwidth=padwidth, padheight=padheight)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.pkl"><code class="name flex">
<span>def <span class="ident">pkl</span></span>(<span>self, pklfile=None)</span>
</code></dt>
<dd>
<div class="desc"><p>save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1919-L1924" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def pkl(self, pklfile=None):
    &#34;&#34;&#34;save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains&#34;&#34;&#34;
    pklfile = pklfile if pklfile is not None else toextension(self.filename(), &#39;.pkl&#39;)
    remkdir(filepath(pklfile))
    vipy.util.save(self, pklfile)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.pklif"><code class="name flex">
<span>def <span class="ident">pklif</span></span>(<span>self, b, pklfile=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the object to the provided pickle file only if b=True. Uuseful for conditional intermediate saving in long fluent chains</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1926-L1929" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def pklif(self, b, pklfile=None):
    &#34;&#34;&#34;Save the object to the provided pickle file only if b=True. Uuseful for conditional intermediate saving in long fluent chains&#34;&#34;&#34;
    assert isinstance(b, bool)
    return self.pkl(pklfile) if b else self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.play"><code class="name flex">
<span>def <span class="ident">play</span></span>(<span>self, verbose=False, notebook=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Play the saved video filename in self.filename()</p>
<p>If there is no filename, try to download it.
If the filter chain is dirty or the pixels are loaded, dump to temp video file first then play it.
This uses 'ffplay' on the PATH if available, otherwise uses a fallback player by showing a sequence of matplotlib frames.
If the output of the ffmpeg filter chain has modified this video, then this will be saved to a temporary video file.
To play the original video (indepenedent of the filter chain of this video), use <code><a title="vipy.video.Video.ffplay" href="#vipy.video.Video.ffplay">Video.ffplay()</a></code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>verbose</code></strong></dt>
<dd>If true, show more verbose output </dd>
<dt><strong><code>notebook</code></strong></dt>
<dd>If true, play in a jupyter notebook</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>The unmodified video object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2067-L2125" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def play(self, verbose=False, notebook=False):
    &#34;&#34;&#34;Play the saved video filename in self.filename()

    If there is no filename, try to download it.  If the filter chain is dirty or the pixels are loaded, dump to temp video file first then play it.  This uses &#39;ffplay&#39; on the PATH if available, otherwise uses a fallback player by showing a sequence of matplotlib frames.
    If the output of the ffmpeg filter chain has modified this video, then this will be saved to a temporary video file.  To play the original video (indepenedent of the filter chain of this video), use `vipy.video.Video.ffplay`.
    
    Args:
        verbose: If true, show more verbose output 
        notebook:  If true, play in a jupyter notebook

    Returns:
        The unmodified video object
    &#34;&#34;&#34;
    

    if not self.isdownloaded() and self.hasurl():
        self.download()
    if iswebp(self.filename()) or isgif(self.filename()):
        self.load()
        
    if notebook:
        # save to temporary video, this video is not cleaned up and may accumulate            
        try_import(&#34;IPython.display&#34;, &#34;ipython&#34;); import IPython.display
        if not self.hasfilename() or self.isloaded() or self._isdirty():
            v = self.saveas(tempMP4())                 
            warnings.warn(&#39;Saving video to temporary file &#34;%s&#34; for notebook viewer ... &#39; % v.filename())
            return IPython.display.Video(v.filename(), embed=True)
        return IPython.display.Video(self.filename(), embed=True)
    elif has_ffplay:
        if self.isloaded() or self._isdirty():
            f = tempMP4()
            if verbose:
                warnings.warn(&#39;%s - Saving video to temporary file &#34;%s&#34; for ffplay ... &#39; % (&#39;Video loaded into memory&#39; if self.isloaded() else &#39;Dirty FFMPEG filter chain&#39;, f))
            v = self.saveas(f)
            cmd = &#39;ffplay &#34;%s&#34;&#39; % v.filename()
            if verbose:
                print(&#39;[vipy.video.play]: Executing &#34;%s&#34;&#39; % cmd)
            os.system(cmd)
            if verbose:
                print(&#39;[vipy.video.play]:  Removing temporary file &#34;%s&#34;&#39; % v.filename())                    
            os.remove(v.filename())  # cleanup
        elif self.hasfilename() or (self.hasurl() and self.download().hasfilename()):  # triggers download
            self.ffplay()
        else:
            raise ValueError(&#39;Invalid video file &#34;%s&#34; - ffplay requires a video filename&#39; % self.filename())
        return self

    else:
        &#34;&#34;&#34;Fallback player.  This can visualize videos without ffplay, but it cannot guarantee frame rates. Large videos with complex scenes will slow this down and will render at lower frame rates.&#34;&#34;&#34;
        fps = self.framerate()
        assert fps &gt; 0, &#34;Invalid display framerate&#34;
        with Stopwatch() as sw:            
            for (k,im) in enumerate(self.load() if self.isloaded() else self.stream()):
                time.sleep(max(0, (1.0/self.framerate())*int(np.ceil((self.framerate()/fps))) - sw.since()))                                
                im.show(figure=figure)
                if vipy.globals._user_hit_escape():
                    break                    
        vipy.show.close(figure)
        return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.preview"><code class="name flex">
<span>def <span class="ident">preview</span></span>(<span>self, framenum=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Return selected frame of filtered video, return vipy.image.Image object.
This is useful for previewing the frame shape of a complex filter chain or the frame contents at a particular location without loading the whole video</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1544-L1582" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def preview(self, framenum=0):
    &#34;&#34;&#34;Return selected frame of filtered video, return vipy.image.Image object.  This is useful for previewing the frame shape of a complex filter chain or the frame contents at a particular location without loading the whole video&#34;&#34;&#34;
    if self.isloaded():
        return self[framenum]
    elif self.hasurl() and not self.hasfilename():
        self.download(verbose=True)  
    if not self.hasfilename():
        raise ValueError(&#39;Video file not found&#39;)
    if iswebp(self.filename()) or isgif(self.filename()):
        return self.load().frame(framenum)
    
    # Convert frame to mjpeg and pipe to stdout, used to get dimensions of video
    #   - The MJPEG encoder will generally output lower quality than H.264 encoded frames
    #   - This means that frame indexing from preview() will generate slightly different images than streaming raw
    #   - Beware running convnets, as the pixels will be slightly different (~4 grey levels in uint8) ... 
    try:
        # FFMPEG frame indexing is inefficient for large framenum.  Need to add &#34;-ss sec.msec&#34; flag before input
        #   - the &#34;ss&#34; option must be provided before the input filename, and is supported by ffmpeg-python as &#34;.input(in_filename, ss=time)&#34;
        #   - Seek to the frame before the desired frame in order to pipe the next (desired) frame 
        timestamp_in_seconds = max(0.0, (framenum-1)/float(self.framerate()))
        f_prepipe = self.clone(shallow=True)._update_ffmpeg_seek(offset=timestamp_in_seconds)._ffmpeg.filter(&#39;select&#39;, &#39;gte(n,{})&#39;.format(0))
        f = f_prepipe.output(&#39;pipe:&#39;, vframes=1, format=&#39;image2&#39;, vcodec=&#39;mjpeg&#39;)\
                     .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;debug&#39; if vipy.globals.isdebug() else &#39;error&#39;)
        (out, err) = f.run(capture_stdout=True, capture_stderr=True)
    except Exception as e:            
        raise ValueError(&#39;[vipy.video.load]: Video preview failed with error &#34;%s&#34;\n  - Video: &#34;%s&#34;\n  - FFMPEG command: \&#39;sh&gt; %s\&#39;\n  - Try manually running this ffmpeg command to see errors.  This error usually means that the video is corrupted.&#39; % (str(e), str(self), str(self._ffmpeg_commandline(f_prepipe.output(&#39;preview.jpg&#39;, vframes=1)))))

    # [EXCEPTION]:  UnidentifiedImageError: cannot identify image file, means usually that FFMPEG piped a zero length image
    try:
        return Image(array=np.array(PIL.Image.open(BytesIO(out))))
    except Exception as e:
        print(&#39;[vipy.video.Video.preview][ERROR]:  %s&#39; % str(e))
        print(&#39;  - FFMPEG attempted to extract a single frame from the following video and failed:\n    %s&#39; % str(self))
        print(&#39;  - This may occur after calling clip() with too short a duration, try increasing the clip to be &gt; 1 sec&#39;)
        print(&#39;  - This may occur after calling clip() with a startframe or endframe outside the duration of the video&#39;)
        print(&#39;  - This may occur if requesting a frame number greater than the length of the video.  At this point, we do not know the video length, and cannot fail gracefully&#39;)
        print(&#39;  - This may occur when the framerate of the video from ffprobe (tbr) does not match that passed to fps filter, resulting in a zero length image preview piped to stdout&#39;)
        print(&#39;  - This may occur if the filter chain fails for some unknown reason on this video.  Try running this ffmpeg command manually and inspect the FFMPEG console output:\n     sh&gt; %s&#39; % str(self._ffmpeg_commandline(f_prepipe.output(&#39;preview.jpg&#39;, vframes=1))))
        raise</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.print"><code class="name flex">
<span>def <span class="ident">print</span></span>(<span>self, prefix='', verbose=True, sleep=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Print the representation of the video</p>
<p>This is useful for debugging in long fluent chains.
Sleep is useful for adding in a delay for distributed processing.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>prefix</code></strong></dt>
<dd>prepend a string prefix to the video <strong>repr</strong> when printing.
Useful for logging.</dd>
<dt><strong><code>verbose</code></strong></dt>
<dd>Print out the video <strong>repr</strong>.
Set verbose=False to just sleep</dd>
<dt><strong><code>sleep</code></strong></dt>
<dd>Integer number of seconds to sleep[ before returning</dd>
</dl>
<p>fluent [bool]:
If true, return self else return None.
This is useful for terminating long fluent chains in lambdas that return None
Returns:<br>
The video object after sleeping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1011-L1030" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def print(self, prefix=&#39;&#39;, verbose=True, sleep=None):
    &#34;&#34;&#34;Print the representation of the video

    This is useful for debugging in long fluent chains.  Sleep is useful for adding in a delay for distributed processing.

    Args:
        prefix: prepend a string prefix to the video __repr__ when printing.  Useful for logging.
        verbose:  Print out the video __repr__.  Set verbose=False to just sleep
        sleep:  Integer number of seconds to sleep[ before returning
        fluent [bool]:  If true, return self else return None.  This is useful for terminating long fluent chains in lambdas that return None

    Returns:  
        The video object after sleeping 
    &#34;&#34;&#34;
    if verbose:
        print(prefix+self.__repr__())
    if sleep is not None:
        assert isinstance(sleep, int) and sleep &gt; 0, &#34;Sleep must be a non-negative integer number of seconds&#34;
        time.sleep(sleep)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.probe"><code class="name flex">
<span>def <span class="ident">probe</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Run ffprobe on the filename and return the result as a dictionary</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1004-L1009" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def probe(self):
    &#34;&#34;&#34;Run ffprobe on the filename and return the result as a dictionary&#34;&#34;&#34;
    if not has_ffprobe:
        raise ValueError(&#39;&#34;ffprobe&#34; executable not found on path, this is optional for vipy.video - Install from http://ffmpeg.org/download.html&#39;)            
    assert self.downloadif().hasfilename(), &#34;Invalid video file &#39;%s&#39; for ffprobe&#34; % self.filename() 
    return ffmpeg.probe(self.filename())</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.probeshape"><code class="name flex">
<span>def <span class="ident">probeshape</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the (height, width) of underlying video file as determined from ffprobe</p>
<div class="admonition warning">
<p class="admonition-title">Warning:&ensp;this does not take into account any applied ffmpeg filters.
The shape will be the (height, width) of the underlying video file.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L947-L954" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def probeshape(self):
    &#34;&#34;&#34;Return the (height, width) of underlying video file as determined from ffprobe
    
    .. warning:: this does not take into account any applied ffmpeg filters.  The shape will be the (height, width) of the underlying video file.  
    &#34;&#34;&#34;
    p = self.probe()
    assert len(p[&#39;streams&#39;]) &gt; 0
    return (p[&#39;streams&#39;][0][&#39;height&#39;], p[&#39;streams&#39;][0][&#39;width&#39;])</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.quicklook"><code class="name flex">
<span>def <span class="ident">quicklook</span></span>(<span>self, n=9, mindim=256, startframe=0, animate=False, dt=30)</span>
</code></dt>
<dd>
<div class="desc"><p>Generate a montage of n uniformly spaced frames.
Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame.</p>
<h2 id="input">Input</h2>
<p>n:
Number of images in the quicklook
mindim:
The minimum dimension of each of the elements in the montage
animate:
If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames
dt:
The number of frames for animation
startframe:
The initial frame index to start the n uniformly sampled frames for the quicklook</p>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;The first frame in the upper left is guaranteed to be the start frame of the labeled activity, but the last frame in the bottom right may not be precisely the end frame and may be off by at most len(video)/9.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2131-L2152" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def quicklook(self, n=9, mindim=256, startframe=0, animate=False, dt=30):
    &#34;&#34;&#34;Generate a montage of n uniformly spaced frames.
       Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame.
    
       Input:
           n:  Number of images in the quicklook
           mindim:  The minimum dimension of each of the elements in the montage
           animate:  If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames
           dt:  The number of frames for animation
           startframe:  The initial frame index to start the n uniformly sampled frames for the quicklook

       ..note:: The first frame in the upper left is guaranteed to be the start frame of the labeled activity, but the last frame in the bottom right may not be precisely the end frame and may be off by at most len(video)/9.
    &#34;&#34;&#34;
    if not self.isloaded():
        self.load()  
    if animate:
        return Video(frames=[self.quicklook(n=n, startframe=k, animate=False, dt=dt) for k in range(0, min(dt, len(self)))], framerate=self.framerate())
    framelist = [min(int(np.round(f))+startframe, len(self)-1) for f in np.linspace(0, len(self)-1, n)]
    imframes = [self.frame(k).maxmatte()  # letterbox or pillarbox
                for (j,k) in enumerate(framelist)]
    imframes = [im.savefig(figure=1).rgb() for im in imframes]  # temp storage in memory
    return vipy.visualize.montage(imframes, imgwidth=mindim, imgheight=mindim)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.randomcrop"><code class="name flex">
<span>def <span class="ident">randomcrop</span></span>(<span>self, shape, withbox=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Crop the video to shape=(H,W) with random position such that the crop contains only valid pixels, and optionally return the box</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1819-L1825" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def randomcrop(self, shape, withbox=False):
    &#34;&#34;&#34;Crop the video to shape=(H,W) with random position such that the crop contains only valid pixels, and optionally return the box&#34;&#34;&#34;
    assert shape[0] &lt;= self.height() and shape[1] &lt;= self.width()  # triggers preview()
    (xmin, ymin) = (np.random.randint(self.height()-shape[0]), np.random.randint(self.width()-shape[1]))
    bb = vipy.geometry.BoundingBox(xmin=int(xmin), ymin=int(ymin), width=int(shape[1]), height=int(shape[0]))  # may be outside frame
    self.crop(bb, zeropad=True)
    return self if not withbox else (self, bb)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.reload"><code class="name flex">
<span>def <span class="ident">reload</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1296-L1297" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def reload(self):
    return self.clone(flush=True).load()</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.relpath"><code class="name flex">
<span>def <span class="ident">relpath</span></span>(<span>self, parent=None, start=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Replace the filename with a relative path to parent (or current working directory if none).</p>
<p>Usage:</p>
<pre><code class="language-python">v = vipy.video.Video(filename='/path/to/dataset/video/category/out.mp4')
v.relpath(parent='/path/to/dataset')
v.filename() == 'video/category/out.mp4'
</code></pre>
<p>If the current working directory is /path/to/dataset, and v.load() is called, the filename will be loaded.</p>
<h2 id="args">Args</h2>
<p>parent [str]: A parent path of the current filename to remove and be relative to.
If filename is '/path/to/video.mp4' then filename must start with parent, then parent will be remvoed from filename.
start [str]:
Return a relative filename starting from path start='/path/to/dir' that will create a relative path to this filename.
If start='/a/b/c' and filename='/a/b/d/e/f.ext' then return filename '../d/e/f.ext'</p>
<h2 id="returns">Returns</h2>
<p>This video object with the filename changed to be a relative path</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1333-L1360" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def relpath(self, parent=None, start=None):
    &#34;&#34;&#34;Replace the filename with a relative path to parent (or current working directory if none).
    
    Usage:
     
    ```python
    v = vipy.video.Video(filename=&#39;/path/to/dataset/video/category/out.mp4&#39;)
    v.relpath(parent=&#39;/path/to/dataset&#39;)
    v.filename() == &#39;video/category/out.mp4&#39;
    ```

    If the current working directory is /path/to/dataset, and v.load() is called, the filename will be loaded.

    Args:
        parent [str]: A parent path of the current filename to remove and be relative to.  If filename is &#39;/path/to/video.mp4&#39; then filename must start with parent, then parent will be remvoed from filename. 
        start [str]:  Return a relative filename starting from path start=&#39;/path/to/dir&#39; that will create a relative path to this filename.  If start=&#39;/a/b/c&#39; and filename=&#39;/a/b/d/e/f.ext&#39; then return filename &#39;../d/e/f.ext&#39;
    Returns:
        This video object with the filename changed to be a relative path

    &#34;&#34;&#34;
    assert parent is not None or start is not None
    if parent is not None:
        parent = parent if parent is not None else os.getcwd()
        assert parent in os.path.expanduser(self.filename()), &#34;Parent path &#39;%s&#39; not found in abspath &#39;%s&#39;&#34; % (parent, self.filename())
        self.filename(PurePath(os.path.expanduser(self.filename())).relative_to(parent))
    if start is not None: 
        self.filename(os.path.join(os.path.relpath(os.path.expanduser(filepath(self.filename())), start), filetail(self.filename())))
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.rename"><code class="name flex">
<span>def <span class="ident">rename</span></span>(<span>self, newname)</span>
</code></dt>
<dd>
<div class="desc"><p>Move the underlying video file preserving the absolute path, such that self.filename() == '/a/b/c.ext' and newname='d.ext', then self.filename() -&gt; '/a/b/d.ext', and move the corresponding file</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1362-L1366" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def rename(self, newname):
    &#34;&#34;&#34;Move the underlying video file preserving the absolute path, such that self.filename() == &#39;/a/b/c.ext&#39; and newname=&#39;d.ext&#39;, then self.filename() -&gt; &#39;/a/b/d.ext&#39;, and move the corresponding file&#34;&#34;&#34;
    newfile = os.path.join(filepath(self.filename()), newname)
    shutil.move(self.filename(), newfile)        
    return self.filename(newfile)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.rescale"><code class="name flex">
<span>def <span class="ident">rescale</span></span>(<span>self, s)</span>
</code></dt>
<dd>
<div class="desc"><p>Rescale the video by factor s, such that the new dimensions are (s<em>H, s</em>W), can only be applied prior to load()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1773-L1780" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def rescale(self, s):
    &#34;&#34;&#34;Rescale the video by factor s, such that the new dimensions are (s*H, s*W), can only be applied prior to load()&#34;&#34;&#34;
    if s == 1:
        return self
    assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
    self.shape(shape=(int(np.round(self.height()*float(np.ceil(s*1e6)/1e6))), int(np.round(self.width()*float(np.ceil(s*1e6)/1e6)))))  # update the known shape        
    self._ffmpeg = self._ffmpeg.filter(&#39;scale&#39;, &#39;iw*%1.6f&#39; % float(np.ceil(s*1e6)/1e6), &#39;ih*%1.6f&#39; % float(np.ceil(s*1e6)/1e6))  # ceil last significant digit to avoid off by one
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.resize"><code class="name flex">
<span>def <span class="ident">resize</span></span>(<span>self, rows=None, cols=None, width=None, height=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Resize the video to be (rows=height, cols=width)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1782-L1806" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def resize(self, rows=None, cols=None, width=None, height=None):
    &#34;&#34;&#34;Resize the video to be (rows=height, cols=width)&#34;&#34;&#34;
    assert not (rows is not None and height is not None)
    assert not (cols is not None and width is not None)
    rows = rows if rows is not None else height
    cols = cols if cols is not None else width
            
    newshape = (rows if rows is not None else int(np.round(self.height()*(cols/self.width()))),
                cols if cols is not None else int(np.round(self.width()*(rows/self.height()))))
                        
    if (rows is None and cols is None):
        return self  # only if strictly necessary
    if not self.isloaded():
        self._ffmpeg = self._ffmpeg.filter(&#39;scale&#39;, cols if cols is not None else -1, rows if rows is not None else -1)
    else:            
        # Do not use self.__iter__() which triggers copy for mutable arrays
        #self.array(np.stack([Image(array=self._array[k]).resize(rows=rows, cols=cols).array() for k in range(len(self))]), copy=False)
        
        # Faster: RGB-&gt;RGBX to allow for PIL.Image.fromarray() without tobytes() copy, padding faster than np.concatenate()
        #self.array(np.stack([PIL.Image.fromarray(x, mode=&#39;RGBX&#39;).resize( (cols, rows), resample=PIL.Image.BILINEAR) for x in np.pad(self._array, ((0,0),(0,0),(0,0),(0,1)))])[:,:,:,:-1], copy=False)  # RGB-&gt;RGBX-&gt;RGB
        
        # Fastest: padding introduces more overhead than just accepting tobytes(), image size dependent?
        self.array(np.stack([PIL.Image.fromarray(x).resize( (newshape[1], newshape[0]), resample=PIL.Image.BILINEAR) for x in np.ascontiguousarray(self._array)]), copy=False)
    self.shape(shape=newshape)  # manually set newshape
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.resolution_of_videofile"><code class="name flex">
<span>def <span class="ident">resolution_of_videofile</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Return video resolution in (height, width) in pixels (NOT the filter chain), requires ffprobe.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L996-L1002" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def resolution_of_videofile(self):
    &#34;&#34;&#34;Return video resolution in (height, width) in pixels (NOT the filter chain), requires ffprobe.
    &#34;&#34;&#34;
    p = self.probe()
    assert &#39;streams&#39; in p and len([&#39;streams&#39;]) &gt; 0
    (H,W) = (p[&#39;streams&#39;][0][&#39;height&#39;], p[&#39;streams&#39;][0][&#39;width&#39;])  # (height, width) in pixels
    return (W,H) if (&#39;tags&#39; in p[&#39;streams&#39;][0] and &#39;rotate&#39; in p[&#39;streams&#39;][0][&#39;tags&#39;] and p[&#39;streams&#39;][0][&#39;tags&#39;][&#39;rotate&#39;] in [&#39;90&#39;,&#39;270&#39;]) else (H,W)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.restore"><code class="name flex">
<span>def <span class="ident">restore</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the currently stored video as set using <code><a title="vipy.video.Video.store" href="#vipy.video.Video.store">Video.store()</a></code> to filename, and set up filename</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L695-L700" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def restore(self, filename):
    &#34;&#34;&#34;Save the currently stored video as set using `vipy.video.Video.store` to filename, and set up filename&#34;&#34;&#34;
    assert self.hasattribute(&#39;__video__&#39;), &#34;Video not stored&#34;
    with open(filename, &#39;wb&#39;) as f:
        f.write(self.attributes[&#39;__video__&#39;])
    return self.filename(filename)                </code></pre>
</details>
</dd>
<dt id="vipy.video.Video.returns"><code class="name flex">
<span>def <span class="ident">returns</span></span>(<span>self, r=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return the provided value, useful for terminating long fluent chains without returning self</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2338-L2340" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def returns(self, r=None):
    &#34;&#34;&#34;Return the provided value, useful for terminating long fluent chains without returning self&#34;&#34;&#34;
    return r</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.rot90ccw"><code class="name flex">
<span>def <span class="ident">rot90ccw</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1752-L1757" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def rot90ccw(self):
    &#34;&#34;&#34;Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()&#34;&#34;&#34;        
    assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
    self.shape(shape=(self.width(), self.height()))  # transposed                
    self._ffmpeg = self._ffmpeg.filter(&#39;transpose&#39;, 2)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.rot90cw"><code class="name flex">
<span>def <span class="ident">rot90cw</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Rotate the video 90 degrees clockwise, can only be applied prior to load()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1745-L1750" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def rot90cw(self):
    &#34;&#34;&#34;Rotate the video 90 degrees clockwise, can only be applied prior to load()&#34;&#34;&#34;
    assert not self.isloaded(), &#34;Filters can only be applied prior to load() - Try calling flush() first&#34;
    self.shape(shape=(self.width(), self.height()))  # transposed        
    self._ffmpeg = self._ffmpeg.filter(&#39;transpose&#39;, 1)
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.sanitize"><code class="name flex">
<span>def <span class="ident">sanitize</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Remove all private keys from the attributes dictionary.</p>
<p>The attributes dictionary is useful storage for arbitrary (key,value) pairs.
However, this storage may contain sensitive information that should be scrubbed from the video before serialization.
As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key.
This is analogous to private or reserved attributes in the python lanugage.
Users should reserve these keynames for those keys that should be sanitized and removed before any seerialization of this object.</p>
<pre><code class="language-python">assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey') == False
</code></pre></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L619-L631" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def sanitize(self):
    &#34;&#34;&#34;Remove all private keys from the attributes dictionary.
    
    The attributes dictionary is useful storage for arbitrary (key,value) pairs.  However, this storage may contain sensitive information that should be scrubbed from the video before serialization.  As a general rule, any key that is of the form &#39;__keyname&#39; prepended by two underscores is a private key.  This is analogous to private or reserved attributes in the python lanugage.  Users should reserve these keynames for those keys that should be sanitized and removed before any seerialization of this object.
    
    ```python
    assert self.setattribute(&#39;__mykey&#39;, 1).sanitize().hasattribute(&#39;__mykey&#39;) == False
    ```

    &#34;&#34;&#34;
    if self._has_private_attribute():
        self.attributes = {k:v for (k,v) in self.attributes.items() if not k.startswith(&#39;__&#39;)}
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.saveas"><code class="name flex">
<span>def <span class="ident">saveas</span></span>(<span>self, outfile=None, framerate=None, vcodec='libx264', verbose=False, ignoreErrors=False, flush=False, pause=5)</span>
</code></dt>
<dd>
<div class="desc"><p>Save video to new output video file.
This function does not draw boxes, it saves pixels to a new video file.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>outfile</code></strong></dt>
<dd>the absolute path to the output video file.
This extension can be .mp4 (for video) or [".webp",".gif"]
(for animated image)</dd>
<dt><strong><code>ignoreErrors</code></strong></dt>
<dd>if True, then exit gracefully without throwing an exception.
Useful for chaining download().saveas() on parallel dataset downloads</dd>
<dt><strong><code>flush</code></strong></dt>
<dd>If true, then flush the buffer for this object right after saving the new video. This is useful for transcoding in parallel</dd>
<dt><strong><code>framerate</code></strong></dt>
<dd>input framerate of the frames in the buffer, or the output framerate of the transcoded video.
If not provided, use framerate of source video</dd>
<dt><strong><code>pause</code></strong></dt>
<dd>an integer in seconds to pause between loops of animated images if the outfile is webp or animated gif</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul>
<li>If self.array() is loaded, then export the contents of self._array to the video file</li>
<li>If self.array() is not loaded, and there exists a valid video file, apply the filter chain directly to the input video</li>
<li>If outfile==None or outfile==self.filename(), then overwrite the current filename</li>
</ul>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1972-L2050" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def saveas(self, outfile=None, framerate=None, vcodec=&#39;libx264&#39;, verbose=False, ignoreErrors=False, flush=False, pause=5):
    &#34;&#34;&#34;Save video to new output video file.  This function does not draw boxes, it saves pixels to a new video file.

    Args:
        outfile: the absolute path to the output video file.  This extension can be .mp4 (for video) or [&#34;.webp&#34;,&#34;.gif&#34;]  (for animated image)
        ignoreErrors:  if True, then exit gracefully without throwing an exception.  Useful for chaining download().saveas() on parallel dataset downloads
        flush:  If true, then flush the buffer for this object right after saving the new video. This is useful for transcoding in parallel
        framerate:  input framerate of the frames in the buffer, or the output framerate of the transcoded video.  If not provided, use framerate of source video
        pause:  an integer in seconds to pause between loops of animated images if the outfile is webp or animated gif

    Returns:
        a new video object with this video filename, and a clean video filter chain

    .. note:: 
        - If self.array() is loaded, then export the contents of self._array to the video file
        - If self.array() is not loaded, and there exists a valid video file, apply the filter chain directly to the input video
        - If outfile==None or outfile==self.filename(), then overwrite the current filename 

    &#34;&#34;&#34;        
    outfile = tocache(tempMP4()) if outfile is None else os.path.normpath(os.path.abspath(os.path.expanduser(outfile)))
    premkdir(outfile)  # create output directory for this file if not exists
    framerate = framerate if framerate is not None else self._framerate
    assert vipy.util.isvideofile(outfile), &#34;Invalid filename extension for video filename&#34;

    if verbose:
        print(&#39;[vipy.video.saveas]: Saving video &#34;%s&#34; ...&#39; % outfile)                      
    try:
        if iswebp(outfile):
            return self.webp(outfile, pause)
        elif isgif(outfile):
            return self.gif(outfile, pause)
        elif isjsonfile(outfile):
            with open(outfile) as f:
                f.write(self.json(encode=True))
            return outfile
        elif self.isloaded():
            # Save numpy() from load() to video, forcing to be even shape
            (n, height, width, channels) = self._array.shape
            process = ffmpeg.input(&#39;pipe:&#39;, format=&#39;rawvideo&#39;, pix_fmt=&#39;rgb24&#39;, s=&#39;{}x{}&#39;.format(width, height), r=framerate) \
                            .filter(&#39;pad&#39;, &#39;ceil(iw/2)*2&#39;, &#39;ceil(ih/2)*2&#39;) \
                            .output(filename=outfile, pix_fmt=&#39;yuv420p&#39;, vcodec=vcodec) \
                            .overwrite_output() \
                            .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;quiet&#39; if not vipy.globals.isdebug() else &#39;debug&#39;) \
                            .run_async(pipe_stdin=True)                
            for frame in self._array:
                process.stdin.write(frame.astype(np.uint8).tobytes())
            process.stdin.close()
            process.wait()
        
        elif (self.isdownloaded() and self._isdirty()) or isRTSPurl(self.filename()) or isRTMPurl(self.filename()):
            # Transcode the video file directly, do not load() then export
            # Requires saving to a tmpfile if the output filename is the same as the input filename
            tmpfile = &#39;%s.tmp%s&#39; % (filefull(outfile), fileext(outfile)) if outfile == self.filename() else outfile
            self._ffmpeg.filter(&#39;pad&#39;, &#39;ceil(iw/2)*2&#39;, &#39;ceil(ih/2)*2&#39;) \
                        .output(filename=tmpfile, pix_fmt=&#39;yuv420p&#39;, vcodec=vcodec, r=framerate) \
                        .overwrite_output() \
                        .global_args(&#39;-cpuflags&#39;, &#39;0&#39;, &#39;-loglevel&#39;, &#39;quiet&#39; if not vipy.globals.isdebug() else &#39;debug&#39;) \
                        .run()
            if outfile == self.filename():
                if os.path.exists(self.filename()):
                    os.remove(self.filename())
                shutil.move(tmpfile, self.filename())
        elif self.hasfilename() and not self._isdirty():
            shutil.copyfile(self.filename(), outfile)
        elif self.hasurl() and not self.hasfilename():
            raise ValueError(&#39;Input video url &#34;%s&#34; not downloaded, call download() first&#39; % self.url())
        elif not self.hasfilename():
            raise ValueError(&#39;Input video file not found &#34;%s&#34;&#39; % self.filename())
        else: 
            raise ValueError(&#39;saveas() failed&#39;)
    except Exception as e:
        if ignoreErrors:
            # useful for saving a large number of videos in parallel where some failed download
            print(&#39;[vipy.video.saveas]:  Failed with error &#34;%s&#34; - Returning empty video&#39; % str(repr(e)))
        else:
            raise

    # Return a new video, cloned from this video with the new video file, optionally flush the video we loaded before returning
    return self.clone(flushforward=True, flushfilter=True, flushbackward=flush).filename(outfile).nourl()</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.savetemp"><code class="name flex">
<span>def <span class="ident">savetemp</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for <code><a title="vipy.video.Video.savetmp" href="#vipy.video.Video.savetmp">Video.savetmp()</a></code></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2055-L2057" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def savetemp(self):
    &#34;&#34;&#34;Alias for `vipy.video.Video.savetmp`&#34;&#34;&#34;
    return self.savetmp()</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.savetmp"><code class="name flex">
<span>def <span class="ident">savetmp</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Call <code><a title="vipy.video.Video.saveas" href="#vipy.video.Video.saveas">Video.saveas()</a></code> using a new temporary video file, and return the video object with this new filename</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2052-L2054" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def savetmp(self):
    &#34;&#34;&#34;Call `vipy.video.Video.saveas` using a new temporary video file, and return the video object with this new filename&#34;&#34;&#34;
    return self.saveas(outfile=tempMP4())</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.setattribute"><code class="name flex">
<span>def <span class="ident">setattribute</span></span>(<span>self, k, v=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2393-L2397" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def setattribute(self, k, v=None):
    if self.attributes is None:
        self.attributes = {}
    self.attributes[k] = v
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.shape"><code class="name flex">
<span>def <span class="ident">shape</span></span>(<span>self, shape=None, probe=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Return (height, width) of the frames, requires loading a preview frame from the video if the video is not already loaded, or providing the shape=(height,width) by the user</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1482-L1505" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def shape(self, shape=None, probe=False):
    &#34;&#34;&#34;Return (height, width) of the frames, requires loading a preview frame from the video if the video is not already loaded, or providing the shape=(height,width) by the user&#34;&#34;&#34;
    if probe:
        # Set the shape of the video from the filename by ffprobe, this should be deprecated
        return self.shape(self.probeshape(), probe=False)
    elif shape is not None:
        # Set the shape of the video using the shape provided by the user (e.g. sometimes the user knows what this will be)
        assert isinstance(shape, tuple), &#34;shape=(height, width) tuple&#34;
        self._shape = shape
        self._channels = self.channels()
        #self._previewhash = hashlib.md5(str(self._ffmpeg_commandline()).encode()).hexdigest() 
        return self
        
    elif not self.isloaded():
        # Preview a frame from the ffmpeg filter chain (more expensive)
        if self._shape is None or len(self._shape) == 0:  # dirty filter chain
            im = self.preview()  # ffmpeg chain changed, load a single frame of video, triggers fetch
            self._shape = (im.height(), im.width())  # cache the shape
            self._channels = im.channels()
            #self._previewhash = previewhash
        return self._shape
    else:
        # Frames already loaded - get shape from numpy array
        return (self._array.shape[1], self._array.shape[2])</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.show"><code class="name flex">
<span>def <span class="ident">show</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for play</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2127-L2129" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def show(self):
    &#34;&#34;&#34;Alias for play&#34;&#34;&#34;
    return self.play()</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.speed"><code class="name flex">
<span>def <span class="ident">speed</span></span>(<span>self, s)</span>
</code></dt>
<dd>
<div class="desc"><p>Change the speed by a multiplier s.
If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1693-L1697" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def speed(self, s):
    &#34;&#34;&#34;Change the speed by a multiplier s.  If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)&#34;&#34;&#34;
    assert s &gt; 0, &#34;Invalid input&#34;
    self._ffmpeg = self._ffmpeg.setpts(&#39;%1.3f*PTS&#39; % float(1.0/float(s)))
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.store"><code class="name flex">
<span>def <span class="ident">store</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Store the current video file as an attribute of this object.
</p>
<p>Useful for archiving an object to be fully self contained without any external references.
</p>
<pre><code class="language-python">v == v.store().restore(v.filename()) 
</code></pre>
<div class="admonition note">
<p class="admonition-title">Note</p>
</div>
<p>-Remove this stored video using unstore()
-Unpack this stored video and set up the video chains using restore()
-This method is more efficient than load() followed by pkl(), as it stores the encoded video as a byte string.
-Useful for creating a single self contained object for distributed processing.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L671-L689" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def store(self):
    &#34;&#34;&#34;Store the current video file as an attribute of this object.  

    Useful for archiving an object to be fully self contained without any external references.  

    ```python
    v == v.store().restore(v.filename()) 
    ```
    
    .. note::
    -Remove this stored video using unstore()
    -Unpack this stored video and set up the video chains using restore() 
    -This method is more efficient than load() followed by pkl(), as it stores the encoded video as a byte string.
    -Useful for creating a single self contained object for distributed processing.  
    &#34;&#34;&#34;
    assert self.hasfilename(), &#34;Video file not found.  Try saveas() first to create a video file to store.&#34;
    with open(self.filename(), &#39;rb&#39;) as f:
        self.attributes[&#39;__video__&#39;] = f.read()
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.stream"><code class="name flex">
<span>def <span class="ident">stream</span></span>(<span>self, write=False, overwrite=False, queuesize=512, bitrate=None, buffered=False, rebuffered=False, bufsize=256)</span>
</code></dt>
<dd>
<div class="desc"><p>Iterator to yield groups of frames streaming from video.</p>
<p>A video stream is a real time iterator to read or write from a video.
Streams are useful to group together frames into clips that are operated on as a group.</p>
<p>The following use cases are supported:</p>
<pre><code class="language-python">v = vipy.video.RandomScene()
</code></pre>
<p>Stream individual video frames lagged by 10 frames and 20 frames</p>
<pre><code class="language-python">for (im1, im2) in zip(v.stream().frame(n=-10), v.stream().frame(n=-20)):
    print(im1, im2)
</code></pre>
<p>Stream overlapping clips such that each clip is a video n=16 frames long and starts at frame i, and the next clip is n=16 frames long and starts at frame i=i+m</p>
<pre><code class="language-python">for vc in v.stream().clip(n=16, m=4):
    print(vc)
</code></pre>
<p>Stream non-overlapping batches of frames such that each clip is a video of length n and starts at frame i, and the next clip is length n and starts at frame i+n</p>
<pre><code class="language-python">for vb in v.stream().batch(n=16):
    print(vb)        
</code></pre>
<p>Create a write stream to incrementally add frames to long video.
</p>
<pre><code class="language-python">vi = vipy.video.Video(filename='/path/to/output.mp4')
vo = vipy.video.Video(filename='/path/to/input.mp4')
with vo.stream(write=True) as s:
    for im in vi.stream():
        s.write(im)  # manipulate pixels of im, if desired
</code></pre>
<p>Create a 480p YouTube live stream from an RTSP camera at 5Hz </p>
<pre><code class="language-python">vo = vipy.video.Scene(url='rtmp://a.rtmp.youtube.com/live2/$SECRET_STREAM_KEY')
vi = vipy.video.Scene(url='rtsp://URL').framerate(5)
with vo.framerate(5).stream(write=True, bitrate='1000k') as s:
    for im in vi.framerate(5).resize(cols=854, rows=480):
        s.write(im)
</code></pre>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>write</code></strong></dt>
<dd>[bool]
If true, create a write stream</dd>
<dt><strong><code>overwrite</code></strong></dt>
<dd>[bool]
If true, and the video output filename already exists, overwrite it</dd>
<dt><strong><code>bufsize</code></strong></dt>
<dd>[int]
The maximum queue size for the ffmpeg pipe thread in the primary iterator.
The queue size is the maximum size of pre-fetched frames from the ffmpeg pip.
This should be big enough that you are never waiting for queue fills</dd>
<dt><strong><code>bitrate</code></strong></dt>
<dd>[str] The ffmpeg bitrate of the output encoder for writing, written like '2000k'</dd>
<dt><strong><code>bufsize</code></strong></dt>
<dd>[int]
The maximum size of the stream buffer in frames.
The stream buffer length should be big enough so that all iterators can yield before deleting old frames</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note:&ensp;Using this iterator may affect PDB debugging due to stdout/stdin redirection.
Use ipdb instead.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L749-L814" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def stream(self, write=False, overwrite=False, queuesize=512, bitrate=None, buffered=False, rebuffered=False, bufsize=256):
    &#34;&#34;&#34;Iterator to yield groups of frames streaming from video.

    A video stream is a real time iterator to read or write from a video.  Streams are useful to group together frames into clips that are operated on as a group.

    The following use cases are supported:
    
    ```python
    v = vipy.video.RandomScene()
    ```

    Stream individual video frames lagged by 10 frames and 20 frames

    ```python
    for (im1, im2) in zip(v.stream().frame(n=-10), v.stream().frame(n=-20)):
        print(im1, im2)
    ```
    
    Stream overlapping clips such that each clip is a video n=16 frames long and starts at frame i, and the next clip is n=16 frames long and starts at frame i=i+m

    ```python
    for vc in v.stream().clip(n=16, m=4):
        print(vc)
    ```

    Stream non-overlapping batches of frames such that each clip is a video of length n and starts at frame i, and the next clip is length n and starts at frame i+n

    ```python
    for vb in v.stream().batch(n=16):
        print(vb)        
    ```

    Create a write stream to incrementally add frames to long video.  

    ```python
    vi = vipy.video.Video(filename=&#39;/path/to/output.mp4&#39;)
    vo = vipy.video.Video(filename=&#39;/path/to/input.mp4&#39;)
    with vo.stream(write=True) as s:
        for im in vi.stream():
            s.write(im)  # manipulate pixels of im, if desired
    ```

    Create a 480p YouTube live stream from an RTSP camera at 5Hz 
    
    ```python
    vo = vipy.video.Scene(url=&#39;rtmp://a.rtmp.youtube.com/live2/$SECRET_STREAM_KEY&#39;)
    vi = vipy.video.Scene(url=&#39;rtsp://URL&#39;).framerate(5)
    with vo.framerate(5).stream(write=True, bitrate=&#39;1000k&#39;) as s:
        for im in vi.framerate(5).resize(cols=854, rows=480):
            s.write(im)
    ```

    Args:
        write: [bool]  If true, create a write stream
        overwrite: [bool]  If true, and the video output filename already exists, overwrite it
        bufsize: [int]  The maximum queue size for the ffmpeg pipe thread in the primary iterator.  The queue size is the maximum size of pre-fetched frames from the ffmpeg pip.  This should be big enough that you are never waiting for queue fills
        bitrate: [str] The ffmpeg bitrate of the output encoder for writing, written like &#39;2000k&#39;
        bufsize: [int]  The maximum size of the stream buffer in frames.  The stream buffer length should be big enough so that all iterators can yield before deleting old frames

    Returns:
        A Stream object

    ..note:: Using this iterator may affect PDB debugging due to stdout/stdin redirection.  Use ipdb instead.

    &#34;&#34;&#34;
    return Stream(self, queuesize=queuesize, write=write, overwrite=overwrite, bitrate=bitrate, buffered=buffered, rebuffered=rebuffered, bufsize=bufsize)  # do not clone</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.take"><code class="name flex">
<span>def <span class="ident">take</span></span>(<span>self, n)</span>
</code></dt>
<dd>
<div class="desc"><p>Return n frames from the clip uniformly spaced as numpy array</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>n</code></strong></dt>
<dd>Integer number of uniformly spaced frames to return </dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning:&ensp;This assumes that the entire video is loaded into memory (e.g. call <code><a title="vipy.video.Video.load" href="#vipy.video.Video.load">Video.load()</a></code>).
Use with caution.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1068-L1081" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def take(self, n):
    &#34;&#34;&#34;Return n frames from the clip uniformly spaced as numpy array
    
    Args:
        n: Integer number of uniformly spaced frames to return 
    
    Returns:
        A numpy array of shape (n,W,H)

    .. warning:: This assumes that the entire video is loaded into memory (e.g. call `vipy.video.Video.load`).  Use with caution.
    &#34;&#34;&#34;
    assert self.isloaded(), &#34;load() is required before take()&#34;
    dt = int(np.round(len(self._array) / float(n)))  # stride
    return self._array[::dt][0:n]</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.thumbnail"><code class="name flex">
<span>def <span class="ident">thumbnail</span></span>(<span>self, outfile=None, frame=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Return annotated frame=k of video, save annotation visualization to provided outfile.</p>
<p>This is functionally equivalent to <code><a title="vipy.video.Video.frame" href="#vipy.video.Video.frame">Video.frame()</a></code> with an additional outfile argument to easily save an annotated thumbnail image.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>outfile</code></strong></dt>
<dd>[str] an optional outfile to save the annotated frame </dd>
<dt><strong><code>frame</code></strong></dt>
<dd>[int &gt;= 0] The frame to output the thumbnail</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>A <code><a title="vipy.image.Image" href="image.html#vipy.image.Image">Image</a></code> object for frame k.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1584-L1597" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def thumbnail(self, outfile=None, frame=0):
    &#34;&#34;&#34;Return annotated frame=k of video, save annotation visualization to provided outfile.

    This is functionally equivalent to `vipy.video.Video.frame` with an additional outfile argument to easily save an annotated thumbnail image.

    Args:
        outfile: [str] an optional outfile to save the annotated frame 
        frame: [int &gt;= 0] The frame to output the thumbnail

    Returns:
        A `vipy.image.Image` object for frame k.  
    &#34;&#34;&#34;
    im = self.frame(frame, img=self.preview(frame).array())
    return im.savefig(outfile) if outfile is not None else im</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.tonumpy"><code class="name flex">
<span>def <span class="ident">tonumpy</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Alias for numpy()</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1270-L1272" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def tonumpy(self):
    &#34;&#34;&#34;Alias for numpy()&#34;&#34;&#34;
    return self.numpy()</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.torch"><code class="name flex">
<span>def <span class="ident">torch</span></span>(<span>self, startframe=0, endframe=None, length=None, stride=1, take=None, boundary='repeat', order='nchw', verbose=False, withslice=False, scale=1.0, withlabel=False, nonelabel=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Convert the loaded video of shape NxHxWxC frames to an MxCxHxW torch tensor/</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>startframe</code></strong></dt>
<dd>[int &gt;= 0] The start frame of the loaded video to use for constructig the torch tensor</dd>
<dt><strong><code>endframe</code></strong></dt>
<dd>[int &gt;= 0] The end frame of the loaded video to use for constructing the torch tensor</dd>
<dt><strong><code>length</code></strong></dt>
<dd>[int &gt;= 0] The length of the torch tensor if endframe is not provided. </dd>
<dt><strong><code>stride</code></strong></dt>
<dd>[int &gt;= 1] The temporal stride in frames.
This is the number of frames to skip.</dd>
<dt><strong><code>take</code></strong></dt>
<dd>[int &gt;= 0]
The number of uniformly spaced frames to include in the tensor.
</dd>
<dt><strong><code>boundary</code></strong></dt>
<dd>['repeat', 'cyclic'] The boundary handling for when the requested tensor slice goes beyond the end of the video</dd>
<dt><strong><code>order</code></strong></dt>
<dd>['nchw', 'nhwc', 'chwn', 'cnhw']
The axis ordering of the returned torch tensor N=number of frames (batchsize), C=channels, H=height, W=width</dd>
<dt>verbose [bool]: Print out the slice used for contructing tensor</dt>
<dt><strong><code>withslice</code></strong></dt>
<dd>[bool] Return a tuple (tensor, slice) that includes the slice used to construct the tensor.
Useful for data provenance.</dd>
<dt><strong><code>scale</code></strong></dt>
<dd>[float] An optional scale factor to apply to the tensor. Useful for converting [0,255] -&gt; [0,1]</dd>
<dt><strong><code>withlabel</code></strong></dt>
<dd>[bool] Return a tuple (tensor, labels) that includes the N framewise activity labels.
</dd>
<dt><strong><code>nonelabel</code></strong></dt>
<dd>[bool] returns tuple (t, None) if withlabel=False</dd>
</dl>
<p>Returns
Returns torch float tensor, analogous to torchvision.transforms.ToTensor()
<br>
Return (tensor, slice) if withslice=True (withslice takes precedence)
Returns (tensor, labellist) if withlabel=True</p>
<div class="admonition notes">
<p class="admonition-title">Notes</p>
<ul>
<li>This triggers a load() of the video</li>
<li>The precedence of arguments is (startframe, endframe) or (startframe, startframe+length), then stride and take.</li>
<li>Follows numpy slicing rules.
Optionally return the slice used if withslice=True</li>
</ul>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2154-L2255" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def torch(self, startframe=0, endframe=None, length=None, stride=1, take=None, boundary=&#39;repeat&#39;, order=&#39;nchw&#39;, verbose=False, withslice=False, scale=1.0, withlabel=False, nonelabel=False):
    &#34;&#34;&#34;Convert the loaded video of shape NxHxWxC frames to an MxCxHxW torch tensor/

    Args:
        startframe: [int &gt;= 0] The start frame of the loaded video to use for constructig the torch tensor
        endframe: [int &gt;= 0] The end frame of the loaded video to use for constructing the torch tensor
        length: [int &gt;= 0] The length of the torch tensor if endframe is not provided. 
        stride: [int &gt;= 1] The temporal stride in frames.  This is the number of frames to skip.
        take: [int &gt;= 0]  The number of uniformly spaced frames to include in the tensor.  
        boundary: [&#39;repeat&#39;, &#39;cyclic&#39;] The boundary handling for when the requested tensor slice goes beyond the end of the video
        order: [&#39;nchw&#39;, &#39;nhwc&#39;, &#39;chwn&#39;, &#39;cnhw&#39;]  The axis ordering of the returned torch tensor N=number of frames (batchsize), C=channels, H=height, W=width
        verbose [bool]: Print out the slice used for contructing tensor
        withslice: [bool] Return a tuple (tensor, slice) that includes the slice used to construct the tensor.  Useful for data provenance.
        scale: [float] An optional scale factor to apply to the tensor. Useful for converting [0,255] -&gt; [0,1]
        withlabel: [bool] Return a tuple (tensor, labels) that includes the N framewise activity labels.  
        nonelabel: [bool] returns tuple (t, None) if withlabel=False

    Returns
        Returns torch float tensor, analogous to torchvision.transforms.ToTensor()           
        Return (tensor, slice) if withslice=True (withslice takes precedence)
        Returns (tensor, labellist) if withlabel=True

    .. notes::
        - This triggers a load() of the video
        - The precedence of arguments is (startframe, endframe) or (startframe, startframe+length), then stride and take.
        - Follows numpy slicing rules.  Optionally return the slice used if withslice=True
    &#34;&#34;&#34;
    try_import(&#39;torch&#39;); import torch
    frames = self.load().numpy() if self.load().numpy().ndim == 4 else np.expand_dims(self.load().numpy(), 3)  # NxHxWx(C=1, C=3)
    assert boundary in [&#39;repeat&#39;, &#39;strict&#39;, &#39;cyclic&#39;], &#34;Invalid boundary mode - must be in [&#39;repeat&#39;, &#39;strict&#39;, &#39;cyclic&#39;]&#34;

    # Slice index (i=start (zero-indexed), j=end (non-inclusive), k=step)
    (i,j,k) = (startframe, endframe, stride)
    if startframe == &#39;random&#39;:
        assert length is not None, &#34;Random start frame requires fixed length&#34;
        i = max(0, np.random.randint(len(frames)-length+1))
    if endframe is not None:
        assert length is None, &#34;Cannot specify both endframe and length&#34;                        
        assert endframe &gt; startframe, &#34;End frame must be greater than start frame&#34;
        (j,k) = (endframe, 1)
    if length is not None:
        assert endframe is None, &#34;Cannot specify both endframe and length&#34;
        assert length &gt;= 0, &#34;Length must be positive&#34;
        (j,k) = (i+length, 1)
    if length is None and endframe is None:
        j = len(frames)  # use them all
    if stride != 1:
        assert take is None, &#34;Cannot specify both take and stride&#34;
        assert stride &gt;= 1, &#34;Stride must be &gt;= 1&#34;
        k = stride
    if take is not None:
        # Uniformly sampled frames to result in len(frames)=take
        assert stride == 1, &#34;Cannot specify both take and stride&#34;
        assert take &lt;= len(frames), &#34;Take must be less than the number of frames&#34;
        k = int(np.ceil(len(frames)/float(take)))

    # Boundary handling
    assert i &gt;= 0, &#34;Start frame must be &gt;= 0&#34;
    assert i &lt; j, &#34;Start frame must be less then end frame&#34;
    assert k &lt;= len(frames), &#34;Stride must be &lt;= len(frames)&#34;
    n = len(frames)  # true video length for labels
    if boundary == &#39;repeat&#39; and j &gt; len(frames):
        for d in range(j-len(frames)):
            frames = np.concatenate( (frames, np.expand_dims(frames[-1], 0) ))
    elif boundary == &#39;cyclic&#39; and j &gt; len(frames):
        for d in range(j-len(frames)):
            frames = np.concatenate( (frames, np.expand_dims(frames[j % len(frames)], 0) ))
    assert j &lt;= len(frames), &#34;invalid slice=%s for frame shape=%s&#34; % (str((i,j,k)), str(frames.shape))
    if verbose:
        print(&#39;[vipy.video.torch]: slice (start,end,step)=%s for frame shape (N,C,H,W)=%s&#39; % (str((i,j,k)), str(frames.shape)))

    # Slice and transpose to torch tensor axis ordering
    t = torch.from_numpy(frames[i:j:k] if (k!=1 or i!=0 or j!=len(frames)) else frames)  # do not copy - This shares the numpy buffer of the video, be careful!
    if t.dim() == 2:
        t = t.unsqueeze(0).unsqueeze(-1)  # HxW -&gt; (N=1)xHxWx(C=1)
    if order == &#39;nchw&#39;:
        t = t.permute(0,3,1,2)  # NxCxHxW, view
    elif order == &#39;nhwc&#39;:
        pass  # NxHxWxC  (native numpy order)
    elif order == &#39;cnhw&#39; or order == &#39;cdhw&#39;:
        t = t.permute(3,0,1,2)  # CxNxHxW == CxDxHxW (for torch conv3d), view
    elif order == &#39;chwn&#39;:
        t = t.permute(3,1,2,0)  # CxHxWxN, view
    else:
        raise ValueError(&#34;Invalid order = must be in [&#39;nchw&#39;, &#39;nhwc&#39;, &#39;chwn&#39;, &#39;cnhw&#39;]&#34;)
        
    # Scaling (optional)
    if scale is not None and self.colorspace() != &#39;float&#39;:
        t = (1.0/255.0)*t  # [0,255] -&gt; [0,1]
    elif scale is not None and scale != 1.0:
        t = scale*t

    # Return tensor or (tensor, slice) or (tensor, labels)
    if withslice:
        return (t, (i,j,k))
    elif withlabel:            
        labels = [sorted(tuple(self.activitylabels( (f%n) if boundary == &#39;cyclic&#39; else min(f, n-1) ))) for f in range(i,j,k)]
        return (t, labels)
    elif nonelabel:
        return (t, None)
    else:
        return t</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.unstore"><code class="name flex">
<span>def <span class="ident">unstore</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Delete the currently stored video from `vipy.video.Video.store</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L691-L693" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def unstore(self):
    &#34;&#34;&#34;Delete the currently stored video from `vipy.video.Video.store&#34;&#34;&#34;
    return self.delattribute(&#39;__video__&#39;)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.url"><code class="name flex">
<span>def <span class="ident">url</span></span>(<span>self, url=None, username=None, password=None, sha1=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Video URL and URL download properties</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1136-L1151" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def url(self, url=None, username=None, password=None, sha1=None):
    &#34;&#34;&#34;Video URL and URL download properties&#34;&#34;&#34;
    if url is not None:
        self._url = url  # note that this does not change anything else, better to use the constructor for this
    if url is not None and (isRTSPurl(url) or isRTMPurl(url)):
        self.filename(self._url) 
    if username is not None:
        self._urluser = username  # basic authentication
    if password is not None:
        self._urlpassword = password  # basic authentication
    if sha1 is not None:
        self._urlsha1 = sha1  # file integrity
    if url is None and username is None and password is None and sha1 is None:
        return self._url
    else:
        return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.videoid"><code class="name flex">
<span>def <span class="ident">videoid</span></span>(<span>self, newid=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Return a unique video identifier for this video, as specified in the 'video_id' attribute, or by SHA1 hash of the <code><a title="vipy.video.Video.filename" href="#vipy.video.Video.filename">Video.filename()</a></code> and <code><a title="vipy.video.Video.url" href="#vipy.video.Video.url">Video.url()</a></code>.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>newid</code></strong></dt>
<dd>[str] If not None, then update the video_id as newid. </dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul>
<li>If the video filename changes (e.g. from transformation), and video_id is not set in self.attributes, then the video ID will change.</li>
<li>If a video does not have a filename or URL or a video ID in the attributes, then this will return None</li>
<li>To preserve a video ID independent of transformations, set self.setattribute('video_id', ${MY_ID}), or pass in newid</li>
</ul>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L634-L652" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def videoid(self, newid=None):
    &#34;&#34;&#34;Return a unique video identifier for this video, as specified in the &#39;video_id&#39; attribute, or by SHA1 hash of the `vipy.video.Video.filename` and `vipy.video.Video.url`.

    Args:
        newid: [str] If not None, then update the video_id as newid. 

    Returns:
        The video ID if newid=None else self

    .. note::
        - If the video filename changes (e.g. from transformation), and video_id is not set in self.attributes, then the video ID will change.
        - If a video does not have a filename or URL or a video ID in the attributes, then this will return None
        - To preserve a video ID independent of transformations, set self.setattribute(&#39;video_id&#39;, ${MY_ID}), or pass in newid
    &#34;&#34;&#34;
    if newid is not None:
        self.setattribute(&#39;video_id&#39;, newid)
        return self
    else:
        return self.attributes[&#39;video_id&#39;] if &#39;video_id&#39; in self.attributes else (hashlib.sha1(str(str(self.filename())+str(self.url())).encode(&#34;UTF-8&#34;)).hexdigest() if (self.filename() is not None or self.url() is not None) else None)</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.webp"><code class="name flex">
<span>def <span class="ident">webp</span></span>(<span>self, outfile=None, pause=3, strict=True, smallest=False, smaller=False, framerate=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Save a video to an animated WEBP file, with pause=N seconds on the last frame between loops.
</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>strict</code></strong></dt>
<dd>If true, assert that the filename must have an .webp extension</dd>
<dt><strong><code>pause</code></strong></dt>
<dd>Integer seconds to pause between loops of the animation</dd>
<dt><strong><code>smallest</code></strong></dt>
<dd>if true, create the smallest possible file but takes much longer to run</dd>
<dt><strong><code>smaller</code></strong></dt>
<dd>If true, create a smaller file, which takes a little longer to run </dd>
</dl>
<p>framerate [float]:
The output framerate of the webp file.
The default is the framerate of the video. </p>
<div class="admonition warning">
<p class="admonition-title">Warning:&ensp;This may be slow for very long or large videos</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1931-L1953" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def webp(self, outfile=None, pause=3, strict=True, smallest=False, smaller=False, framerate=None):
    &#34;&#34;&#34;Save a video to an animated WEBP file, with pause=N seconds on the last frame between loops.  
    
    Args:
        strict: If true, assert that the filename must have an .webp extension
        pause: Integer seconds to pause between loops of the animation
        smallest:  if true, create the smallest possible file but takes much longer to run
        smaller:  If true, create a smaller file, which takes a little longer to run 
        framerate [float]:  The output framerate of the webp file.  The default is the framerate of the video. 

    Returns:
        The filename of the webp file for this video

    .. warning::  This may be slow for very long or large videos
    &#34;&#34;&#34;
    outfile = vipy.util.tempWEBP() if outfile is None else outfile        
    assert strict is False or iswebp(outfile)
    outfile = os.path.normpath(os.path.abspath(os.path.expanduser(outfile)))
    framerate = framerate if framerate is not None else self._framerate
    self.load().frame(0).pil().save(outfile, loop=0, save_all=True, method=6 if smallest else 3 if smaller else 0,
                                    append_images=[self.frame(k).pil() for k in range(1, len(self))],
                                    duration=[int(1000.0/framerate) for k in range(0, len(self)-1)] + [pause*1000])
    return outfile</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.width"><code class="name flex">
<span>def <span class="ident">width</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Width (cols) in pixels of the video for the current filter chain</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1532-L1534" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def width(self):
    &#34;&#34;&#34;Width (cols) in pixels of the video for the current filter chain&#34;&#34;&#34;
    return self.shape()[1]</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.zeropad"><code class="name flex">
<span>def <span class="ident">zeropad</span></span>(<span>self, padwidth, padheight)</span>
</code></dt>
<dd>
<div class="desc"><p>Zero pad the video with padwidth columns before and after, and padheight rows before and after</p>
<div class="admonition notes">
<p class="admonition-title">Notes:&ensp;Older FFMPEG implementations can throw the error "Input area #:#:#:# not within the padded area #:#:#:# or zero-sized, this is often caused by odd sized padding. </p>
<p>Recommend calling self.cropeven().zeropad(&hellip;) to avoid this</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1866-L1879" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def zeropad(self, padwidth, padheight):
    &#34;&#34;&#34;Zero pad the video with padwidth columns before and after, and padheight rows before and after
       
    .. notes:: Older FFMPEG implementations can throw the error &#34;Input area #:#:#:# not within the padded area #:#:#:# or zero-sized, this is often caused by odd sized padding. 
         Recommend calling self.cropeven().zeropad(...) to avoid this

    &#34;&#34;&#34;
    assert isinstance(padwidth, int) and isinstance(padheight, int)        
    if not self.isloaded():
        self.shape(shape=(self.height()+2*padheight, self.width()+2*padwidth))  # manually set shape to avoid preview            
        self._ffmpeg = self._ffmpeg.filter(&#39;pad&#39;, &#39;iw+%d&#39; % (2*padwidth), &#39;ih+%d&#39; % (2*padheight), &#39;%d&#39;%padwidth, &#39;%d&#39;%padheight)
    elif padwidth &gt; 0 or padheight &gt; 0:
        self.array( np.pad(self.array(), ((0,0), (padheight,padheight), (padwidth,padwidth), (0,0)), mode=&#39;constant&#39;), copy=False)  # this is very expensive, since np.pad() must copy (once in np.pad &gt;=1.17)            
    return self</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.zeropadlike"><code class="name flex">
<span>def <span class="ident">zeropadlike</span></span>(<span>self, width, height)</span>
</code></dt>
<dd>
<div class="desc"><p>Zero pad the video balancing the border so that the resulting video size is (width, height).</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1885-L1891" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def zeropadlike(self, width, height):
    &#34;&#34;&#34;Zero pad the video balancing the border so that the resulting video size is (width, height).&#34;&#34;&#34;
    assert width &gt;= self.width() and height &gt;= self.height(), &#34;Invalid input - final (width=%d, height=%d) must be greater than current image size (width=%d, height=%d)&#34; % (width, height, self.width(), self.height())
    assert int(np.floor((width - self.width())/2)) == int(np.ceil((width - self.width())/2)), &#34;Zero pad must be symmetric, this is often due to odd zeropadding which ffmpeg doesn&#39;t like.  Try changing the width +/- 1 pixel&#34;
    assert int(np.floor((height - self.height())/2)) == int(np.ceil((height - self.height())/2)), &#34;Zero pad must be symmetric, this is often due to odd zeropadding which ffmpeg doesn&#39;t like.  Try changing the height +/- 1 pixel&#34;        
    return self.zeropad(int(np.floor((width - self.width())/2)),
                        int(np.floor((height - self.height())/2)))</code></pre>
</details>
</dd>
<dt id="vipy.video.Video.zeros"><code class="name flex">
<span>def <span class="ident">zeros</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L1292-L1294" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def zeros(self):
    self._array = 0*self.load()._array
    return self</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="vipy.video.VideoCategory"><code class="flex name class">
<span>class <span class="ident">VideoCategory</span></span>
<span>(</span><span>filename=None, url=None, framerate=30.0, attributes=None, category=None, array=None, colorspace=None, startframe=None, endframe=None, startsec=None, endsec=None)</span>
</code></dt>
<dd>
<div class="desc"><p>vipy.video.VideoCategory class</p>
<p>A VideoCategory is a video with associated category, such as an activity class.
This class includes all of the constructors of vipy.video.Video
along with the ability to extract a clip based on frames or seconds.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2416-L2461" class="git-link">Browse git</a>
</summary>
<pre><code class="python">class VideoCategory(Video):
    &#34;&#34;&#34;vipy.video.VideoCategory class

    A VideoCategory is a video with associated category, such as an activity class.  This class includes all of the constructors of vipy.video.Video 
    along with the ability to extract a clip based on frames or seconds.

    &#34;&#34;&#34;
    def __init__(self, filename=None, url=None, framerate=30.0, attributes=None, category=None, array=None, colorspace=None, startframe=None, endframe=None, startsec=None, endsec=None):
        super().__init__(url=url, filename=filename, framerate=framerate, attributes=attributes, array=array, colorspace=colorspace,
                                            startframe=startframe, endframe=endframe, startsec=startsec, endsec=endsec)
        self._category = category                

    @classmethod
    def from_json(cls, s):
        d = json.loads(s) if not isinstance(s, dict) else s                        
        v = super().from_json(s)
        v._category = d[&#39;_category&#39;]
        return v
        
    def __repr__(self):
        strlist = []
        if self.isloaded():
            strlist.append(&#34;height=%d, width=%d, frames=%d&#34; % (self._array[0].shape[0], self._array[0].shape[1], len(self._array)))
        if self.filename() is not None:
            strlist.append(&#39;filename=&#34;%s&#34;&#39; % self.filename())
        if self.hasurl():
            strlist.append(&#39;url=&#34;%s&#34;&#39; % self.url())
        if self.category() is not None:
            strlist.append(&#39;category=&#34;%s&#34;&#39; % self.category())
        if not self.isloaded() and self._startframe is not None and self._endframe is not None:
            strlist.append(&#39;clip=(%d,%d)&#39; % (self._startframe, self._endframe))
        if not self.isloaded() and self._startframe is not None and self._endframe is None:
            strlist.append(&#39;clip=(%d,)&#39; % (self._startframe))
        return str(&#39;&lt;vipy.video.VideoCategory: %s&gt;&#39; % (&#39;, &#39;.join(strlist)))

    def json(self, encode=True):
        d = json.loads(super().json())
        d[&#39;_category&#39;] = self._category
        return json.dumps(d) if encode else d
    
    def category(self, c=None):
        if c is None:
            return self._category
        else:
            self._category = c
            return self</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="vipy.video.Scene" href="#vipy.video.Scene">Scene</a></li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="vipy.video.VideoCategory.category"><code class="name flex">
<span>def <span class="ident">category</span></span>(<span>self, c=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
<a href="https://github.com/visym/vipy/blob/cd532e4721b5b9fb6278a4c5653f921180c16fee/vipy/video.py#L2456-L2461" class="git-link">Browse git</a>
</summary>
<pre><code class="python">def category(self, c=None):
    if c is None:
        return self._category
    else:
        self._category = c
        return self</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></b></code>:
<ul class="hlist">
<li><code><a title="vipy.video.Video.abspath" href="#vipy.video.Video.abspath">abspath</a></code></li>
<li><code><a title="vipy.video.Video.array" href="#vipy.video.Video.array">array</a></code></li>
<li><code><a title="vipy.video.Video.aspect_ratio" href="#vipy.video.Video.aspect_ratio">aspect_ratio</a></code></li>
<li><code><a title="vipy.video.Video.bias" href="#vipy.video.Video.bias">bias</a></code></li>
<li><code><a title="vipy.video.Video.bytes" href="#vipy.video.Video.bytes">bytes</a></code></li>
<li><code><a title="vipy.video.Video.canload" href="#vipy.video.Video.canload">canload</a></code></li>
<li><code><a title="vipy.video.Video.cast" href="#vipy.video.Video.cast">cast</a></code></li>
<li><code><a title="vipy.video.Video.centercrop" href="#vipy.video.Video.centercrop">centercrop</a></code></li>
<li><code><a title="vipy.video.Video.centersquare" href="#vipy.video.Video.centersquare">centersquare</a></code></li>
<li><code><a title="vipy.video.Video.channels" href="#vipy.video.Video.channels">channels</a></code></li>
<li><code><a title="vipy.video.Video.channelshape" href="#vipy.video.Video.channelshape">channelshape</a></code></li>
<li><code><a title="vipy.video.Video.clear" href="#vipy.video.Video.clear">clear</a></code></li>
<li><code><a title="vipy.video.Video.clip" href="#vipy.video.Video.clip">clip</a></code></li>
<li><code><a title="vipy.video.Video.cliprange" href="#vipy.video.Video.cliprange">cliprange</a></code></li>
<li><code><a title="vipy.video.Video.clone" href="#vipy.video.Video.clone">clone</a></code></li>
<li><code><a title="vipy.video.Video.colorspace" href="#vipy.video.Video.colorspace">colorspace</a></code></li>
<li><code><a title="vipy.video.Video.commandline" href="#vipy.video.Video.commandline">commandline</a></code></li>
<li><code><a title="vipy.video.Video.concatenate" href="#vipy.video.Video.concatenate">concatenate</a></code></li>
<li><code><a title="vipy.video.Video.crop" href="#vipy.video.Video.crop">crop</a></code></li>
<li><code><a title="vipy.video.Video.cropeven" href="#vipy.video.Video.cropeven">cropeven</a></code></li>
<li><code><a title="vipy.video.Video.dict" href="#vipy.video.Video.dict">dict</a></code></li>
<li><code><a title="vipy.video.Video.download" href="#vipy.video.Video.download">download</a></code></li>
<li><code><a title="vipy.video.Video.downloadif" href="#vipy.video.Video.downloadif">downloadif</a></code></li>
<li><code><a title="vipy.video.Video.duration" href="#vipy.video.Video.duration">duration</a></code></li>
<li><code><a title="vipy.video.Video.duration_in_frames" href="#vipy.video.Video.duration_in_frames">duration_in_frames</a></code></li>
<li><code><a title="vipy.video.Video.duration_in_frames_of_videofile" href="#vipy.video.Video.duration_in_frames_of_videofile">duration_in_frames_of_videofile</a></code></li>
<li><code><a title="vipy.video.Video.duration_in_seconds_of_videofile" href="#vipy.video.Video.duration_in_seconds_of_videofile">duration_in_seconds_of_videofile</a></code></li>
<li><code><a title="vipy.video.Video.fetch" href="#vipy.video.Video.fetch">fetch</a></code></li>
<li><code><a title="vipy.video.Video.ffplay" href="#vipy.video.Video.ffplay">ffplay</a></code></li>
<li><code><a title="vipy.video.Video.filename" href="#vipy.video.Video.filename">filename</a></code></li>
<li><code><a title="vipy.video.Video.filesize" href="#vipy.video.Video.filesize">filesize</a></code></li>
<li><code><a title="vipy.video.Video.fliplr" href="#vipy.video.Video.fliplr">fliplr</a></code></li>
<li><code><a title="vipy.video.Video.flipud" href="#vipy.video.Video.flipud">flipud</a></code></li>
<li><code><a title="vipy.video.Video.flush" href="#vipy.video.Video.flush">flush</a></code></li>
<li><code><a title="vipy.video.Video.flush_and_return" href="#vipy.video.Video.flush_and_return">flush_and_return</a></code></li>
<li><code><a title="vipy.video.Video.frame" href="#vipy.video.Video.frame">frame</a></code></li>
<li><code><a title="vipy.video.Video.framerate" href="#vipy.video.Video.framerate">framerate</a></code></li>
<li><code><a title="vipy.video.Video.framerate_of_videofile" href="#vipy.video.Video.framerate_of_videofile">framerate_of_videofile</a></code></li>
<li><code><a title="vipy.video.Video.frames" href="#vipy.video.Video.frames">frames</a></code></li>
<li><code><a title="vipy.video.Video.from_json" href="#vipy.video.Video.from_json">from_json</a></code></li>
<li><code><a title="vipy.video.Video.fromarray" href="#vipy.video.Video.fromarray">fromarray</a></code></li>
<li><code><a title="vipy.video.Video.fromdirectory" href="#vipy.video.Video.fromdirectory">fromdirectory</a></code></li>
<li><code><a title="vipy.video.Video.fromframes" href="#vipy.video.Video.fromframes">fromframes</a></code></li>
<li><code><a title="vipy.video.Video.gain" href="#vipy.video.Video.gain">gain</a></code></li>
<li><code><a title="vipy.video.Video.gif" href="#vipy.video.Video.gif">gif</a></code></li>
<li><code><a title="vipy.video.Video.hasattribute" href="#vipy.video.Video.hasattribute">hasattribute</a></code></li>
<li><code><a title="vipy.video.Video.hasfilename" href="#vipy.video.Video.hasfilename">hasfilename</a></code></li>
<li><code><a title="vipy.video.Video.hasurl" href="#vipy.video.Video.hasurl">hasurl</a></code></li>
<li><code><a title="vipy.video.Video.height" href="#vipy.video.Video.height">height</a></code></li>
<li><code><a title="vipy.video.Video.iscolor" href="#vipy.video.Video.iscolor">iscolor</a></code></li>
<li><code><a title="vipy.video.Video.isdownloaded" href="#vipy.video.Video.isdownloaded">isdownloaded</a></code></li>
<li><code><a title="vipy.video.Video.isgrayscale" href="#vipy.video.Video.isgrayscale">isgrayscale</a></code></li>
<li><code><a title="vipy.video.Video.isloadable" href="#vipy.video.Video.isloadable">isloadable</a></code></li>
<li><code><a title="vipy.video.Video.isloaded" href="#vipy.video.Video.isloaded">isloaded</a></code></li>
<li><code><a title="vipy.video.Video.issquare" href="#vipy.video.Video.issquare">issquare</a></code></li>
<li><code><a title="vipy.video.Video.json" href="#vipy.video.Video.json">json</a></code></li>
<li><code><a title="vipy.video.Video.load" href="#vipy.video.Video.load">load</a></code></li>
<li><code><a title="vipy.video.Video.map" href="#vipy.video.Video.map">map</a></code></li>
<li><code><a title="vipy.video.Video.maxdim" href="#vipy.video.Video.maxdim">maxdim</a></code></li>
<li><code><a title="vipy.video.Video.maxmatte" href="#vipy.video.Video.maxmatte">maxmatte</a></code></li>
<li><code><a title="vipy.video.Video.maxsquare" href="#vipy.video.Video.maxsquare">maxsquare</a></code></li>
<li><code><a title="vipy.video.Video.metadata" href="#vipy.video.Video.metadata">metadata</a></code></li>
<li><code><a title="vipy.video.Video.mindim" href="#vipy.video.Video.mindim">mindim</a></code></li>
<li><code><a title="vipy.video.Video.minsquare" href="#vipy.video.Video.minsquare">minsquare</a></code></li>
<li><code><a title="vipy.video.Video.mutable" href="#vipy.video.Video.mutable">mutable</a></code></li>
<li><code><a title="vipy.video.Video.normalize" href="#vipy.video.Video.normalize">normalize</a></code></li>
<li><code><a title="vipy.video.Video.nourl" href="#vipy.video.Video.nourl">nourl</a></code></li>
<li><code><a title="vipy.video.Video.numpy" href="#vipy.video.Video.numpy">numpy</a></code></li>
<li><code><a title="vipy.video.Video.pad" href="#vipy.video.Video.pad">pad</a></code></li>
<li><code><a title="vipy.video.Video.pkl" href="#vipy.video.Video.pkl">pkl</a></code></li>
<li><code><a title="vipy.video.Video.pklif" href="#vipy.video.Video.pklif">pklif</a></code></li>
<li><code><a title="vipy.video.Video.play" href="#vipy.video.Video.play">play</a></code></li>
<li><code><a title="vipy.video.Video.preview" href="#vipy.video.Video.preview">preview</a></code></li>
<li><code><a title="vipy.video.Video.print" href="#vipy.video.Video.print">print</a></code></li>
<li><code><a title="vipy.video.Video.probe" href="#vipy.video.Video.probe">probe</a></code></li>
<li><code><a title="vipy.video.Video.probeshape" href="#vipy.video.Video.probeshape">probeshape</a></code></li>
<li><code><a title="vipy.video.Video.quicklook" href="#vipy.video.Video.quicklook">quicklook</a></code></li>
<li><code><a title="vipy.video.Video.randomcrop" href="#vipy.video.Video.randomcrop">randomcrop</a></code></li>
<li><code><a title="vipy.video.Video.relpath" href="#vipy.video.Video.relpath">relpath</a></code></li>
<li><code><a title="vipy.video.Video.rename" href="#vipy.video.Video.rename">rename</a></code></li>
<li><code><a title="vipy.video.Video.rescale" href="#vipy.video.Video.rescale">rescale</a></code></li>
<li><code><a title="vipy.video.Video.resize" href="#vipy.video.Video.resize">resize</a></code></li>
<li><code><a title="vipy.video.Video.resolution_of_videofile" href="#vipy.video.Video.resolution_of_videofile">resolution_of_videofile</a></code></li>
<li><code><a title="vipy.video.Video.restore" href="#vipy.video.Video.restore">restore</a></code></li>
<li><code><a title="vipy.video.Video.returns" href="#vipy.video.Video.returns">returns</a></code></li>
<li><code><a title="vipy.video.Video.rot90ccw" href="#vipy.video.Video.rot90ccw">rot90ccw</a></code></li>
<li><code><a title="vipy.video.Video.rot90cw" href="#vipy.video.Video.rot90cw">rot90cw</a></code></li>
<li><code><a title="vipy.video.Video.sanitize" href="#vipy.video.Video.sanitize">sanitize</a></code></li>
<li><code><a title="vipy.video.Video.saveas" href="#vipy.video.Video.saveas">saveas</a></code></li>
<li><code><a title="vipy.video.Video.savetemp" href="#vipy.video.Video.savetemp">savetemp</a></code></li>
<li><code><a title="vipy.video.Video.savetmp" href="#vipy.video.Video.savetmp">savetmp</a></code></li>
<li><code><a title="vipy.video.Video.shape" href="#vipy.video.Video.shape">shape</a></code></li>
<li><code><a title="vipy.video.Video.show" href="#vipy.video.Video.show">show</a></code></li>
<li><code><a title="vipy.video.Video.speed" href="#vipy.video.Video.speed">speed</a></code></li>
<li><code><a title="vipy.video.Video.store" href="#vipy.video.Video.store">store</a></code></li>
<li><code><a title="vipy.video.Video.stream" href="#vipy.video.Video.stream">stream</a></code></li>
<li><code><a title="vipy.video.Video.take" href="#vipy.video.Video.take">take</a></code></li>
<li><code><a title="vipy.video.Video.thumbnail" href="#vipy.video.Video.thumbnail">thumbnail</a></code></li>
<li><code><a title="vipy.video.Video.tonumpy" href="#vipy.video.Video.tonumpy">tonumpy</a></code></li>
<li><code><a title="vipy.video.Video.torch" href="#vipy.video.Video.torch">torch</a></code></li>
<li><code><a title="vipy.video.Video.unstore" href="#vipy.video.Video.unstore">unstore</a></code></li>
<li><code><a title="vipy.video.Video.url" href="#vipy.video.Video.url">url</a></code></li>
<li><code><a title="vipy.video.Video.videoid" href="#vipy.video.Video.videoid">videoid</a></code></li>
<li><code><a title="vipy.video.Video.webp" href="#vipy.video.Video.webp">webp</a></code></li>
<li><code><a title="vipy.video.Video.width" href="#vipy.video.Video.width">width</a></code></li>
<li><code><a title="vipy.video.Video.zeropad" href="#vipy.video.Video.zeropad">zeropad</a></code></li>
<li><code><a title="vipy.video.Video.zeropadlike" href="#vipy.video.Video.zeropadlike">zeropadlike</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<header>
<a class="homelink" rel="home" title="Vipy" href="https://github.com/visym/vipy/">
<img src="https://www.visym.com/labs/images/visym_logo_black_notext.png" alt="" width="150"> <p> </p>
</a>
</header>
<form>
<input id="lunr-search" name="q" placeholder=" Search ..." aria-label="Search"
disabled minlength="2">
</form>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.css" integrity="sha512-j1u8eUJ4f23xPPxwOrLUPQaCD2dwzNqqmDDcWS4deWsMv2ohLqmXXuP3hU7g8TyzbMSakP/mMqoNBYWj8AEIFg==" crossorigin>
<script src="https://cdnjs.cloudflare.com/ajax/libs/tingle/0.15.3/tingle.min.js" integrity="sha512-plGUER9JkeEWPPqQBE4sdLqBoQug5Ap+BCGMc7bJ8BXkm+VVj6QzkpBz5Yv2yPkkq+cqg9IpkBaGCas6uDbW8g==" crossorigin></script>
<style>
.modal-dialog iframe {
width: 100vw;
height: calc(100vh - 80px);
}
@media screen and (min-width: 700px) {
.modal-dialog iframe {
width: 70vw;
height: 80vh;
}
}
.modal-dialog .tingle-modal-box {width: auto;}
.modal-dialog .tingle-modal-box__content {padding: 0;}
</style>
<script>
const input = document.getElementById('lunr-search');
input.disabled = false;
input.form.addEventListener('submit', (ev) => {
ev.preventDefault();
const url = new URL(window.location);
url.searchParams.set('q', input.value);
history.replaceState({}, null, url.toString());
search(input.value);
});
const query = new URL(window.location).searchParams.get('q');
if (query)
search(query);
function search(query) {
const url = '../doc-search.html#' + encodeURIComponent(query);
new tingle.modal({
cssClass: ['modal-dialog'],
onClose: () => {
const url = new URL(window.location);
url.searchParams.delete('q');
history.replaceState({}, null, url.toString());
setTimeout(() => input.focus(), 100);
}
}).setContent('<iframe src="' + url + '"></iframe>').open();
}
</script>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="vipy" href="index.html">vipy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="vipy.video.EmptyScene" href="#vipy.video.EmptyScene">EmptyScene</a></code></li>
<li><code><a title="vipy.video.RandomScene" href="#vipy.video.RandomScene">RandomScene</a></code></li>
<li><code><a title="vipy.video.RandomSceneActivity" href="#vipy.video.RandomSceneActivity">RandomSceneActivity</a></code></li>
<li><code><a title="vipy.video.RandomVideo" href="#vipy.video.RandomVideo">RandomVideo</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="vipy.video.Scene" href="#vipy.video.Scene">Scene</a></code></h4>
<ul class="two-column">
<li><code><a title="vipy.video.Scene.activities" href="#vipy.video.Scene.activities">activities</a></code></li>
<li><code><a title="vipy.video.Scene.activity" href="#vipy.video.Scene.activity">activity</a></code></li>
<li><code><a title="vipy.video.Scene.activity_categories" href="#vipy.video.Scene.activity_categories">activity_categories</a></code></li>
<li><code><a title="vipy.video.Scene.activitybox" href="#vipy.video.Scene.activitybox">activitybox</a></code></li>
<li><code><a title="vipy.video.Scene.activityclip" href="#vipy.video.Scene.activityclip">activityclip</a></code></li>
<li><code><a title="vipy.video.Scene.activitycuboid" href="#vipy.video.Scene.activitycuboid">activitycuboid</a></code></li>
<li><code><a title="vipy.video.Scene.activityfilter" href="#vipy.video.Scene.activityfilter">activityfilter</a></code></li>
<li><code><a title="vipy.video.Scene.activityindex" href="#vipy.video.Scene.activityindex">activityindex</a></code></li>
<li><code><a title="vipy.video.Scene.activitylabel" href="#vipy.video.Scene.activitylabel">activitylabel</a></code></li>
<li><code><a title="vipy.video.Scene.activitylabels" href="#vipy.video.Scene.activitylabels">activitylabels</a></code></li>
<li><code><a title="vipy.video.Scene.activitylist" href="#vipy.video.Scene.activitylist">activitylist</a></code></li>
<li><code><a title="vipy.video.Scene.activitymap" href="#vipy.video.Scene.activitymap">activitymap</a></code></li>
<li><code><a title="vipy.video.Scene.activitysplit" href="#vipy.video.Scene.activitysplit">activitysplit</a></code></li>
<li><code><a title="vipy.video.Scene.activitysquare" href="#vipy.video.Scene.activitysquare">activitysquare</a></code></li>
<li><code><a title="vipy.video.Scene.activitytube" href="#vipy.video.Scene.activitytube">activitytube</a></code></li>
<li><code><a title="vipy.video.Scene.actor" href="#vipy.video.Scene.actor">actor</a></code></li>
<li><code><a title="vipy.video.Scene.actorid" href="#vipy.video.Scene.actorid">actorid</a></code></li>
<li><code><a title="vipy.video.Scene.actortube" href="#vipy.video.Scene.actortube">actortube</a></code></li>
<li><code><a title="vipy.video.Scene.add" href="#vipy.video.Scene.add">add</a></code></li>
<li><code><a title="vipy.video.Scene.addframe" href="#vipy.video.Scene.addframe">addframe</a></code></li>
<li><code><a title="vipy.video.Scene.annotate" href="#vipy.video.Scene.annotate">annotate</a></code></li>
<li><code><a title="vipy.video.Scene.annotation" href="#vipy.video.Scene.annotation">annotation</a></code></li>
<li><code><a title="vipy.video.Scene.asfloatmask" href="#vipy.video.Scene.asfloatmask">asfloatmask</a></code></li>
<li><code><a title="vipy.video.Scene.asjson" href="#vipy.video.Scene.asjson">asjson</a></code></li>
<li><code><a title="vipy.video.Scene.assign" href="#vipy.video.Scene.assign">assign</a></code></li>
<li><code><a title="vipy.video.Scene.binarymask" href="#vipy.video.Scene.binarymask">binarymask</a></code></li>
<li><code><a title="vipy.video.Scene.blurmask" href="#vipy.video.Scene.blurmask">blurmask</a></code></li>
<li><code><a title="vipy.video.Scene.cast" href="#vipy.video.Scene.cast">cast</a></code></li>
<li><code><a title="vipy.video.Scene.categories" href="#vipy.video.Scene.categories">categories</a></code></li>
<li><code><a title="vipy.video.Scene.clear" href="#vipy.video.Scene.clear">clear</a></code></li>
<li><code><a title="vipy.video.Scene.clearactivities" href="#vipy.video.Scene.clearactivities">clearactivities</a></code></li>
<li><code><a title="vipy.video.Scene.cleartracks" href="#vipy.video.Scene.cleartracks">cleartracks</a></code></li>
<li><code><a title="vipy.video.Scene.clip" href="#vipy.video.Scene.clip">clip</a></code></li>
<li><code><a title="vipy.video.Scene.combine" href="#vipy.video.Scene.combine">combine</a></code></li>
<li><code><a title="vipy.video.Scene.crop" href="#vipy.video.Scene.crop">crop</a></code></li>
<li><code><a title="vipy.video.Scene.csv" href="#vipy.video.Scene.csv">csv</a></code></li>
<li><code><a title="vipy.video.Scene.dedupe" href="#vipy.video.Scene.dedupe">dedupe</a></code></li>
<li><code><a title="vipy.video.Scene.delete" href="#vipy.video.Scene.delete">delete</a></code></li>
<li><code><a title="vipy.video.Scene.downcast" href="#vipy.video.Scene.downcast">downcast</a></code></li>
<li><code><a title="vipy.video.Scene.during" href="#vipy.video.Scene.during">during</a></code></li>
<li><code><a title="vipy.video.Scene.extrapolate" href="#vipy.video.Scene.extrapolate">extrapolate</a></code></li>
<li><code><a title="vipy.video.Scene.fgmask" href="#vipy.video.Scene.fgmask">fgmask</a></code></li>
<li><code><a title="vipy.video.Scene.first_activity" href="#vipy.video.Scene.first_activity">first_activity</a></code></li>
<li><code><a title="vipy.video.Scene.frame" href="#vipy.video.Scene.frame">frame</a></code></li>
<li><code><a title="vipy.video.Scene.framebox" href="#vipy.video.Scene.framebox">framebox</a></code></li>
<li><code><a title="vipy.video.Scene.framecomposite" href="#vipy.video.Scene.framecomposite">framecomposite</a></code></li>
<li><code><a title="vipy.video.Scene.framerate" href="#vipy.video.Scene.framerate">framerate</a></code></li>
<li><code><a title="vipy.video.Scene.from_json" href="#vipy.video.Scene.from_json">from_json</a></code></li>
<li><code><a title="vipy.video.Scene.hasactivities" href="#vipy.video.Scene.hasactivities">hasactivities</a></code></li>
<li><code><a title="vipy.video.Scene.hasactivity" href="#vipy.video.Scene.hasactivity">hasactivity</a></code></li>
<li><code><a title="vipy.video.Scene.hastrack" href="#vipy.video.Scene.hastrack">hastrack</a></code></li>
<li><code><a title="vipy.video.Scene.hastracks" href="#vipy.video.Scene.hastracks">hastracks</a></code></li>
<li><code><a title="vipy.video.Scene.instanceid" href="#vipy.video.Scene.instanceid">instanceid</a></code></li>
<li><code><a title="vipy.video.Scene.isdegenerate" href="#vipy.video.Scene.isdegenerate">isdegenerate</a></code></li>
<li><code><a title="vipy.video.Scene.json" href="#vipy.video.Scene.json">json</a></code></li>
<li><code><a title="vipy.video.Scene.label" href="#vipy.video.Scene.label">label</a></code></li>
<li><code><a title="vipy.video.Scene.labeled_frames" href="#vipy.video.Scene.labeled_frames">labeled_frames</a></code></li>
<li><code><a title="vipy.video.Scene.labels" href="#vipy.video.Scene.labels">labels</a></code></li>
<li><code><a title="vipy.video.Scene.last_activity" href="#vipy.video.Scene.last_activity">last_activity</a></code></li>
<li><code><a title="vipy.video.Scene.meanmask" href="#vipy.video.Scene.meanmask">meanmask</a></code></li>
<li><code><a title="vipy.video.Scene.merge_tracks" href="#vipy.video.Scene.merge_tracks">merge_tracks</a></code></li>
<li><code><a title="vipy.video.Scene.next_activity" href="#vipy.video.Scene.next_activity">next_activity</a></code></li>
<li><code><a title="vipy.video.Scene.noactivityclip" href="#vipy.video.Scene.noactivityclip">noactivityclip</a></code></li>
<li><code><a title="vipy.video.Scene.noactivitylist" href="#vipy.video.Scene.noactivitylist">noactivitylist</a></code></li>
<li><code><a title="vipy.video.Scene.objectlabels" href="#vipy.video.Scene.objectlabels">objectlabels</a></code></li>
<li><code><a title="vipy.video.Scene.objects" href="#vipy.video.Scene.objects">objects</a></code></li>
<li><code><a title="vipy.video.Scene.pack" href="#vipy.video.Scene.pack">pack</a></code></li>
<li><code><a title="vipy.video.Scene.pixelate" href="#vipy.video.Scene.pixelate">pixelate</a></code></li>
<li><code><a title="vipy.video.Scene.pixelize" href="#vipy.video.Scene.pixelize">pixelize</a></code></li>
<li><code><a title="vipy.video.Scene.pixelmask" href="#vipy.video.Scene.pixelmask">pixelmask</a></code></li>
<li><code><a title="vipy.video.Scene.prev_activity" href="#vipy.video.Scene.prev_activity">prev_activity</a></code></li>
<li><code><a title="vipy.video.Scene.primary_activity" href="#vipy.video.Scene.primary_activity">primary_activity</a></code></li>
<li><code><a title="vipy.video.Scene.quicklook" href="#vipy.video.Scene.quicklook">quicklook</a></code></li>
<li><code><a title="vipy.video.Scene.rekey" href="#vipy.video.Scene.rekey">rekey</a></code></li>
<li><code><a title="vipy.video.Scene.replace" href="#vipy.video.Scene.replace">replace</a></code></li>
<li><code><a title="vipy.video.Scene.rescale" href="#vipy.video.Scene.rescale">rescale</a></code></li>
<li><code><a title="vipy.video.Scene.resize" href="#vipy.video.Scene.resize">resize</a></code></li>
<li><code><a title="vipy.video.Scene.setactorid" href="#vipy.video.Scene.setactorid">setactorid</a></code></li>
<li><code><a title="vipy.video.Scene.show" href="#vipy.video.Scene.show">show</a></code></li>
<li><code><a title="vipy.video.Scene.stabilize" href="#vipy.video.Scene.stabilize">stabilize</a></code></li>
<li><code><a title="vipy.video.Scene.startframe" href="#vipy.video.Scene.startframe">startframe</a></code></li>
<li><code><a title="vipy.video.Scene.thumbnail" href="#vipy.video.Scene.thumbnail">thumbnail</a></code></li>
<li><code><a title="vipy.video.Scene.track" href="#vipy.video.Scene.track">track</a></code></li>
<li><code><a title="vipy.video.Scene.trackbox" href="#vipy.video.Scene.trackbox">trackbox</a></code></li>
<li><code><a title="vipy.video.Scene.trackclip" href="#vipy.video.Scene.trackclip">trackclip</a></code></li>
<li><code><a title="vipy.video.Scene.trackcrop" href="#vipy.video.Scene.trackcrop">trackcrop</a></code></li>
<li><code><a title="vipy.video.Scene.trackfilter" href="#vipy.video.Scene.trackfilter">trackfilter</a></code></li>
<li><code><a title="vipy.video.Scene.trackidx" href="#vipy.video.Scene.trackidx">trackidx</a></code></li>
<li><code><a title="vipy.video.Scene.trackindex" href="#vipy.video.Scene.trackindex">trackindex</a></code></li>
<li><code><a title="vipy.video.Scene.tracklist" href="#vipy.video.Scene.tracklist">tracklist</a></code></li>
<li><code><a title="vipy.video.Scene.trackmap" href="#vipy.video.Scene.trackmap">trackmap</a></code></li>
<li><code><a title="vipy.video.Scene.tracks" href="#vipy.video.Scene.tracks">tracks</a></code></li>
<li><code><a title="vipy.video.Scene.tracksplit" href="#vipy.video.Scene.tracksplit">tracksplit</a></code></li>
<li><code><a title="vipy.video.Scene.union" href="#vipy.video.Scene.union">union</a></code></li>
<li><code><a title="vipy.video.Scene.zeromask" href="#vipy.video.Scene.zeromask">zeromask</a></code></li>
<li><code><a title="vipy.video.Scene.zeropad" href="#vipy.video.Scene.zeropad">zeropad</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vipy.video.Stream" href="#vipy.video.Stream">Stream</a></code></h4>
<ul class="">
<li><code><a title="vipy.video.Stream.batch" href="#vipy.video.Stream.batch">batch</a></code></li>
<li><code><a title="vipy.video.Stream.clip" href="#vipy.video.Stream.clip">clip</a></code></li>
<li><code><a title="vipy.video.Stream.frame" href="#vipy.video.Stream.frame">frame</a></code></li>
<li><code><a title="vipy.video.Stream.framerate" href="#vipy.video.Stream.framerate">framerate</a></code></li>
<li><code><a title="vipy.video.Stream.write" href="#vipy.video.Stream.write">write</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vipy.video.Video" href="#vipy.video.Video">Video</a></code></h4>
<ul class="">
<li><code><a title="vipy.video.Video.abspath" href="#vipy.video.Video.abspath">abspath</a></code></li>
<li><code><a title="vipy.video.Video.array" href="#vipy.video.Video.array">array</a></code></li>
<li><code><a title="vipy.video.Video.aspect_ratio" href="#vipy.video.Video.aspect_ratio">aspect_ratio</a></code></li>
<li><code><a title="vipy.video.Video.bias" href="#vipy.video.Video.bias">bias</a></code></li>
<li><code><a title="vipy.video.Video.bytes" href="#vipy.video.Video.bytes">bytes</a></code></li>
<li><code><a title="vipy.video.Video.canload" href="#vipy.video.Video.canload">canload</a></code></li>
<li><code><a title="vipy.video.Video.cast" href="#vipy.video.Video.cast">cast</a></code></li>
<li><code><a title="vipy.video.Video.centercrop" href="#vipy.video.Video.centercrop">centercrop</a></code></li>
<li><code><a title="vipy.video.Video.centersquare" href="#vipy.video.Video.centersquare">centersquare</a></code></li>
<li><code><a title="vipy.video.Video.channel" href="#vipy.video.Video.channel">channel</a></code></li>
<li><code><a title="vipy.video.Video.channels" href="#vipy.video.Video.channels">channels</a></code></li>
<li><code><a title="vipy.video.Video.channelshape" href="#vipy.video.Video.channelshape">channelshape</a></code></li>
<li><code><a title="vipy.video.Video.clear" href="#vipy.video.Video.clear">clear</a></code></li>
<li><code><a title="vipy.video.Video.clip" href="#vipy.video.Video.clip">clip</a></code></li>
<li><code><a title="vipy.video.Video.cliprange" href="#vipy.video.Video.cliprange">cliprange</a></code></li>
<li><code><a title="vipy.video.Video.clone" href="#vipy.video.Video.clone">clone</a></code></li>
<li><code><a title="vipy.video.Video.colorspace" href="#vipy.video.Video.colorspace">colorspace</a></code></li>
<li><code><a title="vipy.video.Video.commandline" href="#vipy.video.Video.commandline">commandline</a></code></li>
<li><code><a title="vipy.video.Video.concatenate" href="#vipy.video.Video.concatenate">concatenate</a></code></li>
<li><code><a title="vipy.video.Video.crop" href="#vipy.video.Video.crop">crop</a></code></li>
<li><code><a title="vipy.video.Video.cropeven" href="#vipy.video.Video.cropeven">cropeven</a></code></li>
<li><code><a title="vipy.video.Video.delattribute" href="#vipy.video.Video.delattribute">delattribute</a></code></li>
<li><code><a title="vipy.video.Video.dict" href="#vipy.video.Video.dict">dict</a></code></li>
<li><code><a title="vipy.video.Video.download" href="#vipy.video.Video.download">download</a></code></li>
<li><code><a title="vipy.video.Video.downloadif" href="#vipy.video.Video.downloadif">downloadif</a></code></li>
<li><code><a title="vipy.video.Video.duration" href="#vipy.video.Video.duration">duration</a></code></li>
<li><code><a title="vipy.video.Video.duration_in_frames" href="#vipy.video.Video.duration_in_frames">duration_in_frames</a></code></li>
<li><code><a title="vipy.video.Video.duration_in_frames_of_videofile" href="#vipy.video.Video.duration_in_frames_of_videofile">duration_in_frames_of_videofile</a></code></li>
<li><code><a title="vipy.video.Video.duration_in_seconds_of_videofile" href="#vipy.video.Video.duration_in_seconds_of_videofile">duration_in_seconds_of_videofile</a></code></li>
<li><code><a title="vipy.video.Video.fetch" href="#vipy.video.Video.fetch">fetch</a></code></li>
<li><code><a title="vipy.video.Video.ffplay" href="#vipy.video.Video.ffplay">ffplay</a></code></li>
<li><code><a title="vipy.video.Video.filename" href="#vipy.video.Video.filename">filename</a></code></li>
<li><code><a title="vipy.video.Video.filesize" href="#vipy.video.Video.filesize">filesize</a></code></li>
<li><code><a title="vipy.video.Video.fliplr" href="#vipy.video.Video.fliplr">fliplr</a></code></li>
<li><code><a title="vipy.video.Video.flipud" href="#vipy.video.Video.flipud">flipud</a></code></li>
<li><code><a title="vipy.video.Video.float" href="#vipy.video.Video.float">float</a></code></li>
<li><code><a title="vipy.video.Video.flush" href="#vipy.video.Video.flush">flush</a></code></li>
<li><code><a title="vipy.video.Video.flush_and_return" href="#vipy.video.Video.flush_and_return">flush_and_return</a></code></li>
<li><code><a title="vipy.video.Video.frame" href="#vipy.video.Video.frame">frame</a></code></li>
<li><code><a title="vipy.video.Video.framelist" href="#vipy.video.Video.framelist">framelist</a></code></li>
<li><code><a title="vipy.video.Video.framerate" href="#vipy.video.Video.framerate">framerate</a></code></li>
<li><code><a title="vipy.video.Video.framerate_of_videofile" href="#vipy.video.Video.framerate_of_videofile">framerate_of_videofile</a></code></li>
<li><code><a title="vipy.video.Video.frames" href="#vipy.video.Video.frames">frames</a></code></li>
<li><code><a title="vipy.video.Video.from_json" href="#vipy.video.Video.from_json">from_json</a></code></li>
<li><code><a title="vipy.video.Video.fromarray" href="#vipy.video.Video.fromarray">fromarray</a></code></li>
<li><code><a title="vipy.video.Video.fromdirectory" href="#vipy.video.Video.fromdirectory">fromdirectory</a></code></li>
<li><code><a title="vipy.video.Video.fromframes" href="#vipy.video.Video.fromframes">fromframes</a></code></li>
<li><code><a title="vipy.video.Video.gain" href="#vipy.video.Video.gain">gain</a></code></li>
<li><code><a title="vipy.video.Video.getattribute" href="#vipy.video.Video.getattribute">getattribute</a></code></li>
<li><code><a title="vipy.video.Video.gif" href="#vipy.video.Video.gif">gif</a></code></li>
<li><code><a title="vipy.video.Video.hasattribute" href="#vipy.video.Video.hasattribute">hasattribute</a></code></li>
<li><code><a title="vipy.video.Video.hasfilename" href="#vipy.video.Video.hasfilename">hasfilename</a></code></li>
<li><code><a title="vipy.video.Video.hasurl" href="#vipy.video.Video.hasurl">hasurl</a></code></li>
<li><code><a title="vipy.video.Video.height" href="#vipy.video.Video.height">height</a></code></li>
<li><code><a title="vipy.video.Video.iscolor" href="#vipy.video.Video.iscolor">iscolor</a></code></li>
<li><code><a title="vipy.video.Video.isdownloaded" href="#vipy.video.Video.isdownloaded">isdownloaded</a></code></li>
<li><code><a title="vipy.video.Video.isgrayscale" href="#vipy.video.Video.isgrayscale">isgrayscale</a></code></li>
<li><code><a title="vipy.video.Video.islive" href="#vipy.video.Video.islive">islive</a></code></li>
<li><code><a title="vipy.video.Video.isloadable" href="#vipy.video.Video.isloadable">isloadable</a></code></li>
<li><code><a title="vipy.video.Video.isloaded" href="#vipy.video.Video.isloaded">isloaded</a></code></li>
<li><code><a title="vipy.video.Video.issquare" href="#vipy.video.Video.issquare">issquare</a></code></li>
<li><code><a title="vipy.video.Video.json" href="#vipy.video.Video.json">json</a></code></li>
<li><code><a title="vipy.video.Video.load" href="#vipy.video.Video.load">load</a></code></li>
<li><code><a title="vipy.video.Video.map" href="#vipy.video.Video.map">map</a></code></li>
<li><code><a title="vipy.video.Video.maxdim" href="#vipy.video.Video.maxdim">maxdim</a></code></li>
<li><code><a title="vipy.video.Video.maxmatte" href="#vipy.video.Video.maxmatte">maxmatte</a></code></li>
<li><code><a title="vipy.video.Video.maxsquare" href="#vipy.video.Video.maxsquare">maxsquare</a></code></li>
<li><code><a title="vipy.video.Video.metadata" href="#vipy.video.Video.metadata">metadata</a></code></li>
<li><code><a title="vipy.video.Video.mindim" href="#vipy.video.Video.mindim">mindim</a></code></li>
<li><code><a title="vipy.video.Video.minsquare" href="#vipy.video.Video.minsquare">minsquare</a></code></li>
<li><code><a title="vipy.video.Video.mutable" href="#vipy.video.Video.mutable">mutable</a></code></li>
<li><code><a title="vipy.video.Video.nofilename" href="#vipy.video.Video.nofilename">nofilename</a></code></li>
<li><code><a title="vipy.video.Video.normalize" href="#vipy.video.Video.normalize">normalize</a></code></li>
<li><code><a title="vipy.video.Video.nourl" href="#vipy.video.Video.nourl">nourl</a></code></li>
<li><code><a title="vipy.video.Video.numpy" href="#vipy.video.Video.numpy">numpy</a></code></li>
<li><code><a title="vipy.video.Video.pad" href="#vipy.video.Video.pad">pad</a></code></li>
<li><code><a title="vipy.video.Video.pkl" href="#vipy.video.Video.pkl">pkl</a></code></li>
<li><code><a title="vipy.video.Video.pklif" href="#vipy.video.Video.pklif">pklif</a></code></li>
<li><code><a title="vipy.video.Video.play" href="#vipy.video.Video.play">play</a></code></li>
<li><code><a title="vipy.video.Video.preview" href="#vipy.video.Video.preview">preview</a></code></li>
<li><code><a title="vipy.video.Video.print" href="#vipy.video.Video.print">print</a></code></li>
<li><code><a title="vipy.video.Video.probe" href="#vipy.video.Video.probe">probe</a></code></li>
<li><code><a title="vipy.video.Video.probeshape" href="#vipy.video.Video.probeshape">probeshape</a></code></li>
<li><code><a title="vipy.video.Video.quicklook" href="#vipy.video.Video.quicklook">quicklook</a></code></li>
<li><code><a title="vipy.video.Video.randomcrop" href="#vipy.video.Video.randomcrop">randomcrop</a></code></li>
<li><code><a title="vipy.video.Video.reload" href="#vipy.video.Video.reload">reload</a></code></li>
<li><code><a title="vipy.video.Video.relpath" href="#vipy.video.Video.relpath">relpath</a></code></li>
<li><code><a title="vipy.video.Video.rename" href="#vipy.video.Video.rename">rename</a></code></li>
<li><code><a title="vipy.video.Video.rescale" href="#vipy.video.Video.rescale">rescale</a></code></li>
<li><code><a title="vipy.video.Video.resize" href="#vipy.video.Video.resize">resize</a></code></li>
<li><code><a title="vipy.video.Video.resolution_of_videofile" href="#vipy.video.Video.resolution_of_videofile">resolution_of_videofile</a></code></li>
<li><code><a title="vipy.video.Video.restore" href="#vipy.video.Video.restore">restore</a></code></li>
<li><code><a title="vipy.video.Video.returns" href="#vipy.video.Video.returns">returns</a></code></li>
<li><code><a title="vipy.video.Video.rot90ccw" href="#vipy.video.Video.rot90ccw">rot90ccw</a></code></li>
<li><code><a title="vipy.video.Video.rot90cw" href="#vipy.video.Video.rot90cw">rot90cw</a></code></li>
<li><code><a title="vipy.video.Video.sanitize" href="#vipy.video.Video.sanitize">sanitize</a></code></li>
<li><code><a title="vipy.video.Video.saveas" href="#vipy.video.Video.saveas">saveas</a></code></li>
<li><code><a title="vipy.video.Video.savetemp" href="#vipy.video.Video.savetemp">savetemp</a></code></li>
<li><code><a title="vipy.video.Video.savetmp" href="#vipy.video.Video.savetmp">savetmp</a></code></li>
<li><code><a title="vipy.video.Video.setattribute" href="#vipy.video.Video.setattribute">setattribute</a></code></li>
<li><code><a title="vipy.video.Video.shape" href="#vipy.video.Video.shape">shape</a></code></li>
<li><code><a title="vipy.video.Video.show" href="#vipy.video.Video.show">show</a></code></li>
<li><code><a title="vipy.video.Video.speed" href="#vipy.video.Video.speed">speed</a></code></li>
<li><code><a title="vipy.video.Video.store" href="#vipy.video.Video.store">store</a></code></li>
<li><code><a title="vipy.video.Video.stream" href="#vipy.video.Video.stream">stream</a></code></li>
<li><code><a title="vipy.video.Video.take" href="#vipy.video.Video.take">take</a></code></li>
<li><code><a title="vipy.video.Video.thumbnail" href="#vipy.video.Video.thumbnail">thumbnail</a></code></li>
<li><code><a title="vipy.video.Video.tonumpy" href="#vipy.video.Video.tonumpy">tonumpy</a></code></li>
<li><code><a title="vipy.video.Video.torch" href="#vipy.video.Video.torch">torch</a></code></li>
<li><code><a title="vipy.video.Video.unstore" href="#vipy.video.Video.unstore">unstore</a></code></li>
<li><code><a title="vipy.video.Video.url" href="#vipy.video.Video.url">url</a></code></li>
<li><code><a title="vipy.video.Video.videoid" href="#vipy.video.Video.videoid">videoid</a></code></li>
<li><code><a title="vipy.video.Video.webp" href="#vipy.video.Video.webp">webp</a></code></li>
<li><code><a title="vipy.video.Video.width" href="#vipy.video.Video.width">width</a></code></li>
<li><code><a title="vipy.video.Video.zeropad" href="#vipy.video.Video.zeropad">zeropad</a></code></li>
<li><code><a title="vipy.video.Video.zeropadlike" href="#vipy.video.Video.zeropadlike">zeropadlike</a></code></li>
<li><code><a title="vipy.video.Video.zeros" href="#vipy.video.Video.zeros">zeros</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="vipy.video.VideoCategory" href="#vipy.video.VideoCategory">VideoCategory</a></code></h4>
<ul class="">
<li><code><a title="vipy.video.VideoCategory.category" href="#vipy.video.VideoCategory.category">category</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>