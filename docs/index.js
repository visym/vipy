URLS=[
"index.html",
"pyramid.html",
"metrics.html",
"show.html",
"gui/index.html",
"gui/using_matplotlib.html",
"activity.html",
"camera.html",
"ssim.html",
"version.html",
"math.html",
"image.html",
"downloader.html",
"annotation.html",
"visualize.html",
"parallel.html",
"video.html",
"calibration.html",
"globals.html",
"torch.html",
"data/index.html",
"data/kinetics.html",
"data/cc12m.html",
"dataset.html",
"data/stanford_dogs.html",
"data/openimages.html",
"data/aflw.html",
"data/youtubefaces.html",
"data/lvis.html",
"data/pip.html",
"data/celebA.html",
"data/vggface.html",
"data/oxford_flowers_102.html",
"data/mit67.html",
"data/inaturalist.html",
"data/charades.html",
"data/visualgenome.html",
"data/widerface.html",
"data/mnist.html",
"data/food101.html",
"data/abo.html",
"data/momentsintime.html",
"data/facescrub.html",
"data/cap.html",
"data/ethzshapes.html",
"data/caltech256.html",
"data/food2k.html",
"data/stanford_cars.html",
"data/caltech101.html",
"data/activitynet.html",
"data/imagenet.html",
"data/ucf101.html",
"data/ava.html",
"data/megaface.html",
"data/coco.html",
"data/youtubeBB.html",
"data/kitti.html",
"data/compcars.html",
"data/d2d.html",
"data/tiny_virat.html",
"data/cifar.html",
"data/kthactions.html",
"data/coil100.html",
"data/casia.html",
"data/imdb_wiki.html",
"data/places.html",
"data/eurosat.html",
"data/lfw.html",
"data/msceleb.html",
"data/mmid.html",
"data/hmdb.html",
"data/hf.html",
"data/vggface2.html",
"data/fddb.html",
"data/objectnet.html",
"data/meva.html",
"data/mmcommons.html",
"noise.html",
"util.html",
"object.html",
"geometry.html",
"linalg.html",
"videosearch.html",
"batch.html",
"flow.html"
];
INDEX=[
{
"ref":"vipy",
"url":0,
"doc":"VIPY is a python package for representation, transformation and visualization of annotated videos and images. Annotations are the ground truth provided by labelers (e.g. object bounding boxes, face identities, temporal activity clips), suitable for training computer vision systems. VIPY provides tools to easily edit videos and images so that the annotations are transformed along with the pixels. This enables a clean interface for transforming complex datasets for input to your computer vision training and testing pipeline. VIPY provides:  Representation of videos with labeled activities that can be resized, clipped, rotated, scaled and cropped  Representation of images with object bounding boxes that can be manipulated as easily as editing an image  Clean visualization of annotated images and videos  Lazy loading of images and videos suitable for distributed procesing (e.g. dask, spark)  Straightforward integration into machine learning toolchains (e.g. torch, numpy)  Fluent interface for chaining operations on videos and images  Dataset download, unpack and import (e.g. Charades, AVA, ActivityNet, Kinetics, Moments in Time)  Video and image web search tools with URL downloading and caching  Minimum dependencies for easy installation (e.g. AWS Lambda)  Design Goals Vipy was created with three design goals.   Simplicity . Annotated Videos and images should be as easy to manipulate as the pixels. We provide a simple fluent API that enables the transformation of media so that pixels are transformed along with the annotations. We provide a comprehensive unit test suite to validate this pipeline with continuous integration.   Portability . Vipy was designed with the goal of allowing it to be easily retargeted to new platforms. For example, deployment on a serverless architecture such as AWS lambda has restrictions on the allowable code that can be executed in layers. We designed Vipy with minimal dependencies on standard and mature machine learning tool chains (numpy, matplotlib, ffmpeg, pillow) to ensure that it can be ported to new computational environments.   Efficiency . Vipy is written in pure python with the goal of performing in place operations and avoiding copies of media whenever possible. This enables fast video processing by operating on videos as chains of transformations. The documentation describes when an object is changed in place vs. copied. Furthermore, loading of media is delayed until explicitly requested by the user (or the pixels are needed) to enable lazy loading for distributed processing.  Getting started The VIPY tools are designed for simple and intuitive interaction with videos and images. Try to create a  vipy.video.Scene object:   v = vipy.video.RandomScene()   Videos are constructed from URLs (e.g. RTSP/RTMP live camera streams, YouTube videos, public or keyed AWS S3 links), SSH accessible paths, local filenames,  vipy.image.Image frame lists, numpy arrays or pytorch tensors. In this example, we create a random video with tracks and activities. Videos can be natively iterated:   for im in v: print(im.numpy(   This will iterate and yield  vipy.image.Image objects corresponding to each frame of the video. You can use the  vipy.image.Image.numpy method to extract the numpy array for this frame. Long videos are streamed to avoid out of memory errors. Under the hood, we represent each video as a filter chain to an FFMPEG pipe, which yields frames corresponding to the appropriate filter transform and framerate. The yielded frames include all of the objects that are present in the video at that frame accessible with the  vipy.image.Scene.objects method. VIPY supports more complex iterators. For example, a common use case for activity detection is iterating over short clips in a video. You can do this using the stream iterator:   for c in v.stream().clip(16): print(c.torch(   This will yield  vipy.video.Scene objects each containing a  vipy.video.Stream.clip of length 16 frames. Each clip overlaps by 15 frames with the next clip, and each clip includes a threaded copy of the pixels. This is useful to provide clips of a fixed length that are output for every frame of the video. Each clip contais the tracks and activities within this clip time period. The method  vipy.video.Video.torch will output a torch tensor suitable for integration into a pytorch based system. These python iterators can be combined together in complex ways   for (im, c, imdelay) in (v, v.stream().clip(16), v.stream().frame(delay=10), a_gpu_function(v.stream().batch(16 ) print(im, c.torch(), imdelay)   This will yield the current frame, a video  vipy.video.Stream.clip of length 16, a  vipy.video.Stream.frame 10 frames ago and a  vipy.video.Stream.batch of 16 frames that is designed for computation and transformation on a GPU. All of the pixels are copied in threaded processing which is efficiently hidden by GPU I/O bound operations. For more examples of complex iterators in real world use cases, see the [HeyVi package](https: github.com/visym/heyvi) for open source visual analytics. Videos can be transformed in complex ways, and the pixels will always be transformed along with the annotations.   v.fliplr()  flip horizontally v.zeropad(10, 20)  zero pad the video horizontally and vertically v.mindim(256)  change the minimum dimension of the video v.framerate(10)  change the framerate of the video   The transformation is lazy and is incorporated into the FFMPEG complex filter chain so that the transformation is applied when the pixels are needed. You can always access the current filter chain using  vipy.video.Video.commandline which will output a commandline string for the ffmpeg executable that you can use to get a deeper underestanding of the transformations that are applied to the video pixels. Finally, annotated videos can be displayed.   v.show() v.show(notebook=True) v.frame().show() v.annotate('/path/to/visualization.mp4') with vipy.video.Video(url='rtmps: youtu.be/ .').mindim(512).framerate(5).stream(write=True) as s: for im in v.framerate(5): s.write(im.annotate().rgb(   This will  vipy.video.Scene.show the video live on your desktop, in a jupyter notebook, show the first  vipy.video.Scene.frame as a static image,  vipy.video.Scene.annotate the video so that annotations are in the pixels and save the corresponding video, or live stream a 5Hz video to youtube. All of the show methods can be configured to customize the colors or captions. See the [demos](https: github.com/visym/vipy/tree/master/demo) for more examples.  Parallelization Vipy includes integration with [Dask Distributed](https: distributed.dask.org) for parallel processing of video and images. This is useful for video preprocessing of datasets to prepare them for training. For example, we can construct a  vipy.dataset.Dataset object from one or more videos. This dataset can be transformed in parallel using two processes:   D = vipy.dataset.Dataset(vipy.video.Scene(filename='/path/to/videofile.mp4' with vipy.globals.parallel(2): R = D.map(lambda v, outdir='/newpath/to/': v.mindim(128).framerate(5).saveas(so.path.join(outdir, vipy.util.filetail(v.filename(  )   The result is a transformed dataset which contains transformed videos downsampled to have minimum dimension 128, framerate of 5Hz, with the annotations transformed accordingly. The  vipy.dataset.Dataset.map method allows for a lambda function to be applied in parallel to all elements in a dataset. The fluent design of the VIPY objects allows for easy chaining of video operations to be expressed as a lambda function. VIPY objects are designed for integration into parallel processing tool chains and can be easily serialized and deserialized for sending to parallel worker tasks. VIPY supports integration with distributed schedulers for massively parallel operation.   D = vipy.dataset.Dataset('/path/to/directory/of/jsonfiles') with vipy.globals.parallel(scheduler='10.0.0.1:8785'): R = D.map(lambda v, outdir='/newpath/to': vipy.util.bz2pkl(os.path.join(outdir, '%s.pkl.bz2' % v.videoid( , v.trackcrop().mindim(128).normalize(mean=(128,128,128 .torch( )   This will lazy load a directory of JSON files, where each JSON file corresponds to the annotations of a single video, such as those collected by [Visym Collector](https: visym.github.io/collector). The  vipy.dataset.Dataset.map method will communicate with a [scheduler](https: docs.dask.org/en/stable/how-to/deploy-dask/ssh.html) at a given IP address and port and will process the lambda function in parallel to the workers tasked by the scheduler. In this example, the video will  vipy.video.Scene.trackcrop the smallest bounding box containing all tracks in the video, resized so this crop is 128 on the smallest side, loaded and normalized to remove the mean, then saved as a torch tensor in a bzipped python pickle file. This is useful for preprocesssing videos to torch tensors for fast loading of dataset augmentation during training.  Import Vipy was designed to define annotated videos and imagery as collections of python objects. The core objects for images are:  [vipy.image.Scene](image.html vipy.image.Scene)  [vipy.object.Detection](object.html vipy.object.Detection)  [vipy.geometry.BoundingBox](geometry.html vipy.geometry.BoundingBox) The core objects for videos:  [vipy.video.Scene](video.html vipy.video.Scene)  [vipy.object.Track](object.html vipy.object.Track)  [vipy.activity.Activity](activity.html vipy.activity.Activity) See the documentation for each object for how to construct them. Alternatively, see our [open source visual analytics](https: github.com/visym/heyvi) for construction of vipy objects from activity and object detectors.  Export All vipy objects can be imported and exported to JSON for interoperatability with other tool chains. This allows for introspection of the vipy object state in an open format providing transparency   vipy.image.owl().json()    Environment variables You can set the following environment variables to customize the output of vipy   VIPY_CACHE ='/path/to/directory'. This directory will contain all of the cached downloaded filenames when downloading URLs. For example, the following will download all media to '~/.vipy'.   os.environ['VIPY_CACHE'] = vipy.util.remkdir('~/.vipy') vipy.image.Image(url='https: upload.wikimedia.org/wikipedia/commons/thumb/2/23/Bubo_virginianus_06.jpg/1920px-Bubo_virginianus_06.jpg').download()   This will output an image object:      This provides control over where large datasets are cached on your local file system. By default, this will be cached to the system temp directory.   VIPY_AWS_ACCESS_KEY_ID ='MYKEY'. This is the [AWS key](https: docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html) to download urls of the form \"s3: \".   VIPY_AWS_SECRET_ACCESS_KEY ='MYKEY'. This is the [AWS secret key](https: docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html) to download urls of the form \"s3: \".   VIPY_BACKEND . This is the [Matplotlib backend](https: matplotlib.org/stable/users/explain/backends.html) to use when rendering figure windows. 'Agg' is recommended for headless operation, and 'TkAgg' is recommended for Linux based X11 forwarding. In most cases, matplotlib will choose the best backend available by default, and this environment variable does not need to override this choice.  Versioning To determine what vipy version you are running you can use: >>> vipy.__version__ >>> vipy.version.is_at_least('1.11.1')  Tutorials The following tutorials show fluent python chains to achieve transformations of annotated images and videos.  Images  Load an image Images can be loaded from URLs, local image files, or numpy arrays. The images exhibit lazy loading, so that pixels will not be fetched until they are needed.   >>> im = vipy.image.Image(filename='/path/to/in.jpg') >>> im = vipy.image.Image(url='https: url/to/in.jpg') >>> im = vipy.image.Image(array=np.random.rand(224,224,3).astype(np.float32    Display an image to stdout All objects have helpful string representations when printed to stdout. This is accessible via the  vipy.image.Image.print method or by using builtin print(). In this example, an image is created from a wikipedia URL. Printing this image object shows the URL, but when it is loaded, the image object shows the size of the image, colorspace and the filename that the URL was downloaded to. When in doubt, print!   >>> print(vipy.image.Scene(url='https: upload.wikimedia.org/wikipedia/commons/thumb/2/23/Bubo_virginianus_06.jpg/1920px-Bubo_virginianus_06.jpg'  >>> vipy.image.Scene(url='https: upload.wikimedia.org/wikipedia/commons/thumb/2/23/Bubo_virginianus_06.jpg/1920px-Bubo_virginianus_06.jpg').load().print()     Transform an image Images can be transformed so that the annotations are updated along with the pixels. In this example, the  vipy.image.owl is a demo image to a wikipedia URL with a bounding box. This can be resized and cropped or anisotropically scaled and the box is updated to match the pixels.   >>> im = vipy.image.owl().mindim(512).fliplr().centersquare().show() >>> im = vipy.image.owl().resize(width=512, height=256).show()      Export as numpy array All images are represented internally as a private attribute  vipy.image.Image._array which is a numpy array representation of the pixels. Image transformations can be chained to operate sequentially on this pixel buffer. In this example, the  vipy.image.owl test image is cropped to retain the center square, converted from uint8 RGB to float32 greyscale, resized to 224x224 then exported to numpy array.   >>> vipy.image.owl().centersquare().greyscale().mindim(224).numpy() array( 0.11470564, 0.11794835, 0.13006495,  ., 0.15657625, 0.15867704, 0.16140679], [0.11835834, 0.11993656, 0.12860955,  ., 0.15611856, 0.15460114, 0.15652661], [0.12262769, 0.1245698 , 0.12809968,  ., 0.153694 , 0.15326852, 0.15336327],  ., [0.42591274, 0.42745316, 0.4352066 ,  ., 0.12994824, 0.13172676, 0.13424061], [0.42972928, 0.43847743, 0.45459685,  ., 0.12558977, 0.12820148, 0.13141613], [0.44050908, 0.45350933, 0.46908155,  ., 0.12246227, 0.1256479 , 0.12941177 , dtype=float32)    Display an image All images can be displayed using the matplotlib library. Matplotlib is the most universally ported GUI library for python, and exhibits minimal dependencies. We enable the user to show images using figure window or \"matlab style\" of image display. This will show pixels with overlayed semi-transparent bounding boxes for objects with captions.   >>> im = vipy.image.owl().mindim(512).show()     Annotate an image By default, images and annotations are represented independently. However, it is sometimes useful to export the annotations into the pixels. The  vipy.image.Scene.annotate method will export the same visualization as when the image is displayed, but the pixel buffer will be overwritten with the shown image. This means that calling  vipy.image.Image.numpy will return the pixel buffer with boxes and captions in the pixels.   >>> vipy.image.owl().mindim(512).maxmatte().annotate().rgb().saveas('out.jpg')     Save an image Images can be saved (without annotations) using the  vipy.image.Image.saveas method. Calling this method with no arguments will save to a random temporary image. In this example, we crop the image, convert from RGB colorspace to BGR colorspace, flip up/down and resize.   >>> vipy.image.owl().centersquare().bgr().flipud().mindim(224).saveas('save_an_image.jpg')     Convert image colorspace All images can be converted between different colorspaces (e.g. RGB, BGR, RGBA, BGRA, HSV, GREY, LUM, float). This will convert the underlying pixel buffer to support the corresponding colorspace.  >>> vipy.image.owl().hsv().saveas('hsv.jpg')    Rescale image All images can be rescaled to a standard range, including the Matlab inspired  vipy.image.Image.mat2gray , which will rescale the pixel buffer between [min, max] -> [0, 1]  Visualize scenes Scenes containing objects can be visualized to display only a subset of objects. In this example, we show the demo image  vipy.image.vehicles which contains four annotated vehicles. There are many more vehicles in this image, but the end user may be interested in these four in particular. Each object is represented internally as a list of  vipy.object.Detection objects which encodes a bounding box and category. This can be visualized just as with images with single objects.   >>> vipy.image.vehicles().show().objects() [ ,  ,  ,  ]     Crop and resize annotated objects in a scene   >>> im = vipy.image.vehicles().show() >>> vipy.visualize.montage([o.dilate(1.2).maxsquare().crop() for o in im]).show()      Find all images in directory Searching for all images recursively from a root directory and lazy load them as  vipy.image.Image objects. This will not trigger loading pixels until the pixel buffers are needed. This is helpful for importing large number of images.   >>> [vipy.image.Image(filename=f) for f in vipy.util.findimages('./docs/tutorials')] [ ,  ,  .    Export scene to JSON All annotated images can be imported and exported to an open JSON format. If images are loaded, then the pixels will be serialized in the JSON output. If this is not desired, then use the  vipy.image.Image.flush method to clear the cached pixel buffer prior to serialization. This can always be reloaded after deserialization as long as the source image or URL is acessible.   >>> json = vipy.image.owl().flush().json() >>> im = vipy.image.Scene.from_json(json) >>> print(json) '{\"_filename\":\"\\/Users\\/jebyrne\\/.vipy\\/1920px-Bubo_virginianus_06.jpg\",\"_url\":\"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/thumb\\/2\\/23\\/Bubo_virginianus_06.jpg\\/1920px-Bubo_virginianus_06.jpg\",\"_loader\":null,\"_array\":null,\"_colorspace\":\"rgb\",\"attributes\":{},\"_category\":\"Nature\",\"_objectlist\":[{\"_xmin\":93.33333333333333,\"_ymin\":85.33333333333333,\"_xmax\":466.6666666666667,\"_ymax\":645.3333333333334,\"_id\":\"a047e21d\",\"_label\":\"Great Horned Owl\",\"_shortlabel\":\"Great Horned Owl\"}]}'    Export scene to CSV All annotated images can be exported to a CSV format using object iterators. Object precision can be changed using  vipy.object.Detection.int . CSV headers can be added with  vipy.util.writecsv .   >>> im = vipy.image.vehicles() >>> vipy.util.writecsv([(im.filename(), o.category(), o.xmin(), o.ymin(), o.width(), o.height( for o in im.objects()], 'out.csv') >>> cat out.csv /Users/jebyrne/.vipy/I-80_Eastshore_Fwy.jpg,car,210.2222222222222,263.2,41.06666666666666,32.622222222222206 /Users/jebyrne/.vipy/I-80_Eastshore_Fwy.jpg,car,626.6666666666666,336.0444444444444,77.86666666666667,65.4666666666667 /Users/jebyrne/.vipy/I-80_Eastshore_Fwy.jpg,car,140.84444444444443,284.4888888888889,53.066666666666634,53.111111111111086 /Users/jebyrne/.vipy/I-80_Eastshore_Fwy.jpg,car,394.17777777777775,396.84444444444443,99.4666666666667,87.37777777777774    Image deduplication Vipy provides a 128 bit differential perceptual hashing function which is used for near-duplicate detection. This is useful for identifying pairs of images that differ slightly due to cropping, resizing, watermarkings. The binary Hamming distance between two perceptual hashes is a similarity metric that can be used to identify duplicates, such that smaller is more likely to be a duplicate.   >>> p = vipy.image.vehicles().perceptualhash()  hex string >>> print(p) '50515541d545f04101a005e801c25945' >>> q = vipy.image.vehicles().greyscale().perceptualhash() >>> print(q) '50515541d545f04101a905e801c27945' >>> vipy.image.Image.perceptualhash_distance(p, q)  Hamming distance 3   The perceptual hash function also allows for ignoring detected objects in the foreground. A background hash  vipy.image.Scene.bghash computes the perceptual hash function using only the regions not contained within the foreground bounding boxes. This is useful for identifying near duplicate background locations where there may be different foreground objects in the scene between images. If the  vipy.image.Scene has no associated foreground objects, then the background hash is equivalent to the perceptual hash above.  Blur Faces   >>> im = vipy.image.Image(url='https: upload.wikimedia.org/wikipedia/en/d/d6/Friends_season_one_cast.jpg') >>> im.facepixelize().show() >>> im.faceblur().show()      Detect People Vipy supports the [HeyVi](https: github.com/visym/heyvi) package for visual analytics to construct annotated videos and images. This performs person detection on an image, and returns a  vipy.image.Scene with the detected people objects. This approach is convenient for person detection in single images, however for real-time performance it is recommended to leveraged batched GPU operations with the full heyvi package.   >>> im = vipy.image.Image(url='https: upload.wikimedia.org/wikipedia/en/d/d6/Friends_season_one_cast.jpg') >>> im.person_detection().show()     Data augmentation for training Data augmentation is the process of introducing synthetic transformations of a given image to introduce additional variation during training. Data augmentation considers scales, crops, translations, mirrors, rotations or chromatic noise which are applied to a source image to generate one or more augmentations. All pixel buffers are shared by default for speed, so the clone() method will enforce that pixel buffers are copied when needed.   im = vipy.image.vehicles() vipy.visualize.montage( o.crop().fliplr(),  spatial mirror o.clone().dilate(1.2).crop(),  zoom out o.clone().translate(4,5).crop(),  translation o.clone().translate(-2,9).crop(),  translation o.clone().dilate(0.8).crop(),  zoom in o.crop().blur(sigma=1),  spatial blur o.crop().additive_noise()]  chromatic noise for o in im])  for all objects in the scene     Vipy vs. Torchvision  Visualization behind SSH Data repositories are often accessed via data storage behind SSH. You can set up port forwarding to visualize this data, but this may require root access to configure firewall rules. If you have SSH public key access to your cluster machine, you can do the following: On a remote machine (e.g. the cluster machine you have accessed via ssh), run:   remote>>> vipy.util.scpsave(vipy.image.owl( [vipy.util.scpsave]: On a local machine where you have public key ssh access to this remote machine run: >>> V = vipy.util.scpload('scp: hostname:/var/folders/sn/6n34qjp513742_5y3lvmhnlw0000gn/T/c4237a25a99b776f.pkl')   Then, on your local machine (e.g. your laptop), run the command output above:   local>>> print(vipy.util.scpload('scp: hostname:/var/folders/sn/6n34qjp513742_5y3lvmhnlw0000gn/T/c4237a25a99b776f.pkl'    The method  vipy.util.scpsave will save a list of vipy objects to a temporary pickle file, such that the URL of each object is prepended with \"scp: \". When calling  vipy.util.scpload on the local machine, this will fetch the pickle file from the remote machine via scp using the default public key. Then, when each vipy object is accessed, it will fetch the URL of the media object via scp from the remote machine. This provides an on-demand fetching of each image from a data storage behind a SSH server without any port forwarding, and uses public key scp. This allows for visualization of datasets that cannot be copied locally, but can be reduced on the local machine which are then fetched for visualization.  Visualization behind AWS S3 Data repositories are often stored with cloud service providers, such as Amazon AWS. These providers require credentials to access URLs in Simple Storage Service (S3). Vipy supports accessing AWS S3 URLs with credential restricted access. Set the following environment variables for the access key and secret access key provided by Amazon AWS. Follow the links below to get a key:   VIPY_AWS_ACCESS_KEY_ID ='MYKEY'. This is the [AWS key](https: docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html) to download urls of the form \"s3: \".   VIPY_AWS_SECRET_ACCESS_KEY ='MYKEY'. This is the [AWS secret key](https: docs.aws.amazon.com/general/latest/gr/aws-sec-cred-types.html) to download urls of the form \"s3: \". Then prepend the URL scheme \"s3: BUCKET_NAME.s3.amazonaws.com/OBJECT_PATH\" when constructing a URL. Here is an example that we use for [Visym Collector](https: visym.com/collector) to store videos uploaded from around the world:   >>> vipy.image.Image(url=\"s3: visym-data-lake140008-visymcprod.s3.amazonaws.com/uploads/Programs/BRIAR/BRIAR Ground/1abd962f-7607-4480-b6c4-cc6d206646533478029165639494950.mp4\")   Finally, if the credentials you provide are authorized to access this bucket and object, then this object will be downloaded on-demand when the pixels are needed. This provides a convenient method of on-demand downloading and caching of large datasets.  Videos  Load from YouTube   v = vipy.video.Video(url='https: youtu.be/kpBCzzzX6zA')    Inspect the FFMPEG command line   print(vipy.video.Video(filename='/path/to/in.mp4').mindim(512).framerate(2).commandline(     'ffmpeg -i /path/to/in.mp4 -filter_complex \"[0]fps=fps=2.0:round=up[s0];[s0]scale=-1:512[s1]\" -map \"[s1]\" dummyfile'    Export frames as vipy images   frames = [im for im in v.framerate(1)]  1 Hz export    Export frames as numpy array   frames = v.framerate(0.1).numpy()  0.1 Hz export    Generate WEBP animations   v = vipy.video.RandomScene().clip(0,30).webp()    Find all videos in directory  Track objects in video  Import RTSP camera streams  Detect activities in video  Blur People and Cars  Make a video mosaic from many streams  Split a video into activity clips  Create quicklooks for fast video watching  Stabilize background  Create video thumbnails  Create compressed and cached tensors for large-scale training  Export to JSON  Datasets  Create a dataset  Resize and crop  Import to torch  Archive to .tar.gz  Export to JSON  Video data augmentation for training  Create standalone HTML visualizations of images  Contact Visym Labs  info@visym.com>>"
},
{
"ref":"vipy.pyramid",
"url":1,
"doc":""
},
{
"ref":"vipy.pyramid.GaussianPyramid",
"url":1,
"doc":"vipy.pyramid.GaussianPyramid() class"
},
{
"ref":"vipy.pyramid.GaussianPyramid.band",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.GaussianPyramid.show",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.LaplacianPyramid",
"url":1,
"doc":"vipy.pyramid.LaplacianPyramid() class"
},
{
"ref":"vipy.pyramid.LaplacianPyramid.band",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.LaplacianPyramid.reconstruct",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.LaplacianPyramid.show",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.LaplacianPyramid.height",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.LaplacianPyramid.width",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.LaplacianPyramid.channels",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.LaplacianPyramid.scales",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.LaplacianPyramid.tensor",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.LaplacianPyramid.fromtensor",
"url":1,
"doc":"Convert a S CxHxW torch tensor back to LaplacianPyramid",
"func":1
},
{
"ref":"vipy.pyramid.Foveation",
"url":1,
"doc":"vipy.pyramid.LaplacianPyramid() class"
},
{
"ref":"vipy.pyramid.Foveation.foveate",
"url":1,
"doc":"Foveate the input image at location (tx, ty) in scaled image coordinates where (0,0) is the center and (1,1) is the upper left",
"func":1
},
{
"ref":"vipy.pyramid.Foveation.visualize",
"url":1,
"doc":"Show the fovea density",
"func":1
},
{
"ref":"vipy.pyramid.Foveation.fromtensor",
"url":1,
"doc":"Convert a S CxHxW torch tensor back to LaplacianPyramid",
"func":1
},
{
"ref":"vipy.pyramid.SteerablePyramid",
"url":1,
"doc":""
},
{
"ref":"vipy.pyramid.SteerablePyramid.num_scales",
"url":1,
"doc":""
},
{
"ref":"vipy.pyramid.SteerablePyramid.num_orientations",
"url":1,
"doc":""
},
{
"ref":"vipy.pyramid.SteerablePyramid.num_channels",
"url":1,
"doc":""
},
{
"ref":"vipy.pyramid.SteerablePyramid.bandpass",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.SteerablePyramid.lowpass",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.SteerablePyramid.highpass",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.SteerablePyramid.synthesis",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.SteerablePyramid.multichannel",
"url":1,
"doc":"a multichannel image is an image of the same shape as the input, but with channels from pyramid decomposition. Coefficients are resized using bilinear interpolation.",
"func":1
},
{
"ref":"vipy.pyramid.SteerablePyramid.montage",
"url":1,
"doc":"scales by row, orientations by col, channels merged back into color image, last image is lowpass",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid",
"url":1,
"doc":""
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.device",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.num_scales",
"url":1,
"doc":""
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.num_orientations",
"url":1,
"doc":""
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.num_channels",
"url":1,
"doc":""
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.to",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.forward",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.forwarded",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.tensor",
"url":1,
"doc":"a pyramid tensor is an NxCxHxW tensor (same shape as the input), but with channels from complex (even, odd) pyramid coefficients The first channel will be the residual highpass and the last will be the residual lowpass. Each band is then a separate channel in (scale, orientation) order input is NxCxHxW tensor",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.band",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.magnitude",
"url":1,
"doc":"return magnitude component of complex steerable pyramid",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.phase",
"url":1,
"doc":"return phase component of complex steerable pyramid",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.montage",
"url":1,
"doc":"return a montage visualization of the pyramid, scales by row, orientations by col, channels merged back into color image, last row is highpass and lowpass",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.synthesis",
"url":1,
"doc":"Generate a synthesis of the multichannel tensor x",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.phase_congruency",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.pyramid.BatchSteerablePyramid.zero_crossing",
"url":1,
"doc":"",
"func":1
},
{
"ref":"vipy.metrics",
"url":2,
"doc":""
},
{
"ref":"vipy.metrics.cumulative_match_characteristic",
"url":2,
"doc":"CMC curve for probe x gallery similarity matrix (larger is more similar) and ground truth match matrix (one +1 per row, rest zeros)",
"func":1
},
{
"ref":"vipy.metrics.plot_cmc",
"url":2,
"doc":"Generate cumulative match characteristic (CMC) plot",
"func":1
},
{
"ref":"vipy.metrics.tdr_at_rank",
"url":2,
"doc":"Janus metric for correct retrieval (true detection rate) within a specific rank",
"func":1
},
{
"ref":"vipy.metrics.roc",
"url":2,
"doc":"",
"func":1
},
{
"ref":"vipy.metrics.roc_per_image",
"url":2,
"doc":"",
"func":1
},
{
"ref":"vipy.metrics.roc_eer",
"url":2,
"doc":"",
"func":1
},
{
"ref":"vipy.metrics.tpr_at_fpr",
"url":2,
"doc":"Janus metric for true positive rate at a specific false positive rate",
"func":1
},
{
"ref":"vipy.metrics.fpr_at_tpr",
"url":2,
"doc":"Janus metric for false positive rate at a specific true positive rate",
"func":1
},
{
"ref":"vipy.metrics.plot_roc",
"url":2,
"doc":"http: scikit-learn.org/stable/auto_examples/plot_roc.html",
"func":1
},
{
"ref":"vipy.metrics.mean_average_precision",
"url":2,
"doc":"numpy wrapper for mean",
"func":1
},
{
"ref":"vipy.metrics.confusion_matrix",
"url":2,
"doc":"Generate a confusion matrix plot for a confusion matrix cm",
"func":1
},
{
"ref":"vipy.metrics.plot_pr",
"url":2,
"doc":"Plot precision recall curve using matplotlib, with optional figure save. Call this multiple times with same figure number to plot multiple curves.",
"func":1
},
{
"ref":"vipy.metrics.plot_ap",
"url":2,
"doc":"Plot Average-Precision bar chart using matplotlib, with optional figure save",
"func":1
},
{
"ref":"vipy.metrics.histogram",
"url":2,
"doc":"Plot histogram bar chart using matplotlib with vertical axis labels on x-axis with optional figure save. Inputs: -freq: the output of (freq, categories) = np.histogram( ., bins=n) -categories [list]: a list of category names that must be length n, or the output of (f,c) = np.histogram( .) and categories=c[:-1] -xrot ['vertical'|None]: rotate the xticks -barcolors [list]: list of named colors equal to the length of categories",
"func":1
},
{
"ref":"vipy.metrics.pie",
"url":2,
"doc":"Generate a matplotlib style pie chart with wedges with specified size and labels, with an optional outfile",
"func":1
},
{
"ref":"vipy.metrics.scatterplot",
"url":2,
"doc":"Generate a scatterplot of 2D points in an Nx2 matrix (X) with provided category labels in list of length N (labels). Each label will be assigned a unique color. Scatterplot saved to outfile (if provided).",
"func":1
},
{
"ref":"vipy.metrics.ascii_bar_chart",
"url":2,
"doc":"Given a list of soft_labels = [(label, confidence),  .], return an ascii horizontal bar chart for each label sorted by confidence. Confidences are specied for the provide range (min_conf, max_conf) The bar_width controls how wide the overall bars are in characters >>> print(vipy.metrics.ascii_bar_chart([('A',1), ('B',0.5), ('C',0.1)] [                    ] A (1.000) [                    ] B (0.500) [                    ] C (0.100)",
"func":1
},
{
"ref":"vipy.show",
"url":3,
"doc":""
},
{
"ref":"vipy.show.figure",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.close",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.closeall",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.show",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.noshow",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.imshow",
"url":3,
"doc":"Show an image in the provided figure number",
"func":1
},
{
"ref":"vipy.show.imbbox",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.imdetection",
"url":3,
"doc":"Show a list of vipy.object.Detections overlayed on img. Image must be RGB",
"func":1
},
{
"ref":"vipy.show.imkeypoints",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.imobjects",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.impoints",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.frame",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.imframe",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.savefig",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.colorlist",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.text",
"url":3,
"doc":"",
"func":1
},
{
"ref":"vipy.show.array",
"url":3,
"doc":"Fast visualization of a numpy array img   vipy.show.array(np.random.rand(16,16,3  ",
"func":1
},
{
"ref":"vipy.gui",
"url":4,
"doc":""
},
{
"ref":"vipy.gui.using_matplotlib",
"url":5,
"doc":""
},
{
"ref":"vipy.gui.using_matplotlib.escape_to_exit",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.flush",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.imflush",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.show",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.noshow",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.savefig",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.figure",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.close",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.closeall",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.imshow",
"url":5,
"doc":"Show an image in a figure window (optionally visible), reuse previous figure if it is the same shape",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.text",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.boundingbox",
"url":5,
"doc":"Draw a captioned bounding box on a previously shown image",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.imdetection",
"url":5,
"doc":"Show bounding boxes from a list of vipy.object.Detections on the same image, plotted in list order with optional captions",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.imkeypoints",
"url":5,
"doc":"Show  vipy.object.Keypoint2d on the same image, plotted in list order with optional captions",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.imobjects",
"url":5,
"doc":"Show  vipy.object.Keypoint2d on the same image, plotted in list order with optional captions",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.imframe",
"url":5,
"doc":"Show a scatterplot of fr= x1,y1],[x2,y2] .] 2D points overlayed on an image, all the same color",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.frame",
"url":5,
"doc":"Show a scatterplot of fr= x1,y1],[x2,y2] .] 2D points, all the same color",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.colorlist",
"url":5,
"doc":"Return a list of named colors that are higher contrast with a white background if light_mode, else named colors that are higher contrast with a dark background if dark_mode",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.edit",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.Annotate",
"url":5,
"doc":""
},
{
"ref":"vipy.gui.using_matplotlib.Annotate.on_press",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.Annotate.on_release",
"url":5,
"doc":"",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangle",
"url":5,
"doc":""
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangle.connect",
"url":5,
"doc":"connect to all the events we need",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangle.on_press",
"url":5,
"doc":"on button press we will see if the mouse is over us and store some data",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangle.on_motion",
"url":5,
"doc":"on motion we will move the rect if the mouse is over us",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangle.on_release",
"url":5,
"doc":"on release we reset the press data",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangle.disconnect",
"url":5,
"doc":"disconnect all the stored connection ids",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangleFast",
"url":5,
"doc":""
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangleFast.lock",
"url":5,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangleFast.connect",
"url":5,
"doc":"connect to all the events we need",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangleFast.on_press",
"url":5,
"doc":"on button press we will see if the mouse is over us and store some data",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangleFast.on_motion",
"url":5,
"doc":"on motion we will move the rect if the mouse is over us",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangleFast.on_release",
"url":5,
"doc":"on release we reset the press data",
"func":1
},
{
"ref":"vipy.gui.using_matplotlib.DraggableRectangleFast.disconnect",
"url":5,
"doc":"disconnect all the stored connection ids",
"func":1
},
{
"ref":"vipy.activity",
"url":6,
"doc":""
},
{
"ref":"vipy.activity.Activity",
"url":6,
"doc":"vipy.object.Activity class An activity is a grouping of one or more tracks involved in an activity within a given startframe and endframe. The activity occurs at a given (startframe, endframe), where these frame indexes are extracted at the provided framerate. All objects are passed by reference with a globally unique track ID, for the tracks involved with the activity. This is done since tracks can exist after an activity completes, and that tracks should update the spatial transformation of boxes. Valid constructors  python t = vipy.object.Track(category='Person') a = vipy.object.Activity(startframe=0, endframe=10, category='Walking', tracks=t.id( a = vipy.object.Activity(startframe=0, endframe=10, category='Walking', tracks=t)   Note shortlabel is kepy for backwards compatibility and will be deprecated"
},
{
"ref":"vipy.activity.Activity.hasattribute",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.confidence",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.from_json",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.duration",
"url":6,
"doc":"The length of the activity in seconds. Args: s: [float] The number of seconds for this activity, starting at the startframe centered: [bool] If true, then set the duration centered on the middle frame Returns: The duration in seconds of this activity object (if s=None) This activity object with the requested duration (if s!=None)",
"func":1
},
{
"ref":"vipy.activity.Activity.dict",
"url":6,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding",
"func":1
},
{
"ref":"vipy.activity.Activity.json",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.actorid",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.startframe",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.endframe",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.middleframe",
"url":6,
"doc":"Return the middle frame number of the activity",
"func":1
},
{
"ref":"vipy.activity.Activity.framerate",
"url":6,
"doc":"Resample (startframe, endframe) from known original framerate set by constructor to be new framerate fps",
"func":1
},
{
"ref":"vipy.activity.Activity.category",
"url":6,
"doc":"Change the label to the new label",
"func":1
},
{
"ref":"vipy.activity.Activity.categoryif",
"url":6,
"doc":"If the current category is equal to ifcategory, then change it to newcategory. Args: ifcategory [dict, str]: May be a dictionary {ifcategory:tocategory}, or just an ifcategory tocategory [str]: the target category Returns: this object with the category changed.  note This is useful for converting synonyms such as self.categoryif('person_sits', 'person_sitting')",
"func":1
},
{
"ref":"vipy.activity.Activity.label",
"url":6,
"doc":"Alias for category",
"func":1
},
{
"ref":"vipy.activity.Activity.add",
"url":6,
"doc":"Add the track id for the track to this activity, so that if the track is changed externally it is reflected here",
"func":1
},
{
"ref":"vipy.activity.Activity.addid",
"url":6,
"doc":"Add the track id for the track to this activity, so that if the track is changed externally it is reflected here",
"func":1
},
{
"ref":"vipy.activity.Activity.tracks",
"url":6,
"doc":"alias for trackids",
"func":1
},
{
"ref":"vipy.activity.Activity.cleartracks",
"url":6,
"doc":"Remove all track IDs from this activity",
"func":1
},
{
"ref":"vipy.activity.Activity.trackids",
"url":6,
"doc":"Return a set of track IDs associated with this activity",
"func":1
},
{
"ref":"vipy.activity.Activity.hasoverlap",
"url":6,
"doc":"Return true if the temporal_iou is greater than the provided threshold between self and other Track or other Activity",
"func":1
},
{
"ref":"vipy.activity.Activity.isneighbor",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.hastrack",
"url":6,
"doc":"Is the track part of the activity?",
"func":1
},
{
"ref":"vipy.activity.Activity.hastrackoverlap",
"url":6,
"doc":"is the activity occurring during the interval when the track is occurring and is this track assigned to the activity?",
"func":1
},
{
"ref":"vipy.activity.Activity.append",
"url":6,
"doc":"Append newtrack to this activity and set as actorid()",
"func":1
},
{
"ref":"vipy.activity.Activity.trackfilter",
"url":6,
"doc":"Remove all tracks such that the lambda function f(trackid) resolves to False",
"func":1
},
{
"ref":"vipy.activity.Activity.replace",
"url":6,
"doc":"Replace oldtrack with newtrack if present in self._tracks. Pass in a trackdict to share reference to track, so that track owner can modify the track and this object observes the change",
"func":1
},
{
"ref":"vipy.activity.Activity.replaceid",
"url":6,
"doc":"Replace oldtrack with newtrack if present in self._tracks. Pass in a trackdict to share reference to track, so that track owner can modify the track and this object observes the change",
"func":1
},
{
"ref":"vipy.activity.Activity.during",
"url":6,
"doc":"Is frame during the time interval (startframe, endframe) inclusive?",
"func":1
},
{
"ref":"vipy.activity.Activity.during_interval",
"url":6,
"doc":"Is the activity occurring for any frames within the interval [startframe, endframe) (non-inclusive of endframe)?",
"func":1
},
{
"ref":"vipy.activity.Activity.union",
"url":6,
"doc":"Compute the union of the new activity other to this activity by updating the start and end times and computing the mean confidence. -Note: other must have the same category and track IDs as self -confweight [0,1]: the convex combinatiopn weight applied to the new activity",
"func":1
},
{
"ref":"vipy.activity.Activity.temporal_iou",
"url":6,
"doc":"Return the temporal intersection over union of two activities or this activity and a track",
"func":1
},
{
"ref":"vipy.activity.Activity.offset",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.truncate",
"url":6,
"doc":"Truncate the activity so that it is between start and end",
"func":1
},
{
"ref":"vipy.activity.Activity.id",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.clone",
"url":6,
"doc":"",
"func":1
},
{
"ref":"vipy.activity.Activity.temporalpad",
"url":6,
"doc":"Add a temporal pad of df=(before frames, after frames) or df=pad frames to the start and end of the activity. The padded start frame may be negative.",
"func":1
},
{
"ref":"vipy.activity.Activity.padto",
"url":6,
"doc":"Add a symmetric temporal pad so that the activity is at least t seconds long",
"func":1
},
{
"ref":"vipy.activity.Activity.disjoint",
"url":6,
"doc":"Enforce disjoint activities with other by shifting the endframe or startframe of self to not overlap if they share the same tracks. Other may be an Activity() or list of Activity() if strict=True, then throw an exception if other or self is fully contained with the other, resulting in degenerate activity after disjoint",
"func":1
},
{
"ref":"vipy.activity.Activity.temporal_distance",
"url":6,
"doc":"Return the temporal distance in frames between self and other which is the minimum frame difference between the end of one to the start of the other, or zero if they overlap",
"func":1
},
{
"ref":"vipy.activity.Activity.within",
"url":6,
"doc":"Is the activity within the frame rate (startframe, endframe)?",
"func":1
},
{
"ref":"vipy.activity.Activity.attributes",
"url":6,
"doc":""
},
{
"ref":"vipy.camera",
"url":7,
"doc":""
},
{
"ref":"vipy.camera.Camera",
"url":7,
"doc":""
},
{
"ref":"vipy.camera.Camera.CAM",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Camera.FRAMERATE",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Camera.TIC",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Camera.TOC",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Camera.RESIZE",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Camera.GREY",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Camera.PROCESS",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Webcam",
"url":7,
"doc":"Create a webcam object that will yield  vipy.image.Image frames. This is a light wrapper to OpenCV webcam object (cv2.VideoCapture) that yields vipy objects. >>> cam = vipy.cmaera.Webcam() >>> cam.frame().show() Or as an iterator: >>> for im in vipy.camera.Webcam(): >>> im.show() To capture a video: >>> Args: framerate: [float] The framerate to grab from the camera url: [int] The camera index to open"
},
{
"ref":"vipy.camera.Webcam.current",
"url":7,
"doc":"Alias for  vipy.camera.Webcam.next ",
"func":1
},
{
"ref":"vipy.camera.Webcam.next",
"url":7,
"doc":"Return a  vipy.image.Image from the camera",
"func":1
},
{
"ref":"vipy.camera.Webcam.frame",
"url":7,
"doc":"Alias for  vipy.camera.Webcam.next ",
"func":1
},
{
"ref":"vipy.camera.Webcam.video",
"url":7,
"doc":"Return a  vipy.video.Video with n frames, constructed using the provided framerate (defaults to 30Hz)",
"func":1
},
{
"ref":"vipy.camera.Webcam.CAM",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Webcam.FRAMERATE",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Webcam.TIC",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Webcam.TOC",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Webcam.RESIZE",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Webcam.GREY",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Webcam.PROCESS",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Ipcam",
"url":7,
"doc":"Create a IPcam object that will yield  vipy.image.Image frames. >>> cam = vipy.cmaera.IPcam() >>> cam.frame().show() Or as an iterator: >>> for im in vipy.camera.IPcam(): >>> im.show()"
},
{
"ref":"vipy.camera.Ipcam.TMPFILE",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Ipcam.next",
"url":7,
"doc":"",
"func":1
},
{
"ref":"vipy.camera.Ipcam.CAM",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Ipcam.FRAMERATE",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Ipcam.TIC",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Ipcam.TOC",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Ipcam.RESIZE",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Ipcam.GREY",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.camera.Ipcam.PROCESS",
"url":7,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.ssim",
"url":8,
"doc":""
},
{
"ref":"vipy.ssim.SSIM",
"url":8,
"doc":"Structural similarity (SSIM) index"
},
{
"ref":"vipy.ssim.SSIM.match",
"url":8,
"doc":"Return a set of matching points in img1 (MxN uint8 numpy) and img2 (MxN uint8 numpy) in the form suitable for homography estimation",
"func":1
},
{
"ref":"vipy.ssim.SSIM.warp",
"url":8,
"doc":"Warp an image im_src with points src_pts to align with dst_pts",
"func":1
},
{
"ref":"vipy.ssim.SSIM.align",
"url":8,
"doc":"Return an image which is the warped version of img1 (MxN uint8 numpy) that aligns with img2 (MxN uint8 numpy)",
"func":1
},
{
"ref":"vipy.ssim.SSIM.rgb2gray",
"url":8,
"doc":"Convert RGB image to grayscale; accesory function",
"func":1
},
{
"ref":"vipy.ssim.SSIM.similarity",
"url":8,
"doc":"Compute the Structural Similarity Index (SSIM) score of two images Inputs: 1) I1, image array 2) I2, image array 3) K1, float (optional, default=0.01) - constant 4) K2, float (optional, default=0.03) - constant Outputs: 1) out; float - SSIM score 2) ssim_map; 2-D image array - SSIM map",
"func":1
},
{
"ref":"vipy.ssim.SSIM.ssim",
"url":8,
"doc":"Return structural similarity score when aligning im_degraded to im_reference >>> (ssim, im_aligned) = vipy.ssim.SSIM(do_alignment=True).ssim(vipy.image.squareowl(), vipy.image.squareowl().rotate(0.01), returnAligned=True) >>> print(ssim) >>> im_aligned.show(figure=1) >>> vipy.image.squareowl().rotate(0.01).show(figure=2)",
"func":1
},
{
"ref":"vipy.ssim.demo",
"url":8,
"doc":"Synthetically rotate an image by 4 degrees, and compute structural similarity with and without alignment, return images >>> (image, degraded_image, aligned_image) = vipy.ssim.demo(vipy.image.Image(filename='/path/to/image.jpg' )",
"func":1
},
{
"ref":"vipy.version",
"url":9,
"doc":""
},
{
"ref":"vipy.version.Version",
"url":9,
"doc":"vipy.version.Version class This provides a simple class for comparing version strings similar to packaging. >>> ver = vipy.version.Version.from_string('1.2.3') >>> ver = vipy.version.Version(major=1, minor=2, release=3) >>> ver >= '1.2.2' >>> ver  '1.2.3'"
},
{
"ref":"vipy.version.Version.is_valid",
"url":9,
"doc":"",
"func":1
},
{
"ref":"vipy.version.Version.from_string",
"url":9,
"doc":"version string can be 'PACKAGE-X.Y.Z' or 'X.Y.Z' or 'X.Y'",
"func":1
},
{
"ref":"vipy.version.Version.int",
"url":9,
"doc":"",
"func":1
},
{
"ref":"vipy.version.Version.version",
"url":9,
"doc":"",
"func":1
},
{
"ref":"vipy.version.Version.at_least_version",
"url":9,
"doc":"Is versionstring='X.Y.Z' at least the current version?",
"func":1
},
{
"ref":"vipy.version.Version.at_least_major_version",
"url":9,
"doc":"",
"func":1
},
{
"ref":"vipy.version.Version.same_major_version",
"url":9,
"doc":"",
"func":1
},
{
"ref":"vipy.version.Version.at_least_minor_version",
"url":9,
"doc":"",
"func":1
},
{
"ref":"vipy.version.Version.at_least_release_version",
"url":9,
"doc":"",
"func":1
},
{
"ref":"vipy.math",
"url":10,
"doc":""
},
{
"ref":"vipy.math.normalize",
"url":10,
"doc":"Whiten the numpy array arr using the provided mean and standard deviation. Computes: (scale (arr - mean / std Args: arr: [numpy] A numpy array mean: [numpy] A broadcastable mean vector std: [numpy] A broadcastable std vector scale: [float] A scale factor to apply to arr before whitening (e.g. to scale to [0,1]) Returns  scale arr) - mean / std  notes Does not check that std > 0",
"func":1
},
{
"ref":"vipy.math.gain",
"url":10,
"doc":"",
"func":1
},
{
"ref":"vipy.math.significant_digits",
"url":10,
"doc":"Return the float f rounded to n significant digits",
"func":1
},
{
"ref":"vipy.math.iseven",
"url":10,
"doc":"is the number x an even number?",
"func":1
},
{
"ref":"vipy.math.isodd",
"url":10,
"doc":"is the number x an odd number?",
"func":1
},
{
"ref":"vipy.math.even",
"url":10,
"doc":"Return the largest even integer less than or equal (or greater than if greaterthan=True) to the value",
"func":1
},
{
"ref":"vipy.math.poweroftwo",
"url":10,
"doc":"Return the closest power of two smaller than the scalar value. x=511 -> 256, x=512 -> 512",
"func":1
},
{
"ref":"vipy.math.signsqrt",
"url":10,
"doc":"Return the signed square root of elements in numpy array x",
"func":1
},
{
"ref":"vipy.math.runningmean",
"url":10,
"doc":"Compute the running unweighted mean of X row-wise, with a history of n, reducing the history at the start for column indexes < n",
"func":1
},
{
"ref":"vipy.math.gaussian",
"url":10,
"doc":"1D gaussian window with M points. Replication of scipy.signal.gaussian",
"func":1
},
{
"ref":"vipy.math.gaussian2d",
"url":10,
"doc":"2D float32 gaussian image of size (rows=H, cols=W) with mu=[x, y] and std=[stdx, stdy]",
"func":1
},
{
"ref":"vipy.math.interp1d",
"url":10,
"doc":"Replication of scipy.interpolate.interp1d with assume_sorted=True, and constant replication of boundary handling. Input must be sorted. Input: 1D numpy arrays y=f(x) Output: Lambda function f that will interpolate f(xi) -> yi",
"func":1
},
{
"ref":"vipy.math.find_closest_positive_divisor",
"url":10,
"doc":"Return non-trivial positive integer divisor (bh) of (a) closest to (b) in abs(b-bh) such that a % bh  0.  notes This uses exhaustive search, which is inefficient for large a.",
"func":1
},
{
"ref":"vipy.math.cartesian_to_polar",
"url":10,
"doc":"Cartesian (x,y) coordinates to polar (radius, theta_radians) coordinates, theta in radians in [-pi,pi]",
"func":1
},
{
"ref":"vipy.math.polar_to_cartesian",
"url":10,
"doc":"Polar (r=radius, t=theta_radians) coordinates to cartesian (x=right,y=down) coordinates. (0,0) is upper left of image",
"func":1
},
{
"ref":"vipy.math.rad2deg",
"url":10,
"doc":"Radians to degrees",
"func":1
},
{
"ref":"vipy.image",
"url":11,
"doc":""
},
{
"ref":"vipy.image.Image",
"url":11,
"doc":"vipy.image.Image class The vipy image class provides a fluent, lazy interface for representing, transforming and visualizing images. The following constructors are supported:   im = vipy.image.Image(filename=\"/path/to/image.ext\")   All image file formats that are readable by PIL are supported here.   im = vipy.image.Image(url=\"http: domain.com/path/to/image.ext\")   The image will be downloaded from the provided url and saved to a temporary filename. The environment variable VIPY_CACHE controls the location of the directory used for saving images, otherwise this will be saved to the system temp directory.   im = vipy.image.Image(url=\"http: domain.com/path/to/image.ext\", filename=\"/path/to/new/image.ext\")   The image will be downloaded from the provided url and saved to the provided filename. The url() method provides optional basic authentication set for username and password   im = vipy.image.Image(array=img, colorspace='rgb')   The image will be constructed from a provided numpy array 'img', with an associated colorspace. The numpy array and colorspace can be one of the following combinations: - 'rgb': uint8, three channel (red, green, blue) - 'rgba': uint8, four channel (rgb + alpha) - 'bgr': uint8, three channel (blue, green, red), such as is returned from cv2.imread() - 'bgra': uint8, four channel - 'hsv': uint8, three channel (hue, saturation, value) - 'lum;: uint8, one channel, luminance (8 bit grey level) - 'grey': float32, one channel in range [0,1] (32 bit intensity) - 'float': float32, any channel in range [-inf, +inf] The most general colorspace is 'float' which is used to manipulate images prior to network encoding, such as applying bias. Args: filename: a path to an image file that is readable by PIL url: a url string to an image file that is readable by PIL array: a numpy array of type uint8 or float32 of shape HxWxC=height x width x channels colorspace: a string in ['rgb', 'rgba', 'bgr', 'bgra', 'hsv', 'float', 'grey', 'lum'] attributes: a python dictionary that is passed by reference to the image. This is useful for encoding metadata about the image. Accessible as im.attributes Returns: A  vipy.image.Image object"
},
{
"ref":"vipy.image.Image.cast",
"url":11,
"doc":"Typecast the conformal vipy.image object im as  vipy.image.Image . This is useful for downcasting  vipy.image.Scene or  vipy.image.ImageDetection down to an image.   ims = vipy.image.RandomScene() im = vipy.image.Image.cast(im)  ",
"func":1
},
{
"ref":"vipy.image.Image.from_dict",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.from_uri",
"url":11,
"doc":"Create an image object from an absolute file path or url",
"func":1
},
{
"ref":"vipy.image.Image.from_json",
"url":11,
"doc":"Import the JSON string s as an  vipy.image.Image object. Args: s: json encoded string This will perform a round trip such that im1  im2   im1 = vupy.image.RandomImage() im2 = vipy.image.Image.from_json(im1.json( assert im1  im2   Note: to construct from non-encoded json (e.g. a dict prior to dumps), use from_dict",
"func":1
},
{
"ref":"vipy.image.Image.sanitize",
"url":11,
"doc":"Remove all private keys from the attributes dictionary. The attributes dictionary is useful storage for arbitrary (key,value) pairs. However, this storage may contain sensitive information that should be scrubbed from the media before serialization. As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key. This is analogous to private or reserved attributes in the python lanugage. Users should reserve these keynames for those keys that should be sanitized and removed before any serialization of this object.   assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey')  False  ",
"func":1
},
{
"ref":"vipy.image.Image.print",
"url":11,
"doc":"Print the representation of the image and return self with an optional sleep=n seconds Useful for debugging or sequential visualization in long fluent chains.",
"func":1
},
{
"ref":"vipy.image.Image.exif",
"url":11,
"doc":"Return the EXIF meta-data in filename as a dictionary. Included non-base EXIF data if extended=True. Returns empty dictionary if no EXIF exists. Triggers download but not load.",
"func":1
},
{
"ref":"vipy.image.Image.tile",
"url":11,
"doc":"Generate an image tiling. A tiling is a decomposition of an image into overlapping or non-overlapping rectangular regions. Args: tilewidth: [int] the image width of each tile tileheight: [int] the image height of each tile overlaprows: [int] the number of overlapping rows (height) for each tile overlapcols: [int] the number of overlapping width (width) for each tile Returns: A list of  vipy.image.Image objects such that each image is a single tile and the set of these tiles forms the original image Each image in the returned list contains the 'tile' attribute which encodes the crop used to create the tile.  note -  vipy.image.Image.tile can be undone using  vipy.image.Image.untile - The identity tiling is im.tile(im.width(), im.height(), overlaprows=0, overlapcols=0) - Ragged tiles outside the image boundary are zero padded - All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.Image.union",
"url":11,
"doc":"No-op for  vipy.image.Image ",
"func":1
},
{
"ref":"vipy.image.Image.untile",
"url":11,
"doc":"Undo an image tiling and recreate the original image.   tiles = im.tile(im.width()/2, im.height()/2, 0, 0) imdst = vipy.image.Image.untile(tiles) assert imdst  im   Args: imlist: this must be the output of  vipy.image.Image.tile Returns: A new  vipy.image.Image object reconstructed from the tiling, such that this is equivalent to the input to vipy.image.Image.tile  note All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.Image.uncrop",
"url":11,
"doc":"Uncrop using provided bounding box and zeropad to shape=(Height, Width). An uncrop is the inverse operation for a crop, which preserves the cropped portion of the image in the correct location and replaces the rest with zeros out to shape.   im = vipy.image.RandomImage(128, 128) bb = vipy.geometry.BoundingBox(xmin=0, ymin=0, width=64, height=64) uncrop = im.crop(bb).uncrop(bb, shape=(128,128   Args: bb: [ vipy.geometry.BoundingBox ] the bounding box used to crop the image in self shape: [tuple] (height, width) of the uncropped image Returns: this  vipy.image.Image object with the pixels uncropped.  note NOT idempotent. This will generate different results if run more than once.",
"func":1
},
{
"ref":"vipy.image.Image.splat",
"url":11,
"doc":"Replace pixels within boundingbox in self with pixels in im",
"func":1
},
{
"ref":"vipy.image.Image.store",
"url":11,
"doc":"Store the current image file as an attribute of this object. Useful for archiving an object to be fully self contained without any external references. -Remove this stored image using unstore() -Unpack this stored image and set up the filename using restore() -This method is more efficient than load() followed by pkl(), as it stores the encoded image as a byte string. -Useful for creating a single self contained object for distributed processing.   v  v.store().restore(v.filename(  ",
"func":1
},
{
"ref":"vipy.image.Image.unstore",
"url":11,
"doc":"Delete the currently stored image from store()",
"func":1
},
{
"ref":"vipy.image.Image.restore",
"url":11,
"doc":"Save the currently stored image to filename, and set up filename",
"func":1
},
{
"ref":"vipy.image.Image.abspath",
"url":11,
"doc":"Change the path of the filename from a relative path to an absolute path (not relocatable)",
"func":1
},
{
"ref":"vipy.image.Image.relpath",
"url":11,
"doc":"Replace the filename with a relative path to parent (or current working directory if none)",
"func":1
},
{
"ref":"vipy.image.Image.canload",
"url":11,
"doc":"Return True if the image can be loaded successfully, useful for filtering bad links or corrupt images",
"func":1
},
{
"ref":"vipy.image.Image.dict",
"url":11,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding",
"func":1
},
{
"ref":"vipy.image.Image.json",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.loader",
"url":11,
"doc":"Lambda function to load an unsupported image filename to a numpy array. This lambda function will be executed during load and the result will be stored in self._array",
"func":1
},
{
"ref":"vipy.image.Image.bytes_array_loader",
"url":11,
"doc":"Load from a bytes array",
"func":1
},
{
"ref":"vipy.image.Image.PIL_loader",
"url":11,
"doc":"Load from a PIL image file object",
"func":1
},
{
"ref":"vipy.image.Image.has_loader",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.load",
"url":11,
"doc":"Load image to cached private '_array' attribute. Args: verbose: [bool] If true, show additional useful printed output Returns: This  vipy.image.Image object with the pixels loaded in self._array as a numpy array.  note This loader supports any image file format supported by PIL. A custom loader can be added using  vipy.image.Image.loader .",
"func":1
},
{
"ref":"vipy.image.Image.download",
"url":11,
"doc":"Download URL to filename provided by constructor, or to temp filename. Args: timeout: [int] The timeout in seconds for an http or https connection attempt. See also [urllib.request.urlopen](https: docs.python.org/3/library/urllib.request.html). verbose: [bool] If true, output more helpful message. cached: [bool] If true, use the cached previously downloaded file (if it exists) Returns: This  vipy.image.Image object with the URL downloaded to  vipy.image.Image.filename or to a  vipy.util.tempimage filename which can be retrieved with  vipy.image.Image.filename .",
"func":1
},
{
"ref":"vipy.image.Image.reload",
"url":11,
"doc":"Flush the image buffer to force reloading from file or URL",
"func":1
},
{
"ref":"vipy.image.Image.isloaded",
"url":11,
"doc":"Return True if  vipy.image.Image.load was successful in reading the image, or if the pixels are present in  vipy.image.Image.array .",
"func":1
},
{
"ref":"vipy.image.Image.loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.Image.is_loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.Image.isdownloaded",
"url":11,
"doc":"Does the filename returned from  vipy.image.Image.filename exist, meaning that the url has been downloaded to a local file?",
"func":1
},
{
"ref":"vipy.image.Image.is_downloaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isdownloaded ",
"func":1
},
{
"ref":"vipy.image.Image.downloadif",
"url":11,
"doc":"Download URL to filename if the filename has not already been downloaded",
"func":1
},
{
"ref":"vipy.image.Image.try_download",
"url":11,
"doc":"Attempt to download URL to filename if the filename has not already been downloaded, return object on failure. Check  vipy.image.Image.is_downloaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.Image.try_load",
"url":11,
"doc":"Attempt to load an image, return the object on failure. Check  vipy.image.Image.is_loaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.Image.channels",
"url":11,
"doc":"Return integer number of color channels",
"func":1
},
{
"ref":"vipy.image.Image.iscolor",
"url":11,
"doc":"Color images are three channel or four channel with transparency, float32 or uint8",
"func":1
},
{
"ref":"vipy.image.Image.istransparent",
"url":11,
"doc":"Transparent images are four channel color images with transparency, float32 or uint8. Return true if this image contains an alpha transparency channel",
"func":1
},
{
"ref":"vipy.image.Image.blend",
"url":11,
"doc":"alpha blend self and im in-place, such that self = alpha self + (1-alpha) im",
"func":1
},
{
"ref":"vipy.image.Image.isgrey",
"url":11,
"doc":"Grey images are one channel, float32",
"func":1
},
{
"ref":"vipy.image.Image.isluminance",
"url":11,
"doc":"Luninance images are one channel, uint8",
"func":1
},
{
"ref":"vipy.image.Image.filesize",
"url":11,
"doc":"Return size of underlying image file, requires fetching metadata from filesystem",
"func":1
},
{
"ref":"vipy.image.Image.width",
"url":11,
"doc":"Return the width (columns) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Image.height",
"url":11,
"doc":"Return the height (rows) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Image.shape",
"url":11,
"doc":"Return the (height, width) or equivalently (rows, cols) of the image. Returns: A tuple (height=int, width=int) of the image.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Image.aspectratio",
"url":11,
"doc":"Return the aspect ratio of the image as (width/height) ratio. Returns: A float equivalent to ( vipy.image.Image.width /  vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Image.area",
"url":11,
"doc":"Return the area of the image as (width  height). Returns: An integer equivalent to ( vipy.image.Image.width   vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Image.centroid",
"url":11,
"doc":"Return the real valued center pixel coordinates of the image (col=x,row=y). The centroid is equivalent to half the  vipy.image.Image.shape . Returns: A tuple (column, row) of the floating point center of the image.",
"func":1
},
{
"ref":"vipy.image.Image.centerpixel",
"url":11,
"doc":"Return the integer valued center pixel coordinates of the image (col=i,row=j) The centerpixel is equivalent to half the  vipy.image.Image.shape floored to the nearest integer pixel coordinate. Returns: A tuple (int(column), int(row of the integer center of the image.",
"func":1
},
{
"ref":"vipy.image.Image.array",
"url":11,
"doc":"Replace self._array with provided numpy array Args: np_array: [numpy array] A new array to use as the pixel buffer for this image. copy: [bool] If true, copy the buffer using np.copy(), else use a reference to this buffer. Returns: - If np_array is not None, return the  vipy.image.Image object such that this object points to the provided numpy array as the pixel buffer - If np_array is None, then return the numpy array.  notes - If copy=False, then this  vipy.image.Image object will share the pixel buffer with the owner of np_array. Changes to pixels in this buffer will be shared. - If copy=True, then this will significantly slow down processing for large images. Use referneces wherevery possible.",
"func":1
},
{
"ref":"vipy.image.Image.fromarray",
"url":11,
"doc":"Alias for  vipy.image.Image.array with copy=True. This will set new numpy array as the pixel buffer with a numpy array copy",
"func":1
},
{
"ref":"vipy.image.Image.tonumpy",
"url":11,
"doc":"Alias for  vipy.image.Image.numpy",
"func":1
},
{
"ref":"vipy.image.Image.numpy",
"url":11,
"doc":"Return a mutable numpy array for this  vipy.image.Image .  notes - This will always return a writeable array with the 'WRITEABLE' numpy flag set. This is useful for returning a mutable numpy array as needed while keeping the original non-mutable numpy array (e.g. loaded from a video or PIL) as the underlying pixel buffer for efficiency reasons. - Triggers a  vipy.image.Image.load if the pixel buffer has not been loaded - This will trigger a copy if the ['WRITEABLE' flag](https: numpy.org/doc/stable/reference/generated/numpy.ndarray.flags.html) is not set.",
"func":1
},
{
"ref":"vipy.image.Image.channel",
"url":11,
"doc":"Return a cloned Image() object for the kth channel, or return an iterator over channels if k=None. Iterate over channels as single channel luminance images:   for c in self.channel(): print(c)   Return the kth channel as a single channel luminance image:   c = self.channel(k=0)  ",
"func":1
},
{
"ref":"vipy.image.Image.channelmean",
"url":11,
"doc":"Return a cloned Image() object for the mean of all channels followed by returning a single channel float image. This is useful for visualizing multichannel images by reducing the channels to one   vipy.image.Image(array=np.random.rand(3,3,16).astype(np.float32 .channelmean().mat2gray().lum().show()  ",
"func":1
},
{
"ref":"vipy.image.Image.red",
"url":11,
"doc":"Return red channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.red()  self.channel(0)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.red()  self.channel(3)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.Image.green",
"url":11,
"doc":"Return green channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.green()  self.channel(1)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.green()  self.channel(1)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.Image.blue",
"url":11,
"doc":"Return blue channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.vlue()  self.channel(2)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.blue()  self.channel(0)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.Image.alpha",
"url":11,
"doc":"Return alpha (transparency) channel as a cloned single channel  vipy.image.Image object",
"func":1
},
{
"ref":"vipy.image.Image.zeros",
"url":11,
"doc":"Set the pixel buffer to all zeros of the same shape and datatype as this  vipy.image.Image object. These are equivalent operations for the resulting buffer shape:   import numpy as np np.zeros( (self.width(), self.height(), self.channels( )  self.zeros().array()   Returns: This  vipy.image.Image object.  note Triggers load() if the pixel buffer has not been loaded yet.",
"func":1
},
{
"ref":"vipy.image.Image.pil",
"url":11,
"doc":"Convert vipy.image.Image to PIL Image. Returns: A [PIL image](https: pillow.readthedocs.io/en/stable/reference/Image.html) object, that shares the pixel buffer by reference",
"func":1
},
{
"ref":"vipy.image.Image.blur",
"url":11,
"doc":"Apply a Gaussian blur with Gaussian kernel radius=sigma to the pixel buffer. Args: sigma: [float >=0] The gaussian blur kernel radius. Returns: This  vipy.image.Image object with the pixel buffer blurred in place.",
"func":1
},
{
"ref":"vipy.image.Image.torch",
"url":11,
"doc":"Convert the batch of 1 HxWxC images to a CxHxW torch tensor. Args: order: ['CHW', 'HWC', 'NCHW', 'NHWC']. The axis order of the torch tensor (channels, height, width) or (height, width, channels) or (1, channels, height, width) or (1, height, width, channels) Returns: A CxHxW or HxWxC or 1xCxHxW or 1xHxWxC [torch tensor](https: pytorch.org/docs/stable/tensors.html) that shares the pixel buffer of this image object by reference.  note This supports numpy types and does not support bfloat16",
"func":1
},
{
"ref":"vipy.image.Image.from_torch",
"url":11,
"doc":"Convert a 1xCxHxW or CxHxW torch tensor (or numpy array with torch channel order) to HxWxC numpy array, returns new  vipy.image.Image with inferred colorspace corresponding to data type in x",
"func":1
},
{
"ref":"vipy.image.Image.fromtorch",
"url":11,
"doc":"Alias for  vipy.image.Image.from_torch ",
"func":1
},
{
"ref":"vipy.image.Image.unload",
"url":11,
"doc":"Remove cached file and loaded array. Note that this will delete the underlying file returned by filename() if there is a backing url, cleaning up cached files and forcing re-download",
"func":1
},
{
"ref":"vipy.image.Image.uncache",
"url":11,
"doc":"Alias for  vipy.image.Image.unload ",
"func":1
},
{
"ref":"vipy.image.Image.filename",
"url":11,
"doc":"Return or set image filename",
"func":1
},
{
"ref":"vipy.image.Image.url",
"url":11,
"doc":"Image URL and URL download properties",
"func":1
},
{
"ref":"vipy.image.Image.colorspace",
"url":11,
"doc":"Return or set the colorspace as ['rgb', 'rgba', 'bgr', 'bgra', 'hsv', 'float', 'grey', 'lum']",
"func":1
},
{
"ref":"vipy.image.Image.uri",
"url":11,
"doc":"Return the URI of the image object, either the URL or the filename, raise exception if neither defined",
"func":1
},
{
"ref":"vipy.image.Image.set_attribute",
"url":11,
"doc":"Set element self.attributes[key]=value",
"func":1
},
{
"ref":"vipy.image.Image.setattribute",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.setattributes",
"url":11,
"doc":"Set many attributes at once by providing a dictionary to be merged with current attributes",
"func":1
},
{
"ref":"vipy.image.Image.getattribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.Image.get_attribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.Image.clear_attributes",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.hasattribute",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.delattribute",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.del_attribute",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.delattributes",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.append_attribute",
"url":11,
"doc":"Append the value to attribute key, creating the key as an empty list if it does not exist",
"func":1
},
{
"ref":"vipy.image.Image.metadata",
"url":11,
"doc":"Return metadata associated with this image, stored in the attributes dictionary",
"func":1
},
{
"ref":"vipy.image.Image.hasurl",
"url":11,
"doc":"synonym for  vipy.image.has_url ",
"func":1
},
{
"ref":"vipy.image.Image.has_url",
"url":11,
"doc":"Return True if the image has a URL input source",
"func":1
},
{
"ref":"vipy.image.Image.has_filename",
"url":11,
"doc":"Return True if the image has a filename input source and this file exists",
"func":1
},
{
"ref":"vipy.image.Image.hasfilename",
"url":11,
"doc":"synonym for has_filename",
"func":1
},
{
"ref":"vipy.image.Image.clone",
"url":11,
"doc":"Create deep copy of object, flushing the original buffer if requested and returning the cloned object. Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned object which can be used for encoding and will be garbage collected.  flushforward: copy the object, and set the cloned object array() to None. This flushes the video buffer for the clone, not the object  flushbackward: copy the object, and set the object array() to None. This flushes the video buffer for the object, not the clone.  flush: set the object array() to None and clone the object. This flushes the video buffer for both the clone and the object.  dereference: remove both the filename and URL (if present) in the cloned object, leaving only the buffer",
"func":1
},
{
"ref":"vipy.image.Image.flush",
"url":11,
"doc":"flush the image buffer in place, alias for self.clone(flush=True)",
"func":1
},
{
"ref":"vipy.image.Image.resize",
"url":11,
"doc":"Resize the image buffer to (rows x cols) with bilinear interpolation. If rows or cols is provided, rescale image maintaining aspect ratio",
"func":1
},
{
"ref":"vipy.image.Image.resize_like",
"url":11,
"doc":"Resize image buffer to be the same size as the provided vipy.image.Image()",
"func":1
},
{
"ref":"vipy.image.Image.rescale",
"url":11,
"doc":"Scale the image buffer by the given factor - NOT idempotent",
"func":1
},
{
"ref":"vipy.image.Image.maxdim",
"url":11,
"doc":"Resize image preserving aspect ratio so that maximum dimension of image = dim, or return maxdim()",
"func":1
},
{
"ref":"vipy.image.Image.mindim",
"url":11,
"doc":"Resize image preserving aspect ratio so that minimum dimension of image = dim, or return mindim()",
"func":1
},
{
"ref":"vipy.image.Image.mindimn",
"url":11,
"doc":"Frequently used shortcut for mindim(dim, interp='nearest')",
"func":1
},
{
"ref":"vipy.image.Image.pad",
"url":11,
"doc":"Alias for  vipy.image.Image.zeropad ",
"func":1
},
{
"ref":"vipy.image.Image.zeropad",
"url":11,
"doc":"Pad image using np.pad constant by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.Image.zeropadlike",
"url":11,
"doc":"Zero pad the image balancing the border so that the resulting image size is (width, height)",
"func":1
},
{
"ref":"vipy.image.Image.meanpad",
"url":11,
"doc":"Pad image using np.pad constant=image mean by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.Image.alphapad",
"url":11,
"doc":"Pad image using alpha transparency by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.Image.minsquare",
"url":11,
"doc":"Crop image of size (HxW) to (min(H,W), min(H,W , keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.Image.maxsquare",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with zeropadding or (S,S) if provided, keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.Image.maxmatte",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with balanced zeropadding forming a letterbox with top/bottom matte or pillarbox with left/right matte",
"func":1
},
{
"ref":"vipy.image.Image.centersquare",
"url":11,
"doc":"Crop image of size (NxN) in the center, such that N=min(width,height), keeping the image centroid constant",
"func":1
},
{
"ref":"vipy.image.Image.centercrop",
"url":11,
"doc":"Crop image of size (height x width) in the center, keeping the image centroid constant",
"func":1
},
{
"ref":"vipy.image.Image.cornercrop",
"url":11,
"doc":"Crop image of size (height x width) from the upper left corner",
"func":1
},
{
"ref":"vipy.image.Image.crop",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.fliplr",
"url":11,
"doc":"Mirror the image buffer about the vertical axis - Not idempotent",
"func":1
},
{
"ref":"vipy.image.Image.flipud",
"url":11,
"doc":"Mirror the image buffer about the horizontal axis - Not idempotent",
"func":1
},
{
"ref":"vipy.image.Image.imagebox",
"url":11,
"doc":"Return the bounding box for the image rectangle",
"func":1
},
{
"ref":"vipy.image.Image.border_mask",
"url":11,
"doc":"Return a binary uint8 image the same size as self, with a border of pad pixels in width or height around the edge",
"func":1
},
{
"ref":"vipy.image.Image.affine_transform",
"url":11,
"doc":"Apply a 3x3 affine geometric transformation to the image. Args: - A [np.ndarray]: 3x3 affine geometric transform from  vipy.geometry.affine_transform - border [str]: 'zero' or 'replicate' to handle elements outside the image rectangle after transformation Returns: - This object with only the array transformed  note The image will be loaded and converted to float() prior to applying the affine transformation.  note This will transform only the pixels, not objects",
"func":1
},
{
"ref":"vipy.image.Image.rotate",
"url":11,
"doc":"Apply a rotation in radians to the pixels, with origin in upper left",
"func":1
},
{
"ref":"vipy.image.Image.rotate_by_exif",
"url":11,
"doc":"Apply a rotation as specified in the 'Orientation' field EXIF metadata",
"func":1
},
{
"ref":"vipy.image.Image.rgb",
"url":11,
"doc":"Convert the image buffer to three channel RGB uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Image.color_transform",
"url":11,
"doc":"Transform the image buffer from the current  vipy.image.Image.colorspace to the provided colorspace",
"func":1
},
{
"ref":"vipy.image.Image.colorspace_like",
"url":11,
"doc":"Convert the image buffer to have the same colorspace as the provided image",
"func":1
},
{
"ref":"vipy.image.Image.rgba",
"url":11,
"doc":"Convert the image buffer to four channel RGBA uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Image.hsv",
"url":11,
"doc":"Convert the image buffer to three channel HSV uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Image.bgr",
"url":11,
"doc":"Convert the image buffer to three channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Image.bgra",
"url":11,
"doc":"Convert the image buffer to four channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Image.float",
"url":11,
"doc":"Convert the image buffer to float32",
"func":1
},
{
"ref":"vipy.image.Image.greyscale",
"url":11,
"doc":"Convert the image buffer to single channel grayscale float32 in range [0,1]",
"func":1
},
{
"ref":"vipy.image.Image.grayscale",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.Image.grey",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.Image.gray",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.Image.luminance",
"url":11,
"doc":"Convert the image buffer to single channel uint8 in range [0,255] corresponding to the luminance component",
"func":1
},
{
"ref":"vipy.image.Image.lum",
"url":11,
"doc":"Alias for luminance()",
"func":1
},
{
"ref":"vipy.image.Image.jet",
"url":11,
"doc":"Apply jet colormap to greyscale image and save as RGB",
"func":1
},
{
"ref":"vipy.image.Image.rainbow",
"url":11,
"doc":"Apply rainbow colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.Image.hot",
"url":11,
"doc":"Apply hot colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.Image.bone",
"url":11,
"doc":"Apply bone colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.Image.saturate",
"url":11,
"doc":"Saturate the image buffer to be clipped between [min,max], types of min/max are specified by _array type",
"func":1
},
{
"ref":"vipy.image.Image.intensity",
"url":11,
"doc":"Convert image to float32 with [min,max] to range [0,1], force colormap to be 'float'. Equivalent to self.mat2gray()",
"func":1
},
{
"ref":"vipy.image.Image.mat2gray",
"url":11,
"doc":"Convert the image buffer so that [min,max] -> [0,1], forces conversion to 'float' colorspace. This does not change the number of color channels",
"func":1
},
{
"ref":"vipy.image.Image.sum_to_one",
"url":11,
"doc":"Return float image in the range [0,1] such that all elements sum to one",
"func":1
},
{
"ref":"vipy.image.Image.gain",
"url":11,
"doc":"Elementwise multiply gain to image array, Gain should be broadcastable to array(). This forces the colospace to 'float'. Don't use numba optimization, it is slower than native multiply",
"func":1
},
{
"ref":"vipy.image.Image.bias",
"url":11,
"doc":"Add a bias to the image array. Bias should be broadcastable to array(). This forces the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.Image.normalize",
"url":11,
"doc":"Apply a multiplicative gain g and additive bias b, such that self.array()  gain self.array() + bias. This is useful for applying a normalization of an image prior to calling  vipy.image.Image.torch . The following operations are equivalent.   im = vipy.image.RandomImage() im.normalize(1/255.0, 0.5)  im.gain(1/255.0).bias(-0.5)    note This will force the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.Image.additive_noise",
"url":11,
"doc":"Apply uniform random additive noise in the given range to the given HSV color channels. Image will be converted to HSV prior to applying noise.",
"func":1
},
{
"ref":"vipy.image.Image.stats",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.min",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.minpixel",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.max",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.maxpixel",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.mean",
"url":11,
"doc":"Mean over all pixels",
"func":1
},
{
"ref":"vipy.image.Image.meanchannel",
"url":11,
"doc":"Mean per channel over all pixels. If channel k is provided, return just the mean for that channel",
"func":1
},
{
"ref":"vipy.image.Image.sum",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Image.closeall",
"url":11,
"doc":"Close all open figure windows",
"func":1
},
{
"ref":"vipy.image.Image.close",
"url":11,
"doc":"Close the requested figure number, or close all of fignum=None",
"func":1
},
{
"ref":"vipy.image.Image.show",
"url":11,
"doc":"Display image on screen in provided figure number (clone and convert to RGB colorspace to show), return object",
"func":1
},
{
"ref":"vipy.image.Image.save",
"url":11,
"doc":"Save the current image to a new filename and return the image object. Resets edit history",
"func":1
},
{
"ref":"vipy.image.Image.pkl",
"url":11,
"doc":"save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.Image.pklif",
"url":11,
"doc":"Save the object to the provided pickle file only if b=True. Useful for conditional intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.Image.saveas",
"url":11,
"doc":"Save current buffer (not including drawing overlays) to new filename and return filename. If filename is not provided, use a temporary JPEG filename.",
"func":1
},
{
"ref":"vipy.image.Image.saveastmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for savetmp()",
"func":1
},
{
"ref":"vipy.image.Image.savetmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for saveastmp()",
"func":1
},
{
"ref":"vipy.image.Image.tocache",
"url":11,
"doc":"Save current buffer to temp JPEG filename in the VIPY cache and return filename.",
"func":1
},
{
"ref":"vipy.image.Image.base64",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page",
"func":1
},
{
"ref":"vipy.image.Image.ascii",
"url":11,
"doc":"Export a base64 ascii encoding of the image suitable for embedding in an  tag",
"func":1
},
{
"ref":"vipy.image.Image.html",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page, enclosed in  tag Returns: -string:  containing base64 encoded JPEG and alt text with lazy loading",
"func":1
},
{
"ref":"vipy.image.Image.annotate",
"url":11,
"doc":"Change pixels of this image to include rendered annotation and return an image object",
"func":1
},
{
"ref":"vipy.image.Image.savefig",
"url":11,
"doc":"Save last figure output from self.show() with drawing overlays to provided filename and return filename",
"func":1
},
{
"ref":"vipy.image.Image.map",
"url":11,
"doc":"Apply lambda function to our numpy array img, such that newimg=f(img), then replace newimg -> self.array(). The output of this lambda function must be a numpy array and if the channels or dtype changes, the colorspace is set to 'float'",
"func":1
},
{
"ref":"vipy.image.Image.perceptualhash",
"url":11,
"doc":"Perceptual differential hash function This function converts to greyscale, resizes with linear interpolation to small image based on desired bit encoding, compute vertical and horizontal gradient signs. Args: bits: [int] longer hashes have lower TAR (true accept rate, some near dupes are missed), but lower FAR (false accept rate), shorter hashes have higher TAR (fewer near-dupes are missed) but higher FAR (more non-dupes are declared as dupes). asbinary: [bool] If true, return a binary array asbytes: [bool] if true return a byte array Returns: A hash string encoding the perceptual hash such that  vipy.image.Image.perceptualhash_distance can be used to compute a hash distance asbytes: a bytes array asbinary: a numpy binary array  notes - Can be used for near duplicate detection by unpacking the returned hex string to binary and computing hamming distance, or performing hamming based nearest neighbor indexing. Equivalently,  vipy.image.Image.perceptualhash_distance . - The default packed hex output can be converted to binary as: np.unpackbits(bytearray().fromhex(h)",
"func":1
},
{
"ref":"vipy.image.Image.perceptualhash_distance",
"url":11,
"doc":"Hamming distance between two perceptual hashes",
"func":1
},
{
"ref":"vipy.image.Image.rot90cw",
"url":11,
"doc":"Rotate the scene 90 degrees clockwise",
"func":1
},
{
"ref":"vipy.image.Image.rot90ccw",
"url":11,
"doc":"Rotate the scene 90 degrees counterclockwise",
"func":1
},
{
"ref":"vipy.image.Image.face_detection",
"url":11,
"doc":"Detect faces in the scene, add as objects, return new scene with just faces Args: mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled back to native resolution prior to return Returns A  vipy.image.Scene object with all detected faces or the union of faces and all objects in self  note This method uses a CPU-only pretrained face detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.Image.person_detection",
"url":11,
"doc":"Detect only people in the scene, add as objects, return new scene with just people Args: mindim [int]: The minimum dimension for downsampling the image for person detection. Will be upsampled back to native resolution prior to return conf [float]: A real value between [0,1] of the minimum confidence for person detection Returns A  vipy.image.Scene object with all detected people or the union of people and all objects in self  note This method uses a CPU-only pretrained person detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.Image.face_blur",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.blurmask , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.blurmask mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with faceblur attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().blurmask()",
"func":1
},
{
"ref":"vipy.image.Image.face_pixelize",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.pixelize , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.radius mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with facepixelize attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().pixelize()",
"func":1
},
{
"ref":"vipy.image.Image.viewport",
"url":11,
"doc":"Return the bounding box of the current loaded pixels in the original filename/url/buffer. This reverses the chain of geometric transformations applied to the original image to recover the bounding box of the pixels in array(). This is useful to specify a region of a larger image that was zoomed in for processing. To show this viewport as a bounding box: >>> im = vipy.image.vehicles().centercrop(100,100) >>> viewport = vipy.object.Detection.cast(im.viewport( >>> im.flush().append(viewport).show()",
"func":1
},
{
"ref":"vipy.image.Image.padcrop",
"url":11,
"doc":"Crop the image buffer using the supplied bounding box object, zero padding if box is outside image rectangle, update all scene objects",
"func":1
},
{
"ref":"vipy.image.Image.recenter",
"url":11,
"doc":"Recenter the image so that point p=(x=col, y=row) in the current image is in the middle of the new image, zeropad to (width, height). This is useful to implement a 'saccade', under the small angle assumption, where a rotation is approximated by a translation",
"func":1
},
{
"ref":"vipy.image.Image.attributes",
"url":11,
"doc":""
},
{
"ref":"vipy.image.ImageCategory",
"url":11,
"doc":"vipy ImageCategory class This class provides a representation of a vipy.image.Image with a category label. Valid constructors include all provided by vipy.image.Image with the additional kwarg 'category' (or alias 'label') and optional confidence   im = vipy.image.ImageCategory(filename='/path/to/dog_image.ext', category='dog') im = vipy.image.ImageCategory(url='http: path/to/dog_image.ext', category='dog') im = vipy.image.ImageCategory(array=dog_img, colorspace='rgb', category='dog')  "
},
{
"ref":"vipy.image.ImageCategory.from_json",
"url":11,
"doc":"Import the JSON string s as an  vipy.image.Image object. Args: s: json encoded string This will perform a round trip such that im1  im2   im1 = vupy.image.RandomImage() im2 = vipy.image.Image.from_json(im1.json( assert im1  im2   Note: to construct from non-encoded json (e.g. a dict prior to dumps), use from_dict",
"func":1
},
{
"ref":"vipy.image.ImageCategory.new_category",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.ImageCategory.category",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.ImageCategory.confidence",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.ImageCategory.tags",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.ImageCategory.attributes",
"url":11,
"doc":""
},
{
"ref":"vipy.image.ImageCategory.cast",
"url":11,
"doc":"Typecast the conformal vipy.image object im as  vipy.image.Image . This is useful for downcasting  vipy.image.Scene or  vipy.image.ImageDetection down to an image.   ims = vipy.image.RandomScene() im = vipy.image.Image.cast(im)  ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.from_uri",
"url":11,
"doc":"Create an image object from an absolute file path or url",
"func":1
},
{
"ref":"vipy.image.ImageCategory.sanitize",
"url":11,
"doc":"Remove all private keys from the attributes dictionary. The attributes dictionary is useful storage for arbitrary (key,value) pairs. However, this storage may contain sensitive information that should be scrubbed from the media before serialization. As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key. This is analogous to private or reserved attributes in the python lanugage. Users should reserve these keynames for those keys that should be sanitized and removed before any serialization of this object.   assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey')  False  ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.print",
"url":11,
"doc":"Print the representation of the image and return self with an optional sleep=n seconds Useful for debugging or sequential visualization in long fluent chains.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.exif",
"url":11,
"doc":"Return the EXIF meta-data in filename as a dictionary. Included non-base EXIF data if extended=True. Returns empty dictionary if no EXIF exists. Triggers download but not load.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.tile",
"url":11,
"doc":"Generate an image tiling. A tiling is a decomposition of an image into overlapping or non-overlapping rectangular regions. Args: tilewidth: [int] the image width of each tile tileheight: [int] the image height of each tile overlaprows: [int] the number of overlapping rows (height) for each tile overlapcols: [int] the number of overlapping width (width) for each tile Returns: A list of  vipy.image.Image objects such that each image is a single tile and the set of these tiles forms the original image Each image in the returned list contains the 'tile' attribute which encodes the crop used to create the tile.  note -  vipy.image.Image.tile can be undone using  vipy.image.Image.untile - The identity tiling is im.tile(im.width(), im.height(), overlaprows=0, overlapcols=0) - Ragged tiles outside the image boundary are zero padded - All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.union",
"url":11,
"doc":"No-op for  vipy.image.Image ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.untile",
"url":11,
"doc":"Undo an image tiling and recreate the original image.   tiles = im.tile(im.width()/2, im.height()/2, 0, 0) imdst = vipy.image.Image.untile(tiles) assert imdst  im   Args: imlist: this must be the output of  vipy.image.Image.tile Returns: A new  vipy.image.Image object reconstructed from the tiling, such that this is equivalent to the input to vipy.image.Image.tile  note All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.uncrop",
"url":11,
"doc":"Uncrop using provided bounding box and zeropad to shape=(Height, Width). An uncrop is the inverse operation for a crop, which preserves the cropped portion of the image in the correct location and replaces the rest with zeros out to shape.   im = vipy.image.RandomImage(128, 128) bb = vipy.geometry.BoundingBox(xmin=0, ymin=0, width=64, height=64) uncrop = im.crop(bb).uncrop(bb, shape=(128,128   Args: bb: [ vipy.geometry.BoundingBox ] the bounding box used to crop the image in self shape: [tuple] (height, width) of the uncropped image Returns: this  vipy.image.Image object with the pixels uncropped.  note NOT idempotent. This will generate different results if run more than once.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.splat",
"url":11,
"doc":"Replace pixels within boundingbox in self with pixels in im",
"func":1
},
{
"ref":"vipy.image.ImageCategory.store",
"url":11,
"doc":"Store the current image file as an attribute of this object. Useful for archiving an object to be fully self contained without any external references. -Remove this stored image using unstore() -Unpack this stored image and set up the filename using restore() -This method is more efficient than load() followed by pkl(), as it stores the encoded image as a byte string. -Useful for creating a single self contained object for distributed processing.   v  v.store().restore(v.filename(  ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.unstore",
"url":11,
"doc":"Delete the currently stored image from store()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.restore",
"url":11,
"doc":"Save the currently stored image to filename, and set up filename",
"func":1
},
{
"ref":"vipy.image.ImageCategory.abspath",
"url":11,
"doc":"Change the path of the filename from a relative path to an absolute path (not relocatable)",
"func":1
},
{
"ref":"vipy.image.ImageCategory.relpath",
"url":11,
"doc":"Replace the filename with a relative path to parent (or current working directory if none)",
"func":1
},
{
"ref":"vipy.image.ImageCategory.canload",
"url":11,
"doc":"Return True if the image can be loaded successfully, useful for filtering bad links or corrupt images",
"func":1
},
{
"ref":"vipy.image.ImageCategory.dict",
"url":11,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding",
"func":1
},
{
"ref":"vipy.image.ImageCategory.loader",
"url":11,
"doc":"Lambda function to load an unsupported image filename to a numpy array. This lambda function will be executed during load and the result will be stored in self._array",
"func":1
},
{
"ref":"vipy.image.ImageCategory.bytes_array_loader",
"url":11,
"doc":"Load from a bytes array",
"func":1
},
{
"ref":"vipy.image.ImageCategory.PIL_loader",
"url":11,
"doc":"Load from a PIL image file object",
"func":1
},
{
"ref":"vipy.image.ImageCategory.load",
"url":11,
"doc":"Load image to cached private '_array' attribute. Args: verbose: [bool] If true, show additional useful printed output Returns: This  vipy.image.Image object with the pixels loaded in self._array as a numpy array.  note This loader supports any image file format supported by PIL. A custom loader can be added using  vipy.image.Image.loader .",
"func":1
},
{
"ref":"vipy.image.ImageCategory.download",
"url":11,
"doc":"Download URL to filename provided by constructor, or to temp filename. Args: timeout: [int] The timeout in seconds for an http or https connection attempt. See also [urllib.request.urlopen](https: docs.python.org/3/library/urllib.request.html). verbose: [bool] If true, output more helpful message. cached: [bool] If true, use the cached previously downloaded file (if it exists) Returns: This  vipy.image.Image object with the URL downloaded to  vipy.image.Image.filename or to a  vipy.util.tempimage filename which can be retrieved with  vipy.image.Image.filename .",
"func":1
},
{
"ref":"vipy.image.ImageCategory.reload",
"url":11,
"doc":"Flush the image buffer to force reloading from file or URL",
"func":1
},
{
"ref":"vipy.image.ImageCategory.isloaded",
"url":11,
"doc":"Return True if  vipy.image.Image.load was successful in reading the image, or if the pixels are present in  vipy.image.Image.array .",
"func":1
},
{
"ref":"vipy.image.ImageCategory.loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.is_loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.isdownloaded",
"url":11,
"doc":"Does the filename returned from  vipy.image.Image.filename exist, meaning that the url has been downloaded to a local file?",
"func":1
},
{
"ref":"vipy.image.ImageCategory.is_downloaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isdownloaded ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.downloadif",
"url":11,
"doc":"Download URL to filename if the filename has not already been downloaded",
"func":1
},
{
"ref":"vipy.image.ImageCategory.try_download",
"url":11,
"doc":"Attempt to download URL to filename if the filename has not already been downloaded, return object on failure. Check  vipy.image.Image.is_downloaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.ImageCategory.try_load",
"url":11,
"doc":"Attempt to load an image, return the object on failure. Check  vipy.image.Image.is_loaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.ImageCategory.channels",
"url":11,
"doc":"Return integer number of color channels",
"func":1
},
{
"ref":"vipy.image.ImageCategory.iscolor",
"url":11,
"doc":"Color images are three channel or four channel with transparency, float32 or uint8",
"func":1
},
{
"ref":"vipy.image.ImageCategory.istransparent",
"url":11,
"doc":"Transparent images are four channel color images with transparency, float32 or uint8. Return true if this image contains an alpha transparency channel",
"func":1
},
{
"ref":"vipy.image.ImageCategory.blend",
"url":11,
"doc":"alpha blend self and im in-place, such that self = alpha self + (1-alpha) im",
"func":1
},
{
"ref":"vipy.image.ImageCategory.isgrey",
"url":11,
"doc":"Grey images are one channel, float32",
"func":1
},
{
"ref":"vipy.image.ImageCategory.isluminance",
"url":11,
"doc":"Luninance images are one channel, uint8",
"func":1
},
{
"ref":"vipy.image.ImageCategory.filesize",
"url":11,
"doc":"Return size of underlying image file, requires fetching metadata from filesystem",
"func":1
},
{
"ref":"vipy.image.ImageCategory.width",
"url":11,
"doc":"Return the width (columns) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.height",
"url":11,
"doc":"Return the height (rows) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.shape",
"url":11,
"doc":"Return the (height, width) or equivalently (rows, cols) of the image. Returns: A tuple (height=int, width=int) of the image.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.aspectratio",
"url":11,
"doc":"Return the aspect ratio of the image as (width/height) ratio. Returns: A float equivalent to ( vipy.image.Image.width /  vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.area",
"url":11,
"doc":"Return the area of the image as (width  height). Returns: An integer equivalent to ( vipy.image.Image.width   vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.centroid",
"url":11,
"doc":"Return the real valued center pixel coordinates of the image (col=x,row=y). The centroid is equivalent to half the  vipy.image.Image.shape . Returns: A tuple (column, row) of the floating point center of the image.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.centerpixel",
"url":11,
"doc":"Return the integer valued center pixel coordinates of the image (col=i,row=j) The centerpixel is equivalent to half the  vipy.image.Image.shape floored to the nearest integer pixel coordinate. Returns: A tuple (int(column), int(row of the integer center of the image.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.array",
"url":11,
"doc":"Replace self._array with provided numpy array Args: np_array: [numpy array] A new array to use as the pixel buffer for this image. copy: [bool] If true, copy the buffer using np.copy(), else use a reference to this buffer. Returns: - If np_array is not None, return the  vipy.image.Image object such that this object points to the provided numpy array as the pixel buffer - If np_array is None, then return the numpy array.  notes - If copy=False, then this  vipy.image.Image object will share the pixel buffer with the owner of np_array. Changes to pixels in this buffer will be shared. - If copy=True, then this will significantly slow down processing for large images. Use referneces wherevery possible.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.fromarray",
"url":11,
"doc":"Alias for  vipy.image.Image.array with copy=True. This will set new numpy array as the pixel buffer with a numpy array copy",
"func":1
},
{
"ref":"vipy.image.ImageCategory.tonumpy",
"url":11,
"doc":"Alias for  vipy.image.Image.numpy",
"func":1
},
{
"ref":"vipy.image.ImageCategory.numpy",
"url":11,
"doc":"Return a mutable numpy array for this  vipy.image.Image .  notes - This will always return a writeable array with the 'WRITEABLE' numpy flag set. This is useful for returning a mutable numpy array as needed while keeping the original non-mutable numpy array (e.g. loaded from a video or PIL) as the underlying pixel buffer for efficiency reasons. - Triggers a  vipy.image.Image.load if the pixel buffer has not been loaded - This will trigger a copy if the ['WRITEABLE' flag](https: numpy.org/doc/stable/reference/generated/numpy.ndarray.flags.html) is not set.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.channel",
"url":11,
"doc":"Return a cloned Image() object for the kth channel, or return an iterator over channels if k=None. Iterate over channels as single channel luminance images:   for c in self.channel(): print(c)   Return the kth channel as a single channel luminance image:   c = self.channel(k=0)  ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.channelmean",
"url":11,
"doc":"Return a cloned Image() object for the mean of all channels followed by returning a single channel float image. This is useful for visualizing multichannel images by reducing the channels to one   vipy.image.Image(array=np.random.rand(3,3,16).astype(np.float32 .channelmean().mat2gray().lum().show()  ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.red",
"url":11,
"doc":"Return red channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.red()  self.channel(0)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.red()  self.channel(3)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.green",
"url":11,
"doc":"Return green channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.green()  self.channel(1)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.green()  self.channel(1)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.blue",
"url":11,
"doc":"Return blue channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.vlue()  self.channel(2)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.blue()  self.channel(0)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.alpha",
"url":11,
"doc":"Return alpha (transparency) channel as a cloned single channel  vipy.image.Image object",
"func":1
},
{
"ref":"vipy.image.ImageCategory.zeros",
"url":11,
"doc":"Set the pixel buffer to all zeros of the same shape and datatype as this  vipy.image.Image object. These are equivalent operations for the resulting buffer shape:   import numpy as np np.zeros( (self.width(), self.height(), self.channels( )  self.zeros().array()   Returns: This  vipy.image.Image object.  note Triggers load() if the pixel buffer has not been loaded yet.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.pil",
"url":11,
"doc":"Convert vipy.image.Image to PIL Image. Returns: A [PIL image](https: pillow.readthedocs.io/en/stable/reference/Image.html) object, that shares the pixel buffer by reference",
"func":1
},
{
"ref":"vipy.image.ImageCategory.blur",
"url":11,
"doc":"Apply a Gaussian blur with Gaussian kernel radius=sigma to the pixel buffer. Args: sigma: [float >=0] The gaussian blur kernel radius. Returns: This  vipy.image.Image object with the pixel buffer blurred in place.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.torch",
"url":11,
"doc":"Convert the batch of 1 HxWxC images to a CxHxW torch tensor. Args: order: ['CHW', 'HWC', 'NCHW', 'NHWC']. The axis order of the torch tensor (channels, height, width) or (height, width, channels) or (1, channels, height, width) or (1, height, width, channels) Returns: A CxHxW or HxWxC or 1xCxHxW or 1xHxWxC [torch tensor](https: pytorch.org/docs/stable/tensors.html) that shares the pixel buffer of this image object by reference.  note This supports numpy types and does not support bfloat16",
"func":1
},
{
"ref":"vipy.image.ImageCategory.from_torch",
"url":11,
"doc":"Convert a 1xCxHxW or CxHxW torch tensor (or numpy array with torch channel order) to HxWxC numpy array, returns new  vipy.image.Image with inferred colorspace corresponding to data type in x",
"func":1
},
{
"ref":"vipy.image.ImageCategory.fromtorch",
"url":11,
"doc":"Alias for  vipy.image.Image.from_torch ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.unload",
"url":11,
"doc":"Remove cached file and loaded array. Note that this will delete the underlying file returned by filename() if there is a backing url, cleaning up cached files and forcing re-download",
"func":1
},
{
"ref":"vipy.image.ImageCategory.uncache",
"url":11,
"doc":"Alias for  vipy.image.Image.unload ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.filename",
"url":11,
"doc":"Return or set image filename",
"func":1
},
{
"ref":"vipy.image.ImageCategory.url",
"url":11,
"doc":"Image URL and URL download properties",
"func":1
},
{
"ref":"vipy.image.ImageCategory.colorspace",
"url":11,
"doc":"Return or set the colorspace as ['rgb', 'rgba', 'bgr', 'bgra', 'hsv', 'float', 'grey', 'lum']",
"func":1
},
{
"ref":"vipy.image.ImageCategory.uri",
"url":11,
"doc":"Return the URI of the image object, either the URL or the filename, raise exception if neither defined",
"func":1
},
{
"ref":"vipy.image.ImageCategory.set_attribute",
"url":11,
"doc":"Set element self.attributes[key]=value",
"func":1
},
{
"ref":"vipy.image.ImageCategory.setattributes",
"url":11,
"doc":"Set many attributes at once by providing a dictionary to be merged with current attributes",
"func":1
},
{
"ref":"vipy.image.ImageCategory.getattribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.ImageCategory.get_attribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.ImageCategory.append_attribute",
"url":11,
"doc":"Append the value to attribute key, creating the key as an empty list if it does not exist",
"func":1
},
{
"ref":"vipy.image.ImageCategory.metadata",
"url":11,
"doc":"Return metadata associated with this image, stored in the attributes dictionary",
"func":1
},
{
"ref":"vipy.image.ImageCategory.hasurl",
"url":11,
"doc":"synonym for  vipy.image.has_url ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.has_url",
"url":11,
"doc":"Return True if the image has a URL input source",
"func":1
},
{
"ref":"vipy.image.ImageCategory.has_filename",
"url":11,
"doc":"Return True if the image has a filename input source and this file exists",
"func":1
},
{
"ref":"vipy.image.ImageCategory.hasfilename",
"url":11,
"doc":"synonym for has_filename",
"func":1
},
{
"ref":"vipy.image.ImageCategory.clone",
"url":11,
"doc":"Create deep copy of object, flushing the original buffer if requested and returning the cloned object. Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned object which can be used for encoding and will be garbage collected.  flushforward: copy the object, and set the cloned object array() to None. This flushes the video buffer for the clone, not the object  flushbackward: copy the object, and set the object array() to None. This flushes the video buffer for the object, not the clone.  flush: set the object array() to None and clone the object. This flushes the video buffer for both the clone and the object.  dereference: remove both the filename and URL (if present) in the cloned object, leaving only the buffer",
"func":1
},
{
"ref":"vipy.image.ImageCategory.flush",
"url":11,
"doc":"flush the image buffer in place, alias for self.clone(flush=True)",
"func":1
},
{
"ref":"vipy.image.ImageCategory.resize",
"url":11,
"doc":"Resize the image buffer to (rows x cols) with bilinear interpolation. If rows or cols is provided, rescale image maintaining aspect ratio",
"func":1
},
{
"ref":"vipy.image.ImageCategory.resize_like",
"url":11,
"doc":"Resize image buffer to be the same size as the provided vipy.image.Image()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.rescale",
"url":11,
"doc":"Scale the image buffer by the given factor - NOT idempotent",
"func":1
},
{
"ref":"vipy.image.ImageCategory.maxdim",
"url":11,
"doc":"Resize image preserving aspect ratio so that maximum dimension of image = dim, or return maxdim()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.mindim",
"url":11,
"doc":"Resize image preserving aspect ratio so that minimum dimension of image = dim, or return mindim()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.mindimn",
"url":11,
"doc":"Frequently used shortcut for mindim(dim, interp='nearest')",
"func":1
},
{
"ref":"vipy.image.ImageCategory.pad",
"url":11,
"doc":"Alias for  vipy.image.Image.zeropad ",
"func":1
},
{
"ref":"vipy.image.ImageCategory.zeropad",
"url":11,
"doc":"Pad image using np.pad constant by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.ImageCategory.zeropadlike",
"url":11,
"doc":"Zero pad the image balancing the border so that the resulting image size is (width, height)",
"func":1
},
{
"ref":"vipy.image.ImageCategory.meanpad",
"url":11,
"doc":"Pad image using np.pad constant=image mean by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.ImageCategory.alphapad",
"url":11,
"doc":"Pad image using alpha transparency by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.ImageCategory.minsquare",
"url":11,
"doc":"Crop image of size (HxW) to (min(H,W), min(H,W , keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.ImageCategory.maxsquare",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with zeropadding or (S,S) if provided, keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.ImageCategory.maxmatte",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with balanced zeropadding forming a letterbox with top/bottom matte or pillarbox with left/right matte",
"func":1
},
{
"ref":"vipy.image.ImageCategory.centersquare",
"url":11,
"doc":"Crop image of size (NxN) in the center, such that N=min(width,height), keeping the image centroid constant",
"func":1
},
{
"ref":"vipy.image.ImageCategory.centercrop",
"url":11,
"doc":"Crop image of size (height x width) in the center, keeping the image centroid constant",
"func":1
},
{
"ref":"vipy.image.ImageCategory.cornercrop",
"url":11,
"doc":"Crop image of size (height x width) from the upper left corner",
"func":1
},
{
"ref":"vipy.image.ImageCategory.fliplr",
"url":11,
"doc":"Mirror the image buffer about the vertical axis - Not idempotent",
"func":1
},
{
"ref":"vipy.image.ImageCategory.flipud",
"url":11,
"doc":"Mirror the image buffer about the horizontal axis - Not idempotent",
"func":1
},
{
"ref":"vipy.image.ImageCategory.imagebox",
"url":11,
"doc":"Return the bounding box for the image rectangle",
"func":1
},
{
"ref":"vipy.image.ImageCategory.border_mask",
"url":11,
"doc":"Return a binary uint8 image the same size as self, with a border of pad pixels in width or height around the edge",
"func":1
},
{
"ref":"vipy.image.ImageCategory.affine_transform",
"url":11,
"doc":"Apply a 3x3 affine geometric transformation to the image. Args: - A [np.ndarray]: 3x3 affine geometric transform from  vipy.geometry.affine_transform - border [str]: 'zero' or 'replicate' to handle elements outside the image rectangle after transformation Returns: - This object with only the array transformed  note The image will be loaded and converted to float() prior to applying the affine transformation.  note This will transform only the pixels, not objects",
"func":1
},
{
"ref":"vipy.image.ImageCategory.rotate",
"url":11,
"doc":"Apply a rotation in radians to the pixels, with origin in upper left",
"func":1
},
{
"ref":"vipy.image.ImageCategory.rotate_by_exif",
"url":11,
"doc":"Apply a rotation as specified in the 'Orientation' field EXIF metadata",
"func":1
},
{
"ref":"vipy.image.ImageCategory.rgb",
"url":11,
"doc":"Convert the image buffer to three channel RGB uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageCategory.color_transform",
"url":11,
"doc":"Transform the image buffer from the current  vipy.image.Image.colorspace to the provided colorspace",
"func":1
},
{
"ref":"vipy.image.ImageCategory.colorspace_like",
"url":11,
"doc":"Convert the image buffer to have the same colorspace as the provided image",
"func":1
},
{
"ref":"vipy.image.ImageCategory.rgba",
"url":11,
"doc":"Convert the image buffer to four channel RGBA uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageCategory.hsv",
"url":11,
"doc":"Convert the image buffer to three channel HSV uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageCategory.bgr",
"url":11,
"doc":"Convert the image buffer to three channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageCategory.bgra",
"url":11,
"doc":"Convert the image buffer to four channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageCategory.float",
"url":11,
"doc":"Convert the image buffer to float32",
"func":1
},
{
"ref":"vipy.image.ImageCategory.greyscale",
"url":11,
"doc":"Convert the image buffer to single channel grayscale float32 in range [0,1]",
"func":1
},
{
"ref":"vipy.image.ImageCategory.grayscale",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.grey",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.gray",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.luminance",
"url":11,
"doc":"Convert the image buffer to single channel uint8 in range [0,255] corresponding to the luminance component",
"func":1
},
{
"ref":"vipy.image.ImageCategory.lum",
"url":11,
"doc":"Alias for luminance()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.jet",
"url":11,
"doc":"Apply jet colormap to greyscale image and save as RGB",
"func":1
},
{
"ref":"vipy.image.ImageCategory.rainbow",
"url":11,
"doc":"Apply rainbow colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.ImageCategory.hot",
"url":11,
"doc":"Apply hot colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.ImageCategory.bone",
"url":11,
"doc":"Apply bone colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.ImageCategory.saturate",
"url":11,
"doc":"Saturate the image buffer to be clipped between [min,max], types of min/max are specified by _array type",
"func":1
},
{
"ref":"vipy.image.ImageCategory.intensity",
"url":11,
"doc":"Convert image to float32 with [min,max] to range [0,1], force colormap to be 'float'. Equivalent to self.mat2gray()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.mat2gray",
"url":11,
"doc":"Convert the image buffer so that [min,max] -> [0,1], forces conversion to 'float' colorspace. This does not change the number of color channels",
"func":1
},
{
"ref":"vipy.image.ImageCategory.sum_to_one",
"url":11,
"doc":"Return float image in the range [0,1] such that all elements sum to one",
"func":1
},
{
"ref":"vipy.image.ImageCategory.gain",
"url":11,
"doc":"Elementwise multiply gain to image array, Gain should be broadcastable to array(). This forces the colospace to 'float'. Don't use numba optimization, it is slower than native multiply",
"func":1
},
{
"ref":"vipy.image.ImageCategory.bias",
"url":11,
"doc":"Add a bias to the image array. Bias should be broadcastable to array(). This forces the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.ImageCategory.normalize",
"url":11,
"doc":"Apply a multiplicative gain g and additive bias b, such that self.array()  gain self.array() + bias. This is useful for applying a normalization of an image prior to calling  vipy.image.Image.torch . The following operations are equivalent.   im = vipy.image.RandomImage() im.normalize(1/255.0, 0.5)  im.gain(1/255.0).bias(-0.5)    note This will force the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.ImageCategory.additive_noise",
"url":11,
"doc":"Apply uniform random additive noise in the given range to the given HSV color channels. Image will be converted to HSV prior to applying noise.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.mean",
"url":11,
"doc":"Mean over all pixels",
"func":1
},
{
"ref":"vipy.image.ImageCategory.meanchannel",
"url":11,
"doc":"Mean per channel over all pixels. If channel k is provided, return just the mean for that channel",
"func":1
},
{
"ref":"vipy.image.ImageCategory.closeall",
"url":11,
"doc":"Close all open figure windows",
"func":1
},
{
"ref":"vipy.image.ImageCategory.close",
"url":11,
"doc":"Close the requested figure number, or close all of fignum=None",
"func":1
},
{
"ref":"vipy.image.ImageCategory.show",
"url":11,
"doc":"Display image on screen in provided figure number (clone and convert to RGB colorspace to show), return object",
"func":1
},
{
"ref":"vipy.image.ImageCategory.save",
"url":11,
"doc":"Save the current image to a new filename and return the image object. Resets edit history",
"func":1
},
{
"ref":"vipy.image.ImageCategory.pkl",
"url":11,
"doc":"save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.ImageCategory.pklif",
"url":11,
"doc":"Save the object to the provided pickle file only if b=True. Useful for conditional intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.ImageCategory.saveas",
"url":11,
"doc":"Save current buffer (not including drawing overlays) to new filename and return filename. If filename is not provided, use a temporary JPEG filename.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.saveastmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for savetmp()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.savetmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for saveastmp()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.tocache",
"url":11,
"doc":"Save current buffer to temp JPEG filename in the VIPY cache and return filename.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.base64",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page",
"func":1
},
{
"ref":"vipy.image.ImageCategory.ascii",
"url":11,
"doc":"Export a base64 ascii encoding of the image suitable for embedding in an  tag",
"func":1
},
{
"ref":"vipy.image.ImageCategory.html",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page, enclosed in  tag Returns: -string:  containing base64 encoded JPEG and alt text with lazy loading",
"func":1
},
{
"ref":"vipy.image.ImageCategory.annotate",
"url":11,
"doc":"Change pixels of this image to include rendered annotation and return an image object",
"func":1
},
{
"ref":"vipy.image.ImageCategory.savefig",
"url":11,
"doc":"Save last figure output from self.show() with drawing overlays to provided filename and return filename",
"func":1
},
{
"ref":"vipy.image.ImageCategory.map",
"url":11,
"doc":"Apply lambda function to our numpy array img, such that newimg=f(img), then replace newimg -> self.array(). The output of this lambda function must be a numpy array and if the channels or dtype changes, the colorspace is set to 'float'",
"func":1
},
{
"ref":"vipy.image.ImageCategory.perceptualhash",
"url":11,
"doc":"Perceptual differential hash function This function converts to greyscale, resizes with linear interpolation to small image based on desired bit encoding, compute vertical and horizontal gradient signs. Args: bits: [int] longer hashes have lower TAR (true accept rate, some near dupes are missed), but lower FAR (false accept rate), shorter hashes have higher TAR (fewer near-dupes are missed) but higher FAR (more non-dupes are declared as dupes). asbinary: [bool] If true, return a binary array asbytes: [bool] if true return a byte array Returns: A hash string encoding the perceptual hash such that  vipy.image.Image.perceptualhash_distance can be used to compute a hash distance asbytes: a bytes array asbinary: a numpy binary array  notes - Can be used for near duplicate detection by unpacking the returned hex string to binary and computing hamming distance, or performing hamming based nearest neighbor indexing. Equivalently,  vipy.image.Image.perceptualhash_distance . - The default packed hex output can be converted to binary as: np.unpackbits(bytearray().fromhex(h)",
"func":1
},
{
"ref":"vipy.image.ImageCategory.perceptualhash_distance",
"url":11,
"doc":"Hamming distance between two perceptual hashes",
"func":1
},
{
"ref":"vipy.image.ImageCategory.rot90cw",
"url":11,
"doc":"Rotate the scene 90 degrees clockwise",
"func":1
},
{
"ref":"vipy.image.ImageCategory.rot90ccw",
"url":11,
"doc":"Rotate the scene 90 degrees counterclockwise",
"func":1
},
{
"ref":"vipy.image.ImageCategory.face_detection",
"url":11,
"doc":"Detect faces in the scene, add as objects, return new scene with just faces Args: mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled back to native resolution prior to return Returns A  vipy.image.Scene object with all detected faces or the union of faces and all objects in self  note This method uses a CPU-only pretrained face detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.person_detection",
"url":11,
"doc":"Detect only people in the scene, add as objects, return new scene with just people Args: mindim [int]: The minimum dimension for downsampling the image for person detection. Will be upsampled back to native resolution prior to return conf [float]: A real value between [0,1] of the minimum confidence for person detection Returns A  vipy.image.Scene object with all detected people or the union of people and all objects in self  note This method uses a CPU-only pretrained person detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.ImageCategory.face_blur",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.blurmask , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.blurmask mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with faceblur attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().blurmask()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.face_pixelize",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.pixelize , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.radius mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with facepixelize attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().pixelize()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.viewport",
"url":11,
"doc":"Return the bounding box of the current loaded pixels in the original filename/url/buffer. This reverses the chain of geometric transformations applied to the original image to recover the bounding box of the pixels in array(). This is useful to specify a region of a larger image that was zoomed in for processing. To show this viewport as a bounding box: >>> im = vipy.image.vehicles().centercrop(100,100) >>> viewport = vipy.object.Detection.cast(im.viewport( >>> im.flush().append(viewport).show()",
"func":1
},
{
"ref":"vipy.image.ImageCategory.padcrop",
"url":11,
"doc":"Crop the image buffer using the supplied bounding box object, zero padding if box is outside image rectangle, update all scene objects",
"func":1
},
{
"ref":"vipy.image.ImageCategory.recenter",
"url":11,
"doc":"Recenter the image so that point p=(x=col, y=row) in the current image is in the middle of the new image, zeropad to (width, height). This is useful to implement a 'saccade', under the small angle assumption, where a rotation is approximated by a translation",
"func":1
},
{
"ref":"vipy.image.TaggedImage",
"url":11,
"doc":"vipy.image.TaggedImage class This class provides a representation of a vipy.image.Image with one or more tags. Valid constructors include all provided by vipy.image.Image with additional labels that provide ground truth for the content of the image.   im = vipy.image.TaggedImage(filename='/path/to/dog.jpg', tags={'dog','canine'})  "
},
{
"ref":"vipy.image.TaggedImage.from_json",
"url":11,
"doc":"Import the JSON string s as an  vipy.image.Image object. Args: s: json encoded string This will perform a round trip such that im1  im2   im1 = vupy.image.RandomImage() im2 = vipy.image.Image.from_json(im1.json( assert im1  im2   Note: to construct from non-encoded json (e.g. a dict prior to dumps), use from_dict",
"func":1
},
{
"ref":"vipy.image.TaggedImage.category",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.confidence",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.has_tag",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.tags",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.add_tag",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.add_caption",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.caption",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.captions",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.add_tags",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.clear_tags",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.TaggedImage.add_soft_tags",
"url":11,
"doc":"Soft tags are a list of (tag, confidence) tuples",
"func":1
},
{
"ref":"vipy.image.TaggedImage.soft_tags",
"url":11,
"doc":"Soft tags are a list of (tag, confidence) tuples",
"func":1
},
{
"ref":"vipy.image.TaggedImage.attributes",
"url":11,
"doc":""
},
{
"ref":"vipy.image.TaggedImage.cast",
"url":11,
"doc":"Typecast the conformal vipy.image object im as  vipy.image.Image . This is useful for downcasting  vipy.image.Scene or  vipy.image.ImageDetection down to an image.   ims = vipy.image.RandomScene() im = vipy.image.Image.cast(im)  ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.from_uri",
"url":11,
"doc":"Create an image object from an absolute file path or url",
"func":1
},
{
"ref":"vipy.image.TaggedImage.sanitize",
"url":11,
"doc":"Remove all private keys from the attributes dictionary. The attributes dictionary is useful storage for arbitrary (key,value) pairs. However, this storage may contain sensitive information that should be scrubbed from the media before serialization. As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key. This is analogous to private or reserved attributes in the python lanugage. Users should reserve these keynames for those keys that should be sanitized and removed before any serialization of this object.   assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey')  False  ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.print",
"url":11,
"doc":"Print the representation of the image and return self with an optional sleep=n seconds Useful for debugging or sequential visualization in long fluent chains.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.exif",
"url":11,
"doc":"Return the EXIF meta-data in filename as a dictionary. Included non-base EXIF data if extended=True. Returns empty dictionary if no EXIF exists. Triggers download but not load.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.tile",
"url":11,
"doc":"Generate an image tiling. A tiling is a decomposition of an image into overlapping or non-overlapping rectangular regions. Args: tilewidth: [int] the image width of each tile tileheight: [int] the image height of each tile overlaprows: [int] the number of overlapping rows (height) for each tile overlapcols: [int] the number of overlapping width (width) for each tile Returns: A list of  vipy.image.Image objects such that each image is a single tile and the set of these tiles forms the original image Each image in the returned list contains the 'tile' attribute which encodes the crop used to create the tile.  note -  vipy.image.Image.tile can be undone using  vipy.image.Image.untile - The identity tiling is im.tile(im.width(), im.height(), overlaprows=0, overlapcols=0) - Ragged tiles outside the image boundary are zero padded - All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.union",
"url":11,
"doc":"No-op for  vipy.image.Image ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.untile",
"url":11,
"doc":"Undo an image tiling and recreate the original image.   tiles = im.tile(im.width()/2, im.height()/2, 0, 0) imdst = vipy.image.Image.untile(tiles) assert imdst  im   Args: imlist: this must be the output of  vipy.image.Image.tile Returns: A new  vipy.image.Image object reconstructed from the tiling, such that this is equivalent to the input to vipy.image.Image.tile  note All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.uncrop",
"url":11,
"doc":"Uncrop using provided bounding box and zeropad to shape=(Height, Width). An uncrop is the inverse operation for a crop, which preserves the cropped portion of the image in the correct location and replaces the rest with zeros out to shape.   im = vipy.image.RandomImage(128, 128) bb = vipy.geometry.BoundingBox(xmin=0, ymin=0, width=64, height=64) uncrop = im.crop(bb).uncrop(bb, shape=(128,128   Args: bb: [ vipy.geometry.BoundingBox ] the bounding box used to crop the image in self shape: [tuple] (height, width) of the uncropped image Returns: this  vipy.image.Image object with the pixels uncropped.  note NOT idempotent. This will generate different results if run more than once.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.splat",
"url":11,
"doc":"Replace pixels within boundingbox in self with pixels in im",
"func":1
},
{
"ref":"vipy.image.TaggedImage.store",
"url":11,
"doc":"Store the current image file as an attribute of this object. Useful for archiving an object to be fully self contained without any external references. -Remove this stored image using unstore() -Unpack this stored image and set up the filename using restore() -This method is more efficient than load() followed by pkl(), as it stores the encoded image as a byte string. -Useful for creating a single self contained object for distributed processing.   v  v.store().restore(v.filename(  ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.unstore",
"url":11,
"doc":"Delete the currently stored image from store()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.restore",
"url":11,
"doc":"Save the currently stored image to filename, and set up filename",
"func":1
},
{
"ref":"vipy.image.TaggedImage.abspath",
"url":11,
"doc":"Change the path of the filename from a relative path to an absolute path (not relocatable)",
"func":1
},
{
"ref":"vipy.image.TaggedImage.relpath",
"url":11,
"doc":"Replace the filename with a relative path to parent (or current working directory if none)",
"func":1
},
{
"ref":"vipy.image.TaggedImage.canload",
"url":11,
"doc":"Return True if the image can be loaded successfully, useful for filtering bad links or corrupt images",
"func":1
},
{
"ref":"vipy.image.TaggedImage.dict",
"url":11,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding",
"func":1
},
{
"ref":"vipy.image.TaggedImage.loader",
"url":11,
"doc":"Lambda function to load an unsupported image filename to a numpy array. This lambda function will be executed during load and the result will be stored in self._array",
"func":1
},
{
"ref":"vipy.image.TaggedImage.bytes_array_loader",
"url":11,
"doc":"Load from a bytes array",
"func":1
},
{
"ref":"vipy.image.TaggedImage.PIL_loader",
"url":11,
"doc":"Load from a PIL image file object",
"func":1
},
{
"ref":"vipy.image.TaggedImage.load",
"url":11,
"doc":"Load image to cached private '_array' attribute. Args: verbose: [bool] If true, show additional useful printed output Returns: This  vipy.image.Image object with the pixels loaded in self._array as a numpy array.  note This loader supports any image file format supported by PIL. A custom loader can be added using  vipy.image.Image.loader .",
"func":1
},
{
"ref":"vipy.image.TaggedImage.download",
"url":11,
"doc":"Download URL to filename provided by constructor, or to temp filename. Args: timeout: [int] The timeout in seconds for an http or https connection attempt. See also [urllib.request.urlopen](https: docs.python.org/3/library/urllib.request.html). verbose: [bool] If true, output more helpful message. cached: [bool] If true, use the cached previously downloaded file (if it exists) Returns: This  vipy.image.Image object with the URL downloaded to  vipy.image.Image.filename or to a  vipy.util.tempimage filename which can be retrieved with  vipy.image.Image.filename .",
"func":1
},
{
"ref":"vipy.image.TaggedImage.reload",
"url":11,
"doc":"Flush the image buffer to force reloading from file or URL",
"func":1
},
{
"ref":"vipy.image.TaggedImage.isloaded",
"url":11,
"doc":"Return True if  vipy.image.Image.load was successful in reading the image, or if the pixels are present in  vipy.image.Image.array .",
"func":1
},
{
"ref":"vipy.image.TaggedImage.loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.is_loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.isdownloaded",
"url":11,
"doc":"Does the filename returned from  vipy.image.Image.filename exist, meaning that the url has been downloaded to a local file?",
"func":1
},
{
"ref":"vipy.image.TaggedImage.is_downloaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isdownloaded ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.downloadif",
"url":11,
"doc":"Download URL to filename if the filename has not already been downloaded",
"func":1
},
{
"ref":"vipy.image.TaggedImage.try_download",
"url":11,
"doc":"Attempt to download URL to filename if the filename has not already been downloaded, return object on failure. Check  vipy.image.Image.is_downloaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.TaggedImage.try_load",
"url":11,
"doc":"Attempt to load an image, return the object on failure. Check  vipy.image.Image.is_loaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.TaggedImage.channels",
"url":11,
"doc":"Return integer number of color channels",
"func":1
},
{
"ref":"vipy.image.TaggedImage.iscolor",
"url":11,
"doc":"Color images are three channel or four channel with transparency, float32 or uint8",
"func":1
},
{
"ref":"vipy.image.TaggedImage.istransparent",
"url":11,
"doc":"Transparent images are four channel color images with transparency, float32 or uint8. Return true if this image contains an alpha transparency channel",
"func":1
},
{
"ref":"vipy.image.TaggedImage.blend",
"url":11,
"doc":"alpha blend self and im in-place, such that self = alpha self + (1-alpha) im",
"func":1
},
{
"ref":"vipy.image.TaggedImage.isgrey",
"url":11,
"doc":"Grey images are one channel, float32",
"func":1
},
{
"ref":"vipy.image.TaggedImage.isluminance",
"url":11,
"doc":"Luninance images are one channel, uint8",
"func":1
},
{
"ref":"vipy.image.TaggedImage.filesize",
"url":11,
"doc":"Return size of underlying image file, requires fetching metadata from filesystem",
"func":1
},
{
"ref":"vipy.image.TaggedImage.width",
"url":11,
"doc":"Return the width (columns) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.height",
"url":11,
"doc":"Return the height (rows) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.shape",
"url":11,
"doc":"Return the (height, width) or equivalently (rows, cols) of the image. Returns: A tuple (height=int, width=int) of the image.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.aspectratio",
"url":11,
"doc":"Return the aspect ratio of the image as (width/height) ratio. Returns: A float equivalent to ( vipy.image.Image.width /  vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.area",
"url":11,
"doc":"Return the area of the image as (width  height). Returns: An integer equivalent to ( vipy.image.Image.width   vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.centroid",
"url":11,
"doc":"Return the real valued center pixel coordinates of the image (col=x,row=y). The centroid is equivalent to half the  vipy.image.Image.shape . Returns: A tuple (column, row) of the floating point center of the image.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.centerpixel",
"url":11,
"doc":"Return the integer valued center pixel coordinates of the image (col=i,row=j) The centerpixel is equivalent to half the  vipy.image.Image.shape floored to the nearest integer pixel coordinate. Returns: A tuple (int(column), int(row of the integer center of the image.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.array",
"url":11,
"doc":"Replace self._array with provided numpy array Args: np_array: [numpy array] A new array to use as the pixel buffer for this image. copy: [bool] If true, copy the buffer using np.copy(), else use a reference to this buffer. Returns: - If np_array is not None, return the  vipy.image.Image object such that this object points to the provided numpy array as the pixel buffer - If np_array is None, then return the numpy array.  notes - If copy=False, then this  vipy.image.Image object will share the pixel buffer with the owner of np_array. Changes to pixels in this buffer will be shared. - If copy=True, then this will significantly slow down processing for large images. Use referneces wherevery possible.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.fromarray",
"url":11,
"doc":"Alias for  vipy.image.Image.array with copy=True. This will set new numpy array as the pixel buffer with a numpy array copy",
"func":1
},
{
"ref":"vipy.image.TaggedImage.tonumpy",
"url":11,
"doc":"Alias for  vipy.image.Image.numpy",
"func":1
},
{
"ref":"vipy.image.TaggedImage.numpy",
"url":11,
"doc":"Return a mutable numpy array for this  vipy.image.Image .  notes - This will always return a writeable array with the 'WRITEABLE' numpy flag set. This is useful for returning a mutable numpy array as needed while keeping the original non-mutable numpy array (e.g. loaded from a video or PIL) as the underlying pixel buffer for efficiency reasons. - Triggers a  vipy.image.Image.load if the pixel buffer has not been loaded - This will trigger a copy if the ['WRITEABLE' flag](https: numpy.org/doc/stable/reference/generated/numpy.ndarray.flags.html) is not set.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.channel",
"url":11,
"doc":"Return a cloned Image() object for the kth channel, or return an iterator over channels if k=None. Iterate over channels as single channel luminance images:   for c in self.channel(): print(c)   Return the kth channel as a single channel luminance image:   c = self.channel(k=0)  ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.channelmean",
"url":11,
"doc":"Return a cloned Image() object for the mean of all channels followed by returning a single channel float image. This is useful for visualizing multichannel images by reducing the channels to one   vipy.image.Image(array=np.random.rand(3,3,16).astype(np.float32 .channelmean().mat2gray().lum().show()  ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.red",
"url":11,
"doc":"Return red channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.red()  self.channel(0)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.red()  self.channel(3)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.green",
"url":11,
"doc":"Return green channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.green()  self.channel(1)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.green()  self.channel(1)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.blue",
"url":11,
"doc":"Return blue channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.vlue()  self.channel(2)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.blue()  self.channel(0)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.alpha",
"url":11,
"doc":"Return alpha (transparency) channel as a cloned single channel  vipy.image.Image object",
"func":1
},
{
"ref":"vipy.image.TaggedImage.zeros",
"url":11,
"doc":"Set the pixel buffer to all zeros of the same shape and datatype as this  vipy.image.Image object. These are equivalent operations for the resulting buffer shape:   import numpy as np np.zeros( (self.width(), self.height(), self.channels( )  self.zeros().array()   Returns: This  vipy.image.Image object.  note Triggers load() if the pixel buffer has not been loaded yet.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.pil",
"url":11,
"doc":"Convert vipy.image.Image to PIL Image. Returns: A [PIL image](https: pillow.readthedocs.io/en/stable/reference/Image.html) object, that shares the pixel buffer by reference",
"func":1
},
{
"ref":"vipy.image.TaggedImage.blur",
"url":11,
"doc":"Apply a Gaussian blur with Gaussian kernel radius=sigma to the pixel buffer. Args: sigma: [float >=0] The gaussian blur kernel radius. Returns: This  vipy.image.Image object with the pixel buffer blurred in place.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.torch",
"url":11,
"doc":"Convert the batch of 1 HxWxC images to a CxHxW torch tensor. Args: order: ['CHW', 'HWC', 'NCHW', 'NHWC']. The axis order of the torch tensor (channels, height, width) or (height, width, channels) or (1, channels, height, width) or (1, height, width, channels) Returns: A CxHxW or HxWxC or 1xCxHxW or 1xHxWxC [torch tensor](https: pytorch.org/docs/stable/tensors.html) that shares the pixel buffer of this image object by reference.  note This supports numpy types and does not support bfloat16",
"func":1
},
{
"ref":"vipy.image.TaggedImage.from_torch",
"url":11,
"doc":"Convert a 1xCxHxW or CxHxW torch tensor (or numpy array with torch channel order) to HxWxC numpy array, returns new  vipy.image.Image with inferred colorspace corresponding to data type in x",
"func":1
},
{
"ref":"vipy.image.TaggedImage.fromtorch",
"url":11,
"doc":"Alias for  vipy.image.Image.from_torch ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.unload",
"url":11,
"doc":"Remove cached file and loaded array. Note that this will delete the underlying file returned by filename() if there is a backing url, cleaning up cached files and forcing re-download",
"func":1
},
{
"ref":"vipy.image.TaggedImage.uncache",
"url":11,
"doc":"Alias for  vipy.image.Image.unload ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.filename",
"url":11,
"doc":"Return or set image filename",
"func":1
},
{
"ref":"vipy.image.TaggedImage.url",
"url":11,
"doc":"Image URL and URL download properties",
"func":1
},
{
"ref":"vipy.image.TaggedImage.colorspace",
"url":11,
"doc":"Return or set the colorspace as ['rgb', 'rgba', 'bgr', 'bgra', 'hsv', 'float', 'grey', 'lum']",
"func":1
},
{
"ref":"vipy.image.TaggedImage.uri",
"url":11,
"doc":"Return the URI of the image object, either the URL or the filename, raise exception if neither defined",
"func":1
},
{
"ref":"vipy.image.TaggedImage.set_attribute",
"url":11,
"doc":"Set element self.attributes[key]=value",
"func":1
},
{
"ref":"vipy.image.TaggedImage.setattributes",
"url":11,
"doc":"Set many attributes at once by providing a dictionary to be merged with current attributes",
"func":1
},
{
"ref":"vipy.image.TaggedImage.getattribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.TaggedImage.get_attribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.TaggedImage.append_attribute",
"url":11,
"doc":"Append the value to attribute key, creating the key as an empty list if it does not exist",
"func":1
},
{
"ref":"vipy.image.TaggedImage.metadata",
"url":11,
"doc":"Return metadata associated with this image, stored in the attributes dictionary",
"func":1
},
{
"ref":"vipy.image.TaggedImage.hasurl",
"url":11,
"doc":"synonym for  vipy.image.has_url ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.has_url",
"url":11,
"doc":"Return True if the image has a URL input source",
"func":1
},
{
"ref":"vipy.image.TaggedImage.has_filename",
"url":11,
"doc":"Return True if the image has a filename input source and this file exists",
"func":1
},
{
"ref":"vipy.image.TaggedImage.hasfilename",
"url":11,
"doc":"synonym for has_filename",
"func":1
},
{
"ref":"vipy.image.TaggedImage.clone",
"url":11,
"doc":"Create deep copy of object, flushing the original buffer if requested and returning the cloned object. Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned object which can be used for encoding and will be garbage collected.  flushforward: copy the object, and set the cloned object array() to None. This flushes the video buffer for the clone, not the object  flushbackward: copy the object, and set the object array() to None. This flushes the video buffer for the object, not the clone.  flush: set the object array() to None and clone the object. This flushes the video buffer for both the clone and the object.  dereference: remove both the filename and URL (if present) in the cloned object, leaving only the buffer",
"func":1
},
{
"ref":"vipy.image.TaggedImage.flush",
"url":11,
"doc":"flush the image buffer in place, alias for self.clone(flush=True)",
"func":1
},
{
"ref":"vipy.image.TaggedImage.resize",
"url":11,
"doc":"Resize the image buffer to (rows x cols) with bilinear interpolation. If rows or cols is provided, rescale image maintaining aspect ratio",
"func":1
},
{
"ref":"vipy.image.TaggedImage.resize_like",
"url":11,
"doc":"Resize image buffer to be the same size as the provided vipy.image.Image()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.rescale",
"url":11,
"doc":"Scale the image buffer by the given factor - NOT idempotent",
"func":1
},
{
"ref":"vipy.image.TaggedImage.maxdim",
"url":11,
"doc":"Resize image preserving aspect ratio so that maximum dimension of image = dim, or return maxdim()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.mindim",
"url":11,
"doc":"Resize image preserving aspect ratio so that minimum dimension of image = dim, or return mindim()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.mindimn",
"url":11,
"doc":"Frequently used shortcut for mindim(dim, interp='nearest')",
"func":1
},
{
"ref":"vipy.image.TaggedImage.pad",
"url":11,
"doc":"Alias for  vipy.image.Image.zeropad ",
"func":1
},
{
"ref":"vipy.image.TaggedImage.zeropad",
"url":11,
"doc":"Pad image using np.pad constant by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.TaggedImage.zeropadlike",
"url":11,
"doc":"Zero pad the image balancing the border so that the resulting image size is (width, height)",
"func":1
},
{
"ref":"vipy.image.TaggedImage.meanpad",
"url":11,
"doc":"Pad image using np.pad constant=image mean by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.TaggedImage.alphapad",
"url":11,
"doc":"Pad image using alpha transparency by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.TaggedImage.minsquare",
"url":11,
"doc":"Crop image of size (HxW) to (min(H,W), min(H,W , keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.TaggedImage.maxsquare",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with zeropadding or (S,S) if provided, keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.TaggedImage.maxmatte",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with balanced zeropadding forming a letterbox with top/bottom matte or pillarbox with left/right matte",
"func":1
},
{
"ref":"vipy.image.TaggedImage.centersquare",
"url":11,
"doc":"Crop image of size (NxN) in the center, such that N=min(width,height), keeping the image centroid constant",
"func":1
},
{
"ref":"vipy.image.TaggedImage.centercrop",
"url":11,
"doc":"Crop image of size (height x width) in the center, keeping the image centroid constant",
"func":1
},
{
"ref":"vipy.image.TaggedImage.cornercrop",
"url":11,
"doc":"Crop image of size (height x width) from the upper left corner",
"func":1
},
{
"ref":"vipy.image.TaggedImage.fliplr",
"url":11,
"doc":"Mirror the image buffer about the vertical axis - Not idempotent",
"func":1
},
{
"ref":"vipy.image.TaggedImage.flipud",
"url":11,
"doc":"Mirror the image buffer about the horizontal axis - Not idempotent",
"func":1
},
{
"ref":"vipy.image.TaggedImage.imagebox",
"url":11,
"doc":"Return the bounding box for the image rectangle",
"func":1
},
{
"ref":"vipy.image.TaggedImage.border_mask",
"url":11,
"doc":"Return a binary uint8 image the same size as self, with a border of pad pixels in width or height around the edge",
"func":1
},
{
"ref":"vipy.image.TaggedImage.affine_transform",
"url":11,
"doc":"Apply a 3x3 affine geometric transformation to the image. Args: - A [np.ndarray]: 3x3 affine geometric transform from  vipy.geometry.affine_transform - border [str]: 'zero' or 'replicate' to handle elements outside the image rectangle after transformation Returns: - This object with only the array transformed  note The image will be loaded and converted to float() prior to applying the affine transformation.  note This will transform only the pixels, not objects",
"func":1
},
{
"ref":"vipy.image.TaggedImage.rotate",
"url":11,
"doc":"Apply a rotation in radians to the pixels, with origin in upper left",
"func":1
},
{
"ref":"vipy.image.TaggedImage.rotate_by_exif",
"url":11,
"doc":"Apply a rotation as specified in the 'Orientation' field EXIF metadata",
"func":1
},
{
"ref":"vipy.image.TaggedImage.rgb",
"url":11,
"doc":"Convert the image buffer to three channel RGB uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.TaggedImage.color_transform",
"url":11,
"doc":"Transform the image buffer from the current  vipy.image.Image.colorspace to the provided colorspace",
"func":1
},
{
"ref":"vipy.image.TaggedImage.colorspace_like",
"url":11,
"doc":"Convert the image buffer to have the same colorspace as the provided image",
"func":1
},
{
"ref":"vipy.image.TaggedImage.rgba",
"url":11,
"doc":"Convert the image buffer to four channel RGBA uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.TaggedImage.hsv",
"url":11,
"doc":"Convert the image buffer to three channel HSV uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.TaggedImage.bgr",
"url":11,
"doc":"Convert the image buffer to three channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.TaggedImage.bgra",
"url":11,
"doc":"Convert the image buffer to four channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.TaggedImage.float",
"url":11,
"doc":"Convert the image buffer to float32",
"func":1
},
{
"ref":"vipy.image.TaggedImage.greyscale",
"url":11,
"doc":"Convert the image buffer to single channel grayscale float32 in range [0,1]",
"func":1
},
{
"ref":"vipy.image.TaggedImage.grayscale",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.grey",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.gray",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.luminance",
"url":11,
"doc":"Convert the image buffer to single channel uint8 in range [0,255] corresponding to the luminance component",
"func":1
},
{
"ref":"vipy.image.TaggedImage.lum",
"url":11,
"doc":"Alias for luminance()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.jet",
"url":11,
"doc":"Apply jet colormap to greyscale image and save as RGB",
"func":1
},
{
"ref":"vipy.image.TaggedImage.rainbow",
"url":11,
"doc":"Apply rainbow colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.TaggedImage.hot",
"url":11,
"doc":"Apply hot colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.TaggedImage.bone",
"url":11,
"doc":"Apply bone colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.TaggedImage.saturate",
"url":11,
"doc":"Saturate the image buffer to be clipped between [min,max], types of min/max are specified by _array type",
"func":1
},
{
"ref":"vipy.image.TaggedImage.intensity",
"url":11,
"doc":"Convert image to float32 with [min,max] to range [0,1], force colormap to be 'float'. Equivalent to self.mat2gray()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.mat2gray",
"url":11,
"doc":"Convert the image buffer so that [min,max] -> [0,1], forces conversion to 'float' colorspace. This does not change the number of color channels",
"func":1
},
{
"ref":"vipy.image.TaggedImage.sum_to_one",
"url":11,
"doc":"Return float image in the range [0,1] such that all elements sum to one",
"func":1
},
{
"ref":"vipy.image.TaggedImage.gain",
"url":11,
"doc":"Elementwise multiply gain to image array, Gain should be broadcastable to array(). This forces the colospace to 'float'. Don't use numba optimization, it is slower than native multiply",
"func":1
},
{
"ref":"vipy.image.TaggedImage.bias",
"url":11,
"doc":"Add a bias to the image array. Bias should be broadcastable to array(). This forces the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.TaggedImage.normalize",
"url":11,
"doc":"Apply a multiplicative gain g and additive bias b, such that self.array()  gain self.array() + bias. This is useful for applying a normalization of an image prior to calling  vipy.image.Image.torch . The following operations are equivalent.   im = vipy.image.RandomImage() im.normalize(1/255.0, 0.5)  im.gain(1/255.0).bias(-0.5)    note This will force the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.TaggedImage.additive_noise",
"url":11,
"doc":"Apply uniform random additive noise in the given range to the given HSV color channels. Image will be converted to HSV prior to applying noise.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.mean",
"url":11,
"doc":"Mean over all pixels",
"func":1
},
{
"ref":"vipy.image.TaggedImage.meanchannel",
"url":11,
"doc":"Mean per channel over all pixels. If channel k is provided, return just the mean for that channel",
"func":1
},
{
"ref":"vipy.image.TaggedImage.closeall",
"url":11,
"doc":"Close all open figure windows",
"func":1
},
{
"ref":"vipy.image.TaggedImage.close",
"url":11,
"doc":"Close the requested figure number, or close all of fignum=None",
"func":1
},
{
"ref":"vipy.image.TaggedImage.show",
"url":11,
"doc":"Display image on screen in provided figure number (clone and convert to RGB colorspace to show), return object",
"func":1
},
{
"ref":"vipy.image.TaggedImage.save",
"url":11,
"doc":"Save the current image to a new filename and return the image object. Resets edit history",
"func":1
},
{
"ref":"vipy.image.TaggedImage.pkl",
"url":11,
"doc":"save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.TaggedImage.pklif",
"url":11,
"doc":"Save the object to the provided pickle file only if b=True. Useful for conditional intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.TaggedImage.saveas",
"url":11,
"doc":"Save current buffer (not including drawing overlays) to new filename and return filename. If filename is not provided, use a temporary JPEG filename.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.saveastmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for savetmp()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.savetmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for saveastmp()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.tocache",
"url":11,
"doc":"Save current buffer to temp JPEG filename in the VIPY cache and return filename.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.base64",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page",
"func":1
},
{
"ref":"vipy.image.TaggedImage.ascii",
"url":11,
"doc":"Export a base64 ascii encoding of the image suitable for embedding in an  tag",
"func":1
},
{
"ref":"vipy.image.TaggedImage.html",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page, enclosed in  tag Returns: -string:  containing base64 encoded JPEG and alt text with lazy loading",
"func":1
},
{
"ref":"vipy.image.TaggedImage.annotate",
"url":11,
"doc":"Change pixels of this image to include rendered annotation and return an image object",
"func":1
},
{
"ref":"vipy.image.TaggedImage.savefig",
"url":11,
"doc":"Save last figure output from self.show() with drawing overlays to provided filename and return filename",
"func":1
},
{
"ref":"vipy.image.TaggedImage.map",
"url":11,
"doc":"Apply lambda function to our numpy array img, such that newimg=f(img), then replace newimg -> self.array(). The output of this lambda function must be a numpy array and if the channels or dtype changes, the colorspace is set to 'float'",
"func":1
},
{
"ref":"vipy.image.TaggedImage.perceptualhash",
"url":11,
"doc":"Perceptual differential hash function This function converts to greyscale, resizes with linear interpolation to small image based on desired bit encoding, compute vertical and horizontal gradient signs. Args: bits: [int] longer hashes have lower TAR (true accept rate, some near dupes are missed), but lower FAR (false accept rate), shorter hashes have higher TAR (fewer near-dupes are missed) but higher FAR (more non-dupes are declared as dupes). asbinary: [bool] If true, return a binary array asbytes: [bool] if true return a byte array Returns: A hash string encoding the perceptual hash such that  vipy.image.Image.perceptualhash_distance can be used to compute a hash distance asbytes: a bytes array asbinary: a numpy binary array  notes - Can be used for near duplicate detection by unpacking the returned hex string to binary and computing hamming distance, or performing hamming based nearest neighbor indexing. Equivalently,  vipy.image.Image.perceptualhash_distance . - The default packed hex output can be converted to binary as: np.unpackbits(bytearray().fromhex(h)",
"func":1
},
{
"ref":"vipy.image.TaggedImage.perceptualhash_distance",
"url":11,
"doc":"Hamming distance between two perceptual hashes",
"func":1
},
{
"ref":"vipy.image.TaggedImage.rot90cw",
"url":11,
"doc":"Rotate the scene 90 degrees clockwise",
"func":1
},
{
"ref":"vipy.image.TaggedImage.rot90ccw",
"url":11,
"doc":"Rotate the scene 90 degrees counterclockwise",
"func":1
},
{
"ref":"vipy.image.TaggedImage.face_detection",
"url":11,
"doc":"Detect faces in the scene, add as objects, return new scene with just faces Args: mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled back to native resolution prior to return Returns A  vipy.image.Scene object with all detected faces or the union of faces and all objects in self  note This method uses a CPU-only pretrained face detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.person_detection",
"url":11,
"doc":"Detect only people in the scene, add as objects, return new scene with just people Args: mindim [int]: The minimum dimension for downsampling the image for person detection. Will be upsampled back to native resolution prior to return conf [float]: A real value between [0,1] of the minimum confidence for person detection Returns A  vipy.image.Scene object with all detected people or the union of people and all objects in self  note This method uses a CPU-only pretrained person detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.TaggedImage.face_blur",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.blurmask , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.blurmask mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with faceblur attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().blurmask()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.face_pixelize",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.pixelize , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.radius mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with facepixelize attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().pixelize()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.viewport",
"url":11,
"doc":"Return the bounding box of the current loaded pixels in the original filename/url/buffer. This reverses the chain of geometric transformations applied to the original image to recover the bounding box of the pixels in array(). This is useful to specify a region of a larger image that was zoomed in for processing. To show this viewport as a bounding box: >>> im = vipy.image.vehicles().centercrop(100,100) >>> viewport = vipy.object.Detection.cast(im.viewport( >>> im.flush().append(viewport).show()",
"func":1
},
{
"ref":"vipy.image.TaggedImage.padcrop",
"url":11,
"doc":"Crop the image buffer using the supplied bounding box object, zero padding if box is outside image rectangle, update all scene objects",
"func":1
},
{
"ref":"vipy.image.TaggedImage.recenter",
"url":11,
"doc":"Recenter the image so that point p=(x=col, y=row) in the current image is in the middle of the new image, zeropad to (width, height). This is useful to implement a 'saccade', under the small angle assumption, where a rotation is approximated by a translation",
"func":1
},
{
"ref":"vipy.image.Scene",
"url":11,
"doc":"vipy.image.Scene class This class provides a representation of a vipy.image.TaggedImage with one or more vipy.object.Object. The goal of this class is to provide a unified representation for all objects in a scene. Valid constructors include all provided by vipy.image.Image() and vipy.image.ImageCategory() with the additional kwarg 'objects', which is a list of vipy.object.Object()   im = vipy.image.Scene(filename='/path/to/city_image.jpg', category='city', objects=[vipy.object.Detection(category='vehicle', xmin=0, ymin=0, width=100, height=100)]) im = vipy.image.Scene(filename='/path/to/city_image.jpg', category='city').objects([vipy.object.Detection(category='vehicle', xmin=0, ymin=0, width=100, height=100)]) im = vipy.image.Scene(filename='/path/to/city_image.jpg', category='office', boxlabels='face', xywh=[0,0,100,100]) im = vipy.image.Scene(filename='/path/to/city_image.jpg', category='office', boxlabels='face', xywh= 0,0,100,100], [100,100,200,200 ) im = vipy.image.Scene(filename='/path/to/city_image.jpg', category='office', boxlabels=['face', 'desk'] xywh= 0,0,100,100], [200,200,300,300 )  "
},
{
"ref":"vipy.image.Scene.cast",
"url":11,
"doc":"Typecast the conformal vipy.image object im as  vipy.image.Image . This is useful for downcasting  vipy.image.Scene or  vipy.image.ImageDetection down to an image.   ims = vipy.image.RandomScene() im = vipy.image.Image.cast(im)  ",
"func":1
},
{
"ref":"vipy.image.Scene.from_json",
"url":11,
"doc":"Import the JSON string s as an  vipy.image.Image object. Args: s: json encoded string This will perform a round trip such that im1  im2   im1 = vupy.image.RandomImage() im2 = vipy.image.Image.from_json(im1.json( assert im1  im2   Note: to construct from non-encoded json (e.g. a dict prior to dumps), use from_dict",
"func":1
},
{
"ref":"vipy.image.Scene.num_objects",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Scene.json",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Scene.image_tags",
"url":11,
"doc":"Return the image level tags of the scene",
"func":1
},
{
"ref":"vipy.image.Scene.tags",
"url":11,
"doc":"Return the image level and object level tags of the scene",
"func":1
},
{
"ref":"vipy.image.Scene.load",
"url":11,
"doc":"Load image to cached private '_array' attribute. Args: verbose: [bool] If true, show additional useful printed output Returns: This  vipy.image.Image object with the pixels loaded in self._array as a numpy array.  note This loader supports any image file format supported by PIL. A custom loader can be added using  vipy.image.Image.loader .",
"func":1
},
{
"ref":"vipy.image.Scene.split",
"url":11,
"doc":"Split a scene with K objects into a list of K  vipy.image.Scene objects, each with one object in the scene.  note The pixel buffer is shared between each split. Use [im.clone() for im in self.split()] for an explicit copy.",
"func":1
},
{
"ref":"vipy.image.Scene.split_and_recenter",
"url":11,
"doc":"Split a scene with K objects into a list of K  vipy.image.Scene objects, each with one object in the scene, with the scene centered on the object with zeropadding  note The pixel buffer is shared between each split. Use [im.clone() for im in self.split()] for an explicit copy.",
"func":1
},
{
"ref":"vipy.image.Scene.append_object",
"url":11,
"doc":"Append the provided vipy.object.Detection object to the scene object list",
"func":1
},
{
"ref":"vipy.image.Scene.add_object",
"url":11,
"doc":"Alias for append",
"func":1
},
{
"ref":"vipy.image.Scene.objects",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Scene.objectmap",
"url":11,
"doc":"Apply lambda function f to each object. If f is a list of lambda, apply one to one with the objects",
"func":1
},
{
"ref":"vipy.image.Scene.objectfilter",
"url":11,
"doc":"Apply lambda function f to each object and keep if filter is True",
"func":1
},
{
"ref":"vipy.image.Scene.nms",
"url":11,
"doc":"Non-maximum supporession of objects() by category based on confidence and spatial IoU and cover thresholds",
"func":1
},
{
"ref":"vipy.image.Scene.intersection",
"url":11,
"doc":"Return a Scene() containing the objects in both self and other, that overlap by miniou with greedy assignment",
"func":1
},
{
"ref":"vipy.image.Scene.difference",
"url":11,
"doc":"Return a Scene() containing the objects in self but not other, that overlap by miniou with greedy assignment",
"func":1
},
{
"ref":"vipy.image.Scene.union",
"url":11,
"doc":"Combine the objects of the scene with other and self with no duplicate checking unless miniou is not None",
"func":1
},
{
"ref":"vipy.image.Scene.uncrop",
"url":11,
"doc":"Uncrop a previous crop(bb) called with the supplied bb=BoundingBox(), and zeropad to shape=(H,W)",
"func":1
},
{
"ref":"vipy.image.Scene.clear",
"url":11,
"doc":"Remove all objects from this scene.",
"func":1
},
{
"ref":"vipy.image.Scene.boundingbox",
"url":11,
"doc":"The boundingbox of a scene is the union of all object bounding boxes, or None if there are no objects. Load to compensate for normalized coordinates",
"func":1
},
{
"ref":"vipy.image.Scene.object_tags",
"url":11,
"doc":"Return list of unique object tags in scene",
"func":1
},
{
"ref":"vipy.image.Scene.flush_array",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Scene.flush",
"url":11,
"doc":"Free the image buffer, and undo all of the object transformations to restore alignment with the reference image filename/url",
"func":1
},
{
"ref":"vipy.image.Scene.imclip",
"url":11,
"doc":"Clip all bounding boxes to the image rectangle, silently rejecting those boxes that are degenerate or outside the image",
"func":1
},
{
"ref":"vipy.image.Scene.rescale",
"url":11,
"doc":"Rescale image buffer and all bounding boxes - Not idempotent",
"func":1
},
{
"ref":"vipy.image.Scene.resize",
"url":11,
"doc":"Resize image buffer to (height=rows, width=cols) and transform all bounding boxes accordingly. If cols or rows is None, then scale isotropically. cols is a synonym for width, rows is a synonym for height",
"func":1
},
{
"ref":"vipy.image.Scene.centersquare",
"url":11,
"doc":"Crop the image of size (H,W) to be centersquare (min(H,W), min(H,W preserving center, and update bounding boxes",
"func":1
},
{
"ref":"vipy.image.Scene.fliplr",
"url":11,
"doc":"Mirror buffer and all bounding box around vertical axis",
"func":1
},
{
"ref":"vipy.image.Scene.flipud",
"url":11,
"doc":"Mirror buffer and all bounding box around vertical axis",
"func":1
},
{
"ref":"vipy.image.Scene.dilate",
"url":11,
"doc":"Dilate all bounding boxes by scale factor, dilated boxes may be outside image rectangle",
"func":1
},
{
"ref":"vipy.image.Scene.zeropad",
"url":11,
"doc":"Zero pad image with padwidth cols before and after and padheight rows before and after, then update bounding box offsets",
"func":1
},
{
"ref":"vipy.image.Scene.meanpad",
"url":11,
"doc":"Mean pad (image color mean) image with padwidth cols before and after and padheight rows before and after, then update bounding box offsets",
"func":1
},
{
"ref":"vipy.image.Scene.rot90cw",
"url":11,
"doc":"Rotate the scene 90 degrees clockwise, and update objects",
"func":1
},
{
"ref":"vipy.image.Scene.rot90ccw",
"url":11,
"doc":"Rotate the scene 90 degrees counterclockwise, and update objects",
"func":1
},
{
"ref":"vipy.image.Scene.maxdim",
"url":11,
"doc":"Resize scene preserving aspect ratio so that maximum dimension of image = dim, update all objects",
"func":1
},
{
"ref":"vipy.image.Scene.mindim",
"url":11,
"doc":"Resize scene preserving aspect ratio so that minimum dimension of image = dim, update all objects",
"func":1
},
{
"ref":"vipy.image.Scene.crop",
"url":11,
"doc":"Crop the image buffer using the supplied bounding box object (or the only object if bbox=None), clipping the box to the image rectangle, update all scene objects",
"func":1
},
{
"ref":"vipy.image.Scene.objectcrop",
"url":11,
"doc":"Crop image using the  vipy.image.Scene.boundingbox with dilation factor. Crop will be zeropadded if outside the image rectangle.",
"func":1
},
{
"ref":"vipy.image.Scene.objectsquare",
"url":11,
"doc":"Crop image using the  vipy.image.Scene.boundingbox with dilation factor, setting to maxsquare prior to crop. Crop will be zeropadded if outside the image rectangle.",
"func":1
},
{
"ref":"vipy.image.Scene.centercrop",
"url":11,
"doc":"Crop image of size (height x width) in the center, keeping the image centroid constant",
"func":1
},
{
"ref":"vipy.image.Scene.cornercrop",
"url":11,
"doc":"Crop image of size (height x width) from the upper left corner, returning valid pixels only",
"func":1
},
{
"ref":"vipy.image.Scene.padcrop",
"url":11,
"doc":"Crop the image buffer using the supplied bounding box object, zero padding if box is outside image rectangle, update all scene objects",
"func":1
},
{
"ref":"vipy.image.Scene.cornerpadcrop",
"url":11,
"doc":"Crop image of size (height x width) from the upper left corner, returning zero padded result out to (height, width)",
"func":1
},
{
"ref":"vipy.image.Scene.rectangular_mask",
"url":11,
"doc":"Return a binary array of the same size as the image (or using the provided image width and height (W,H) size to avoid an image load), with ones inside all bounding boxes",
"func":1
},
{
"ref":"vipy.image.Scene.binarymask",
"url":11,
"doc":"Alias for rectangular_mask with in-place update",
"func":1
},
{
"ref":"vipy.image.Scene.bgmask",
"url":11,
"doc":"Set all pixels outside object bounding boxes to zero",
"func":1
},
{
"ref":"vipy.image.Scene.fgmask",
"url":11,
"doc":"Set all pixels inside object bounding boxes to zero",
"func":1
},
{
"ref":"vipy.image.Scene.pixelmask",
"url":11,
"doc":"Replace pixels within all foreground objects with a privacy preserving pixelated foreground with larger pixels (e.g. like privacy glass)",
"func":1
},
{
"ref":"vipy.image.Scene.pixelize",
"url":11,
"doc":"Alias for pixelmask",
"func":1
},
{
"ref":"vipy.image.Scene.pixelate",
"url":11,
"doc":"Alias for pixelmask",
"func":1
},
{
"ref":"vipy.image.Scene.blurmask",
"url":11,
"doc":"Replace pixels within all foreground objects with a privacy preserving blurred foreground",
"func":1
},
{
"ref":"vipy.image.Scene.blurmask_only",
"url":11,
"doc":"Replace pixels within all foreground objects with specified category with a privacy preserving blurred foreground",
"func":1
},
{
"ref":"vipy.image.Scene.replace",
"url":11,
"doc":"Set all image values within the bounding box equal to the provided img, triggers load() and imclip()",
"func":1
},
{
"ref":"vipy.image.Scene.meanmask",
"url":11,
"doc":"Replace pixels within the foreground objects with the mean pixel color",
"func":1
},
{
"ref":"vipy.image.Scene.perceptualhash",
"url":11,
"doc":"Perceptual differential hash function. This function sets foreground objects to mean color, convert to greyscale, resize with linear interpolation to small image based on desired bit encoding, compute vertical and horizontal gradient signs. Args: bits: [int] longer hashes have lower TAR (true accept rate, some near dupes are missed), but lower FAR (false accept rate), shorter hashes have higher TAR (fewer near-dupes are missed) but higher FAR (more non-dupes are declared as dupes). objmask: [bool] if true, replace the foreground object masks with the mean color prior to computing asbinary: [bool] If true, return a binary array asbytes: [bool] if true return a byte array Returns: A hash string encoding the perceptual hash such that  vipy.image.Image.perceptualhash_distance can be used to compute a hash distance asbytes: a bytes array asbinary: a numpy binary array  notes - Can be used for near duplicate detection of background scenes by unpacking the returned hex string to binary and computing hamming distance, or performing hamming based nearest neighbor indexing. Equivalently,  vipy.image.Image.perceptualhash_distance . - The default packed hex output can be converted to binary as: np.unpackbits(bytearray().fromhex( bghash()  which is equivalent to perceptualhash(asbinary=True)",
"func":1
},
{
"ref":"vipy.image.Scene.fghash",
"url":11,
"doc":"Perceptual differential hash function, computed for each foreground region independently",
"func":1
},
{
"ref":"vipy.image.Scene.bghash",
"url":11,
"doc":"Percetual differential hash function, masking out foreground regions",
"func":1
},
{
"ref":"vipy.image.Scene.isduplicate",
"url":11,
"doc":"Background hash near duplicate detection, returns true if self and im are near duplicate images using bghash",
"func":1
},
{
"ref":"vipy.image.Scene.show",
"url":11,
"doc":"Show scene detection Args: - categories: [list] List of category names in the scene to show - fontsize: [int] or [str]: Size of the font, fontsize=int for points, fontsize='NN:scaled' to scale the font relative to the image size - figure: [int|str] Figure number or title, show the image in the provided figure=int numbered window - nocaption: [bool] Show or do not show the text caption in the upper left of the box - nocaption_withstring: [list]: Do not show captions for those object categories containing any of the strings in the provided list - boxalpha (float, [0,1]): Set the text box background to be semi-transparent with an alpha - d_category2color (dict): Define a dictionary of required mapping of specific category() to box colors. Non-specified categories are assigned a random named color from vipy.show.colorlist() - caption_offset (int, int): The relative position of the caption to the upper right corner of the box. - nowindow (bool): Display or not display the image, used by  vipy.image.Scene.annotation - shortlabel (dict): An optional dictionary mapping category names to short names easier to display - mutator (lambda): A lambda function with signature lambda im: f(im) which will modify this image prior to show. Useful for changing labels on the fly - timestampoffset (tuple): (x,y) coordinate offsets to shift the upper left corner timestamp - theme [str]: If 'dark' use dark mode, if 'light' use light mode to visualize captions with high contrast dark or light foregrounds",
"func":1
},
{
"ref":"vipy.image.Scene.annotate",
"url":11,
"doc":"Alias for  vipy.image.Scene.savefig",
"func":1
},
{
"ref":"vipy.image.Scene.savefig",
"url":11,
"doc":"Save  vipy.image.Scene.show output to given file or return buffer without popping up a window",
"func":1
},
{
"ref":"vipy.image.Scene.attributes",
"url":11,
"doc":""
},
{
"ref":"vipy.image.Scene.add_soft_tags",
"url":11,
"doc":"Soft tags are a list of (tag, confidence) tuples",
"func":1
},
{
"ref":"vipy.image.Scene.soft_tags",
"url":11,
"doc":"Soft tags are a list of (tag, confidence) tuples",
"func":1
},
{
"ref":"vipy.image.Scene.from_uri",
"url":11,
"doc":"Create an image object from an absolute file path or url",
"func":1
},
{
"ref":"vipy.image.Scene.sanitize",
"url":11,
"doc":"Remove all private keys from the attributes dictionary. The attributes dictionary is useful storage for arbitrary (key,value) pairs. However, this storage may contain sensitive information that should be scrubbed from the media before serialization. As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key. This is analogous to private or reserved attributes in the python lanugage. Users should reserve these keynames for those keys that should be sanitized and removed before any serialization of this object.   assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey')  False  ",
"func":1
},
{
"ref":"vipy.image.Scene.print",
"url":11,
"doc":"Print the representation of the image and return self with an optional sleep=n seconds Useful for debugging or sequential visualization in long fluent chains.",
"func":1
},
{
"ref":"vipy.image.Scene.exif",
"url":11,
"doc":"Return the EXIF meta-data in filename as a dictionary. Included non-base EXIF data if extended=True. Returns empty dictionary if no EXIF exists. Triggers download but not load.",
"func":1
},
{
"ref":"vipy.image.Scene.tile",
"url":11,
"doc":"Generate an image tiling. A tiling is a decomposition of an image into overlapping or non-overlapping rectangular regions. Args: tilewidth: [int] the image width of each tile tileheight: [int] the image height of each tile overlaprows: [int] the number of overlapping rows (height) for each tile overlapcols: [int] the number of overlapping width (width) for each tile Returns: A list of  vipy.image.Image objects such that each image is a single tile and the set of these tiles forms the original image Each image in the returned list contains the 'tile' attribute which encodes the crop used to create the tile.  note -  vipy.image.Image.tile can be undone using  vipy.image.Image.untile - The identity tiling is im.tile(im.width(), im.height(), overlaprows=0, overlapcols=0) - Ragged tiles outside the image boundary are zero padded - All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.Scene.untile",
"url":11,
"doc":"Undo an image tiling and recreate the original image.   tiles = im.tile(im.width()/2, im.height()/2, 0, 0) imdst = vipy.image.Image.untile(tiles) assert imdst  im   Args: imlist: this must be the output of  vipy.image.Image.tile Returns: A new  vipy.image.Image object reconstructed from the tiling, such that this is equivalent to the input to vipy.image.Image.tile  note All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.Scene.splat",
"url":11,
"doc":"Replace pixels within boundingbox in self with pixels in im",
"func":1
},
{
"ref":"vipy.image.Scene.store",
"url":11,
"doc":"Store the current image file as an attribute of this object. Useful for archiving an object to be fully self contained without any external references. -Remove this stored image using unstore() -Unpack this stored image and set up the filename using restore() -This method is more efficient than load() followed by pkl(), as it stores the encoded image as a byte string. -Useful for creating a single self contained object for distributed processing.   v  v.store().restore(v.filename(  ",
"func":1
},
{
"ref":"vipy.image.Scene.unstore",
"url":11,
"doc":"Delete the currently stored image from store()",
"func":1
},
{
"ref":"vipy.image.Scene.restore",
"url":11,
"doc":"Save the currently stored image to filename, and set up filename",
"func":1
},
{
"ref":"vipy.image.Scene.abspath",
"url":11,
"doc":"Change the path of the filename from a relative path to an absolute path (not relocatable)",
"func":1
},
{
"ref":"vipy.image.Scene.relpath",
"url":11,
"doc":"Replace the filename with a relative path to parent (or current working directory if none)",
"func":1
},
{
"ref":"vipy.image.Scene.canload",
"url":11,
"doc":"Return True if the image can be loaded successfully, useful for filtering bad links or corrupt images",
"func":1
},
{
"ref":"vipy.image.Scene.dict",
"url":11,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding",
"func":1
},
{
"ref":"vipy.image.Scene.loader",
"url":11,
"doc":"Lambda function to load an unsupported image filename to a numpy array. This lambda function will be executed during load and the result will be stored in self._array",
"func":1
},
{
"ref":"vipy.image.Scene.bytes_array_loader",
"url":11,
"doc":"Load from a bytes array",
"func":1
},
{
"ref":"vipy.image.Scene.PIL_loader",
"url":11,
"doc":"Load from a PIL image file object",
"func":1
},
{
"ref":"vipy.image.Scene.download",
"url":11,
"doc":"Download URL to filename provided by constructor, or to temp filename. Args: timeout: [int] The timeout in seconds for an http or https connection attempt. See also [urllib.request.urlopen](https: docs.python.org/3/library/urllib.request.html). verbose: [bool] If true, output more helpful message. cached: [bool] If true, use the cached previously downloaded file (if it exists) Returns: This  vipy.image.Image object with the URL downloaded to  vipy.image.Image.filename or to a  vipy.util.tempimage filename which can be retrieved with  vipy.image.Image.filename .",
"func":1
},
{
"ref":"vipy.image.Scene.reload",
"url":11,
"doc":"Flush the image buffer to force reloading from file or URL",
"func":1
},
{
"ref":"vipy.image.Scene.isloaded",
"url":11,
"doc":"Return True if  vipy.image.Image.load was successful in reading the image, or if the pixels are present in  vipy.image.Image.array .",
"func":1
},
{
"ref":"vipy.image.Scene.loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.Scene.is_loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.Scene.isdownloaded",
"url":11,
"doc":"Does the filename returned from  vipy.image.Image.filename exist, meaning that the url has been downloaded to a local file?",
"func":1
},
{
"ref":"vipy.image.Scene.is_downloaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isdownloaded ",
"func":1
},
{
"ref":"vipy.image.Scene.downloadif",
"url":11,
"doc":"Download URL to filename if the filename has not already been downloaded",
"func":1
},
{
"ref":"vipy.image.Scene.try_download",
"url":11,
"doc":"Attempt to download URL to filename if the filename has not already been downloaded, return object on failure. Check  vipy.image.Image.is_downloaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.Scene.try_load",
"url":11,
"doc":"Attempt to load an image, return the object on failure. Check  vipy.image.Image.is_loaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.Scene.channels",
"url":11,
"doc":"Return integer number of color channels",
"func":1
},
{
"ref":"vipy.image.Scene.iscolor",
"url":11,
"doc":"Color images are three channel or four channel with transparency, float32 or uint8",
"func":1
},
{
"ref":"vipy.image.Scene.istransparent",
"url":11,
"doc":"Transparent images are four channel color images with transparency, float32 or uint8. Return true if this image contains an alpha transparency channel",
"func":1
},
{
"ref":"vipy.image.Scene.blend",
"url":11,
"doc":"alpha blend self and im in-place, such that self = alpha self + (1-alpha) im",
"func":1
},
{
"ref":"vipy.image.Scene.isgrey",
"url":11,
"doc":"Grey images are one channel, float32",
"func":1
},
{
"ref":"vipy.image.Scene.isluminance",
"url":11,
"doc":"Luninance images are one channel, uint8",
"func":1
},
{
"ref":"vipy.image.Scene.filesize",
"url":11,
"doc":"Return size of underlying image file, requires fetching metadata from filesystem",
"func":1
},
{
"ref":"vipy.image.Scene.width",
"url":11,
"doc":"Return the width (columns) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Scene.height",
"url":11,
"doc":"Return the height (rows) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Scene.shape",
"url":11,
"doc":"Return the (height, width) or equivalently (rows, cols) of the image. Returns: A tuple (height=int, width=int) of the image.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Scene.aspectratio",
"url":11,
"doc":"Return the aspect ratio of the image as (width/height) ratio. Returns: A float equivalent to ( vipy.image.Image.width /  vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Scene.area",
"url":11,
"doc":"Return the area of the image as (width  height). Returns: An integer equivalent to ( vipy.image.Image.width   vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.Scene.centroid",
"url":11,
"doc":"Return the real valued center pixel coordinates of the image (col=x,row=y). The centroid is equivalent to half the  vipy.image.Image.shape . Returns: A tuple (column, row) of the floating point center of the image.",
"func":1
},
{
"ref":"vipy.image.Scene.centerpixel",
"url":11,
"doc":"Return the integer valued center pixel coordinates of the image (col=i,row=j) The centerpixel is equivalent to half the  vipy.image.Image.shape floored to the nearest integer pixel coordinate. Returns: A tuple (int(column), int(row of the integer center of the image.",
"func":1
},
{
"ref":"vipy.image.Scene.array",
"url":11,
"doc":"Replace self._array with provided numpy array Args: np_array: [numpy array] A new array to use as the pixel buffer for this image. copy: [bool] If true, copy the buffer using np.copy(), else use a reference to this buffer. Returns: - If np_array is not None, return the  vipy.image.Image object such that this object points to the provided numpy array as the pixel buffer - If np_array is None, then return the numpy array.  notes - If copy=False, then this  vipy.image.Image object will share the pixel buffer with the owner of np_array. Changes to pixels in this buffer will be shared. - If copy=True, then this will significantly slow down processing for large images. Use referneces wherevery possible.",
"func":1
},
{
"ref":"vipy.image.Scene.fromarray",
"url":11,
"doc":"Alias for  vipy.image.Image.array with copy=True. This will set new numpy array as the pixel buffer with a numpy array copy",
"func":1
},
{
"ref":"vipy.image.Scene.tonumpy",
"url":11,
"doc":"Alias for  vipy.image.Image.numpy",
"func":1
},
{
"ref":"vipy.image.Scene.numpy",
"url":11,
"doc":"Return a mutable numpy array for this  vipy.image.Image .  notes - This will always return a writeable array with the 'WRITEABLE' numpy flag set. This is useful for returning a mutable numpy array as needed while keeping the original non-mutable numpy array (e.g. loaded from a video or PIL) as the underlying pixel buffer for efficiency reasons. - Triggers a  vipy.image.Image.load if the pixel buffer has not been loaded - This will trigger a copy if the ['WRITEABLE' flag](https: numpy.org/doc/stable/reference/generated/numpy.ndarray.flags.html) is not set.",
"func":1
},
{
"ref":"vipy.image.Scene.channel",
"url":11,
"doc":"Return a cloned Image() object for the kth channel, or return an iterator over channels if k=None. Iterate over channels as single channel luminance images:   for c in self.channel(): print(c)   Return the kth channel as a single channel luminance image:   c = self.channel(k=0)  ",
"func":1
},
{
"ref":"vipy.image.Scene.channelmean",
"url":11,
"doc":"Return a cloned Image() object for the mean of all channels followed by returning a single channel float image. This is useful for visualizing multichannel images by reducing the channels to one   vipy.image.Image(array=np.random.rand(3,3,16).astype(np.float32 .channelmean().mat2gray().lum().show()  ",
"func":1
},
{
"ref":"vipy.image.Scene.red",
"url":11,
"doc":"Return red channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.red()  self.channel(0)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.red()  self.channel(3)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.Scene.green",
"url":11,
"doc":"Return green channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.green()  self.channel(1)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.green()  self.channel(1)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.Scene.blue",
"url":11,
"doc":"Return blue channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.vlue()  self.channel(2)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.blue()  self.channel(0)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.Scene.alpha",
"url":11,
"doc":"Return alpha (transparency) channel as a cloned single channel  vipy.image.Image object",
"func":1
},
{
"ref":"vipy.image.Scene.zeros",
"url":11,
"doc":"Set the pixel buffer to all zeros of the same shape and datatype as this  vipy.image.Image object. These are equivalent operations for the resulting buffer shape:   import numpy as np np.zeros( (self.width(), self.height(), self.channels( )  self.zeros().array()   Returns: This  vipy.image.Image object.  note Triggers load() if the pixel buffer has not been loaded yet.",
"func":1
},
{
"ref":"vipy.image.Scene.pil",
"url":11,
"doc":"Convert vipy.image.Image to PIL Image. Returns: A [PIL image](https: pillow.readthedocs.io/en/stable/reference/Image.html) object, that shares the pixel buffer by reference",
"func":1
},
{
"ref":"vipy.image.Scene.blur",
"url":11,
"doc":"Apply a Gaussian blur with Gaussian kernel radius=sigma to the pixel buffer. Args: sigma: [float >=0] The gaussian blur kernel radius. Returns: This  vipy.image.Image object with the pixel buffer blurred in place.",
"func":1
},
{
"ref":"vipy.image.Scene.torch",
"url":11,
"doc":"Convert the batch of 1 HxWxC images to a CxHxW torch tensor. Args: order: ['CHW', 'HWC', 'NCHW', 'NHWC']. The axis order of the torch tensor (channels, height, width) or (height, width, channels) or (1, channels, height, width) or (1, height, width, channels) Returns: A CxHxW or HxWxC or 1xCxHxW or 1xHxWxC [torch tensor](https: pytorch.org/docs/stable/tensors.html) that shares the pixel buffer of this image object by reference.  note This supports numpy types and does not support bfloat16",
"func":1
},
{
"ref":"vipy.image.Scene.from_torch",
"url":11,
"doc":"Convert a 1xCxHxW or CxHxW torch tensor (or numpy array with torch channel order) to HxWxC numpy array, returns new  vipy.image.Image with inferred colorspace corresponding to data type in x",
"func":1
},
{
"ref":"vipy.image.Scene.fromtorch",
"url":11,
"doc":"Alias for  vipy.image.Image.from_torch ",
"func":1
},
{
"ref":"vipy.image.Scene.unload",
"url":11,
"doc":"Remove cached file and loaded array. Note that this will delete the underlying file returned by filename() if there is a backing url, cleaning up cached files and forcing re-download",
"func":1
},
{
"ref":"vipy.image.Scene.uncache",
"url":11,
"doc":"Alias for  vipy.image.Image.unload ",
"func":1
},
{
"ref":"vipy.image.Scene.filename",
"url":11,
"doc":"Return or set image filename",
"func":1
},
{
"ref":"vipy.image.Scene.url",
"url":11,
"doc":"Image URL and URL download properties",
"func":1
},
{
"ref":"vipy.image.Scene.colorspace",
"url":11,
"doc":"Return or set the colorspace as ['rgb', 'rgba', 'bgr', 'bgra', 'hsv', 'float', 'grey', 'lum']",
"func":1
},
{
"ref":"vipy.image.Scene.uri",
"url":11,
"doc":"Return the URI of the image object, either the URL or the filename, raise exception if neither defined",
"func":1
},
{
"ref":"vipy.image.Scene.set_attribute",
"url":11,
"doc":"Set element self.attributes[key]=value",
"func":1
},
{
"ref":"vipy.image.Scene.setattributes",
"url":11,
"doc":"Set many attributes at once by providing a dictionary to be merged with current attributes",
"func":1
},
{
"ref":"vipy.image.Scene.getattribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.Scene.get_attribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.Scene.append_attribute",
"url":11,
"doc":"Append the value to attribute key, creating the key as an empty list if it does not exist",
"func":1
},
{
"ref":"vipy.image.Scene.metadata",
"url":11,
"doc":"Return metadata associated with this image, stored in the attributes dictionary",
"func":1
},
{
"ref":"vipy.image.Scene.hasurl",
"url":11,
"doc":"synonym for  vipy.image.has_url ",
"func":1
},
{
"ref":"vipy.image.Scene.has_url",
"url":11,
"doc":"Return True if the image has a URL input source",
"func":1
},
{
"ref":"vipy.image.Scene.has_filename",
"url":11,
"doc":"Return True if the image has a filename input source and this file exists",
"func":1
},
{
"ref":"vipy.image.Scene.hasfilename",
"url":11,
"doc":"synonym for has_filename",
"func":1
},
{
"ref":"vipy.image.Scene.clone",
"url":11,
"doc":"Create deep copy of object, flushing the original buffer if requested and returning the cloned object. Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned object which can be used for encoding and will be garbage collected.  flushforward: copy the object, and set the cloned object array() to None. This flushes the video buffer for the clone, not the object  flushbackward: copy the object, and set the object array() to None. This flushes the video buffer for the object, not the clone.  flush: set the object array() to None and clone the object. This flushes the video buffer for both the clone and the object.  dereference: remove both the filename and URL (if present) in the cloned object, leaving only the buffer",
"func":1
},
{
"ref":"vipy.image.Scene.resize_like",
"url":11,
"doc":"Resize image buffer to be the same size as the provided vipy.image.Image()",
"func":1
},
{
"ref":"vipy.image.Scene.mindimn",
"url":11,
"doc":"Frequently used shortcut for mindim(dim, interp='nearest')",
"func":1
},
{
"ref":"vipy.image.Scene.pad",
"url":11,
"doc":"Alias for  vipy.image.Image.zeropad ",
"func":1
},
{
"ref":"vipy.image.Scene.zeropadlike",
"url":11,
"doc":"Zero pad the image balancing the border so that the resulting image size is (width, height)",
"func":1
},
{
"ref":"vipy.image.Scene.alphapad",
"url":11,
"doc":"Pad image using alpha transparency by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.Scene.minsquare",
"url":11,
"doc":"Crop image of size (HxW) to (min(H,W), min(H,W , keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.Scene.maxsquare",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with zeropadding or (S,S) if provided, keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.Scene.maxmatte",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with balanced zeropadding forming a letterbox with top/bottom matte or pillarbox with left/right matte",
"func":1
},
{
"ref":"vipy.image.Scene.imagebox",
"url":11,
"doc":"Return the bounding box for the image rectangle",
"func":1
},
{
"ref":"vipy.image.Scene.border_mask",
"url":11,
"doc":"Return a binary uint8 image the same size as self, with a border of pad pixels in width or height around the edge",
"func":1
},
{
"ref":"vipy.image.Scene.affine_transform",
"url":11,
"doc":"Apply a 3x3 affine geometric transformation to the image. Args: - A [np.ndarray]: 3x3 affine geometric transform from  vipy.geometry.affine_transform - border [str]: 'zero' or 'replicate' to handle elements outside the image rectangle after transformation Returns: - This object with only the array transformed  note The image will be loaded and converted to float() prior to applying the affine transformation.  note This will transform only the pixels, not objects",
"func":1
},
{
"ref":"vipy.image.Scene.rotate",
"url":11,
"doc":"Apply a rotation in radians to the pixels, with origin in upper left",
"func":1
},
{
"ref":"vipy.image.Scene.rotate_by_exif",
"url":11,
"doc":"Apply a rotation as specified in the 'Orientation' field EXIF metadata",
"func":1
},
{
"ref":"vipy.image.Scene.rgb",
"url":11,
"doc":"Convert the image buffer to three channel RGB uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Scene.color_transform",
"url":11,
"doc":"Transform the image buffer from the current  vipy.image.Image.colorspace to the provided colorspace",
"func":1
},
{
"ref":"vipy.image.Scene.colorspace_like",
"url":11,
"doc":"Convert the image buffer to have the same colorspace as the provided image",
"func":1
},
{
"ref":"vipy.image.Scene.rgba",
"url":11,
"doc":"Convert the image buffer to four channel RGBA uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Scene.hsv",
"url":11,
"doc":"Convert the image buffer to three channel HSV uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Scene.bgr",
"url":11,
"doc":"Convert the image buffer to three channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Scene.bgra",
"url":11,
"doc":"Convert the image buffer to four channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.Scene.float",
"url":11,
"doc":"Convert the image buffer to float32",
"func":1
},
{
"ref":"vipy.image.Scene.greyscale",
"url":11,
"doc":"Convert the image buffer to single channel grayscale float32 in range [0,1]",
"func":1
},
{
"ref":"vipy.image.Scene.grayscale",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.Scene.grey",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.Scene.gray",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.Scene.luminance",
"url":11,
"doc":"Convert the image buffer to single channel uint8 in range [0,255] corresponding to the luminance component",
"func":1
},
{
"ref":"vipy.image.Scene.lum",
"url":11,
"doc":"Alias for luminance()",
"func":1
},
{
"ref":"vipy.image.Scene.jet",
"url":11,
"doc":"Apply jet colormap to greyscale image and save as RGB",
"func":1
},
{
"ref":"vipy.image.Scene.rainbow",
"url":11,
"doc":"Apply rainbow colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.Scene.hot",
"url":11,
"doc":"Apply hot colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.Scene.bone",
"url":11,
"doc":"Apply bone colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.Scene.saturate",
"url":11,
"doc":"Saturate the image buffer to be clipped between [min,max], types of min/max are specified by _array type",
"func":1
},
{
"ref":"vipy.image.Scene.intensity",
"url":11,
"doc":"Convert image to float32 with [min,max] to range [0,1], force colormap to be 'float'. Equivalent to self.mat2gray()",
"func":1
},
{
"ref":"vipy.image.Scene.mat2gray",
"url":11,
"doc":"Convert the image buffer so that [min,max] -> [0,1], forces conversion to 'float' colorspace. This does not change the number of color channels",
"func":1
},
{
"ref":"vipy.image.Scene.sum_to_one",
"url":11,
"doc":"Return float image in the range [0,1] such that all elements sum to one",
"func":1
},
{
"ref":"vipy.image.Scene.gain",
"url":11,
"doc":"Elementwise multiply gain to image array, Gain should be broadcastable to array(). This forces the colospace to 'float'. Don't use numba optimization, it is slower than native multiply",
"func":1
},
{
"ref":"vipy.image.Scene.bias",
"url":11,
"doc":"Add a bias to the image array. Bias should be broadcastable to array(). This forces the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.Scene.normalize",
"url":11,
"doc":"Apply a multiplicative gain g and additive bias b, such that self.array()  gain self.array() + bias. This is useful for applying a normalization of an image prior to calling  vipy.image.Image.torch . The following operations are equivalent.   im = vipy.image.RandomImage() im.normalize(1/255.0, 0.5)  im.gain(1/255.0).bias(-0.5)    note This will force the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.Scene.additive_noise",
"url":11,
"doc":"Apply uniform random additive noise in the given range to the given HSV color channels. Image will be converted to HSV prior to applying noise.",
"func":1
},
{
"ref":"vipy.image.Scene.mean",
"url":11,
"doc":"Mean over all pixels",
"func":1
},
{
"ref":"vipy.image.Scene.meanchannel",
"url":11,
"doc":"Mean per channel over all pixels. If channel k is provided, return just the mean for that channel",
"func":1
},
{
"ref":"vipy.image.Scene.closeall",
"url":11,
"doc":"Close all open figure windows",
"func":1
},
{
"ref":"vipy.image.Scene.close",
"url":11,
"doc":"Close the requested figure number, or close all of fignum=None",
"func":1
},
{
"ref":"vipy.image.Scene.save",
"url":11,
"doc":"Save the current image to a new filename and return the image object. Resets edit history",
"func":1
},
{
"ref":"vipy.image.Scene.pkl",
"url":11,
"doc":"save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.Scene.pklif",
"url":11,
"doc":"Save the object to the provided pickle file only if b=True. Useful for conditional intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.Scene.saveas",
"url":11,
"doc":"Save current buffer (not including drawing overlays) to new filename and return filename. If filename is not provided, use a temporary JPEG filename.",
"func":1
},
{
"ref":"vipy.image.Scene.saveastmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for savetmp()",
"func":1
},
{
"ref":"vipy.image.Scene.savetmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for saveastmp()",
"func":1
},
{
"ref":"vipy.image.Scene.tocache",
"url":11,
"doc":"Save current buffer to temp JPEG filename in the VIPY cache and return filename.",
"func":1
},
{
"ref":"vipy.image.Scene.base64",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page",
"func":1
},
{
"ref":"vipy.image.Scene.ascii",
"url":11,
"doc":"Export a base64 ascii encoding of the image suitable for embedding in an  tag",
"func":1
},
{
"ref":"vipy.image.Scene.html",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page, enclosed in  tag Returns: -string:  containing base64 encoded JPEG and alt text with lazy loading",
"func":1
},
{
"ref":"vipy.image.Scene.map",
"url":11,
"doc":"Apply lambda function to our numpy array img, such that newimg=f(img), then replace newimg -> self.array(). The output of this lambda function must be a numpy array and if the channels or dtype changes, the colorspace is set to 'float'",
"func":1
},
{
"ref":"vipy.image.Scene.perceptualhash_distance",
"url":11,
"doc":"Hamming distance between two perceptual hashes",
"func":1
},
{
"ref":"vipy.image.Scene.face_detection",
"url":11,
"doc":"Detect faces in the scene, add as objects, return new scene with just faces Args: mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled back to native resolution prior to return Returns A  vipy.image.Scene object with all detected faces or the union of faces and all objects in self  note This method uses a CPU-only pretrained face detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.Scene.person_detection",
"url":11,
"doc":"Detect only people in the scene, add as objects, return new scene with just people Args: mindim [int]: The minimum dimension for downsampling the image for person detection. Will be upsampled back to native resolution prior to return conf [float]: A real value between [0,1] of the minimum confidence for person detection Returns A  vipy.image.Scene object with all detected people or the union of people and all objects in self  note This method uses a CPU-only pretrained person detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.Scene.face_blur",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.blurmask , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.blurmask mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with faceblur attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().blurmask()",
"func":1
},
{
"ref":"vipy.image.Scene.face_pixelize",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.pixelize , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.radius mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with facepixelize attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().pixelize()",
"func":1
},
{
"ref":"vipy.image.Scene.viewport",
"url":11,
"doc":"Return the bounding box of the current loaded pixels in the original filename/url/buffer. This reverses the chain of geometric transformations applied to the original image to recover the bounding box of the pixels in array(). This is useful to specify a region of a larger image that was zoomed in for processing. To show this viewport as a bounding box: >>> im = vipy.image.vehicles().centercrop(100,100) >>> viewport = vipy.object.Detection.cast(im.viewport( >>> im.flush().append(viewport).show()",
"func":1
},
{
"ref":"vipy.image.Scene.recenter",
"url":11,
"doc":"Recenter the image so that point p=(x=col, y=row) in the current image is in the middle of the new image, zeropad to (width, height). This is useful to implement a 'saccade', under the small angle assumption, where a rotation is approximated by a translation",
"func":1
},
{
"ref":"vipy.image.ImageDetection",
"url":11,
"doc":"vipy.image.ImageDetection class This class provides a representation of a  vipy.image.Image with a single  vipy.object.Detection . This is useful for direct bounding box manipulations. This class inherits all methods of  vipy.image.Image and  vipy.object.Detection (and therefore  vipy.geometry.BoundingBox ). Inheritance priority is for Image. Overloaded methods such as rescale() or width() will transform or return values for the Image. Valid constructors include all provided by vipy.image.Image and BoundingBox coordinates   im = vipy.image.ImageDetection(filename='/path/to/dog_image.ext', category='dog', xmin=0, ymin=0, width=100, height=100) im = vipy.image.ImageDetection(filename='/path/to/dog_image.ext', category='dog', xmin=0, ymin=0, xmax=100, ymax=100) im = vipy.image.ImageDetection(filename='/path/to/dog_image.ext', category='dog', xcentroid=50, ycentroid=50, width=100, height=100)    notes - The inheritance resolution order will prefer the subclass methods for  vipy.image.Image . For example, the shape() method will return the image shape. - Use  vipy.image.DetectionImage or  vipy.image.ImageDetection.detectionimage cast if you prefer overloaded methods to resolve to bounding box manipulation - All methods in this class will transform the pixels or the box independently. The use case for this class is to manipulate boxes relative to the image for refinement (e.g. data augmentation). - If you want the pixels to be transformed along with the boxes, use the  vipy.image.ImageDetection.scene method to cast this to a  vipy.image.Scene object."
},
{
"ref":"vipy.image.ImageDetection.num_objects",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.ImageDetection.from_json",
"url":11,
"doc":"Import the JSON string s as an  vipy.image.Image object. Args: s: json encoded string This will perform a round trip such that im1  im2   im1 = vupy.image.RandomImage() im2 = vipy.image.Image.from_json(im1.json( assert im1  im2   Note: to construct from non-encoded json (e.g. a dict prior to dumps), use from_dict",
"func":1
},
{
"ref":"vipy.image.ImageDetection.boundingbox",
"url":11,
"doc":"The boundingbox of a scene is the union of all object bounding boxes, or None if there are no objects. Load to compensate for normalized coordinates",
"func":1
},
{
"ref":"vipy.image.ImageDetection.crop",
"url":11,
"doc":"Crop the image using the bounding box and return a  vipy.image.Image for the cropped pixels",
"func":1
},
{
"ref":"vipy.image.ImageDetection.cast",
"url":11,
"doc":"Typecast the conformal vipy.image object im as  vipy.image.Image . This is useful for downcasting  vipy.image.Scene or  vipy.image.ImageDetection down to an image.   ims = vipy.image.RandomScene() im = vipy.image.Image.cast(im)  ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.image_tags",
"url":11,
"doc":"Return the image level tags of the scene",
"func":1
},
{
"ref":"vipy.image.ImageDetection.tags",
"url":11,
"doc":"Return the image level and object level tags of the scene",
"func":1
},
{
"ref":"vipy.image.ImageDetection.load",
"url":11,
"doc":"Load image to cached private '_array' attribute. Args: verbose: [bool] If true, show additional useful printed output Returns: This  vipy.image.Image object with the pixels loaded in self._array as a numpy array.  note This loader supports any image file format supported by PIL. A custom loader can be added using  vipy.image.Image.loader .",
"func":1
},
{
"ref":"vipy.image.ImageDetection.split",
"url":11,
"doc":"Split a scene with K objects into a list of K  vipy.image.Scene objects, each with one object in the scene.  note The pixel buffer is shared between each split. Use [im.clone() for im in self.split()] for an explicit copy.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.split_and_recenter",
"url":11,
"doc":"Split a scene with K objects into a list of K  vipy.image.Scene objects, each with one object in the scene, with the scene centered on the object with zeropadding  note The pixel buffer is shared between each split. Use [im.clone() for im in self.split()] for an explicit copy.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.append_object",
"url":11,
"doc":"Append the provided vipy.object.Detection object to the scene object list",
"func":1
},
{
"ref":"vipy.image.ImageDetection.add_object",
"url":11,
"doc":"Alias for append",
"func":1
},
{
"ref":"vipy.image.ImageDetection.objectmap",
"url":11,
"doc":"Apply lambda function f to each object. If f is a list of lambda, apply one to one with the objects",
"func":1
},
{
"ref":"vipy.image.ImageDetection.objectfilter",
"url":11,
"doc":"Apply lambda function f to each object and keep if filter is True",
"func":1
},
{
"ref":"vipy.image.ImageDetection.nms",
"url":11,
"doc":"Non-maximum supporession of objects() by category based on confidence and spatial IoU and cover thresholds",
"func":1
},
{
"ref":"vipy.image.ImageDetection.intersection",
"url":11,
"doc":"Return a Scene() containing the objects in both self and other, that overlap by miniou with greedy assignment",
"func":1
},
{
"ref":"vipy.image.ImageDetection.difference",
"url":11,
"doc":"Return a Scene() containing the objects in self but not other, that overlap by miniou with greedy assignment",
"func":1
},
{
"ref":"vipy.image.ImageDetection.union",
"url":11,
"doc":"Combine the objects of the scene with other and self with no duplicate checking unless miniou is not None",
"func":1
},
{
"ref":"vipy.image.ImageDetection.uncrop",
"url":11,
"doc":"Uncrop a previous crop(bb) called with the supplied bb=BoundingBox(), and zeropad to shape=(H,W)",
"func":1
},
{
"ref":"vipy.image.ImageDetection.clear",
"url":11,
"doc":"Remove all objects from this scene.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.object_tags",
"url":11,
"doc":"Return list of unique object tags in scene",
"func":1
},
{
"ref":"vipy.image.ImageDetection.flush",
"url":11,
"doc":"Free the image buffer, and undo all of the object transformations to restore alignment with the reference image filename/url",
"func":1
},
{
"ref":"vipy.image.ImageDetection.imclip",
"url":11,
"doc":"Clip all bounding boxes to the image rectangle, silently rejecting those boxes that are degenerate or outside the image",
"func":1
},
{
"ref":"vipy.image.ImageDetection.rescale",
"url":11,
"doc":"Rescale image buffer and all bounding boxes - Not idempotent",
"func":1
},
{
"ref":"vipy.image.ImageDetection.resize",
"url":11,
"doc":"Resize image buffer to (height=rows, width=cols) and transform all bounding boxes accordingly. If cols or rows is None, then scale isotropically. cols is a synonym for width, rows is a synonym for height",
"func":1
},
{
"ref":"vipy.image.ImageDetection.centersquare",
"url":11,
"doc":"Crop the image of size (H,W) to be centersquare (min(H,W), min(H,W preserving center, and update bounding boxes",
"func":1
},
{
"ref":"vipy.image.ImageDetection.fliplr",
"url":11,
"doc":"Mirror buffer and all bounding box around vertical axis",
"func":1
},
{
"ref":"vipy.image.ImageDetection.flipud",
"url":11,
"doc":"Mirror buffer and all bounding box around vertical axis",
"func":1
},
{
"ref":"vipy.image.ImageDetection.dilate",
"url":11,
"doc":"Dilate all bounding boxes by scale factor, dilated boxes may be outside image rectangle",
"func":1
},
{
"ref":"vipy.image.ImageDetection.zeropad",
"url":11,
"doc":"Zero pad image with padwidth cols before and after and padheight rows before and after, then update bounding box offsets",
"func":1
},
{
"ref":"vipy.image.ImageDetection.meanpad",
"url":11,
"doc":"Mean pad (image color mean) image with padwidth cols before and after and padheight rows before and after, then update bounding box offsets",
"func":1
},
{
"ref":"vipy.image.ImageDetection.rot90cw",
"url":11,
"doc":"Rotate the scene 90 degrees clockwise, and update objects",
"func":1
},
{
"ref":"vipy.image.ImageDetection.rot90ccw",
"url":11,
"doc":"Rotate the scene 90 degrees counterclockwise, and update objects",
"func":1
},
{
"ref":"vipy.image.ImageDetection.maxdim",
"url":11,
"doc":"Resize scene preserving aspect ratio so that maximum dimension of image = dim, update all objects",
"func":1
},
{
"ref":"vipy.image.ImageDetection.mindim",
"url":11,
"doc":"Resize scene preserving aspect ratio so that minimum dimension of image = dim, update all objects",
"func":1
},
{
"ref":"vipy.image.ImageDetection.objectcrop",
"url":11,
"doc":"Crop image using the  vipy.image.Scene.boundingbox with dilation factor. Crop will be zeropadded if outside the image rectangle.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.objectsquare",
"url":11,
"doc":"Crop image using the  vipy.image.Scene.boundingbox with dilation factor, setting to maxsquare prior to crop. Crop will be zeropadded if outside the image rectangle.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.centercrop",
"url":11,
"doc":"Crop image of size (height x width) in the center, keeping the image centroid constant",
"func":1
},
{
"ref":"vipy.image.ImageDetection.cornercrop",
"url":11,
"doc":"Crop image of size (height x width) from the upper left corner, returning valid pixels only",
"func":1
},
{
"ref":"vipy.image.ImageDetection.padcrop",
"url":11,
"doc":"Crop the image buffer using the supplied bounding box object, zero padding if box is outside image rectangle, update all scene objects",
"func":1
},
{
"ref":"vipy.image.ImageDetection.cornerpadcrop",
"url":11,
"doc":"Crop image of size (height x width) from the upper left corner, returning zero padded result out to (height, width)",
"func":1
},
{
"ref":"vipy.image.ImageDetection.rectangular_mask",
"url":11,
"doc":"Return a binary array of the same size as the image (or using the provided image width and height (W,H) size to avoid an image load), with ones inside all bounding boxes",
"func":1
},
{
"ref":"vipy.image.ImageDetection.binarymask",
"url":11,
"doc":"Alias for rectangular_mask with in-place update",
"func":1
},
{
"ref":"vipy.image.ImageDetection.bgmask",
"url":11,
"doc":"Set all pixels outside object bounding boxes to zero",
"func":1
},
{
"ref":"vipy.image.ImageDetection.fgmask",
"url":11,
"doc":"Set all pixels inside object bounding boxes to zero",
"func":1
},
{
"ref":"vipy.image.ImageDetection.pixelmask",
"url":11,
"doc":"Replace pixels within all foreground objects with a privacy preserving pixelated foreground with larger pixels (e.g. like privacy glass)",
"func":1
},
{
"ref":"vipy.image.ImageDetection.pixelize",
"url":11,
"doc":"Alias for pixelmask",
"func":1
},
{
"ref":"vipy.image.ImageDetection.pixelate",
"url":11,
"doc":"Alias for pixelmask",
"func":1
},
{
"ref":"vipy.image.ImageDetection.blurmask",
"url":11,
"doc":"Replace pixels within all foreground objects with a privacy preserving blurred foreground",
"func":1
},
{
"ref":"vipy.image.ImageDetection.blurmask_only",
"url":11,
"doc":"Replace pixels within all foreground objects with specified category with a privacy preserving blurred foreground",
"func":1
},
{
"ref":"vipy.image.ImageDetection.replace",
"url":11,
"doc":"Set all image values within the bounding box equal to the provided img, triggers load() and imclip()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.meanmask",
"url":11,
"doc":"Replace pixels within the foreground objects with the mean pixel color",
"func":1
},
{
"ref":"vipy.image.ImageDetection.perceptualhash",
"url":11,
"doc":"Perceptual differential hash function. This function sets foreground objects to mean color, convert to greyscale, resize with linear interpolation to small image based on desired bit encoding, compute vertical and horizontal gradient signs. Args: bits: [int] longer hashes have lower TAR (true accept rate, some near dupes are missed), but lower FAR (false accept rate), shorter hashes have higher TAR (fewer near-dupes are missed) but higher FAR (more non-dupes are declared as dupes). objmask: [bool] if true, replace the foreground object masks with the mean color prior to computing asbinary: [bool] If true, return a binary array asbytes: [bool] if true return a byte array Returns: A hash string encoding the perceptual hash such that  vipy.image.Image.perceptualhash_distance can be used to compute a hash distance asbytes: a bytes array asbinary: a numpy binary array  notes - Can be used for near duplicate detection of background scenes by unpacking the returned hex string to binary and computing hamming distance, or performing hamming based nearest neighbor indexing. Equivalently,  vipy.image.Image.perceptualhash_distance . - The default packed hex output can be converted to binary as: np.unpackbits(bytearray().fromhex( bghash()  which is equivalent to perceptualhash(asbinary=True)",
"func":1
},
{
"ref":"vipy.image.ImageDetection.fghash",
"url":11,
"doc":"Perceptual differential hash function, computed for each foreground region independently",
"func":1
},
{
"ref":"vipy.image.ImageDetection.bghash",
"url":11,
"doc":"Percetual differential hash function, masking out foreground regions",
"func":1
},
{
"ref":"vipy.image.ImageDetection.isduplicate",
"url":11,
"doc":"Background hash near duplicate detection, returns true if self and im are near duplicate images using bghash",
"func":1
},
{
"ref":"vipy.image.ImageDetection.show",
"url":11,
"doc":"Show scene detection Args: - categories: [list] List of category names in the scene to show - fontsize: [int] or [str]: Size of the font, fontsize=int for points, fontsize='NN:scaled' to scale the font relative to the image size - figure: [int|str] Figure number or title, show the image in the provided figure=int numbered window - nocaption: [bool] Show or do not show the text caption in the upper left of the box - nocaption_withstring: [list]: Do not show captions for those object categories containing any of the strings in the provided list - boxalpha (float, [0,1]): Set the text box background to be semi-transparent with an alpha - d_category2color (dict): Define a dictionary of required mapping of specific category() to box colors. Non-specified categories are assigned a random named color from vipy.show.colorlist() - caption_offset (int, int): The relative position of the caption to the upper right corner of the box. - nowindow (bool): Display or not display the image, used by  vipy.image.Scene.annotation - shortlabel (dict): An optional dictionary mapping category names to short names easier to display - mutator (lambda): A lambda function with signature lambda im: f(im) which will modify this image prior to show. Useful for changing labels on the fly - timestampoffset (tuple): (x,y) coordinate offsets to shift the upper left corner timestamp - theme [str]: If 'dark' use dark mode, if 'light' use light mode to visualize captions with high contrast dark or light foregrounds",
"func":1
},
{
"ref":"vipy.image.ImageDetection.annotate",
"url":11,
"doc":"Alias for  vipy.image.Scene.savefig",
"func":1
},
{
"ref":"vipy.image.ImageDetection.savefig",
"url":11,
"doc":"Save  vipy.image.Scene.show output to given file or return buffer without popping up a window",
"func":1
},
{
"ref":"vipy.image.ImageDetection.add_soft_tags",
"url":11,
"doc":"Soft tags are a list of (tag, confidence) tuples",
"func":1
},
{
"ref":"vipy.image.ImageDetection.soft_tags",
"url":11,
"doc":"Soft tags are a list of (tag, confidence) tuples",
"func":1
},
{
"ref":"vipy.image.ImageDetection.from_uri",
"url":11,
"doc":"Create an image object from an absolute file path or url",
"func":1
},
{
"ref":"vipy.image.ImageDetection.sanitize",
"url":11,
"doc":"Remove all private keys from the attributes dictionary. The attributes dictionary is useful storage for arbitrary (key,value) pairs. However, this storage may contain sensitive information that should be scrubbed from the media before serialization. As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key. This is analogous to private or reserved attributes in the python lanugage. Users should reserve these keynames for those keys that should be sanitized and removed before any serialization of this object.   assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey')  False  ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.print",
"url":11,
"doc":"Print the representation of the image and return self with an optional sleep=n seconds Useful for debugging or sequential visualization in long fluent chains.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.exif",
"url":11,
"doc":"Return the EXIF meta-data in filename as a dictionary. Included non-base EXIF data if extended=True. Returns empty dictionary if no EXIF exists. Triggers download but not load.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.tile",
"url":11,
"doc":"Generate an image tiling. A tiling is a decomposition of an image into overlapping or non-overlapping rectangular regions. Args: tilewidth: [int] the image width of each tile tileheight: [int] the image height of each tile overlaprows: [int] the number of overlapping rows (height) for each tile overlapcols: [int] the number of overlapping width (width) for each tile Returns: A list of  vipy.image.Image objects such that each image is a single tile and the set of these tiles forms the original image Each image in the returned list contains the 'tile' attribute which encodes the crop used to create the tile.  note -  vipy.image.Image.tile can be undone using  vipy.image.Image.untile - The identity tiling is im.tile(im.width(), im.height(), overlaprows=0, overlapcols=0) - Ragged tiles outside the image boundary are zero padded - All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.untile",
"url":11,
"doc":"Undo an image tiling and recreate the original image.   tiles = im.tile(im.width()/2, im.height()/2, 0, 0) imdst = vipy.image.Image.untile(tiles) assert imdst  im   Args: imlist: this must be the output of  vipy.image.Image.tile Returns: A new  vipy.image.Image object reconstructed from the tiling, such that this is equivalent to the input to vipy.image.Image.tile  note All annotations are updated properly for each tile, when the source image is  vipy.image.Scene ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.splat",
"url":11,
"doc":"Replace pixels within boundingbox in self with pixels in im",
"func":1
},
{
"ref":"vipy.image.ImageDetection.store",
"url":11,
"doc":"Store the current image file as an attribute of this object. Useful for archiving an object to be fully self contained without any external references. -Remove this stored image using unstore() -Unpack this stored image and set up the filename using restore() -This method is more efficient than load() followed by pkl(), as it stores the encoded image as a byte string. -Useful for creating a single self contained object for distributed processing.   v  v.store().restore(v.filename(  ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.unstore",
"url":11,
"doc":"Delete the currently stored image from store()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.restore",
"url":11,
"doc":"Save the currently stored image to filename, and set up filename",
"func":1
},
{
"ref":"vipy.image.ImageDetection.abspath",
"url":11,
"doc":"Change the path of the filename from a relative path to an absolute path (not relocatable)",
"func":1
},
{
"ref":"vipy.image.ImageDetection.relpath",
"url":11,
"doc":"Replace the filename with a relative path to parent (or current working directory if none)",
"func":1
},
{
"ref":"vipy.image.ImageDetection.canload",
"url":11,
"doc":"Return True if the image can be loaded successfully, useful for filtering bad links or corrupt images",
"func":1
},
{
"ref":"vipy.image.ImageDetection.dict",
"url":11,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding",
"func":1
},
{
"ref":"vipy.image.ImageDetection.loader",
"url":11,
"doc":"Lambda function to load an unsupported image filename to a numpy array. This lambda function will be executed during load and the result will be stored in self._array",
"func":1
},
{
"ref":"vipy.image.ImageDetection.bytes_array_loader",
"url":11,
"doc":"Load from a bytes array",
"func":1
},
{
"ref":"vipy.image.ImageDetection.PIL_loader",
"url":11,
"doc":"Load from a PIL image file object",
"func":1
},
{
"ref":"vipy.image.ImageDetection.download",
"url":11,
"doc":"Download URL to filename provided by constructor, or to temp filename. Args: timeout: [int] The timeout in seconds for an http or https connection attempt. See also [urllib.request.urlopen](https: docs.python.org/3/library/urllib.request.html). verbose: [bool] If true, output more helpful message. cached: [bool] If true, use the cached previously downloaded file (if it exists) Returns: This  vipy.image.Image object with the URL downloaded to  vipy.image.Image.filename or to a  vipy.util.tempimage filename which can be retrieved with  vipy.image.Image.filename .",
"func":1
},
{
"ref":"vipy.image.ImageDetection.reload",
"url":11,
"doc":"Flush the image buffer to force reloading from file or URL",
"func":1
},
{
"ref":"vipy.image.ImageDetection.isloaded",
"url":11,
"doc":"Return True if  vipy.image.Image.load was successful in reading the image, or if the pixels are present in  vipy.image.Image.array .",
"func":1
},
{
"ref":"vipy.image.ImageDetection.loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.is_loaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isloaded ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.isdownloaded",
"url":11,
"doc":"Does the filename returned from  vipy.image.Image.filename exist, meaning that the url has been downloaded to a local file?",
"func":1
},
{
"ref":"vipy.image.ImageDetection.is_downloaded",
"url":11,
"doc":"Alias for  vipy.image.Image.isdownloaded ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.downloadif",
"url":11,
"doc":"Download URL to filename if the filename has not already been downloaded",
"func":1
},
{
"ref":"vipy.image.ImageDetection.try_download",
"url":11,
"doc":"Attempt to download URL to filename if the filename has not already been downloaded, return object on failure. Check  vipy.image.Image.is_downloaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.ImageDetection.try_load",
"url":11,
"doc":"Attempt to load an image, return the object on failure. Check  vipy.image.Image.is_loaded on returned object for success",
"func":1
},
{
"ref":"vipy.image.ImageDetection.channels",
"url":11,
"doc":"Return integer number of color channels",
"func":1
},
{
"ref":"vipy.image.ImageDetection.iscolor",
"url":11,
"doc":"Color images are three channel or four channel with transparency, float32 or uint8",
"func":1
},
{
"ref":"vipy.image.ImageDetection.istransparent",
"url":11,
"doc":"Transparent images are four channel color images with transparency, float32 or uint8. Return true if this image contains an alpha transparency channel",
"func":1
},
{
"ref":"vipy.image.ImageDetection.blend",
"url":11,
"doc":"alpha blend self and im in-place, such that self = alpha self + (1-alpha) im",
"func":1
},
{
"ref":"vipy.image.ImageDetection.isgrey",
"url":11,
"doc":"Grey images are one channel, float32",
"func":1
},
{
"ref":"vipy.image.ImageDetection.isluminance",
"url":11,
"doc":"Luninance images are one channel, uint8",
"func":1
},
{
"ref":"vipy.image.ImageDetection.filesize",
"url":11,
"doc":"Return size of underlying image file, requires fetching metadata from filesystem",
"func":1
},
{
"ref":"vipy.image.ImageDetection.width",
"url":11,
"doc":"Return the width (columns) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.height",
"url":11,
"doc":"Return the height (rows) of the image in integer pixels.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.shape",
"url":11,
"doc":"Return the (height, width) or equivalently (rows, cols) of the image. Returns: A tuple (height=int, width=int) of the image.  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.aspectratio",
"url":11,
"doc":"Return the aspect ratio of the image as (width/height) ratio. Returns: A float equivalent to ( vipy.image.Image.width /  vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.area",
"url":11,
"doc":"Return the area of the image as (width  height). Returns: An integer equivalent to ( vipy.image.Image.width   vipy.image.Image.height )  note This triggers a  vipy.image.Image.load if the image is not already loaded.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.centroid",
"url":11,
"doc":"Return the real valued center pixel coordinates of the image (col=x,row=y). The centroid is equivalent to half the  vipy.image.Image.shape . Returns: A tuple (column, row) of the floating point center of the image.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.centerpixel",
"url":11,
"doc":"Return the integer valued center pixel coordinates of the image (col=i,row=j) The centerpixel is equivalent to half the  vipy.image.Image.shape floored to the nearest integer pixel coordinate. Returns: A tuple (int(column), int(row of the integer center of the image.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.array",
"url":11,
"doc":"Replace self._array with provided numpy array Args: np_array: [numpy array] A new array to use as the pixel buffer for this image. copy: [bool] If true, copy the buffer using np.copy(), else use a reference to this buffer. Returns: - If np_array is not None, return the  vipy.image.Image object such that this object points to the provided numpy array as the pixel buffer - If np_array is None, then return the numpy array.  notes - If copy=False, then this  vipy.image.Image object will share the pixel buffer with the owner of np_array. Changes to pixels in this buffer will be shared. - If copy=True, then this will significantly slow down processing for large images. Use referneces wherevery possible.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.fromarray",
"url":11,
"doc":"Alias for  vipy.image.Image.array with copy=True. This will set new numpy array as the pixel buffer with a numpy array copy",
"func":1
},
{
"ref":"vipy.image.ImageDetection.tonumpy",
"url":11,
"doc":"Alias for  vipy.image.Image.numpy",
"func":1
},
{
"ref":"vipy.image.ImageDetection.numpy",
"url":11,
"doc":"Return a mutable numpy array for this  vipy.image.Image .  notes - This will always return a writeable array with the 'WRITEABLE' numpy flag set. This is useful for returning a mutable numpy array as needed while keeping the original non-mutable numpy array (e.g. loaded from a video or PIL) as the underlying pixel buffer for efficiency reasons. - Triggers a  vipy.image.Image.load if the pixel buffer has not been loaded - This will trigger a copy if the ['WRITEABLE' flag](https: numpy.org/doc/stable/reference/generated/numpy.ndarray.flags.html) is not set.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.channel",
"url":11,
"doc":"Return a cloned Image() object for the kth channel, or return an iterator over channels if k=None. Iterate over channels as single channel luminance images:   for c in self.channel(): print(c)   Return the kth channel as a single channel luminance image:   c = self.channel(k=0)  ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.channelmean",
"url":11,
"doc":"Return a cloned Image() object for the mean of all channels followed by returning a single channel float image. This is useful for visualizing multichannel images by reducing the channels to one   vipy.image.Image(array=np.random.rand(3,3,16).astype(np.float32 .channelmean().mat2gray().lum().show()  ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.red",
"url":11,
"doc":"Return red channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.red()  self.channel(0)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.red()  self.channel(3)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.green",
"url":11,
"doc":"Return green channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.green()  self.channel(1)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.green()  self.channel(1)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.blue",
"url":11,
"doc":"Return blue channel as a cloned single channel  vipy.image.Image object. These are equivalent operations if the colorspace is 'rgb' or 'rgba':   self.vlue()  self.channel(2)   These are equivalent operations if the colorspace is 'bgr' or 'bgra':   self.blue()  self.channel(0)    note OpenCV returns images in BGR colorspace. Use this method to always return the desired channel by color.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.alpha",
"url":11,
"doc":"Return alpha (transparency) channel as a cloned single channel  vipy.image.Image object",
"func":1
},
{
"ref":"vipy.image.ImageDetection.zeros",
"url":11,
"doc":"Set the pixel buffer to all zeros of the same shape and datatype as this  vipy.image.Image object. These are equivalent operations for the resulting buffer shape:   import numpy as np np.zeros( (self.width(), self.height(), self.channels( )  self.zeros().array()   Returns: This  vipy.image.Image object.  note Triggers load() if the pixel buffer has not been loaded yet.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.pil",
"url":11,
"doc":"Convert vipy.image.Image to PIL Image. Returns: A [PIL image](https: pillow.readthedocs.io/en/stable/reference/Image.html) object, that shares the pixel buffer by reference",
"func":1
},
{
"ref":"vipy.image.ImageDetection.blur",
"url":11,
"doc":"Apply a Gaussian blur with Gaussian kernel radius=sigma to the pixel buffer. Args: sigma: [float >=0] The gaussian blur kernel radius. Returns: This  vipy.image.Image object with the pixel buffer blurred in place.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.torch",
"url":11,
"doc":"Convert the batch of 1 HxWxC images to a CxHxW torch tensor. Args: order: ['CHW', 'HWC', 'NCHW', 'NHWC']. The axis order of the torch tensor (channels, height, width) or (height, width, channels) or (1, channels, height, width) or (1, height, width, channels) Returns: A CxHxW or HxWxC or 1xCxHxW or 1xHxWxC [torch tensor](https: pytorch.org/docs/stable/tensors.html) that shares the pixel buffer of this image object by reference.  note This supports numpy types and does not support bfloat16",
"func":1
},
{
"ref":"vipy.image.ImageDetection.from_torch",
"url":11,
"doc":"Convert a 1xCxHxW or CxHxW torch tensor (or numpy array with torch channel order) to HxWxC numpy array, returns new  vipy.image.Image with inferred colorspace corresponding to data type in x",
"func":1
},
{
"ref":"vipy.image.ImageDetection.fromtorch",
"url":11,
"doc":"Alias for  vipy.image.Image.from_torch ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.unload",
"url":11,
"doc":"Remove cached file and loaded array. Note that this will delete the underlying file returned by filename() if there is a backing url, cleaning up cached files and forcing re-download",
"func":1
},
{
"ref":"vipy.image.ImageDetection.uncache",
"url":11,
"doc":"Alias for  vipy.image.Image.unload ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.filename",
"url":11,
"doc":"Return or set image filename",
"func":1
},
{
"ref":"vipy.image.ImageDetection.url",
"url":11,
"doc":"Image URL and URL download properties",
"func":1
},
{
"ref":"vipy.image.ImageDetection.colorspace",
"url":11,
"doc":"Return or set the colorspace as ['rgb', 'rgba', 'bgr', 'bgra', 'hsv', 'float', 'grey', 'lum']",
"func":1
},
{
"ref":"vipy.image.ImageDetection.uri",
"url":11,
"doc":"Return the URI of the image object, either the URL or the filename, raise exception if neither defined",
"func":1
},
{
"ref":"vipy.image.ImageDetection.set_attribute",
"url":11,
"doc":"Set element self.attributes[key]=value",
"func":1
},
{
"ref":"vipy.image.ImageDetection.setattributes",
"url":11,
"doc":"Set many attributes at once by providing a dictionary to be merged with current attributes",
"func":1
},
{
"ref":"vipy.image.ImageDetection.getattribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.ImageDetection.get_attribute",
"url":11,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.image.ImageDetection.append_attribute",
"url":11,
"doc":"Append the value to attribute key, creating the key as an empty list if it does not exist",
"func":1
},
{
"ref":"vipy.image.ImageDetection.metadata",
"url":11,
"doc":"Return metadata associated with this image, stored in the attributes dictionary",
"func":1
},
{
"ref":"vipy.image.ImageDetection.hasurl",
"url":11,
"doc":"synonym for  vipy.image.has_url ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.has_url",
"url":11,
"doc":"Return True if the image has a URL input source",
"func":1
},
{
"ref":"vipy.image.ImageDetection.has_filename",
"url":11,
"doc":"Return True if the image has a filename input source and this file exists",
"func":1
},
{
"ref":"vipy.image.ImageDetection.hasfilename",
"url":11,
"doc":"synonym for has_filename",
"func":1
},
{
"ref":"vipy.image.ImageDetection.clone",
"url":11,
"doc":"Create deep copy of object, flushing the original buffer if requested and returning the cloned object. Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned object which can be used for encoding and will be garbage collected.  flushforward: copy the object, and set the cloned object array() to None. This flushes the video buffer for the clone, not the object  flushbackward: copy the object, and set the object array() to None. This flushes the video buffer for the object, not the clone.  flush: set the object array() to None and clone the object. This flushes the video buffer for both the clone and the object.  dereference: remove both the filename and URL (if present) in the cloned object, leaving only the buffer",
"func":1
},
{
"ref":"vipy.image.ImageDetection.resize_like",
"url":11,
"doc":"Resize image buffer to be the same size as the provided vipy.image.Image()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.mindimn",
"url":11,
"doc":"Frequently used shortcut for mindim(dim, interp='nearest')",
"func":1
},
{
"ref":"vipy.image.ImageDetection.pad",
"url":11,
"doc":"Alias for  vipy.image.Image.zeropad ",
"func":1
},
{
"ref":"vipy.image.ImageDetection.zeropadlike",
"url":11,
"doc":"Zero pad the image balancing the border so that the resulting image size is (width, height)",
"func":1
},
{
"ref":"vipy.image.ImageDetection.alphapad",
"url":11,
"doc":"Pad image using alpha transparency by adding padwidth on both left and right , or padwidth=(left,right) for different pre/postpadding and padheight on top and bottom or padheight=(top,bottom) for different pre/post padding",
"func":1
},
{
"ref":"vipy.image.ImageDetection.minsquare",
"url":11,
"doc":"Crop image of size (HxW) to (min(H,W), min(H,W , keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.ImageDetection.maxsquare",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with zeropadding or (S,S) if provided, keeping upper left corner constant",
"func":1
},
{
"ref":"vipy.image.ImageDetection.maxmatte",
"url":11,
"doc":"Crop image of size (HxW) to (max(H,W), max(H,W with balanced zeropadding forming a letterbox with top/bottom matte or pillarbox with left/right matte",
"func":1
},
{
"ref":"vipy.image.ImageDetection.imagebox",
"url":11,
"doc":"Return the bounding box for the image rectangle",
"func":1
},
{
"ref":"vipy.image.ImageDetection.border_mask",
"url":11,
"doc":"Return a binary uint8 image the same size as self, with a border of pad pixels in width or height around the edge",
"func":1
},
{
"ref":"vipy.image.ImageDetection.affine_transform",
"url":11,
"doc":"Apply a 3x3 affine geometric transformation to the image. Args: - A [np.ndarray]: 3x3 affine geometric transform from  vipy.geometry.affine_transform - border [str]: 'zero' or 'replicate' to handle elements outside the image rectangle after transformation Returns: - This object with only the array transformed  note The image will be loaded and converted to float() prior to applying the affine transformation.  note This will transform only the pixels, not objects",
"func":1
},
{
"ref":"vipy.image.ImageDetection.rotate",
"url":11,
"doc":"Apply a rotation in radians to the pixels, with origin in upper left",
"func":1
},
{
"ref":"vipy.image.ImageDetection.rotate_by_exif",
"url":11,
"doc":"Apply a rotation as specified in the 'Orientation' field EXIF metadata",
"func":1
},
{
"ref":"vipy.image.ImageDetection.rgb",
"url":11,
"doc":"Convert the image buffer to three channel RGB uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageDetection.color_transform",
"url":11,
"doc":"Transform the image buffer from the current  vipy.image.Image.colorspace to the provided colorspace",
"func":1
},
{
"ref":"vipy.image.ImageDetection.colorspace_like",
"url":11,
"doc":"Convert the image buffer to have the same colorspace as the provided image",
"func":1
},
{
"ref":"vipy.image.ImageDetection.rgba",
"url":11,
"doc":"Convert the image buffer to four channel RGBA uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageDetection.hsv",
"url":11,
"doc":"Convert the image buffer to three channel HSV uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageDetection.bgr",
"url":11,
"doc":"Convert the image buffer to three channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageDetection.bgra",
"url":11,
"doc":"Convert the image buffer to four channel BGR uint8 colorspace",
"func":1
},
{
"ref":"vipy.image.ImageDetection.float",
"url":11,
"doc":"Convert the image buffer to float32",
"func":1
},
{
"ref":"vipy.image.ImageDetection.greyscale",
"url":11,
"doc":"Convert the image buffer to single channel grayscale float32 in range [0,1]",
"func":1
},
{
"ref":"vipy.image.ImageDetection.grayscale",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.grey",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.gray",
"url":11,
"doc":"Alias for greyscale()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.luminance",
"url":11,
"doc":"Convert the image buffer to single channel uint8 in range [0,255] corresponding to the luminance component",
"func":1
},
{
"ref":"vipy.image.ImageDetection.lum",
"url":11,
"doc":"Alias for luminance()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.jet",
"url":11,
"doc":"Apply jet colormap to greyscale image and save as RGB",
"func":1
},
{
"ref":"vipy.image.ImageDetection.rainbow",
"url":11,
"doc":"Apply rainbow colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.ImageDetection.hot",
"url":11,
"doc":"Apply hot colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.ImageDetection.bone",
"url":11,
"doc":"Apply bone colormap to greyscale image and convert to RGB",
"func":1
},
{
"ref":"vipy.image.ImageDetection.saturate",
"url":11,
"doc":"Saturate the image buffer to be clipped between [min,max], types of min/max are specified by _array type",
"func":1
},
{
"ref":"vipy.image.ImageDetection.intensity",
"url":11,
"doc":"Convert image to float32 with [min,max] to range [0,1], force colormap to be 'float'. Equivalent to self.mat2gray()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.mat2gray",
"url":11,
"doc":"Convert the image buffer so that [min,max] -> [0,1], forces conversion to 'float' colorspace. This does not change the number of color channels",
"func":1
},
{
"ref":"vipy.image.ImageDetection.sum_to_one",
"url":11,
"doc":"Return float image in the range [0,1] such that all elements sum to one",
"func":1
},
{
"ref":"vipy.image.ImageDetection.gain",
"url":11,
"doc":"Elementwise multiply gain to image array, Gain should be broadcastable to array(). This forces the colospace to 'float'. Don't use numba optimization, it is slower than native multiply",
"func":1
},
{
"ref":"vipy.image.ImageDetection.bias",
"url":11,
"doc":"Add a bias to the image array. Bias should be broadcastable to array(). This forces the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.ImageDetection.normalize",
"url":11,
"doc":"Apply a multiplicative gain g and additive bias b, such that self.array()  gain self.array() + bias. This is useful for applying a normalization of an image prior to calling  vipy.image.Image.torch . The following operations are equivalent.   im = vipy.image.RandomImage() im.normalize(1/255.0, 0.5)  im.gain(1/255.0).bias(-0.5)    note This will force the colorspace to 'float'",
"func":1
},
{
"ref":"vipy.image.ImageDetection.additive_noise",
"url":11,
"doc":"Apply uniform random additive noise in the given range to the given HSV color channels. Image will be converted to HSV prior to applying noise.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.mean",
"url":11,
"doc":"Mean over all pixels",
"func":1
},
{
"ref":"vipy.image.ImageDetection.meanchannel",
"url":11,
"doc":"Mean per channel over all pixels. If channel k is provided, return just the mean for that channel",
"func":1
},
{
"ref":"vipy.image.ImageDetection.closeall",
"url":11,
"doc":"Close all open figure windows",
"func":1
},
{
"ref":"vipy.image.ImageDetection.close",
"url":11,
"doc":"Close the requested figure number, or close all of fignum=None",
"func":1
},
{
"ref":"vipy.image.ImageDetection.save",
"url":11,
"doc":"Save the current image to a new filename and return the image object. Resets edit history",
"func":1
},
{
"ref":"vipy.image.ImageDetection.pkl",
"url":11,
"doc":"save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.ImageDetection.pklif",
"url":11,
"doc":"Save the object to the provided pickle file only if b=True. Useful for conditional intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.image.ImageDetection.saveas",
"url":11,
"doc":"Save current buffer (not including drawing overlays) to new filename and return filename. If filename is not provided, use a temporary JPEG filename.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.saveastmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for savetmp()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.savetmp",
"url":11,
"doc":"Save current buffer to temp JPEG filename and return filename. Alias for saveastmp()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.tocache",
"url":11,
"doc":"Save current buffer to temp JPEG filename in the VIPY cache and return filename.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.base64",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page",
"func":1
},
{
"ref":"vipy.image.ImageDetection.ascii",
"url":11,
"doc":"Export a base64 ascii encoding of the image suitable for embedding in an  tag",
"func":1
},
{
"ref":"vipy.image.ImageDetection.html",
"url":11,
"doc":"Export a base64 encoding of the image suitable for embedding in an html page, enclosed in  tag Returns: -string:  containing base64 encoded JPEG and alt text with lazy loading",
"func":1
},
{
"ref":"vipy.image.ImageDetection.map",
"url":11,
"doc":"Apply lambda function to our numpy array img, such that newimg=f(img), then replace newimg -> self.array(). The output of this lambda function must be a numpy array and if the channels or dtype changes, the colorspace is set to 'float'",
"func":1
},
{
"ref":"vipy.image.ImageDetection.perceptualhash_distance",
"url":11,
"doc":"Hamming distance between two perceptual hashes",
"func":1
},
{
"ref":"vipy.image.ImageDetection.face_detection",
"url":11,
"doc":"Detect faces in the scene, add as objects, return new scene with just faces Args: mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled back to native resolution prior to return Returns A  vipy.image.Scene object with all detected faces or the union of faces and all objects in self  note This method uses a CPU-only pretrained face detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.person_detection",
"url":11,
"doc":"Detect only people in the scene, add as objects, return new scene with just people Args: mindim [int]: The minimum dimension for downsampling the image for person detection. Will be upsampled back to native resolution prior to return conf [float]: A real value between [0,1] of the minimum confidence for person detection Returns A  vipy.image.Scene object with all detected people or the union of people and all objects in self  note This method uses a CPU-only pretrained person detector. This is convenient, but slow. See the heyvi package for optimized GPU batch processing for faster operation.",
"func":1
},
{
"ref":"vipy.image.ImageDetection.face_blur",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.blurmask , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.blurmask mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with faceblur attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().blurmask()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.face_pixelize",
"url":11,
"doc":"Replace pixels for all detected faces with  vipy.image.Scene.pixelize , add locations of detected faces into attributes. Args: radius [int]: The radius of pixels for  vipy.image.Scene.radius mindim [int]: The minimum dimension for downsampling the image for face detection. Will be upsampled prior to pixelize. Returns: A  vipy.image.Image object with a pixel buffer with all faces pixelized, with facepixelize attribute set in  vipy.image.Image.metadata showing the locations of the blurred faces.  notes - This method uses a CPU-only pretrained torch network for face detection from the heyvi visual analytics package, which is re-initialized on each call to this method. - For batch operations on many images, it is preferred to set up the detection network once, then calling many images sequentially. - To retain boxes, use self.face_detection().pixelize()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.viewport",
"url":11,
"doc":"Return the bounding box of the current loaded pixels in the original filename/url/buffer. This reverses the chain of geometric transformations applied to the original image to recover the bounding box of the pixels in array(). This is useful to specify a region of a larger image that was zoomed in for processing. To show this viewport as a bounding box: >>> im = vipy.image.vehicles().centercrop(100,100) >>> viewport = vipy.object.Detection.cast(im.viewport( >>> im.flush().append(viewport).show()",
"func":1
},
{
"ref":"vipy.image.ImageDetection.recenter",
"url":11,
"doc":"Recenter the image so that point p=(x=col, y=row) in the current image is in the middle of the new image, zeropad to (width, height). This is useful to implement a 'saccade', under the small angle assumption, where a rotation is approximated by a translation",
"func":1
},
{
"ref":"vipy.image.mutator_show_trackid",
"url":11,
"doc":"Mutate the image to show track ID with a fixed number of digits appended to the category as ( )",
"func":1
},
{
"ref":"vipy.image.mutator_show_trackindex",
"url":11,
"doc":"Mutate the image to show track index appended to the category as ( )",
"func":1
},
{
"ref":"vipy.image.mutator_show_track_only",
"url":11,
"doc":"Mutate the image to show track as a consistently colored box with no categories",
"func":1
},
{
"ref":"vipy.image.mutator_show_noun_only",
"url":11,
"doc":"Mutate the image to show the noun only. Args: nocaption: [bool] If true, then do not display the caption, only consistently colored boxes for the noun.  note To color boxes by track rather than noun, use  vipy.image.mutator_show_trackonly ",
"func":1
},
{
"ref":"vipy.image.mutator_show_verb_only",
"url":11,
"doc":"Mutate the image to show the verb only",
"func":1
},
{
"ref":"vipy.image.mutator_show_noun_or_verb",
"url":11,
"doc":"Mutate the image to show the verb only if it is non-zero else noun",
"func":1
},
{
"ref":"vipy.image.mutator_show_noun_verb",
"url":11,
"doc":"Mutate the image to show the category as 'Noun Verb1 Noun Verb2'",
"func":1
},
{
"ref":"vipy.image.mutator_show_trackindex_verbonly",
"url":11,
"doc":"Mutate the image to show boxes colored by track index, and only show 'verb' captions with activity confidence, sorted in decreasing order",
"func":1
},
{
"ref":"vipy.image.RandomImage",
"url":11,
"doc":"Return a uniform random color  vipy.image.Image of size (rows, cols)",
"func":1
},
{
"ref":"vipy.image.RandomImageDetection",
"url":11,
"doc":"Return a uniform random color  vipy.image.ImageDetection of size (rows, cols) with a random bounding box",
"func":1
},
{
"ref":"vipy.image.RandomScene",
"url":11,
"doc":"Return a uniform random color  vipy.image.Scene of size (rows, cols) with a specified number of vipy.object.Object objects",
"func":1
},
{
"ref":"vipy.image.owl",
"url":11,
"doc":"Return a superb owl image for testing",
"func":1
},
{
"ref":"vipy.image.vehicles",
"url":11,
"doc":"Return a highway scene with the four highest confidence vehicle detections for testing",
"func":1
},
{
"ref":"vipy.image.people",
"url":11,
"doc":"Return a crowd scene with the four highest confidence person detections for testing",
"func":1
},
{
"ref":"vipy.image.Transform",
"url":11,
"doc":"Transforms are static methods that implement common transformation patterns used in distributed processing. These are useful for parallel processing of noisy or corrupted images when anonymous functions are not supported (e.g. multiprocessing) See also:  vipy.dataset.Dataset.minibatch for parallel processing of batches of images for downloading, loading, resizing, cropping, augmenting, tensor prep etc."
},
{
"ref":"vipy.image.Transform.is_loaded",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.load",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.download",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.mindim",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.thumbnail",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.saveas",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.annotate",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.centersquare_32x32_normalized",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.centersquare_32x32_lum_normalized",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.centersquare_256x256_normalized",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.mindim256_normalized",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.tensor",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.image.Transform.to_tensor",
"url":11,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader",
"url":12,
"doc":""
},
{
"ref":"vipy.downloader.youtube",
"url":12,
"doc":"Use yt-dlp to download a video URL to a video file",
"func":1
},
{
"ref":"vipy.downloader.generate_sha1",
"url":12,
"doc":"Generate the SHA1 hash of the provided filename. This is equivalent on a linux flavor to: >>> vipy.downloader.generate_sha1('/path/to/file')  os.system('sha1sum /path/to/file')",
"func":1
},
{
"ref":"vipy.downloader.verify_sha1",
"url":12,
"doc":"Verify that the provide SHA1 hash is equivalent to the provided file",
"func":1
},
{
"ref":"vipy.downloader.verify_md5",
"url":12,
"doc":"Verify that the provide MD5 hash is equivalent to the provided file",
"func":1
},
{
"ref":"vipy.downloader.generate_md5",
"url":12,
"doc":"Generate the MD5 sum of the provided filename. This is equivalent on a linux flavor to: >>> vipy.downloader.generate_md5('/path/to/file')  os.system('md5sum /path/to/file')",
"func":1
},
{
"ref":"vipy.downloader.scp",
"url":12,
"doc":"Download using pre-installed SSH keys where hostname is formatted 'scp: hostname.com/path/to/file.jpg'",
"func":1
},
{
"ref":"vipy.downloader.s3",
"url":12,
"doc":"Thin wrapper for boto3",
"func":1
},
{
"ref":"vipy.downloader.s3_bucket",
"url":12,
"doc":"Thin wrapper for boto3",
"func":1
},
{
"ref":"vipy.downloader.downloadif",
"url":12,
"doc":"Downloads file at  url and write it in  output_filename only if the file does not exist with the provided SHA1 hash",
"func":1
},
{
"ref":"vipy.downloader.download",
"url":12,
"doc":"Downloads file at  url and write it in  output_filename ",
"func":1
},
{
"ref":"vipy.downloader.unpack",
"url":12,
"doc":"Extracts  archive_filename in  output_dirname . Supported archives:          -  Zip formats and equivalents: .zip, .egg, .jar  Tar and compressed tar formats: .tar, .tar.gz, .tgz, .tar.bz2, .tz2  gzip compressed files  non-tar .bz2",
"func":1
},
{
"ref":"vipy.downloader.download_and_unpack",
"url":12,
"doc":"Downloads and extracts archive in  url into  output_dirname . Note that  output_dirname has to exist and won't be created by this function.",
"func":1
},
{
"ref":"vipy.downloader.download_unpack_and_cleanup",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.unpack_and_cleanup",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.ArchiveException",
"url":12,
"doc":"Base exception class for all archive errors."
},
{
"ref":"vipy.downloader.UnrecognizedArchiveFormat",
"url":12,
"doc":"Error raised when passed file is not a recognized archive format."
},
{
"ref":"vipy.downloader.extract",
"url":12,
"doc":"Unpack the tar or zip file at the specified  archive_filename to the directory specified by  output_dirname .",
"func":1
},
{
"ref":"vipy.downloader.Archive",
"url":12,
"doc":"The external API class that encapsulates an archive implementation."
},
{
"ref":"vipy.downloader.Archive.extract",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.Archive.list",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.BaseArchive",
"url":12,
"doc":"Base Archive class. Implementations should inherit this class."
},
{
"ref":"vipy.downloader.BaseArchive.extract",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.BaseArchive.list",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.ExtractInterface",
"url":12,
"doc":"Interface class exposing common extract functionalities for standard-library-based Archive classes (e.g. based on modules like tarfile, zipfile)."
},
{
"ref":"vipy.downloader.ExtractInterface.extract",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.TarArchive",
"url":12,
"doc":"Interface class exposing common extract functionalities for standard-library-based Archive classes (e.g. based on modules like tarfile, zipfile)."
},
{
"ref":"vipy.downloader.TarArchive.list",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.TarArchive.get_members",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.ZipArchive",
"url":12,
"doc":"Interface class exposing common extract functionalities for standard-library-based Archive classes (e.g. based on modules like tarfile, zipfile). Password should be bytes encoded string, (e.g. passwd=b'thepassword')"
},
{
"ref":"vipy.downloader.ZipArchive.list",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.downloader.ZipArchive.get_members",
"url":12,
"doc":"",
"func":1
},
{
"ref":"vipy.annotation",
"url":13,
"doc":""
},
{
"ref":"vipy.annotation.googlesearch",
"url":13,
"doc":"Return a list of image URLs from google image search associated with the provided tag",
"func":1
},
{
"ref":"vipy.annotation.basic_level_categories",
"url":13,
"doc":"Return a list of nouns from wordnet that can be used as an initial list of basic level object categories",
"func":1
},
{
"ref":"vipy.annotation.nouns",
"url":13,
"doc":"Return nouns from wordnet as a dictionary of imagenet 'wordnet id' (e.g. n + offset) keys to a list of synset names",
"func":1
},
{
"ref":"vipy.annotation.verbs",
"url":13,
"doc":"Return a list of verbs from verbnet that can be used to define a set of activities",
"func":1
},
{
"ref":"vipy.annotation.Selector",
"url":13,
"doc":"HTML+javascript based UI for selecting images from a group.  Given a list of lists of  vipy.image.Image objects, display each image in a standalone HTML file.  Allow the user to click on desirable images to select them.  When done, the user selects the Download JSON button to export the selected elements.  The selected elements are stored in a JSON file which is exported back into this object to return only the selected images   imlist =  vipy.image.RandomScene(128,128) for k in range(10)] for j in range(5)] s = vipy.annotation.Selector(imlist) s.html(show=True)  annotate locally in browser by selecting images to keep, then download the resulting jsonfile selected_imlist = s.fromjson('/path/to/downloaded.json')  returns only those images selected in the UI  "
},
{
"ref":"vipy.annotation.Selector.html",
"url":13,
"doc":"Given a list of tuples of  vipy.image.Image objects, create a standalone HTML file that will allow the user to select individual images in the group. Selected images are output to jsonfile",
"func":1
},
{
"ref":"vipy.annotation.Selector.fromjson",
"url":13,
"doc":"Given the JSON file downloaded from the HTML selector, return only those that were selected",
"func":1
},
{
"ref":"vipy.annotation.Filter",
"url":13,
"doc":"HTML+javascript based UI for filtering images from a group.  Given a list of lists of  vipy.image.Image objects, display each image in a standalone HTML file.  Allow the user to click on non-desirable images to remove them.  When done, the user selects the Download JSON button to export the filtered elements.  The filtered elements are stored in a JSON file which is exported back into this object to return all but the filtered images   imlist =  vipy.image.RandomScene(128,128) for k in range(10)] for j in range(5)] s = vipy.annotation.Filter(imlist) s.html(show=True)  annotate locally in browser by selecting images to remove and download the resulting jsonfile filtered_imlist = s.fromjson('/path/to/downloaded.json')  returns images with those selected in the UI removed  "
},
{
"ref":"vipy.annotation.Filter.html",
"url":13,
"doc":"Given a list of tuples of  vipy.image.Image objects, create a standalone HTML file that will allow the user to select individual images in the group. Selected images are output to jsonfile",
"func":1
},
{
"ref":"vipy.annotation.Filter.fromjson",
"url":13,
"doc":"Given the JSON file downloader from the HTML selector, return a filter of only those that were  not selected",
"func":1
},
{
"ref":"vipy.visualize",
"url":14,
"doc":""
},
{
"ref":"vipy.visualize.scene_explorer",
"url":14,
"doc":"Generate a standalone scene_explorer visualization. A scene_explorer visualization is a standalone HTML file that shows a single  vipy.image.Scene object with an interactive search and visualization of all objects, attributes, captions and tags Args: im: a  vipy.image.Scene object for visualization outfile: an html output file, if None a temp file with an html extension will be used title [str]: the title of the html file previewurl [str]: A url containing an image thumbnail of what the html file contains. Useful for previewing the file contents if shared on social media keypoint_alpha [float]: the keypoint transparency in the range (0,1) popup_alpha [float]: the popup window transparency in the range (0,1) embed [bool]: If true, embed the image as base64 encoded image. If false, use the provided url in the image open_in_browser [bool]: If true, open the html file in the default browser on the current system tag_formatter [lambda]: A lambda function with a single argument equal to the input image that returns a HTML string for display in the tag popup. This can be any valid html. attribute_formatter [lambda]: A lambda function with a single argument equal to the input image that returns a HTML string for display in the attribute popup. This can be any valid html description_formatter [lambda]: A lambda function with a single argument equal to the input image that returns a HTML string for display in the description popup. This can be any valid html Returns: outfile Current support for  vipy.object.Keypoint2d only,  vipy.object.Detection are ignored",
"func":1
},
{
"ref":"vipy.visualize.hoverpixel",
"url":14,
"doc":"Generate a standalone hoverpixel visualization. A hoverpixel visualization is an HTML file that shows a montage such that each pixel in the montage is a video or image. When the user hovers the mouse over a pixel in the montage, a high resolution magnified popup for the corresponding video or image is displayed. This is a way to visualize and explore large datasets, showing the entire dataset in a glance, but allowing the user to zoom into specific sections. Each of the magnified media elements must be publicly accessible as a URL. If the URL is a webp animation, then the magnified media will show the animation (if the browser supports it). Args: urls: a list of urls to publicly accessible images or webp files. These are the URLs that are used to display inside the magnified popup. outfile: an html output file, if None a temp file will be used pixelsize [int]: the square size of the elements in the montage aspectratio [float]: The ratio of columns/rows in the pixel montage. Set to 1 for square. sortby: if 'color' then sort the images rowwise by increasing hue, if None, then use provided ordering of URLs loupe: if true, then the magnifier should be a circle hoversize: the diameter of the magnifier ultext: string to include overlay on the upper left. include  tags for line breaks in string, and standard html text string escaping (e.g. &lt, &gt for  ). if None, nothing is displayed display: if true, then open the html file in the defult browser when done ultextcolor: an html color string (e.g. \"white\", \"black\") for the upper left text color ultextsize: an html font-size string (e.g. \"large\", \"x-large\") for the upper left text ultextoffset [tuple): An offset in (x=pixels, y=pixels) of the origin of the upper left text Returns: A standalone html file that renders each url in montage such that hovering over elements in the montage will show the url in a magnifier.  note - Use fullscreen browsing for best experience. - Try to zoom out in your browser to see the full montage. - Wrap this HTML output file in an iframe for integration into your website:   ",
"func":1
},
{
"ref":"vipy.visualize.hoverpixel_selector",
"url":14,
"doc":"Create a dropdown selector of hoverpixel visualizations by legend. Args: htmllist: a list of HTML files output from  vipy.visualize.hoverpixel which have been created with a specific ordering legendlist: a list of strings describing how the hoverpixel was sorted (e.g. Color, Category, Size, Region) offset (x,y): A tuple of integers (x=right,y=down) for the absolute position in pixel units of the dropdown menu relative to the upper left of the page. fullscreen [bool]: If true, include an expand button next to the selector to put the hoverpixel iframe into fullscreen mode. Be sure to add allowfullscreen to the iframe. Returns: An HTML file that loads the hoverpixel HTML in an iframe with an overlaid dropdown menu to select which hoverpixel animation is displayed  note The fullscreen display will not work on iPhone since it is unsupported.",
"func":1
},
{
"ref":"vipy.visualize.mosaic",
"url":14,
"doc":"Create a mosaic iterator from an iterable of videos. A mosaic is a tiling of videos into a grid such that each grid element is one video. This function returns an iterator that iterates frames in the video mosaic. This mosaic generation can also be performed using ffmpeg, but here we use python iterators to zip a set of videos into a spatial mosaic. >>> for im in vipy.visualize.mosaic( (vipy.video.RandomScene(64,64,32), vipy.video.RandomScene(64,64,32 ) >>> im.show() Args: videos [iterable of  vipy.video.Video ] Returns: A generator which yields frames of the mosaic. All videos are at their native frame rates, and all videos are anisotropically resized to the (height, width) of the first video  note This is the streaming version of  vipy.visualize.videomontage which requires all videos to be loadable .",
"func":1
},
{
"ref":"vipy.visualize.videomosaic",
"url":14,
"doc":"Return a mosaic video from an iterable of videos. A mosaic will output a video montage such that all videos are exactly the same length, without cycling. This assumes that the videos are showing the same timestamps like in a security mosaic view.  note This will generate a framewise videomontage, and large videos can result in out of memory condition.",
"func":1
},
{
"ref":"vipy.visualize.montage",
"url":14,
"doc":"Create a montage image from the of provided list of  vipy.image.Image objects. >>> vipy.visualize.montage( im.crop() for im in vipy.image.vehicles() ).show() Args: imlist: [list, tuple, vipy.dataset.Dataset] iterable of  vipy.image.Image objects which is used to montage rowwise, or a list of lists such that each element defines  vipy.image.Image objects on a grid row. imgheight: [int] The height of each individual image in the grid, defaults to 256 px imgwidth: [int] the width of each individual image in the grid, defaults to 256 px, use centersquare() for isotropic scaling gridrows: [int] The number of images per row, and number of images per column. This defines the montage shape. gridcols: [int] The number of images per row, and number of images per column. This defines the montage shape. aspectratio: [float]. This is an optional parameter which defines the shape of the montage as (gridcols/gridrows) without specifying the gridrows, gridcols input crop: [bool] If true, the vipy.image.Image objects should call crop(), which will trigger a load skip: [bool] Whether images should be skipped on failure to load(), useful for lazy downloading border: [int], (leftright, topbottom) a border of size in pixels surrounding each image in the grid, may be a tuple specifying top/bottom border and left/right border border_rgb [tuple (r,g,b)]: the border color in a rgb color tuple (r,g,b) in [0,255], uint8 do_flush: [bool] flush the loaded images as garbage collection for large montages verbose: [bool] display optional verbose messages Returns: Return a  vipy.image.Image montage which is of size (gridrows (imgheight + 2 border), gridcols (imgwidth+2 border ",
"func":1
},
{
"ref":"vipy.visualize.videomontage",
"url":14,
"doc":"Generate a video montage for the provided videos by creating a image montage for every frame. Args:  vipy.visualize.montage : See the args framerate: [float] the framerate of the montage video. All of the input videos are resampled to this common frame rate max_duration: [float] If not None, the maximum duration an element in seconds in the montage before it cycles. If None, then use the duration of the longest video Returns: An video file in outfile that shows each video tiled into a montage.   warning - This loads every video into memory, so be careful with large montages! - If max_duration is not set, then this can result in loading very long video elements in the montage, which will make for long videos",
"func":1
},
{
"ref":"vipy.visualize.urls",
"url":14,
"doc":"Given a list of public image URLs, create a stand-alone HTML page to show them all. Args: urllist: [list] A list of urls to display title: [str] The title of the html file imagewidth: [int] The size of the images in the page outfile: [str] The path to the output html file display: [bool] open the html file in the default system viewer when complete",
"func":1
},
{
"ref":"vipy.visualize.tohtml",
"url":14,
"doc":"Given a list of vipy.image.Image objects, show the images along with the dictionary contents of imdict (one per image) in a single standalone HTML file Args: imlist: [list  vipy.image.Image ] imdict: [list of dict] An optional list of dictionaries, such that each dictionary is visualized per image title: [str] The title of the html file imagewidth: [int] The size of the images in the page outfile: [str] The path to the output html file display: [bool] open the html file in the default system viewer when complete maxwidth [int]: the maximum width of the html container in pixels Returns: An html file in outfile that contains all the images as a standalone embedded file (no links or external files).",
"func":1
},
{
"ref":"vipy.visualize.videolist",
"url":14,
"doc":"Create a standalone HTML file that will visualize the set of videos in vidlist using HTML5 video player",
"func":1
},
{
"ref":"vipy.visualize.imagelist",
"url":14,
"doc":"Given a list of image filenames wth absolute paths, copy to outdir, and create an index.html file that visualizes each.",
"func":1
},
{
"ref":"vipy.visualize.imagetuplelist",
"url":14,
"doc":"Imagelist but put tuples on same row",
"func":1
},
{
"ref":"vipy.parallel",
"url":15,
"doc":""
},
{
"ref":"vipy.parallel.map",
"url":15,
"doc":"Apply the function f to each element in the iterator, returning the results unordered. Function cannot be anonymous if cf executor is multiprocess",
"func":1
},
{
"ref":"vipy.parallel.identity",
"url":15,
"doc":"",
"func":1
},
{
"ref":"vipy.parallel.iter",
"url":15,
"doc":"Return an iterator on the input generator that will apply the mapper to each object and yield only those elements where the accepter is true   with vipy.globals.parallel(8): for im in vipy.parallel.iter(vipy.dataset.registry('yfcc100m_url:train'), mapper=lambda im: im.try_download(), accepter=lambda im: im.is_downloaded( : print(im)   Most common use cases will use  vipy.dataset.Dataset.minibatch or  vipy.dataset.Dataset.__parallel_iter__ instead of using this iterator directly Args: ingen [generator]: mapper [callable]: A function applied to each element before yielding bufsize [int]: The maximum size of the parallel queue used by producers. accepter [callable]: A function which returns true or false, such that the iterator only yields elements for which the accepter returns true Returns: An iterator that yields mapped and accepted elements from ingen, whre mapping is performed in parallel by vipy.parallel.cf() executor",
"func":1
},
{
"ref":"vipy.parallel.ordered_map",
"url":15,
"doc":"Apply the function f to each element in the iterator, returning tuples (order, result) results sorted by order",
"func":1
},
{
"ref":"vipy.video",
"url":16,
"doc":""
},
{
"ref":"vipy.video.Stream",
"url":16,
"doc":"vipy.video.Stream class. This class is the primary mechanism for streaming frames and clips from long videos or live video streams. - The stream is constructed from a shared underlying video in self._video. - As the shared video is updated with annotations, the stream can generate frames and clips that contain these annotations - The shared video allows for multiple concurrent iterators all sourced from the same video, iterating over different frames, clips and rates - The iterator leverages a pipe to FFMPEG, reading numpy frames from the video filter chain. - The pipe is written from a thread which is dedicated to reading frames from ffmpeg - Each numpy frame is added to a queue, with a null termintor when end of stream is reached - The iterator then reads from the queue, and returns annotated frames This iterator can also be used as a buffered stream. Buffered streams have a primary iterator which saves a fixed stream buffer of frames so that subsequent iterators can pull temporally aligned frames. This is useful to avoid having multiple FFMPEG pipes open simultaneously, and can allow for synchronized access to live video streams without timestamping. - The primary iterator is the first iterator over the video with stream(buffered=True) - The primary iterator creates a private attribute self._video.attributes['__stream_buffer'] which caches frames - The stream buffer saves numpy arrays from the iterator with a fixed buffer length (number of frames) - The secondary iterator (e.g. any iterator that accesses the video after the primary iterator is initially created) will read from the stream buffer - All iterators share the underlying self._video object in the stream so that if the video annotations are updated by an iterator, the annotated frames are accessible in the iterators - The secondary iterators are synchronized to the stream buffer that is read by the primary iterator. This is useful for synchronizing streams for live camera streams without absolute timestamps. - There can be an unlimited number of secondary iterators, without incurring a penalty on frame access This iterator can iterate over clips, frames or batches. - A clip is a sequence of frames such that each clip is separated by a fixed number of frames. - Clips are useful for temporal encoding of short atomic activities - A batch is a sequence of n frames with a stride of n. - A batch is useful for iterating over groups of frames that are operated in parallel on a GPU   for (im1, im2, v3) in zip(v.stream(buffered=True), v.stream(buffered=True).frame(delay=30), v.stream(buffered=True).clip(n=16,m=1):  im1:  vipy.image.Scene at frame index k  im2:  vipy.image.Scene at frame index k-30  v3:  vipy.video.Scene at frame range [k, k-16]    note - This is designed to be accessed as  vipy.video.Video.stream and not accessed as a standalone class "
},
{
"ref":"vipy.video.Stream.framerate",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Stream.write",
"url":16,
"doc":"Write individual frames to write stream",
"func":1
},
{
"ref":"vipy.video.Stream.clip",
"url":16,
"doc":"Stream clips of length n such that the yielded video clip contains frame(0+delay) to frame(n+delay), and next contains frame(m+delay) to frame(n+m+delay). Usage examples:  python for vc in v.stream().clip(n=16, m=2):  yields video vc with frames [0,16] from v  then video vc with frames [2,18] from v   . finally video with frames [len(v)-n-1, len(v)-1]   Introducing a delay so that the clips start at a temporal offset from v   for vc in v.stream().clip(n=8, m=3, delay=1):  yields video vc with frames [1,9]  then video vc with frames [4,12]  .   Args: n: [int] the length of the clip in frames m: [int] the stride between clips in frames delay: [int] The temporal delay in frames for the clip, must be less than n and >= 0 continuous: [bool] if true, then yield None for the sequential frames not aligned with a stride so that a clip is yielded on every frame activities: [bool] if false, then activities from the source video are not copied into the clip tracks: [bool] if false, then tracks from the source video are not copied into the clip Returns: An iterator that yields  vipy.video.Video objects each of length n with startframe += m, starting at frame=delay, such that each video contains the tracks and activities (if requested) for this clip sourced from the shared stream video.  note This iterator runs in a thread to help speed up fetching of frames for GPU I/Oe bound operations",
"func":1
},
{
"ref":"vipy.video.Stream.batch",
"url":16,
"doc":"Stream batches of length n such that each batch contains frames [0, n-1], [n, 2n-1],  . Last batch will be ragged. The primary use case for batch() is to provide a mechanism for parallel batch processing on a GPU.   for im_gpu in myfunc(vi.stream().batch(16 ): print(im_gpu) def myfunc(gen): for vb in gen:  process the batch vb (length n) in parallel by encoding on a GPU with batchsize=n for im in f_gpu(vb): yield im_gpu:   This will then yield the GPU batched processed image im_gpu.",
"func":1
},
{
"ref":"vipy.video.Stream.frame",
"url":16,
"doc":"Stream individual frames of video with negative offset n frames to the stream head. If delay=30, this will return a frame 30 frames ago",
"func":1
},
{
"ref":"vipy.video.Video",
"url":16,
"doc":"vipy.video.Video class The vipy.video class provides a fluent, lazy interface for representing, transforming and visualizing videos. The following constructors are supported:   vid = vipy.video.Video(filename='/path/to/video.ext')   Valid video extensions are those that are supported by ffmpeg ['.avi','.mp4','.mov','.wmv','.mpg', 'mkv', 'webm'].   vid = vipy.video.Video(url='https: www.youtube.com/watch?v=MrIN959JuV8') vid = vipy.video.Video(url='http: path/to/video.ext', filename='/path/to/video.ext')   Youtube URLs are downloaded to a temporary filename, retrievable as vid.download().filename(). If the environment variable 'VIPY_CACHE' is defined, then videos are saved to this directory rather than the system temporary directory. If a filename is provided to the constructor, then that filename will be used instead of a temp or cached filename. URLs can be defined as an absolute URL to a video file, or to a site supported by 'yt-dlp' (https: github.com/yt-dlp/yt-dlp?tab=readme-ov-file installation)   vid = vipy.video.Video(url='s3: BUCKET.s3.amazonaws.com/PATH/video.ext')   If you set the environment variables VIPY_AWS_ACCESS_KEY_ID and VIPY_AWS_SECRET_ACCESS_KEY, then this will download videos directly from S3 using boto3 and store in VIPY_CACHE. Note that the URL protocol should be 's3' and not 'http' to enable keyed downloads.   vid = vipy.video.Video(array=array, colorspace='rgb')   The input 'array' is an NxHxWx3 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video Note that some video transformations are only available prior to load(), and the array() is assumed immutable after load().   frames = [im for im in vipy.video.RandomVideo()] vid = vipy.video.Video(frames=frames)   The input can be an RTSP video stream. Note that streaming is most efficiently performed using  vipy.video.Scene . The URL must contain the 'rtsp: ' url scheme. You can experiment with this using the free Periscope H.264 RTSP App (https: apps.apple.com/us/app/periscope-hd-h-264-rtsp-cam/id1095600218)   vipy.video.Scene(url='rtsp: 127.0.0.1:8554/live.sdp').show() for im in vipy.video.Scene(url='rtsp: 127.0.0.1:8554/live.sdp').stream(): print(im)   Args: filename: [str] The path to a video file. url: [str] The URL to a video file. If filename is not provided, then a random filename is assigned in VIPY_CACHE on download framerate: [float] The framerate of the video file. This is required. You can introspect this using ffprobe. attributes: [dict] A user supplied dictionary of metadata about this video. colorspace: [str] Must be in ['rgb', 'float'] array: [numpy] An NxHxWxC numpy array for N frames each HxWxC shape startframe: [int] A start frame to clip the video endframe: [int] An end frame to clip the video startsec: [float] A start time in seconds to clip the video endsec: [float] An end time in seconds to clip the video frames: [list of  vipy.image.Image ] A list of frames in the video probeshape: [bool] If true, then probe the shape of the video from ffprobe to avoid an explicit preview later. This can speed up loading in some circumstances. shape: [tuple (rows,cols)] If the shape of the video is known, then this avoids requiring preview or probe. Useful for some camera streams which may be off at init time."
},
{
"ref":"vipy.video.Video.cast",
"url":16,
"doc":"Cast a conformal video object to a  vipy.video.Video object. This is useful for downcasting superclasses.   vs = vipy.video.RandomScene() v = vipy.video.Video.cast(vs)  ",
"func":1
},
{
"ref":"vipy.video.Video.from_json",
"url":16,
"doc":"Import a json string as a  vipy.video.Video object. This will perform a round trip from a video to json and back to a video object. This same operation is used for serialization of all vipy objects to JSON for storage.   v = vipy.video.Video.from_json(vipy.video.RandomVideo().json(  ",
"func":1
},
{
"ref":"vipy.video.Video.metadata",
"url":16,
"doc":"Return a dictionary of metadata about this video. Args: k [str]: If provided, return just the specified key of the attributes dictionary, otherwise return the attributes dictionary Returns: The 'attributes' dictionary, or just the value for the provided key k if provided",
"func":1
},
{
"ref":"vipy.video.Video.sanitize",
"url":16,
"doc":"Remove all private keys from the attributes dictionary. The attributes dictionary is useful storage for arbitrary (key,value) pairs. However, this storage may contain sensitive information that should be scrubbed from the video before serialization. As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key. This is analogous to private or reserved attributes in the python lanugage. Users should reserve these keynames for those keys that should be sanitized and removed before any seerialization of this object.   assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey')  False  ",
"func":1
},
{
"ref":"vipy.video.Video.videoid",
"url":16,
"doc":"Return a unique video identifier for this video, as specified in the 'video_id' attribute Args: newid: [str] If not None, then update the video_id as newid. Returns: The video ID if newid=None else self",
"func":1
},
{
"ref":"vipy.video.Video.frame",
"url":16,
"doc":"Return the kth frame as an  vipy.image Image object",
"func":1
},
{
"ref":"vipy.video.Video.store",
"url":16,
"doc":"Store the current video file as an attribute of this object. Useful for archiving an object to be fully self contained without any external references.   v  v.store().restore(v.filename(    note -Remove this stored video using unstore() -Unpack this stored video and set up the video chains using restore() -This method is more efficient than load() followed by pkl(), as it stores the encoded video as a byte string. -Useful for creating a single self contained object for distributed processing.",
"func":1
},
{
"ref":"vipy.video.Video.unstore",
"url":16,
"doc":"Delete the currently stored video from  vipy.video.Video.store",
"func":1
},
{
"ref":"vipy.video.Video.restore",
"url":16,
"doc":"Save the currently stored video as set using  vipy.video.Video.store to filename, and set up filename",
"func":1
},
{
"ref":"vipy.video.Video.concatenate",
"url":16,
"doc":"Temporally concatenate a sequence of videos into a single video stored in outfile.   (v1, v2, v3) = (vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32 vc = vipy.video.Video.concatenate v1, v2, v3), 'concatenated.mp4', youtube_chapters=lambda v: v.category(   In this example, vc will point to concatenated.mp4 which will contain (v1,v2,v3) concatenated temporally . Args: videos: a single video or an iterable of videos of type  vipy.video.Video or an iterable of video files outfile: the output filename to store the concatenation. youtube_chapters: [bool, callable]: If true, output a string that can be used to define the start and end times of chapters if this video is uploaded to youtube. The string output should be copied to the youtube video description in order to enable chapters on playback. This argument will default to the string representation ofo the video, but you may also pass a callable of the form: 'youtube_chapters=lambda v: str(v)' which will output the provided string for each video chapter. A useful lambda is 'youtube_chapters=lambda v: v.category()' framerate: [float]: The output frame rate of outfile Returns: A  vipy.video.Video object with filename()=outfile, such that outfile contains the temporal concatenation of pixels in (self, videos).  note - self will not be modified, this will return a new  vipy.video.Video object. - All videos must be the same shape(). If the videos are different shapes, you must pad them to a common size equal to self.shape(). Try  vipy.video.Video.zeropadlike . - The output video will be at the framerate of self.framerate(). - if you want to concatenate annotations, call  vipy.video.Scene.annotate first on the videos to save the annotations into the pixels, then concatenate.",
"func":1
},
{
"ref":"vipy.video.Video.stream",
"url":16,
"doc":"Iterator to yield groups of frames streaming from video. A video stream is a real time iterator to read or write from a video. Streams are useful to group together frames into clips that are operated on as a group. The following use cases are supported:   v = vipy.video.RandomScene()   Stream individual video frames lagged by 10 frames and 20 frames   for (im1, im2) in zip(v.stream().frame(n=-10), v.stream().frame(n=-20 : print(im1, im2)   Stream overlapping clips such that each clip is a video n=16 frames long and starts at frame i, and the next clip is n=16 frames long and starts at frame i=i+m   for vc in v.stream().clip(n=16, m=4): print(vc)   Stream non-overlapping batches of frames such that each clip is a video of length n and starts at frame i, and the next clip is length n and starts at frame i+n   for vb in v.stream().batch(n=16): print(vb)   Create a write stream to incrementally add frames to long video.   vi = vipy.video.Video(filename='/path/to/output.mp4') vo = vipy.video.Video(filename='/path/to/input.mp4') with vo.stream(write=True) as s: for im in vi.stream(): s.write(im)  manipulate pixels of im, if desired   Create a 480p YouTube live stream from an RTSP camera at 5Hz   vo = vipy.video.Scene(url='rtmp: a.rtmp.youtube.com/live2/$SECRET_STREAM_KEY') vi = vipy.video.Scene(url='rtsp: URL').framerate(5) with vo.framerate(5).stream(write=True, bitrate='1000k') as s: for im in vi.framerate(5).resize(cols=854, rows=480): s.write(im)   Args: write: [bool] If true, create a write stream overwrite: [bool] If true, and the video output filename already exists, overwrite it bufsize: [int] The maximum queue size for the ffmpeg pipe thread in the primary iterator. The queue size is the maximum size of pre-fetched frames from the ffmpeg pip. This should be big enough that you are never waiting for queue fills bitrate: [str] The ffmpeg bitrate of the output encoder for writing, written like '2000k' bufsize: [int] The maximum size of the stream buffer in frames. The stream buffer length should be big enough so that all iterators can yield before deleting old frames Returns: A Stream object  note Using this iterator may affect PDB debugging due to stdout/stdin redirection. Use ipdb instead.",
"func":1
},
{
"ref":"vipy.video.Video.clear",
"url":16,
"doc":"no-op for  vipy.video.Video object, used only for  vipy.video.Scene ",
"func":1
},
{
"ref":"vipy.video.Video.bytes",
"url":16,
"doc":"Return a bytes representation of the video file",
"func":1
},
{
"ref":"vipy.video.Video.frames",
"url":16,
"doc":"Alias for __iter__()",
"func":1
},
{
"ref":"vipy.video.Video.framelist",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.commandline",
"url":16,
"doc":"Return the equivalent ffmpeg command line string that will be used to transcode the video. This is useful for introspecting the complex filter chain that will be used to process the video. You can try to run this command line yourself for debugging purposes, by replacing 'dummyfile' with an appropriately named output file.",
"func":1
},
{
"ref":"vipy.video.Video.probeshape",
"url":16,
"doc":"Return the (height, width) of underlying video file as determined from ffprobe  warning this does not take into account any applied ffmpeg filters. The shape will be the (height, width) of the underlying video file.",
"func":1
},
{
"ref":"vipy.video.Video.duration_in_seconds_of_videofile",
"url":16,
"doc":"Return video duration of the source filename (NOT the filter chain) in seconds, requires ffprobe. Fetch once and cache.  notes This is the duration of the source video and NOT the duration of the filter chain. If you load(), this may be different duration depending on clip() or framerate() directives.",
"func":1
},
{
"ref":"vipy.video.Video.duration_in_frames_of_videofile",
"url":16,
"doc":"Return video duration of the source video file (NOT the filter chain) in frames, requires ffprobe.  notes This is the duration of the source video and NOT the duration of the filter chain. If you load(), this may be different duration depending on clip() or framerate() directives.",
"func":1
},
{
"ref":"vipy.video.Video.duration",
"url":16,
"doc":"Return a video clipped with frame indexes between (0, frames) or (0,seconds self.framerate( or (0,minutes 60 self.framerate(). Return duration in seconds if no arguments are provided.",
"func":1
},
{
"ref":"vipy.video.Video.duration_in_frames",
"url":16,
"doc":"Return the duration of the video filter chain in frames, equal to round(self.duration() self.framerate( . Requires a probe() of the video to get duration",
"func":1
},
{
"ref":"vipy.video.Video.framerate_of_videofile",
"url":16,
"doc":"Return video framerate in frames per second of the source video file (NOT the filter chain), requires ffprobe.",
"func":1
},
{
"ref":"vipy.video.Video.resolution_of_videofile",
"url":16,
"doc":"Return video resolution in (height, width) in pixels (NOT the filter chain), requires ffprobe.",
"func":1
},
{
"ref":"vipy.video.Video.probe",
"url":16,
"doc":"Run ffprobe on the filename and return the result as a dictionary Args: Any keyword arguments supported by python-ffmpeg probe() - these are passed in as-is - for flags, use flag_name=None (e.g., show_frames=None) so that ffmpeg.probe() handles them correctly",
"func":1
},
{
"ref":"vipy.video.Video.frame_meta",
"url":16,
"doc":"Return the frame metadata of the underlying video file using ffprobe for all frames as a list of dicts, each list element corresponding to a frame. This is useful for extracting frame types (e.g. i-frames). Args: k [int]: Return only the frame metadata for frame index k (relative to framerate of source videofile, not filter chain) Returns: a list of metadata dicts (one per frame) or a single dict for the requested frame.  notes - This will return a large amount of metadata for the entire source video (not the FFMPEG filter chain), use with caution. - To get frame metata for a filter chain use vipy.video.Video.savetemp().frame_meta(), which will save the video to a temporary file prior to extracting frame metadata",
"func":1
},
{
"ref":"vipy.video.Video.metaframe",
"url":16,
"doc":"Alias for  vipy.video.Video.frame_meta ",
"func":1
},
{
"ref":"vipy.video.Video.iframes",
"url":16,
"doc":"Return a list of i-frame indexes (e.g. intra-frame, a video frame that is independent from other frames for decoding) in this video file.  note - To return the i-frame indexes for the current filter chain use self.saveas().iframes() to save to a temporary file prior to i-frame index extraction. - To extract the i-frame itself, use [self.frame(k) for k in self.iframes()]",
"func":1
},
{
"ref":"vipy.video.Video.print",
"url":16,
"doc":"Print the representation of the video This is useful for debugging in long fluent chains. Sleep is useful for adding in a delay for distributed processing. Args: prefix: prepend a string prefix to the video __repr__ when printing. Useful for logging. sleep: Integer number of seconds to sleep[ before returning Returns: The video object after sleeping",
"func":1
},
{
"ref":"vipy.video.Video.printif",
"url":16,
"doc":"Call  vipy.video.Video.print if b=True. Useful for fluent chains to print periodically.",
"func":1
},
{
"ref":"vipy.video.Video.dict",
"url":16,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding.",
"func":1
},
{
"ref":"vipy.video.Video.json",
"url":16,
"doc":"Return a json representation of the video. Args: encode: If true, return a JSON encoded string using json.dumps Returns: A JSON encoded string if encode=True, else returns a dictionary object  note If the video is loaded, then the JSON will not include the pixels. Try using  vipy.video.Video.store to serialize videos, or call  vipy.video.Video.flush first.",
"func":1
},
{
"ref":"vipy.video.Video.take",
"url":16,
"doc":"Return n frames from the clip uniformly spaced as numpy array Args: n: Integer number of uniformly spaced frames to return Returns: A numpy array of shape (n,W,H)  warning This assumes that the entire video is loaded into memory (e.g. call  vipy.video.Video.load ). Use with caution.",
"func":1
},
{
"ref":"vipy.video.Video.framerate",
"url":16,
"doc":"Change the input framerate for the video and update frame indexes for all annotations Args: fps: [Float] frames per second to process the underlying video round ['up','down','near'] the rounding option for the ffmpeg fps filter Returns: If fps is None, return the current framerate, otherwise set the framerate to fps",
"func":1
},
{
"ref":"vipy.video.Video.colorspace",
"url":16,
"doc":"Return or set the colorspace as ['rgb', 'bgr', 'lum', 'float']. This will not change pixels, only the colorspace interpretation of pixels.",
"func":1
},
{
"ref":"vipy.video.Video.nourl",
"url":16,
"doc":"Remove the  vipy.video.Video.url from the video",
"func":1
},
{
"ref":"vipy.video.Video.url",
"url":16,
"doc":"Video URL and URL download properties",
"func":1
},
{
"ref":"vipy.video.Video.isloaded",
"url":16,
"doc":"Return True if the video has been loaded",
"func":1
},
{
"ref":"vipy.video.Video.is_loaded",
"url":16,
"doc":"Return True if the video has been loaded",
"func":1
},
{
"ref":"vipy.video.Video.isloadable",
"url":16,
"doc":"Return True if the video can be loaded successfully. This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version. Args: flush: [bool] If true, flush the video after it loads. This will clear the video pixel buffer Returns: True if load() can be called without FFMPEG exception. If flush=False, then self will contain the loaded video, which is helpful to avoid load() twice in some conditions  warning This requires loading and flushing the video. This is an expensive operation when performed on many videos and may result in out of memory conditions with long videos. Use with caution! Try  vipy.video.Video.canload to test if a single frame can be loaded as a less expensive alternative.",
"func":1
},
{
"ref":"vipy.video.Video.canload",
"url":16,
"doc":"Return True if the video can be previewed at frame=k successfully. This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.  notes This will only try to preview a single frame. This will not check if the entire video is loadable. Use  vipy.video.Video.isloadable in this case This will hang if calling canload on a streaming URL.",
"func":1
},
{
"ref":"vipy.video.Video.iscolor",
"url":16,
"doc":"Is the video a three channel color video as returned from  vipy.video.Video.channels ?",
"func":1
},
{
"ref":"vipy.video.Video.isstreaming",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.isgrayscale",
"url":16,
"doc":"Is the video a single channel as returned from  vipy.video.Video.channels ?",
"func":1
},
{
"ref":"vipy.video.Video.hasfilename",
"url":16,
"doc":"Does the filename returned from  vipy.video.Video.filename exist?",
"func":1
},
{
"ref":"vipy.video.Video.isdownloaded",
"url":16,
"doc":"Alias for  vipy.video.Video.is_downloaded ",
"func":1
},
{
"ref":"vipy.video.Video.is_downloaded",
"url":16,
"doc":"Does the filename returned from  vipy.video.Video.filename exist, meaning that the url has been downloaded to a local file?",
"func":1
},
{
"ref":"vipy.video.Video.hasurl",
"url":16,
"doc":"Is the url returned from  vipy.video.Video.url a well formed url?",
"func":1
},
{
"ref":"vipy.video.Video.islive",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.array",
"url":16,
"doc":"Set or return the video buffer as a numpy array. Args: array: [np.array] A numpy array of size NxHxWxC = (frames, height, width, channels) of type uint8 or float32. array: [list] A list of  vipy.image.Image objects copy: [bool] If true, copy the buffer by value instaed of by reference. Copied buffers do not share pixels. Returns: if array=None, return a reference to the pixel buffer as a numpy array, otherwise return the video object with the array populated",
"func":1
},
{
"ref":"vipy.video.Video.from_array",
"url":16,
"doc":"Create a new video from a shared array, Equivalent to self.array( ., copy=False)",
"func":1
},
{
"ref":"vipy.video.Video.from_directory",
"url":16,
"doc":"Create a video from a directory of frames stored as individual image filenames. Given a directory with files: framedir/image_0001.jpg framedir/image_0002.jpg   vipy.video.Video(frames='/path/to/framedir')  ",
"func":1
},
{
"ref":"vipy.video.Video.from_frames",
"url":16,
"doc":"Create a video from a list of frames",
"func":1
},
{
"ref":"vipy.video.Video.from_annotation_sequence",
"url":16,
"doc":"Construct a video from an input image im where each frame is the acculation of annnotated objects in im. This is useful for visualization of a labeling sequence",
"func":1
},
{
"ref":"vipy.video.Video.to_numpy",
"url":16,
"doc":"Alias for numpy()",
"func":1
},
{
"ref":"vipy.video.Video.mutable",
"url":16,
"doc":"Return a video object with a writeable mutable frame array. Video must be loaded, triggers copy of underlying numpy array if the buffer is not writeable. Returns: This object with a mutable frame buffer in self.array() or self.numpy()",
"func":1
},
{
"ref":"vipy.video.Video.numpy",
"url":16,
"doc":"Convert the video to a writeable numpy array, triggers a load() and copy() as needed. Returns the numpy array.",
"func":1
},
{
"ref":"vipy.video.Video.zeros",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.reload",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.nofilename",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.filename",
"url":16,
"doc":"Update video Filename with optional copy or symlink from existing file (self.filename( to new file",
"func":1
},
{
"ref":"vipy.video.Video.abspath",
"url":16,
"doc":"Change the path of the filename from a relative path to an absolute path (not relocatable)",
"func":1
},
{
"ref":"vipy.video.Video.relpath",
"url":16,
"doc":"Replace the filename with a relative path to parent (or current working directory if none). Usage:   v = vipy.video.Video(filename='/path/to/dataset/video/category/out.mp4') v.relpath(parent='/path/to/dataset') v.filename()  'video/category/out.mp4'   If the current working directory is /path/to/dataset, and v.load() is called, the filename will be loaded. Args: parent [str]: A parent path of the current filename to remove and be relative to. If filename is '/path/to/video.mp4' then filename must start with parent, then parent will be remvoed from filename. start [str]: Return a relative filename starting from path start='/path/to/dir' that will create a relative path to this filename. If start='/a/b/c' and filename='/a/b/d/e/f.ext' then return filename ' /d/e/f.ext' Returns: This video object with the filename changed to be a relative path",
"func":1
},
{
"ref":"vipy.video.Video.rename",
"url":16,
"doc":"Move the underlying video file preserving the absolute path, such that self.filename()  '/a/b/c.ext' and newname='d.ext', then self.filename() -> '/a/b/d.ext', and move the corresponding file",
"func":1
},
{
"ref":"vipy.video.Video.filesize",
"url":16,
"doc":"Return the size in bytes of the filename(), None if the filename() is invalid",
"func":1
},
{
"ref":"vipy.video.Video.downloadif",
"url":16,
"doc":"Download URL to filename if the filename has not already been downloaded",
"func":1
},
{
"ref":"vipy.video.Video.download",
"url":16,
"doc":"Download URL to filename provided by constructor, or to temp filename. Args: timeout: [int] An integer timeout in seconds for the download to connect verbose: [bool] If trye, show more verbose console output max_filesize: [str] A string of the form 'NNNg' or 'NNNm' for youtube downloads to limit the maximum size of a URL to '350m' 350MB or '12g' for 12GB. Returns: This video object with the video downloaded to the filename()",
"func":1
},
{
"ref":"vipy.video.Video.fetch",
"url":16,
"doc":"Download only if hasfilename() is not found",
"func":1
},
{
"ref":"vipy.video.Video.shape",
"url":16,
"doc":"Return (height, width) of the frames, requires loading a preview frame from the video if the video is not already loaded, or providing the shape=(height,width) by the user",
"func":1
},
{
"ref":"vipy.video.Video.channelshape",
"url":16,
"doc":"Return a tuple (channels, height, width) for the video",
"func":1
},
{
"ref":"vipy.video.Video.issquare",
"url":16,
"doc":"Return true if the video has square dimensions (height  width), else false",
"func":1
},
{
"ref":"vipy.video.Video.channels",
"url":16,
"doc":"Return integer number of color channels",
"func":1
},
{
"ref":"vipy.video.Video.width",
"url":16,
"doc":"Width (cols) in pixels of the video for the current filter chain",
"func":1
},
{
"ref":"vipy.video.Video.height",
"url":16,
"doc":"Height (rows) in pixels of the video for the current filter chain",
"func":1
},
{
"ref":"vipy.video.Video.aspect_ratio",
"url":16,
"doc":"The width/height of the video expressed as a fraction",
"func":1
},
{
"ref":"vipy.video.Video.preview",
"url":16,
"doc":"Return selected frame of filtered video, return vipy.image.Image object. This is useful for previewing the frame shape of a complex filter chain or the frame contents at a particular location without loading the whole video",
"func":1
},
{
"ref":"vipy.video.Video.thumbnail",
"url":16,
"doc":"Return annotated frame=k of video, save annotation visualization to provided outfile. This is functionally equivalent to  vipy.video.Video.frame with an additional outfile argument to easily save an annotated thumbnail image. Args: outfile: [str] an optional outfile to save the annotated frame frame: [int >= 0] The frame to output the thumbnail Returns: A  vipy.image.Image object for frame k.",
"func":1
},
{
"ref":"vipy.video.Video.load",
"url":16,
"doc":"Load a video using ffmpeg, applying the requested filter chain. Args: verbose: [bool] if True. then ffmpeg console output will be displayed. shape: [tuple (height, width, channels)] If provided, use this shape for reading and reshaping the byte stream from ffmpeg. This is useful for efficient loading in some scenarios. Knowing the final output shape can speed up loads by avoiding a preview() of the filter chain to get the frame size Returns: this video object, with the pixels loaded in self.array()  warning Loading long videos can result in out of memory conditions. Try to call clip() first to extract a video segment to load().",
"func":1
},
{
"ref":"vipy.video.Video.speed",
"url":16,
"doc":"Change the speed by a multiplier s. If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)",
"func":1
},
{
"ref":"vipy.video.Video.clip",
"url":16,
"doc":"Clip the video to between (start, end). This clip is relative to clip() shown by __repr__(). Args: start: [int|float] the start frame|second relative to the video framerate() for the clip end: [int|float] the end frame|second relative to the video framerate for the clip, may be none Returns: This video object, clipped so that a load() will result in frame=0 equivalent to startframe.  note: - This does not load the video. This updates the ffmpeg filter chain to temporally trim the video. See self.commandline() for the updated filter chain to run.",
"func":1
},
{
"ref":"vipy.video.Video.cliprange",
"url":16,
"doc":"Return the planned clip (startframe, endframe) range. This is useful for introspection of the planned clip() before load(), such as for data augmentation purposes without triggering a load. Returns: (startframe, endframe) of the video() such that after load(), the pixel buffer will contain frame=0 equivalent to startframe in the source video, and frame=endframe-startframe-1 equivalent to endframe in the source video. (0, None) If a video does not have a clip() (e.g. clip() was never called, the filter chain does not include a 'trim')  notes The endframe can be retrieved (inefficiently) using:   int(round(self.duration_in_frames_of_videofile()  (self.framerate() / self.framerate_of_videofile(   ",
"func":1
},
{
"ref":"vipy.video.Video.rot90cw",
"url":16,
"doc":"Rotate the video 90 degrees clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.Video.rot90ccw",
"url":16,
"doc":"Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.Video.fliplr",
"url":16,
"doc":"Mirror the video left/right by flipping horizontally",
"func":1
},
{
"ref":"vipy.video.Video.flipud",
"url":16,
"doc":"Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.Video.rescale",
"url":16,
"doc":"Rescale the video by factor s, such that the new dimensions are (s H, s W), can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.Video.resize",
"url":16,
"doc":"Resize the video to be (rows=height, cols=width)",
"func":1
},
{
"ref":"vipy.video.Video.mindim",
"url":16,
"doc":"Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio, return the minimum dimension if dim=None",
"func":1
},
{
"ref":"vipy.video.Video.set_mindim",
"url":16,
"doc":"Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio, do nothing if dim=None",
"func":1
},
{
"ref":"vipy.video.Video.maxdim",
"url":16,
"doc":"Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio",
"func":1
},
{
"ref":"vipy.video.Video.randomcrop",
"url":16,
"doc":"Crop the video to shape=(H,W) with random position such that the crop contains only valid pixels, and optionally return the box",
"func":1
},
{
"ref":"vipy.video.Video.centercrop",
"url":16,
"doc":"Crop the video to shape=(H,W) preserving the integer centroid position, and optionally return the box",
"func":1
},
{
"ref":"vipy.video.Video.centersquare",
"url":16,
"doc":"Crop video of size (NxN) in the center, such that N=min(width,height), keeping the video centroid constant",
"func":1
},
{
"ref":"vipy.video.Video.cropeven",
"url":16,
"doc":"Crop the video to the largest even (width,height) less than or equal to current (width,height). This is useful for some codecs or filters which require even shape.",
"func":1
},
{
"ref":"vipy.video.Video.maxsquare",
"url":16,
"doc":"Pad the video to be square, preserving the upper left corner of the video",
"func":1
},
{
"ref":"vipy.video.Video.minsquare",
"url":16,
"doc":"Return a square crop of the video, preserving the upper left corner of the video",
"func":1
},
{
"ref":"vipy.video.Video.maxmatte",
"url":16,
"doc":"Return a square video with dimensions (self.maxdim(), self.maxdim( with zeropadded lack bars or mattes above or below the video forming a letterboxed video.",
"func":1
},
{
"ref":"vipy.video.Video.zeropad",
"url":16,
"doc":"Zero pad the video with padwidth columns before and after, and padheight rows before and after  notes Older FFMPEG implementations can throw the error \"Input area  : : : not within the padded area  : : : or zero-sized, this is often caused by odd sized padding. Recommend calling self.cropeven().zeropad( .) to avoid this",
"func":1
},
{
"ref":"vipy.video.Video.pad",
"url":16,
"doc":"Alias for zeropad",
"func":1
},
{
"ref":"vipy.video.Video.zeropadlike",
"url":16,
"doc":"Zero pad the video balancing the border so that the resulting video size is (width, height).",
"func":1
},
{
"ref":"vipy.video.Video.crop",
"url":16,
"doc":"Spatially crop the video using the supplied vipy.geometry.BoundingBox, can only be applied prior to load().  note Crop is performed in place overwriting pixels of self.array(). Clone() before crop() if array() must be preserved.",
"func":1
},
{
"ref":"vipy.video.Video.pkl",
"url":16,
"doc":"save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.video.Video.pklif",
"url":16,
"doc":"Save the object to the provided pickle file only if b=True. Uuseful for conditional intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.video.Video.webp",
"url":16,
"doc":"Save a video to an animated WEBP file, with pause=N seconds on the last frame between loops. Args: strict: If true, assert that the filename must have an .webp extension pause: Integer seconds to pause between loops of the animation smallest: if true, create the smallest possible file but takes much longer to run smaller: If true, create a smaller file, which takes a little longer to run framerate [float]: The output framerate of the webp file. The default is the framerate of the video. Returns: The filename of the webp file for this video  warning This may be slow for very long or large videos",
"func":1
},
{
"ref":"vipy.video.Video.gif",
"url":16,
"doc":"Save a video to an animated GIF file, with pause=N seconds between loops. Args: pause: Integer seconds to pause between loops of the animation smallest: If true, create the smallest possible file but takes much longer to run smaller: if trye, create a smaller file, which takes a little longer to run framerate [float]: The output framerate of the webp file. The default is the framerate of the video. Returns: The filename of the animated GIF of this video  warning This will be very large for big videos, consider using  vipy.video.Video.webp instead.",
"func":1
},
{
"ref":"vipy.video.Video.save",
"url":16,
"doc":"Save video to new output video file. This function does not draw boxes, it saves pixels to a new video file. Args: outfile: the absolute path to the output video file. This extension can be .mp4 (for video) or [\".webp\",\".gif\"] (for animated image) flush: If true, then flush the buffer for this object right after saving the new video. This is useful for transcoding in parallel framerate: input framerate of the frames in the buffer, or the output framerate of the transcoded video. If not provided, use framerate of source video pause: an integer in seconds to pause between loops of animated images if the outfile is webp or animated gif Returns: a new video object with this video filename, and a clean video filter chain  note - If self.array() is loaded, then export the contents of self._array to the video file - If self.array() is not loaded, and there exists a valid video file, apply the filter chain directly to the input video - If outfile None or outfile self.filename(), then overwrite the current filename",
"func":1
},
{
"ref":"vipy.video.Video.saveas",
"url":16,
"doc":"Call  vipy.video.Video.saveas using a new temporary video file, and return the video object with this new filename",
"func":1
},
{
"ref":"vipy.video.Video.savetmp",
"url":16,
"doc":"Call  vipy.video.Video.saveas using a new temporary video file, and return the video object with this new filename",
"func":1
},
{
"ref":"vipy.video.Video.ffplay",
"url":16,
"doc":"Play the video file using ffplay",
"func":1
},
{
"ref":"vipy.video.Video.play",
"url":16,
"doc":"Play the saved video filename in self.filename() If there is no filename, try to download it. If the filter chain is dirty or the pixels are loaded, dump to temp video file first then play it. This uses 'ffplay' on the PATH if available, otherwise uses a fallback player by showing a sequence of matplotlib frames. If the output of the ffmpeg filter chain has modified this video, then this will be saved to a temporary video file. To play the original video (indepenedent of the filter chain of this video), use  vipy.video.Video.ffplay . Args: verbose: If true, show more verbose output notebook: If true, play in a jupyter notebook ffplay: If true, use ffplay to display the video (if available) Returns: The unmodified video object",
"func":1
},
{
"ref":"vipy.video.Video.show",
"url":16,
"doc":"Alias for play",
"func":1
},
{
"ref":"vipy.video.Video.quicklook",
"url":16,
"doc":"Generate a montage of n uniformly spaced frames. Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame. Input: n: Number of images in the quicklook mindim: The minimum dimension of each of the elements in the montage animate: If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames dt: The number of frames for animation startframe: The initial frame index to start the n uniformly sampled frames for the quicklook thumbnail [ vipy.image.Image ]: If provided, prepent the first element in the montage with this thumbnail. This is useful for showing a high resolution image (e.g. a face, small object) to be contained in the video for review. aspectratio [float]: the ratio of gridcols/gridrows in vipy.visualize.montage  note The first frame in the upper left is guaranteed to be the start frame of the labeled activity, but the last frame in the bottom right may not be precisely the end frame and may be off by at most len(video)/9.",
"func":1
},
{
"ref":"vipy.video.Video.torch",
"url":16,
"doc":"Convert the loaded video of shape NxHxWxC frames to an MxCxHxW torch tensor/ Args: startframe: [int >= 0] The start frame of the loaded video to use for constructig the torch tensor endframe: [int >= 0] The end frame of the loaded video to use for constructing the torch tensor length: [int >= 0] The length of the torch tensor if endframe is not provided. stride: [int >= 1] The temporal stride in frames. This is the number of frames to skip. take: [int >= 0] The number of uniformly spaced frames to include in the tensor. boundary: ['repeat', 'cyclic'] The boundary handling for when the requested tensor slice goes beyond the end of the video order: ['nchw', 'nhwc', 'chwn', 'cnhw'] The axis ordering of the returned torch tensor N=number of frames (batchsize), C=channels, H=height, W=width verbose [bool]: Print out the slice used for contructing tensor withslice: [bool] Return a tuple (tensor, slice) that includes the slice used to construct the tensor. Useful for data provenance. scale: [float] An optional scale factor to apply to the tensor. Useful for converting [0,255] -> [0,1] withlabel: [bool] Return a tuple (tensor, labels) that includes the N framewise activity labels. nonelabel: [bool] returns tuple (t, None) if withlabel=False Returns Returns torch float tensor, analogous to torchvision.transforms.ToTensor() Return (tensor, slice) if withslice=True (withslice takes precedence) Returns (tensor, labellist) if withlabel=True  notes - This triggers a load() of the video - The precedence of arguments is (startframe, endframe) or (startframe, startframe+length), then stride and take. - Follows numpy slicing rules. Optionally return the slice used if withslice=True",
"func":1
},
{
"ref":"vipy.video.Video.clone",
"url":16,
"doc":"Create deep copy of video object, flushing the original buffer if requested and returning the cloned object. Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned object which can be used for encoding and will be garbage collected. Args: flushforward: copy the object, and set the cloned object  vipy.video.Video.array to None. This flushes the video buffer for the clone, not the object flushbackward: copy the object, and set the object array() to None. This flushes the video buffer for the object, not the clone. flush: set the object array() to None and clone the object. This flushes the video buffer for both the clone and the object. flushfilter: Set the ffmpeg filter chain to the default in the new object, useful for saving new videos flushfile: Remove the filename and the URL from the video object. Useful for creating new video objects from loaded pixels. rekey: Generate new unique track ID and activity ID keys for this scene shallow: shallow copy everything (copy by reference), except for ffmpeg object. attributes dictionary is shallow copied sharedarray: deep copy of everything, except for pixel buffer which is shared. Changing the pixel buffer on self is reflected in the clone. sanitize: remove private attributes from self.attributes dictionary. A private attribute is any key with two leading underscores '__' which should not be propagated to clone Returns: A deepcopy of the video object such that changes to self are not reflected in the copy  note Cloning videos is an expensive operation and can slow down real time code. Use sparingly.",
"func":1
},
{
"ref":"vipy.video.Video.flush",
"url":16,
"doc":"Alias for clone(flush=True), returns self not clone",
"func":1
},
{
"ref":"vipy.video.Video.unload",
"url":16,
"doc":"Remove cached file and loaded array. Note that this will delete the underlying file returned by filename() if there is a backing url, cleaning up cached files and forcing re-download",
"func":1
},
{
"ref":"vipy.video.Video.uncache",
"url":16,
"doc":"Alias for  vipy.image.Image.unload ",
"func":1
},
{
"ref":"vipy.video.Video.returns",
"url":16,
"doc":"Return the provided value, useful for terminating long fluent chains without returning self",
"func":1
},
{
"ref":"vipy.video.Video.flush_and_return",
"url":16,
"doc":"Flush the video and return the parameter supplied, useful for long fluent chains",
"func":1
},
{
"ref":"vipy.video.Video.map",
"url":16,
"doc":"Apply lambda function to the loaded numpy array img, changes pixels not shape Lambda function must have the following signature:  newimg = func(img)  img: HxWxC numpy array for a single frame of video  newimg: HxWxC modified numpy array for this frame. Change only the pixels, not the shape The lambda function will be applied to every frame in the video in frame index order.",
"func":1
},
{
"ref":"vipy.video.Video.gain",
"url":16,
"doc":"Pixelwise multiplicative gain, such that each pixel p_{ij} = g  p_{ij}",
"func":1
},
{
"ref":"vipy.video.Video.bias",
"url":16,
"doc":"Pixelwise additive bias, such that each pixel p_{ij} = b + p_{ij}",
"func":1
},
{
"ref":"vipy.video.Video.float",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.channel",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.normalize",
"url":16,
"doc":"Pixelwise whitening, out =  scale in) - mean) / std); triggers load(). All computations float32",
"func":1
},
{
"ref":"vipy.video.Video.set_attribute",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.hasattribute",
"url":16,
"doc":"Does the attributes dictionary (self.attributes) contain the provided key",
"func":1
},
{
"ref":"vipy.video.Video.delattribute",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Video.clearattributes",
"url":16,
"doc":"Remove all attributes",
"func":1
},
{
"ref":"vipy.video.Video.clear_attributes",
"url":16,
"doc":"Remove all attributes",
"func":1
},
{
"ref":"vipy.video.Video.get_attribute",
"url":16,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.video.Video.attributes",
"url":16,
"doc":""
},
{
"ref":"vipy.video.VideoCategory",
"url":16,
"doc":"vipy.video.VideoCategory class A VideoCategory is a video with associated category, such as an activity class. This class includes all of the constructors of vipy.video.Video along with the ability to extract a clip based on frames or seconds."
},
{
"ref":"vipy.video.VideoCategory.from_json",
"url":16,
"doc":"Import a json string as a  vipy.video.Video object. This will perform a round trip from a video to json and back to a video object. This same operation is used for serialization of all vipy objects to JSON for storage.   v = vipy.video.Video.from_json(vipy.video.RandomVideo().json(  ",
"func":1
},
{
"ref":"vipy.video.VideoCategory.category",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.VideoCategory.new_category",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.VideoCategory.attributes",
"url":16,
"doc":""
},
{
"ref":"vipy.video.VideoCategory.cast",
"url":16,
"doc":"Cast a conformal video object to a  vipy.video.Video object. This is useful for downcasting superclasses.   vs = vipy.video.RandomScene() v = vipy.video.Video.cast(vs)  ",
"func":1
},
{
"ref":"vipy.video.VideoCategory.metadata",
"url":16,
"doc":"Return a dictionary of metadata about this video. Args: k [str]: If provided, return just the specified key of the attributes dictionary, otherwise return the attributes dictionary Returns: The 'attributes' dictionary, or just the value for the provided key k if provided",
"func":1
},
{
"ref":"vipy.video.VideoCategory.sanitize",
"url":16,
"doc":"Remove all private keys from the attributes dictionary. The attributes dictionary is useful storage for arbitrary (key,value) pairs. However, this storage may contain sensitive information that should be scrubbed from the video before serialization. As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key. This is analogous to private or reserved attributes in the python lanugage. Users should reserve these keynames for those keys that should be sanitized and removed before any seerialization of this object.   assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey')  False  ",
"func":1
},
{
"ref":"vipy.video.VideoCategory.videoid",
"url":16,
"doc":"Return a unique video identifier for this video, as specified in the 'video_id' attribute Args: newid: [str] If not None, then update the video_id as newid. Returns: The video ID if newid=None else self",
"func":1
},
{
"ref":"vipy.video.VideoCategory.frame",
"url":16,
"doc":"Return the kth frame as an  vipy.image Image object",
"func":1
},
{
"ref":"vipy.video.VideoCategory.store",
"url":16,
"doc":"Store the current video file as an attribute of this object. Useful for archiving an object to be fully self contained without any external references.   v  v.store().restore(v.filename(    note -Remove this stored video using unstore() -Unpack this stored video and set up the video chains using restore() -This method is more efficient than load() followed by pkl(), as it stores the encoded video as a byte string. -Useful for creating a single self contained object for distributed processing.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.unstore",
"url":16,
"doc":"Delete the currently stored video from  vipy.video.Video.store",
"func":1
},
{
"ref":"vipy.video.VideoCategory.restore",
"url":16,
"doc":"Save the currently stored video as set using  vipy.video.Video.store to filename, and set up filename",
"func":1
},
{
"ref":"vipy.video.VideoCategory.concatenate",
"url":16,
"doc":"Temporally concatenate a sequence of videos into a single video stored in outfile.   (v1, v2, v3) = (vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32 vc = vipy.video.Video.concatenate v1, v2, v3), 'concatenated.mp4', youtube_chapters=lambda v: v.category(   In this example, vc will point to concatenated.mp4 which will contain (v1,v2,v3) concatenated temporally . Args: videos: a single video or an iterable of videos of type  vipy.video.Video or an iterable of video files outfile: the output filename to store the concatenation. youtube_chapters: [bool, callable]: If true, output a string that can be used to define the start and end times of chapters if this video is uploaded to youtube. The string output should be copied to the youtube video description in order to enable chapters on playback. This argument will default to the string representation ofo the video, but you may also pass a callable of the form: 'youtube_chapters=lambda v: str(v)' which will output the provided string for each video chapter. A useful lambda is 'youtube_chapters=lambda v: v.category()' framerate: [float]: The output frame rate of outfile Returns: A  vipy.video.Video object with filename()=outfile, such that outfile contains the temporal concatenation of pixels in (self, videos).  note - self will not be modified, this will return a new  vipy.video.Video object. - All videos must be the same shape(). If the videos are different shapes, you must pad them to a common size equal to self.shape(). Try  vipy.video.Video.zeropadlike . - The output video will be at the framerate of self.framerate(). - if you want to concatenate annotations, call  vipy.video.Scene.annotate first on the videos to save the annotations into the pixels, then concatenate.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.stream",
"url":16,
"doc":"Iterator to yield groups of frames streaming from video. A video stream is a real time iterator to read or write from a video. Streams are useful to group together frames into clips that are operated on as a group. The following use cases are supported:   v = vipy.video.RandomScene()   Stream individual video frames lagged by 10 frames and 20 frames   for (im1, im2) in zip(v.stream().frame(n=-10), v.stream().frame(n=-20 : print(im1, im2)   Stream overlapping clips such that each clip is a video n=16 frames long and starts at frame i, and the next clip is n=16 frames long and starts at frame i=i+m   for vc in v.stream().clip(n=16, m=4): print(vc)   Stream non-overlapping batches of frames such that each clip is a video of length n and starts at frame i, and the next clip is length n and starts at frame i+n   for vb in v.stream().batch(n=16): print(vb)   Create a write stream to incrementally add frames to long video.   vi = vipy.video.Video(filename='/path/to/output.mp4') vo = vipy.video.Video(filename='/path/to/input.mp4') with vo.stream(write=True) as s: for im in vi.stream(): s.write(im)  manipulate pixels of im, if desired   Create a 480p YouTube live stream from an RTSP camera at 5Hz   vo = vipy.video.Scene(url='rtmp: a.rtmp.youtube.com/live2/$SECRET_STREAM_KEY') vi = vipy.video.Scene(url='rtsp: URL').framerate(5) with vo.framerate(5).stream(write=True, bitrate='1000k') as s: for im in vi.framerate(5).resize(cols=854, rows=480): s.write(im)   Args: write: [bool] If true, create a write stream overwrite: [bool] If true, and the video output filename already exists, overwrite it bufsize: [int] The maximum queue size for the ffmpeg pipe thread in the primary iterator. The queue size is the maximum size of pre-fetched frames from the ffmpeg pip. This should be big enough that you are never waiting for queue fills bitrate: [str] The ffmpeg bitrate of the output encoder for writing, written like '2000k' bufsize: [int] The maximum size of the stream buffer in frames. The stream buffer length should be big enough so that all iterators can yield before deleting old frames Returns: A Stream object  note Using this iterator may affect PDB debugging due to stdout/stdin redirection. Use ipdb instead.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.clear",
"url":16,
"doc":"no-op for  vipy.video.Video object, used only for  vipy.video.Scene ",
"func":1
},
{
"ref":"vipy.video.VideoCategory.bytes",
"url":16,
"doc":"Return a bytes representation of the video file",
"func":1
},
{
"ref":"vipy.video.VideoCategory.frames",
"url":16,
"doc":"Alias for __iter__()",
"func":1
},
{
"ref":"vipy.video.VideoCategory.commandline",
"url":16,
"doc":"Return the equivalent ffmpeg command line string that will be used to transcode the video. This is useful for introspecting the complex filter chain that will be used to process the video. You can try to run this command line yourself for debugging purposes, by replacing 'dummyfile' with an appropriately named output file.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.probeshape",
"url":16,
"doc":"Return the (height, width) of underlying video file as determined from ffprobe  warning this does not take into account any applied ffmpeg filters. The shape will be the (height, width) of the underlying video file.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.duration_in_seconds_of_videofile",
"url":16,
"doc":"Return video duration of the source filename (NOT the filter chain) in seconds, requires ffprobe. Fetch once and cache.  notes This is the duration of the source video and NOT the duration of the filter chain. If you load(), this may be different duration depending on clip() or framerate() directives.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.duration_in_frames_of_videofile",
"url":16,
"doc":"Return video duration of the source video file (NOT the filter chain) in frames, requires ffprobe.  notes This is the duration of the source video and NOT the duration of the filter chain. If you load(), this may be different duration depending on clip() or framerate() directives.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.duration",
"url":16,
"doc":"Return a video clipped with frame indexes between (0, frames) or (0,seconds self.framerate( or (0,minutes 60 self.framerate(). Return duration in seconds if no arguments are provided.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.duration_in_frames",
"url":16,
"doc":"Return the duration of the video filter chain in frames, equal to round(self.duration() self.framerate( . Requires a probe() of the video to get duration",
"func":1
},
{
"ref":"vipy.video.VideoCategory.framerate_of_videofile",
"url":16,
"doc":"Return video framerate in frames per second of the source video file (NOT the filter chain), requires ffprobe.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.resolution_of_videofile",
"url":16,
"doc":"Return video resolution in (height, width) in pixels (NOT the filter chain), requires ffprobe.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.probe",
"url":16,
"doc":"Run ffprobe on the filename and return the result as a dictionary Args: Any keyword arguments supported by python-ffmpeg probe() - these are passed in as-is - for flags, use flag_name=None (e.g., show_frames=None) so that ffmpeg.probe() handles them correctly",
"func":1
},
{
"ref":"vipy.video.VideoCategory.frame_meta",
"url":16,
"doc":"Return the frame metadata of the underlying video file using ffprobe for all frames as a list of dicts, each list element corresponding to a frame. This is useful for extracting frame types (e.g. i-frames). Args: k [int]: Return only the frame metadata for frame index k (relative to framerate of source videofile, not filter chain) Returns: a list of metadata dicts (one per frame) or a single dict for the requested frame.  notes - This will return a large amount of metadata for the entire source video (not the FFMPEG filter chain), use with caution. - To get frame metata for a filter chain use vipy.video.Video.savetemp().frame_meta(), which will save the video to a temporary file prior to extracting frame metadata",
"func":1
},
{
"ref":"vipy.video.VideoCategory.metaframe",
"url":16,
"doc":"Alias for  vipy.video.Video.frame_meta ",
"func":1
},
{
"ref":"vipy.video.VideoCategory.iframes",
"url":16,
"doc":"Return a list of i-frame indexes (e.g. intra-frame, a video frame that is independent from other frames for decoding) in this video file.  note - To return the i-frame indexes for the current filter chain use self.saveas().iframes() to save to a temporary file prior to i-frame index extraction. - To extract the i-frame itself, use [self.frame(k) for k in self.iframes()]",
"func":1
},
{
"ref":"vipy.video.VideoCategory.print",
"url":16,
"doc":"Print the representation of the video This is useful for debugging in long fluent chains. Sleep is useful for adding in a delay for distributed processing. Args: prefix: prepend a string prefix to the video __repr__ when printing. Useful for logging. sleep: Integer number of seconds to sleep[ before returning Returns: The video object after sleeping",
"func":1
},
{
"ref":"vipy.video.VideoCategory.printif",
"url":16,
"doc":"Call  vipy.video.Video.print if b=True. Useful for fluent chains to print periodically.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.dict",
"url":16,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.json",
"url":16,
"doc":"Return a json representation of the video. Args: encode: If true, return a JSON encoded string using json.dumps Returns: A JSON encoded string if encode=True, else returns a dictionary object  note If the video is loaded, then the JSON will not include the pixels. Try using  vipy.video.Video.store to serialize videos, or call  vipy.video.Video.flush first.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.take",
"url":16,
"doc":"Return n frames from the clip uniformly spaced as numpy array Args: n: Integer number of uniformly spaced frames to return Returns: A numpy array of shape (n,W,H)  warning This assumes that the entire video is loaded into memory (e.g. call  vipy.video.Video.load ). Use with caution.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.framerate",
"url":16,
"doc":"Change the input framerate for the video and update frame indexes for all annotations Args: fps: [Float] frames per second to process the underlying video round ['up','down','near'] the rounding option for the ffmpeg fps filter Returns: If fps is None, return the current framerate, otherwise set the framerate to fps",
"func":1
},
{
"ref":"vipy.video.VideoCategory.colorspace",
"url":16,
"doc":"Return or set the colorspace as ['rgb', 'bgr', 'lum', 'float']. This will not change pixels, only the colorspace interpretation of pixels.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.nourl",
"url":16,
"doc":"Remove the  vipy.video.Video.url from the video",
"func":1
},
{
"ref":"vipy.video.VideoCategory.url",
"url":16,
"doc":"Video URL and URL download properties",
"func":1
},
{
"ref":"vipy.video.VideoCategory.isloaded",
"url":16,
"doc":"Return True if the video has been loaded",
"func":1
},
{
"ref":"vipy.video.VideoCategory.is_loaded",
"url":16,
"doc":"Return True if the video has been loaded",
"func":1
},
{
"ref":"vipy.video.VideoCategory.isloadable",
"url":16,
"doc":"Return True if the video can be loaded successfully. This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version. Args: flush: [bool] If true, flush the video after it loads. This will clear the video pixel buffer Returns: True if load() can be called without FFMPEG exception. If flush=False, then self will contain the loaded video, which is helpful to avoid load() twice in some conditions  warning This requires loading and flushing the video. This is an expensive operation when performed on many videos and may result in out of memory conditions with long videos. Use with caution! Try  vipy.video.Video.canload to test if a single frame can be loaded as a less expensive alternative.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.canload",
"url":16,
"doc":"Return True if the video can be previewed at frame=k successfully. This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.  notes This will only try to preview a single frame. This will not check if the entire video is loadable. Use  vipy.video.Video.isloadable in this case This will hang if calling canload on a streaming URL.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.iscolor",
"url":16,
"doc":"Is the video a three channel color video as returned from  vipy.video.Video.channels ?",
"func":1
},
{
"ref":"vipy.video.VideoCategory.isgrayscale",
"url":16,
"doc":"Is the video a single channel as returned from  vipy.video.Video.channels ?",
"func":1
},
{
"ref":"vipy.video.VideoCategory.hasfilename",
"url":16,
"doc":"Does the filename returned from  vipy.video.Video.filename exist?",
"func":1
},
{
"ref":"vipy.video.VideoCategory.isdownloaded",
"url":16,
"doc":"Alias for  vipy.video.Video.is_downloaded ",
"func":1
},
{
"ref":"vipy.video.VideoCategory.is_downloaded",
"url":16,
"doc":"Does the filename returned from  vipy.video.Video.filename exist, meaning that the url has been downloaded to a local file?",
"func":1
},
{
"ref":"vipy.video.VideoCategory.hasurl",
"url":16,
"doc":"Is the url returned from  vipy.video.Video.url a well formed url?",
"func":1
},
{
"ref":"vipy.video.VideoCategory.array",
"url":16,
"doc":"Set or return the video buffer as a numpy array. Args: array: [np.array] A numpy array of size NxHxWxC = (frames, height, width, channels) of type uint8 or float32. array: [list] A list of  vipy.image.Image objects copy: [bool] If true, copy the buffer by value instaed of by reference. Copied buffers do not share pixels. Returns: if array=None, return a reference to the pixel buffer as a numpy array, otherwise return the video object with the array populated",
"func":1
},
{
"ref":"vipy.video.VideoCategory.from_array",
"url":16,
"doc":"Create a new video from a shared array, Equivalent to self.array( ., copy=False)",
"func":1
},
{
"ref":"vipy.video.VideoCategory.from_directory",
"url":16,
"doc":"Create a video from a directory of frames stored as individual image filenames. Given a directory with files: framedir/image_0001.jpg framedir/image_0002.jpg   vipy.video.Video(frames='/path/to/framedir')  ",
"func":1
},
{
"ref":"vipy.video.VideoCategory.from_frames",
"url":16,
"doc":"Create a video from a list of frames",
"func":1
},
{
"ref":"vipy.video.VideoCategory.from_annotation_sequence",
"url":16,
"doc":"Construct a video from an input image im where each frame is the acculation of annnotated objects in im. This is useful for visualization of a labeling sequence",
"func":1
},
{
"ref":"vipy.video.VideoCategory.to_numpy",
"url":16,
"doc":"Alias for numpy()",
"func":1
},
{
"ref":"vipy.video.VideoCategory.mutable",
"url":16,
"doc":"Return a video object with a writeable mutable frame array. Video must be loaded, triggers copy of underlying numpy array if the buffer is not writeable. Returns: This object with a mutable frame buffer in self.array() or self.numpy()",
"func":1
},
{
"ref":"vipy.video.VideoCategory.numpy",
"url":16,
"doc":"Convert the video to a writeable numpy array, triggers a load() and copy() as needed. Returns the numpy array.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.filename",
"url":16,
"doc":"Update video Filename with optional copy or symlink from existing file (self.filename( to new file",
"func":1
},
{
"ref":"vipy.video.VideoCategory.abspath",
"url":16,
"doc":"Change the path of the filename from a relative path to an absolute path (not relocatable)",
"func":1
},
{
"ref":"vipy.video.VideoCategory.relpath",
"url":16,
"doc":"Replace the filename with a relative path to parent (or current working directory if none). Usage:   v = vipy.video.Video(filename='/path/to/dataset/video/category/out.mp4') v.relpath(parent='/path/to/dataset') v.filename()  'video/category/out.mp4'   If the current working directory is /path/to/dataset, and v.load() is called, the filename will be loaded. Args: parent [str]: A parent path of the current filename to remove and be relative to. If filename is '/path/to/video.mp4' then filename must start with parent, then parent will be remvoed from filename. start [str]: Return a relative filename starting from path start='/path/to/dir' that will create a relative path to this filename. If start='/a/b/c' and filename='/a/b/d/e/f.ext' then return filename ' /d/e/f.ext' Returns: This video object with the filename changed to be a relative path",
"func":1
},
{
"ref":"vipy.video.VideoCategory.rename",
"url":16,
"doc":"Move the underlying video file preserving the absolute path, such that self.filename()  '/a/b/c.ext' and newname='d.ext', then self.filename() -> '/a/b/d.ext', and move the corresponding file",
"func":1
},
{
"ref":"vipy.video.VideoCategory.filesize",
"url":16,
"doc":"Return the size in bytes of the filename(), None if the filename() is invalid",
"func":1
},
{
"ref":"vipy.video.VideoCategory.downloadif",
"url":16,
"doc":"Download URL to filename if the filename has not already been downloaded",
"func":1
},
{
"ref":"vipy.video.VideoCategory.download",
"url":16,
"doc":"Download URL to filename provided by constructor, or to temp filename. Args: timeout: [int] An integer timeout in seconds for the download to connect verbose: [bool] If trye, show more verbose console output max_filesize: [str] A string of the form 'NNNg' or 'NNNm' for youtube downloads to limit the maximum size of a URL to '350m' 350MB or '12g' for 12GB. Returns: This video object with the video downloaded to the filename()",
"func":1
},
{
"ref":"vipy.video.VideoCategory.fetch",
"url":16,
"doc":"Download only if hasfilename() is not found",
"func":1
},
{
"ref":"vipy.video.VideoCategory.shape",
"url":16,
"doc":"Return (height, width) of the frames, requires loading a preview frame from the video if the video is not already loaded, or providing the shape=(height,width) by the user",
"func":1
},
{
"ref":"vipy.video.VideoCategory.channelshape",
"url":16,
"doc":"Return a tuple (channels, height, width) for the video",
"func":1
},
{
"ref":"vipy.video.VideoCategory.issquare",
"url":16,
"doc":"Return true if the video has square dimensions (height  width), else false",
"func":1
},
{
"ref":"vipy.video.VideoCategory.channels",
"url":16,
"doc":"Return integer number of color channels",
"func":1
},
{
"ref":"vipy.video.VideoCategory.width",
"url":16,
"doc":"Width (cols) in pixels of the video for the current filter chain",
"func":1
},
{
"ref":"vipy.video.VideoCategory.height",
"url":16,
"doc":"Height (rows) in pixels of the video for the current filter chain",
"func":1
},
{
"ref":"vipy.video.VideoCategory.aspect_ratio",
"url":16,
"doc":"The width/height of the video expressed as a fraction",
"func":1
},
{
"ref":"vipy.video.VideoCategory.preview",
"url":16,
"doc":"Return selected frame of filtered video, return vipy.image.Image object. This is useful for previewing the frame shape of a complex filter chain or the frame contents at a particular location without loading the whole video",
"func":1
},
{
"ref":"vipy.video.VideoCategory.thumbnail",
"url":16,
"doc":"Return annotated frame=k of video, save annotation visualization to provided outfile. This is functionally equivalent to  vipy.video.Video.frame with an additional outfile argument to easily save an annotated thumbnail image. Args: outfile: [str] an optional outfile to save the annotated frame frame: [int >= 0] The frame to output the thumbnail Returns: A  vipy.image.Image object for frame k.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.load",
"url":16,
"doc":"Load a video using ffmpeg, applying the requested filter chain. Args: verbose: [bool] if True. then ffmpeg console output will be displayed. shape: [tuple (height, width, channels)] If provided, use this shape for reading and reshaping the byte stream from ffmpeg. This is useful for efficient loading in some scenarios. Knowing the final output shape can speed up loads by avoiding a preview() of the filter chain to get the frame size Returns: this video object, with the pixels loaded in self.array()  warning Loading long videos can result in out of memory conditions. Try to call clip() first to extract a video segment to load().",
"func":1
},
{
"ref":"vipy.video.VideoCategory.speed",
"url":16,
"doc":"Change the speed by a multiplier s. If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)",
"func":1
},
{
"ref":"vipy.video.VideoCategory.clip",
"url":16,
"doc":"Clip the video to between (start, end). This clip is relative to clip() shown by __repr__(). Args: start: [int|float] the start frame|second relative to the video framerate() for the clip end: [int|float] the end frame|second relative to the video framerate for the clip, may be none Returns: This video object, clipped so that a load() will result in frame=0 equivalent to startframe.  note: - This does not load the video. This updates the ffmpeg filter chain to temporally trim the video. See self.commandline() for the updated filter chain to run.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.cliprange",
"url":16,
"doc":"Return the planned clip (startframe, endframe) range. This is useful for introspection of the planned clip() before load(), such as for data augmentation purposes without triggering a load. Returns: (startframe, endframe) of the video() such that after load(), the pixel buffer will contain frame=0 equivalent to startframe in the source video, and frame=endframe-startframe-1 equivalent to endframe in the source video. (0, None) If a video does not have a clip() (e.g. clip() was never called, the filter chain does not include a 'trim')  notes The endframe can be retrieved (inefficiently) using:   int(round(self.duration_in_frames_of_videofile()  (self.framerate() / self.framerate_of_videofile(   ",
"func":1
},
{
"ref":"vipy.video.VideoCategory.rot90cw",
"url":16,
"doc":"Rotate the video 90 degrees clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.VideoCategory.rot90ccw",
"url":16,
"doc":"Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.VideoCategory.fliplr",
"url":16,
"doc":"Mirror the video left/right by flipping horizontally",
"func":1
},
{
"ref":"vipy.video.VideoCategory.flipud",
"url":16,
"doc":"Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.VideoCategory.rescale",
"url":16,
"doc":"Rescale the video by factor s, such that the new dimensions are (s H, s W), can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.VideoCategory.resize",
"url":16,
"doc":"Resize the video to be (rows=height, cols=width)",
"func":1
},
{
"ref":"vipy.video.VideoCategory.mindim",
"url":16,
"doc":"Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio, return the minimum dimension if dim=None",
"func":1
},
{
"ref":"vipy.video.VideoCategory.set_mindim",
"url":16,
"doc":"Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio, do nothing if dim=None",
"func":1
},
{
"ref":"vipy.video.VideoCategory.maxdim",
"url":16,
"doc":"Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio",
"func":1
},
{
"ref":"vipy.video.VideoCategory.randomcrop",
"url":16,
"doc":"Crop the video to shape=(H,W) with random position such that the crop contains only valid pixels, and optionally return the box",
"func":1
},
{
"ref":"vipy.video.VideoCategory.centercrop",
"url":16,
"doc":"Crop the video to shape=(H,W) preserving the integer centroid position, and optionally return the box",
"func":1
},
{
"ref":"vipy.video.VideoCategory.centersquare",
"url":16,
"doc":"Crop video of size (NxN) in the center, such that N=min(width,height), keeping the video centroid constant",
"func":1
},
{
"ref":"vipy.video.VideoCategory.cropeven",
"url":16,
"doc":"Crop the video to the largest even (width,height) less than or equal to current (width,height). This is useful for some codecs or filters which require even shape.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.maxsquare",
"url":16,
"doc":"Pad the video to be square, preserving the upper left corner of the video",
"func":1
},
{
"ref":"vipy.video.VideoCategory.minsquare",
"url":16,
"doc":"Return a square crop of the video, preserving the upper left corner of the video",
"func":1
},
{
"ref":"vipy.video.VideoCategory.maxmatte",
"url":16,
"doc":"Return a square video with dimensions (self.maxdim(), self.maxdim( with zeropadded lack bars or mattes above or below the video forming a letterboxed video.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.zeropad",
"url":16,
"doc":"Zero pad the video with padwidth columns before and after, and padheight rows before and after  notes Older FFMPEG implementations can throw the error \"Input area  : : : not within the padded area  : : : or zero-sized, this is often caused by odd sized padding. Recommend calling self.cropeven().zeropad( .) to avoid this",
"func":1
},
{
"ref":"vipy.video.VideoCategory.pad",
"url":16,
"doc":"Alias for zeropad",
"func":1
},
{
"ref":"vipy.video.VideoCategory.zeropadlike",
"url":16,
"doc":"Zero pad the video balancing the border so that the resulting video size is (width, height).",
"func":1
},
{
"ref":"vipy.video.VideoCategory.crop",
"url":16,
"doc":"Spatially crop the video using the supplied vipy.geometry.BoundingBox, can only be applied prior to load().  note Crop is performed in place overwriting pixels of self.array(). Clone() before crop() if array() must be preserved.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.pkl",
"url":16,
"doc":"save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.video.VideoCategory.pklif",
"url":16,
"doc":"Save the object to the provided pickle file only if b=True. Uuseful for conditional intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.video.VideoCategory.webp",
"url":16,
"doc":"Save a video to an animated WEBP file, with pause=N seconds on the last frame between loops. Args: strict: If true, assert that the filename must have an .webp extension pause: Integer seconds to pause between loops of the animation smallest: if true, create the smallest possible file but takes much longer to run smaller: If true, create a smaller file, which takes a little longer to run framerate [float]: The output framerate of the webp file. The default is the framerate of the video. Returns: The filename of the webp file for this video  warning This may be slow for very long or large videos",
"func":1
},
{
"ref":"vipy.video.VideoCategory.gif",
"url":16,
"doc":"Save a video to an animated GIF file, with pause=N seconds between loops. Args: pause: Integer seconds to pause between loops of the animation smallest: If true, create the smallest possible file but takes much longer to run smaller: if trye, create a smaller file, which takes a little longer to run framerate [float]: The output framerate of the webp file. The default is the framerate of the video. Returns: The filename of the animated GIF of this video  warning This will be very large for big videos, consider using  vipy.video.Video.webp instead.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.save",
"url":16,
"doc":"Save video to new output video file. This function does not draw boxes, it saves pixels to a new video file. Args: outfile: the absolute path to the output video file. This extension can be .mp4 (for video) or [\".webp\",\".gif\"] (for animated image) flush: If true, then flush the buffer for this object right after saving the new video. This is useful for transcoding in parallel framerate: input framerate of the frames in the buffer, or the output framerate of the transcoded video. If not provided, use framerate of source video pause: an integer in seconds to pause between loops of animated images if the outfile is webp or animated gif Returns: a new video object with this video filename, and a clean video filter chain  note - If self.array() is loaded, then export the contents of self._array to the video file - If self.array() is not loaded, and there exists a valid video file, apply the filter chain directly to the input video - If outfile None or outfile self.filename(), then overwrite the current filename",
"func":1
},
{
"ref":"vipy.video.VideoCategory.saveas",
"url":16,
"doc":"Call  vipy.video.Video.saveas using a new temporary video file, and return the video object with this new filename",
"func":1
},
{
"ref":"vipy.video.VideoCategory.savetmp",
"url":16,
"doc":"Call  vipy.video.Video.saveas using a new temporary video file, and return the video object with this new filename",
"func":1
},
{
"ref":"vipy.video.VideoCategory.ffplay",
"url":16,
"doc":"Play the video file using ffplay",
"func":1
},
{
"ref":"vipy.video.VideoCategory.play",
"url":16,
"doc":"Play the saved video filename in self.filename() If there is no filename, try to download it. If the filter chain is dirty or the pixels are loaded, dump to temp video file first then play it. This uses 'ffplay' on the PATH if available, otherwise uses a fallback player by showing a sequence of matplotlib frames. If the output of the ffmpeg filter chain has modified this video, then this will be saved to a temporary video file. To play the original video (indepenedent of the filter chain of this video), use  vipy.video.Video.ffplay . Args: verbose: If true, show more verbose output notebook: If true, play in a jupyter notebook ffplay: If true, use ffplay to display the video (if available) Returns: The unmodified video object",
"func":1
},
{
"ref":"vipy.video.VideoCategory.show",
"url":16,
"doc":"Alias for play",
"func":1
},
{
"ref":"vipy.video.VideoCategory.quicklook",
"url":16,
"doc":"Generate a montage of n uniformly spaced frames. Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame. Input: n: Number of images in the quicklook mindim: The minimum dimension of each of the elements in the montage animate: If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames dt: The number of frames for animation startframe: The initial frame index to start the n uniformly sampled frames for the quicklook thumbnail [ vipy.image.Image ]: If provided, prepent the first element in the montage with this thumbnail. This is useful for showing a high resolution image (e.g. a face, small object) to be contained in the video for review. aspectratio [float]: the ratio of gridcols/gridrows in vipy.visualize.montage  note The first frame in the upper left is guaranteed to be the start frame of the labeled activity, but the last frame in the bottom right may not be precisely the end frame and may be off by at most len(video)/9.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.torch",
"url":16,
"doc":"Convert the loaded video of shape NxHxWxC frames to an MxCxHxW torch tensor/ Args: startframe: [int >= 0] The start frame of the loaded video to use for constructig the torch tensor endframe: [int >= 0] The end frame of the loaded video to use for constructing the torch tensor length: [int >= 0] The length of the torch tensor if endframe is not provided. stride: [int >= 1] The temporal stride in frames. This is the number of frames to skip. take: [int >= 0] The number of uniformly spaced frames to include in the tensor. boundary: ['repeat', 'cyclic'] The boundary handling for when the requested tensor slice goes beyond the end of the video order: ['nchw', 'nhwc', 'chwn', 'cnhw'] The axis ordering of the returned torch tensor N=number of frames (batchsize), C=channels, H=height, W=width verbose [bool]: Print out the slice used for contructing tensor withslice: [bool] Return a tuple (tensor, slice) that includes the slice used to construct the tensor. Useful for data provenance. scale: [float] An optional scale factor to apply to the tensor. Useful for converting [0,255] -> [0,1] withlabel: [bool] Return a tuple (tensor, labels) that includes the N framewise activity labels. nonelabel: [bool] returns tuple (t, None) if withlabel=False Returns Returns torch float tensor, analogous to torchvision.transforms.ToTensor() Return (tensor, slice) if withslice=True (withslice takes precedence) Returns (tensor, labellist) if withlabel=True  notes - This triggers a load() of the video - The precedence of arguments is (startframe, endframe) or (startframe, startframe+length), then stride and take. - Follows numpy slicing rules. Optionally return the slice used if withslice=True",
"func":1
},
{
"ref":"vipy.video.VideoCategory.clone",
"url":16,
"doc":"Create deep copy of video object, flushing the original buffer if requested and returning the cloned object. Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned object which can be used for encoding and will be garbage collected. Args: flushforward: copy the object, and set the cloned object  vipy.video.Video.array to None. This flushes the video buffer for the clone, not the object flushbackward: copy the object, and set the object array() to None. This flushes the video buffer for the object, not the clone. flush: set the object array() to None and clone the object. This flushes the video buffer for both the clone and the object. flushfilter: Set the ffmpeg filter chain to the default in the new object, useful for saving new videos flushfile: Remove the filename and the URL from the video object. Useful for creating new video objects from loaded pixels. rekey: Generate new unique track ID and activity ID keys for this scene shallow: shallow copy everything (copy by reference), except for ffmpeg object. attributes dictionary is shallow copied sharedarray: deep copy of everything, except for pixel buffer which is shared. Changing the pixel buffer on self is reflected in the clone. sanitize: remove private attributes from self.attributes dictionary. A private attribute is any key with two leading underscores '__' which should not be propagated to clone Returns: A deepcopy of the video object such that changes to self are not reflected in the copy  note Cloning videos is an expensive operation and can slow down real time code. Use sparingly.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.flush",
"url":16,
"doc":"Alias for clone(flush=True), returns self not clone",
"func":1
},
{
"ref":"vipy.video.VideoCategory.unload",
"url":16,
"doc":"Remove cached file and loaded array. Note that this will delete the underlying file returned by filename() if there is a backing url, cleaning up cached files and forcing re-download",
"func":1
},
{
"ref":"vipy.video.VideoCategory.uncache",
"url":16,
"doc":"Alias for  vipy.image.Image.unload ",
"func":1
},
{
"ref":"vipy.video.VideoCategory.returns",
"url":16,
"doc":"Return the provided value, useful for terminating long fluent chains without returning self",
"func":1
},
{
"ref":"vipy.video.VideoCategory.flush_and_return",
"url":16,
"doc":"Flush the video and return the parameter supplied, useful for long fluent chains",
"func":1
},
{
"ref":"vipy.video.VideoCategory.map",
"url":16,
"doc":"Apply lambda function to the loaded numpy array img, changes pixels not shape Lambda function must have the following signature:  newimg = func(img)  img: HxWxC numpy array for a single frame of video  newimg: HxWxC modified numpy array for this frame. Change only the pixels, not the shape The lambda function will be applied to every frame in the video in frame index order.",
"func":1
},
{
"ref":"vipy.video.VideoCategory.gain",
"url":16,
"doc":"Pixelwise multiplicative gain, such that each pixel p_{ij} = g  p_{ij}",
"func":1
},
{
"ref":"vipy.video.VideoCategory.bias",
"url":16,
"doc":"Pixelwise additive bias, such that each pixel p_{ij} = b + p_{ij}",
"func":1
},
{
"ref":"vipy.video.VideoCategory.normalize",
"url":16,
"doc":"Pixelwise whitening, out =  scale in) - mean) / std); triggers load(). All computations float32",
"func":1
},
{
"ref":"vipy.video.VideoCategory.hasattribute",
"url":16,
"doc":"Does the attributes dictionary (self.attributes) contain the provided key",
"func":1
},
{
"ref":"vipy.video.VideoCategory.clearattributes",
"url":16,
"doc":"Remove all attributes",
"func":1
},
{
"ref":"vipy.video.VideoCategory.clear_attributes",
"url":16,
"doc":"Remove all attributes",
"func":1
},
{
"ref":"vipy.video.VideoCategory.get_attribute",
"url":16,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.video.Scene",
"url":16,
"doc":"vipy.video.Scene class The vipy.video.Scene class provides a fluent, lazy interface for representing, transforming and visualizing annotated videos. The following constructors are supported:   vid = vipy.video.Scene(filename='/path/to/video.ext')   Valid video extensions are those that are supported by ffmpeg ['.avi','.mp4','.mov','.wmv','.mpg', 'mkv', 'webm'].   vid = vipy.video.Scene(url='https: www.youtube.com/watch?v=MrIN959JuV8') vid = vipy.video.Scene(url='http: path/to/video.ext', filename='/path/to/video.ext')   Youtube URLs are downloaded to a temporary filename, retrievable as vid.download().filename(). If the environment variable 'VIPY_CACHE' is defined, then videos are saved to this directory rather than the system temporary directory. If a filename is provided to the constructor, then that filename will be used instead of a temp or cached filename. URLs can be defined as an absolute URL to a video file, or to a site supported by 'youtube-dl' [https: ytdl-org.github.io/youtube-dl/supportedsites.html]   vid = vipy.video.Scene(array=frames, colorspace='rgb')   The input 'frames' is an NxHxWx3 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video Note that the video transformations (clip, resize, rescale, rotate) are only available prior to load(), and the array() is assumed immutable after load().   vid = vipy.video.Scene(array=greyframes, colorspace='lum')   The input 'greyframes' is an NxHxWx1 numpy array corresponding to an N-length list of HxWx3 uint8 numpy array which is a single frame of pre-loaded video This corresponds to the luminance of an RGB colorspace   vid = vipy.video.Scene(array=greyframes, colorspace='lum', tracks=tracks, activities=activities)   - tracks = [vipy.object.Track(),  .] - activities = [vipy.object.Activity(),  .] The inputs are lists of tracks and/or activities. An object is a spatial bounding box with a category label. A track is a spatiotemporal bounding box with a category label, such that the box contains the same instance of an object. An activity is one or more tracks with a start and end frame for an activity performed by the object instances. Track and activity timing must be relative to the start frame of the Scene() constructor."
},
{
"ref":"vipy.video.Scene.category",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.new_category",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.confidence",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.tags",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.confidences",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.add_tag",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.add_tags",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.cast",
"url":16,
"doc":"Cast a conformal vipy object to this class. This is useful for downcast and upcast conversion of video objects.",
"func":1
},
{
"ref":"vipy.video.Scene.asjson",
"url":16,
"doc":"Restore an object serialized with self.json(). Alas for  vipy.video.Scene.from_json . Usage:   vs = vipy.video.Scene.asjson(v.json(  ",
"func":1
},
{
"ref":"vipy.video.Scene.from_json",
"url":16,
"doc":"Restore an object serialized with self.json() Usage:   vs = vipy.video.Scene.from_json(v.json(  ",
"func":1
},
{
"ref":"vipy.video.Scene.pack",
"url":16,
"doc":"Packing a scene returns the scene with the annotations JSON serialized. - This is useful for fast garbage collection when there are many objects in memory - This is useful for distributed processing prior to serializing from a scheduler to a client - This is useful for lazy deserialization of complex attributes when loading many videos into memory - Unpacking is transparent to the end user and is performed on the fly when annotations are accessed. There is no unpack() method. - See the notes in from_json() for why this helps with nested containers and reference cycle tracking with the python garbage collector",
"func":1
},
{
"ref":"vipy.video.Scene.frame",
"url":16,
"doc":"Return  vipy.image.Scene object at frame k -The attributes of each of the  vipy.image.Scene.objects in the scene contains helpful metadata for the provenance of the detection, including: - 'trackid' of the track of this detection - 'track_index' of the track of this detection - 'activityid' associated with this detection - 'activity category' of this detection, used for visualization - 'track category' of this detection, used for visualization - 'activity_conf' of this detection, used for visualization Args: k: [int >= 0] The frame index requested. This is relative to the current frame rate of the video. img: [numpy, None] An optional image to be used for this frame. This is useful to construct frames efficiently for videos if the pixel buffer is already available from a stream rather than a preview. noimage [bool]: If True, then return only annotations at frame k with empty frame buffer (e.g. no image pixels in the returned image object) t: [float >= 0] The frame time requested. This is converted into a frame index using the current framerate of the video. Return: A  vipy.image.Scene object for frame k containing all objects in this frame and pixels if img != None or preview=True  note - Modifying this frame will not affect the source video - If multiple objects are associated with an activity and a primary actor is defined, then only the primary actor is displayed as \"Noun Verbing\", objects are shown as \"Noun\" with the activityid in the attribute - If noun is associated with more than one activity, then this is shown as \"Noun Verbing1 Noun Verbing2\", with a newline separator",
"func":1
},
{
"ref":"vipy.video.Scene.during",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.labeled_frames",
"url":16,
"doc":"Iterate over frames, yielding tuples (activity+object labelset in scene, vipy.image.Scene( ",
"func":1
},
{
"ref":"vipy.video.Scene.framecomposite",
"url":16,
"doc":"Generate a single composite image with minimum dimension mindim as the uniformly blended composite of n frames each separated by dt frames",
"func":1
},
{
"ref":"vipy.video.Scene.isdegenerate",
"url":16,
"doc":"Degenerate scene has empty or malformed tracks",
"func":1
},
{
"ref":"vipy.video.Scene.quicklook",
"url":16,
"doc":"Generate a montage of n uniformly spaced annotated frames centered on the union of the labeled boxes in the current frame to show the activity ocurring in this scene at a glance Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame. This quicklook is most useful when len(self.activities() 1) for generating a quicklook from an activityclip(). Args: n: [int]: Number of images in the quicklook dilate: [float]: The dilation factor for the bounding box prior to crop for display mindim: [int]: The minimum dimension of each of the elemenets in the montage fontsize: [int]: The size of the font for the bounding box label context: [bool]: If true, replace the first and last frame in the montage with the full frame annotation, to help show the scale of the scene animate: [bool]: If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames dt: [int]: The number of frames for animation startframe: [int]: The initial frame index to start the n uniformly sampled frames for the quicklook thumbnail [ vipy.image.Image ]: If provided, prepend the first element in the montage with this thumbnail. This is useful for showing a high resolution image (e.g. a face, small object) to be contained in the video for review. aspectratio [float]: the ratio of gridcols/gridrows in vipy.visualize.montage",
"func":1
},
{
"ref":"vipy.video.Scene.tracks",
"url":16,
"doc":"Return mutable dictionary of tracks, Args: tracks [dict]: If provided, replace track dictionary with provided track dictionary, and return self id [str]: If provided, return just the track associated with the provided track id Returns: This object if tracks!=None, otherwise the requested track (if id!=None) or trackdict (tracks=None)",
"func":1
},
{
"ref":"vipy.video.Scene.track",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.trackindex",
"url":16,
"doc":"Return the index in the tracklist of the track with the provided track id",
"func":1
},
{
"ref":"vipy.video.Scene.trackidx",
"url":16,
"doc":"Return the track at the specified index in the tracklist",
"func":1
},
{
"ref":"vipy.video.Scene.activity",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.next_activity",
"url":16,
"doc":"Return the next activity just after the given activityid",
"func":1
},
{
"ref":"vipy.video.Scene.prev_activity",
"url":16,
"doc":"Return the previous activity just before the given activityid",
"func":1
},
{
"ref":"vipy.video.Scene.tracklist",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.objects",
"url":16,
"doc":"The objects in a scene are the unique categories of tracks",
"func":1
},
{
"ref":"vipy.video.Scene.actorid",
"url":16,
"doc":"Return or set the actor ID for the video. - The actor ID is the track ID of the primary actor in the scene. This is useful for assigning a role for activities that are performed by the actor. - The actor ID is the first track is in the tracklist Args: id: [str] if not None, then use this track ID as the actor fluent: [bool] If true, always return self. This is useful for those cases where the actorid being set is None. Returns: [id=None, fluent=False] the actor ID [id is not None] The video with the actor ID set, only if the ID is found in the tracklist  note Not to be confused with biometric subject id. For videos collected with Visym Collector platform (https: visym.com/collector), the biometric subject ID can be retrieved via  vipy.video.Video.metadata (e.g. self.metadata()['subject_ids']).",
"func":1
},
{
"ref":"vipy.video.Scene.setactorid",
"url":16,
"doc":"Alias for  vipy.video.Scene.actorid ",
"func":1
},
{
"ref":"vipy.video.Scene.actor",
"url":16,
"doc":"Return the primary actor (first  vipy.object.Track ) in the video",
"func":1
},
{
"ref":"vipy.video.Scene.primary_activity",
"url":16,
"doc":"Return the primary activity of the video. - The primary activity is the first activity in the activitylist. - This is useful for activityclip() videos that are centered on a single activity Returns:  vipy.activity.Activity that is first in the  vipy.video.Scene.activitylist ",
"func":1
},
{
"ref":"vipy.video.Scene.first_activity",
"url":16,
"doc":"Return the first activity of the video with the earliest start frame",
"func":1
},
{
"ref":"vipy.video.Scene.last_activity",
"url":16,
"doc":"Return the last activity of the video with the latest end frame",
"func":1
},
{
"ref":"vipy.video.Scene.activities",
"url":16,
"doc":"Return mutable dictionary of activities. All temporal alignment is relative to the current clip().",
"func":1
},
{
"ref":"vipy.video.Scene.activityindex",
"url":16,
"doc":"Return the  vipy.activity.Activity at the requested index order in the video",
"func":1
},
{
"ref":"vipy.video.Scene.activitylist",
"url":16,
"doc":"Return a list of activities in the video, returned in insertion order. Returns: A list of  vipy.activity.Activity insertion ordered into the original video  note The order of the activitylist() will not match the order of activityclip(), which is sorted by activity startframe. To match, use sorted(activitylist, key=lambda a: a.startframe( ",
"func":1
},
{
"ref":"vipy.video.Scene.activityfilter",
"url":16,
"doc":"Apply boolean lambda function f to each activity and keep activity if function is true, remove activity if function is false Filter out all activities longer than 128 frames   vid = vid.activityfilter(lambda a: len(a)<128)   Filter out activities with category in set   vid = vid.activityfilter(lambda a: a.category() in set(['category1', 'category2']   Args: f: [lambda] a lambda function that takes an activity and returns a boolean Returns: This video with the activities f(a) False removed.",
"func":1
},
{
"ref":"vipy.video.Scene.trackfilter",
"url":16,
"doc":"Apply lambda function f to each object and keep if filter is True. Args: activitytrack: [bool] If true, remove track assignment from activities also, may result in activities with no tracks f: [lambda] The lambda function to apply to each track t, and if f(t) returns True, then keep the track Returns: self, with tracks removed in-place  note Applying track filter with activitytrack=True may result in activities with no associated tracks. You should follow up with self.activityfilter(lambda a: len(a.trackids( > 0).",
"func":1
},
{
"ref":"vipy.video.Scene.trackmap",
"url":16,
"doc":"Apply lambda function f to each activity -strict=True: enforce that lambda function must return non-degenerate Track() objects",
"func":1
},
{
"ref":"vipy.video.Scene.activitymap",
"url":16,
"doc":"Apply lambda function f to each activity",
"func":1
},
{
"ref":"vipy.video.Scene.rekey",
"url":16,
"doc":"Change the track and activity IDs to randomly assigned UUIDs. Useful for cloning unique scenes.   v = vipy.video.RandomScene() v.rekey()  randomly rekey all track and activity ID v.rekey(tracks={ .})  rekey tracks (oldkey -> newkey) according to dictionary, randomly rekey activities v.rekey(tracks={ .}, activities={})  rekey tracks according to dict, no change to activities   Args: tracks [dict]: If not None, use this dictionary to remap oldkey->newkey for tracks. If None, use random keys. If empty dict, no change (do not rekey tracks) activities [dict]: If not None, use this dictionary to remap oldkey->newkey for activities. If None, use random keys. If empty dict, no change (do not rekey activities) Returns: This object, with all track ID and activity ID rekeyed as specified. All actor IDs in activities will be updated.",
"func":1
},
{
"ref":"vipy.video.Scene.annotation",
"url":16,
"doc":"Return an iterator over annotations in each frame.   for y in self.annotation(): for (bb,a) in y: print bb,a   Yields: for each frame yield the tuple: ( ( vipy.object.Detection , (tuple of  vipy.activity.Activity performed by the actor in this bounding box ,  . )  note The preferred method for accessing annotations is a frame iterator, which includes pixels. However, this method provides access to just the annotations without pixels.",
"func":1
},
{
"ref":"vipy.video.Scene.label",
"url":16,
"doc":"Return an iterator over labels in each frame",
"func":1
},
{
"ref":"vipy.video.Scene.labels",
"url":16,
"doc":"Return a set of all object and activity labels in this scene, or at frame int(k)",
"func":1
},
{
"ref":"vipy.video.Scene.activitylabel",
"url":16,
"doc":"Return an iterator over activity labels in each frame, starting from startframe and ending when there are no more activities",
"func":1
},
{
"ref":"vipy.video.Scene.activitylabels",
"url":16,
"doc":"Return a set of all activity categories in this scene, or at startframe, or in range [startframe, endframe]",
"func":1
},
{
"ref":"vipy.video.Scene.objectlabels",
"url":16,
"doc":"Return a python set of all activity categories in this scene, or at frame k. Args: k: [int] The object labels present at frame k. If k=None, then all object labels in the video lower: [bool] If true, return the object labels in alll lower case for case invariant string comparisonsn",
"func":1
},
{
"ref":"vipy.video.Scene.categories",
"url":16,
"doc":"Alias for labels()",
"func":1
},
{
"ref":"vipy.video.Scene.activity_categories",
"url":16,
"doc":"Alias for activitylabels()",
"func":1
},
{
"ref":"vipy.video.Scene.hasactivities",
"url":16,
"doc":"Does this video have any activities?",
"func":1
},
{
"ref":"vipy.video.Scene.hasactivity",
"url":16,
"doc":"Does this video have this activity id?",
"func":1
},
{
"ref":"vipy.video.Scene.hastracks",
"url":16,
"doc":"Does this video have any tracks?",
"func":1
},
{
"ref":"vipy.video.Scene.hastrack",
"url":16,
"doc":"Does the video have this trackid?  note Track IDs are available as vipy.object.Track().id()",
"func":1
},
{
"ref":"vipy.video.Scene.add",
"url":16,
"doc":"Synomym for  vipu.video.Scene.add_object ",
"func":1
},
{
"ref":"vipy.video.Scene.add_object",
"url":16,
"doc":"Add the object obj to the scene, and return an index to this object for future updates This function is used to incrementally build up a scene frame by frame. Obj can be one of the following types: - obj = vipy.object.Detection(), this must be called from within a frame iterator (e.g. for im in video) to get the current frame index - obj = vipy.object.Track() - obj = vipy.activity.Activity() It is recomended that the objects are added as follows. For a v=vipy.video.Scene():   for im in v:  Do some processing on frame im to detect objects v.add(object_detection(im   The frame iterator will keep track of the current frame in the video and add the objects in the appropriate place. Alternatively,   v.add(vipy.object.Track( ), frame=k)   Args: obj: A conformal python object to add to the scene ( vipy.object.Detection ,  vipy.object.Track ,  vipy.activity.Activity frame: [int] The frame to add the object rangecheck: [bool] If true, check if the object is within the image rectangle and throw an exception if not. This requires introspecting the video shape using  vipy.video.Video.shape . fluent: [bool] If true, return self instead of the object index",
"func":1
},
{
"ref":"vipy.video.Scene.delete_id",
"url":16,
"doc":"Delete a given track or activity by id, if present",
"func":1
},
{
"ref":"vipy.video.Scene.delete",
"url":16,
"doc":"Synonym for  vipy.video.Scene.delete_id ",
"func":1
},
{
"ref":"vipy.video.Scene.addframe",
"url":16,
"doc":"Add im=vipy.image.Scene() into vipy.video.Scene() at given frame. The input image must have been generated using im=self[k] for this to be meaningful, so that trackid can be associated",
"func":1
},
{
"ref":"vipy.video.Scene.clear",
"url":16,
"doc":"Remove all activities and tracks from this object",
"func":1
},
{
"ref":"vipy.video.Scene.cleartracks",
"url":16,
"doc":"Synonym for  vipy.video.Scene.clear_tracks ",
"func":1
},
{
"ref":"vipy.video.Scene.clear_tracks",
"url":16,
"doc":"Clear all tracks from this object",
"func":1
},
{
"ref":"vipy.video.Scene.clearactivities",
"url":16,
"doc":"Synonym for  vipy.video.Scene.clear_activities ",
"func":1
},
{
"ref":"vipy.video.Scene.clear_activities",
"url":16,
"doc":"Clear all activities from this object",
"func":1
},
{
"ref":"vipy.video.Scene.replace",
"url":16,
"doc":"Replace tracks and activities with other if activity/track is during frame",
"func":1
},
{
"ref":"vipy.video.Scene.json",
"url":16,
"doc":"Return JSON encoded string of this object. This may fail if attributes contain non-json encodeable object. Try self.sanitize() or self.clone(sanitize=True) first",
"func":1
},
{
"ref":"vipy.video.Scene.csv",
"url":16,
"doc":"Export scene to CSV file format with header. If there are no tracks, this will be empty.",
"func":1
},
{
"ref":"vipy.video.Scene.framerate",
"url":16,
"doc":"Return the current frame rate of change the input framerate for the video and update frame indexes for all annotations. The framerate may be None in the constructor if the framerate is not know until a video is downloaded This function will request the framerate from the video file if it has been downloaded and cache it in _framerate If the video has not been loaded, the framerate will be changed in the ffmpeg filter chain and will update framerate for tracks/activities If the video has been loaded, the framerate will not be changed, since this requires resampling the image buffer which is an unsupported operation If the framerate is allowed to change after load, then any objects will no longer match the pixels and the framerate will only change the playback speed which is not very useful   fps = self.framerate() self.framerate(fps=15.0)   Args: fps [float]: the new frames per second round ['up','down','near']: The rounding option for ffmpeg fps filter, used for temporal downsampling",
"func":1
},
{
"ref":"vipy.video.Scene.activitysplit",
"url":16,
"doc":"Split the scene into k separate scenes, one for each activity. Do not include overlapping activities. Args: idx: [int],[tuple],[list]. Return only those activities in the provided activity index list, where the activity index is the integer index of the activity in the video.  note This is useful for union()",
"func":1
},
{
"ref":"vipy.video.Scene.tracksplit",
"url":16,
"doc":"Split the scene into k separate scenes, one for each track. Each scene starts at frame 0 and is a shallow copy of self containing exactly one track. - This is useful for visualization by breaking a scene into a list of scenes that contain only one track. - The attribute '_trackindex' is set in the attributes dictionary to provide provenance for the track relative to the source video  notes Use clone() to create a deep copy if needed.",
"func":1
},
{
"ref":"vipy.video.Scene.trackclip",
"url":16,
"doc":"Split the scene into k separate scenes, one for each track. Each scene starts and ends when the track starts and ends",
"func":1
},
{
"ref":"vipy.video.Scene.activityclip",
"url":16,
"doc":"Return a list of  vipy.video.Scene objects each clipped to be temporally centered on a single activity, with an optional padframes before and after. Args: padframes: [int] for symmetric padding same before and after padframes: [tuple] (int, int) for asymmetric padding before and after padframes: [list[tuples [(int, int),  .] for activity specific asymmetric padding. See also padto. multilabel: [bool] include overlapping multilabel secondary activities in each activityclip idx: [int], [tuple], [list]. The indexes of the activities to return, where the index is the integer index order of the activity in the video. Useful for complex videos. padto: [int] padding so that each activity clip is at least padto frames long, with symmetric padding around the activity. padtosec: [float] padding so that each activity clip is at least padtosec seconds long, with symmetric padding around the activity. Returns: A list of  vipy.video.Scene each cloned from the source video and clipped on one activity in the scene  notes - The Scene() category is updated to be the activity category of the clip, and only the objects participating in the activity are included. - Clips are returned ordered in the temporal order they appear in the video. - The returned vipy.video.Scene() objects for each activityclip are clones of the video, with the video buffer flushed. - Each activityclip() is associated with each activity in the scene, and includes all other secondary activities that the objects in the primary activity also perform (if multilabel=True). See activityclip().labels(). - Calling activityclip() on activityclip(multilabel=True) will duplicate activities, due to the overlapping secondary activities being included in each clip with an overlap. Be careful!",
"func":1
},
{
"ref":"vipy.video.Scene.noactivitylist",
"url":16,
"doc":"Return a list of  vipy.activity.Activity which are segments of each track with no associated activities. Args: label: [str] The activity label to give the background activities. Defaults to the track category (lowercase) Returns: A list of  vipy.activity.Activity such that each activity is associated with a track with temporal support where no activities are performed. The union of activitylist() and noactivitylist() should cover the temporal support of all track",
"func":1
},
{
"ref":"vipy.video.Scene.noactivityclip",
"url":16,
"doc":"Return a list of vipy.video.Scene() each clipped on a track segment that has no associated activities. Args: label: [str] The activity label to give the background activities. Defaults to the track category (lowercase) padframes: [int] The amount of temporal padding to apply to the clips before and after in frames. See  vipy.video.Scene.activityclip for options. Returns: A list of  vipy.video.Scene each cloned from the source video and clipped in the temporal region between activities. The union of activityclip() and noactivityclip() should equal the entire video.  notes - Each clip will contain exactly one activity \"Background\" which is the interval for this track where no activities are occurring - Each clip will be at least one frame long",
"func":1
},
{
"ref":"vipy.video.Scene.trackbox",
"url":16,
"doc":"The trackbox is the union of all track bounding boxes in the video, or None if there are no tracks Args: dilate: [float] A dilation factor to apply to the trackbox before returning. See  vipy.geometry.BoundingBox.dilate Returns: A  vipy.geometry.BoundingBox which is the union of all boxes in the track (or None if no boxes exist)",
"func":1
},
{
"ref":"vipy.video.Scene.framebox",
"url":16,
"doc":"Return the bounding box for the image rectangle. Returns: A  vipy.geometry.BoundingBox which defines the image rectangle  notes: This requires calling  vipy.video.Video.preview to get the frame shape from the current filter chain, which touches the video file",
"func":1
},
{
"ref":"vipy.video.Scene.trackcrop",
"url":16,
"doc":"Return the trackcrop() of the scene which is the crop of the video using the  vipy.video.Scene.trackbox . Args: zeropad: [bool] If True, the zero pad the crop if it is outside the image rectangle, otherwise return only valid pixels inside the image rectangle maxsquare: [bool] If True, make the bounding box the maximum square before cropping dilate: [float] The dilation factor to apply to the trackbox prior to cropping Returns: A  vipy.video.Scene object from cropping the video using the trackbox. If there are no tracks, return None.",
"func":1
},
{
"ref":"vipy.video.Scene.activitybox",
"url":16,
"doc":"The activitybox is the union of all activity bounding boxes in the video, which is the union of all tracks contributing to all activities. This is most useful after activityclip(). The activitybox is the smallest bounding box that contains all of the boxes from all of the tracks in all activities in this video.",
"func":1
},
{
"ref":"vipy.video.Scene.activitycuboid",
"url":16,
"doc":"The activitycuboid() is the fixed square spatial crop corresponding to the activitybox (or supplied bounding box), which contains all of the valid activities in the scene. This is most useful after activityclip(). The activitycuboid() is a spatial crop of the video corresponding to the supplied boundingbox or the square activitybox(). This crop must be resized such that the maximum dimension is provided since the crop can be tiny and will not be encodable by ffmpeg",
"func":1
},
{
"ref":"vipy.video.Scene.activitysquare",
"url":16,
"doc":"The activity square is the maxsquare activitybox that contains only valid (non-padded) pixels interior to the image",
"func":1
},
{
"ref":"vipy.video.Scene.activitytube",
"url":16,
"doc":"The activitytube() is a sequence of crops where the spatial box changes on every frame to track the activity. The box in each frame is the square activitybox() for this video which is the union of boxes contributing to this activity in each frame. This function does not perform any temporal clipping. Use activityclip() first to split into individual activities. Crops will be optionally dilated, with zeropadding if the box is outside the image rectangle. All crops will be resized so that the maximum dimension is maxdim (and square by default)",
"func":1
},
{
"ref":"vipy.video.Scene.actortube",
"url":16,
"doc":"The actortube() is a sequence of crops where the spatial box changes on every frame to track the primary actor performing an activity. The box in each frame is the square box centered on the primary actor performing the activity, dilated by a given factor (the original box around the actor is unchanged, this just increases the context, with zero padding) This function does not perform any temporal clipping. Use activityclip() first to split into individual activities. All crops will be resized so that the maximum dimension is maxdim (and square by default)",
"func":1
},
{
"ref":"vipy.video.Scene.speed",
"url":16,
"doc":"Change the speed by a multiplier s. If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)",
"func":1
},
{
"ref":"vipy.video.Scene.clip",
"url":16,
"doc":"Clip the video to between (start, end), relative to the current clip in the source video shown by __repr__(). Args: start: [int|float] the start frame|second relative to the video framerate() for the clip end: [int|float] the end frame|second relative to the video framerate for the clip, may be none Returns: This video object, clipped so that a load() will result in frame=0 equivalent to startframe. All tracks and activities updated relative to the new startframe.  note: - This return a clone of the video for idempotence - This does not load the video. This updates the ffmpeg filter chain to temporally trim the video. See self.commandline() for the updated filter chain to run.",
"func":1
},
{
"ref":"vipy.video.Scene.crop",
"url":16,
"doc":"Crop the video using the supplied box, update tracks relative to crop, video is zeropadded if box is outside frame rectangle",
"func":1
},
{
"ref":"vipy.video.Scene.zeropad",
"url":16,
"doc":"Zero pad the video with padwidth columns before and after, and padheight rows before and after Update tracks accordingly.",
"func":1
},
{
"ref":"vipy.video.Scene.fliplr",
"url":16,
"doc":"Mirror the video left/right by flipping horizontally",
"func":1
},
{
"ref":"vipy.video.Scene.flipud",
"url":16,
"doc":"Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.Scene.rot90ccw",
"url":16,
"doc":"Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.Scene.rot90cw",
"url":16,
"doc":"Rotate the video 90 degrees clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.video.Scene.resize",
"url":16,
"doc":"Resize the video to (rows, cols), preserving the aspect ratio if only rows or cols is provided",
"func":1
},
{
"ref":"vipy.video.Scene.mindim",
"url":16,
"doc":"Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio, return the minimum dimension if dim=None",
"func":1
},
{
"ref":"vipy.video.Scene.maxdim",
"url":16,
"doc":"Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio",
"func":1
},
{
"ref":"vipy.video.Scene.rescale",
"url":16,
"doc":"Spatially rescale the scene by a constant scale factor. Args: s: [float] Scale factor > 0 to isotropically scale the image.",
"func":1
},
{
"ref":"vipy.video.Scene.startframe",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Scene.extrapolate",
"url":16,
"doc":"Extrapolate the video to frame f and add the extrapolated tracks to the video",
"func":1
},
{
"ref":"vipy.video.Scene.download",
"url":16,
"doc":"Download URL to filename provided by constructor, or to temp filename. Args: timeout: [int] An integer timeout in seconds for the download to connect verbose: [bool] If trye, show more verbose console output max_filesize: [str] A string of the form 'NNNg' or 'NNNm' for youtube downloads to limit the maximum size of a URL to '350m' 350MB or '12g' for 12GB. Returns: This video object with the video downloaded to the filename()",
"func":1
},
{
"ref":"vipy.video.Scene.dedupe",
"url":16,
"doc":"Find and delete duplicate tracks and activities by overlap. Track deduplication algorithm - For each pair of tracks with the same category, find the larest temporal segment that contains both tracks. - For this segment, compute the IOU for each box interpolated at a stride of dt frames - Compute the mean IOU for this segment. This is the segment IOU. - If the segment IOU is greater than the threshold, merge the shorter of the two tracks with the current track. Activity deduplication algorithm - For each pair of activities in insertion order - If the temporal IOU is greater than the threshold, then merge the older activity (later insertion) with the newer activity (earlier insertion) - Update the actor ID of the merged activity to be that of the newer activity",
"func":1
},
{
"ref":"vipy.video.Scene.combine",
"url":16,
"doc":"Combine the activities and tracks from both scenes into self.  note This does not perform a union, it simply combines dictionaries. For deduplication, see  vipy.video.Scene.union ",
"func":1
},
{
"ref":"vipy.video.Scene.union",
"url":16,
"doc":"Compute the union two scenes as the set of unique activities and tracks. A pair of activities or tracks are non-unique if they overlap spatially and temporally by a given IoU threshold. Merge overlapping tracks. Tracks are merged by considering the mean IoU at the overlapping segment of two tracks with the same category greater than the provided spatial_iou_threshold threshold Activities are merged by considering the temporal IoU of the activities of the same class greater than the provided temporal_iou_threshold threshold Args: Other: Scene or list of scenes for union. Other may be a clip of self at a different framerate, spatial isotropic scake, clip offset spatial_iou_threshold: The intersection over union threshold for the mean of the two segments of an overlapping track, Disable by setting to 1.0 temporal_iou_threshold: The intersection over union threshold for a temporal bounding box for a pair of activities to be declared duplicates. Disable by setting to 1.0 strict: Require both scenes to share the same underlying video filename overlap=['average', 'replace', 'keep'] - average: Merge two tracks by averaging the boxes (average=True) if overlapping - replace: merge two tracks by replacing overlapping boxes with other (discard self) - keep: merge two tracks by keeping overlapping boxes with other (discard other) percentilecover: [0,1]: When determining the assignment of two tracks, compute the percentilecover of two tracks by ranking the cover in the overlapping segment and computing the mean of the top-k assignments, where k=len(segment) percentilecover. percentilesamples: [>1]: the number of samples along the overlapping scemgne for computing percentile cover activity: [bool]: union() of activities only track: [bool]: union() of tracks only Returns: Updates this scene to include the non-overlapping activities from other. By default, it takes the strict union of all activities and tracks.  note - This is useful for merging scenes computed using a lower resolution/framerate/clipped object or activity detector without running the detector on the high-res scene - This function will preserve the invariance for v  v.clear().union(v.rescale(0.5).framerate(5).activityclip( , to within the quantization error of framerate() downsampling. - percentileiou is a robust method of track assignment when boxes for two tracks (e.g. ground truth and detections) where one track may deform due to occlusion.",
"func":1
},
{
"ref":"vipy.video.Scene.annotate",
"url":16,
"doc":"Generate a video visualization of all annotated objects and activities in the video. The annotation video will be at the resolution and framerate of the underlying video, and pixels in this video will now contain the overlay. This function does not play the video, it only generates an annotation video frames. Use show() which is equivalent to annotate().saveas().play() Args: outfile: [str] An optional file to stream the anntation to without storing the annotated video in memory fontsize: [int] The fontsize of bounding box captions, used by matplotlib captionoffset: (tuple) The (x,y) offset relative to the bounding box to place the caption for each box. shortlabel: [dict] If provided, convert the label to shortlabel for display boxalpha: [float] The transparency of the box face behind the text. Must be in [0,1], where 0=transparent and 1=opaque. d_category2color: [dict] A dictionary mapping categories of objects in the scene to their box colors. Named colors must be in  vipy.gui.using_matplotlib.colorlist . categories: [list] Only show these categories, or show them all if None nocaption_withstring: [list]: Do not show captions for those detection categories containing any of the strings in the provided list nocaption: [bool] If true, do not show any captions, just boxes mutator: [lambda] A lambda function that will mutate an image to allow for complex visualizations. This should be a mutator like  vipy.image.mutator_show_trackid . timestamp: [bool] If true, show a semitransparent timestamp (when the annotation occurs, not when the video was collected) with frame number in the upper left corner of the video theme [str]: If 'dark', visualize captions with darkj background and light foreground, if 'light' visualize captions with light background and dark foreground verbose: [bool] Show more helpful messages if true Returns: A  vipy.video.Video with annotations in the pixels. If outfile is provided, then the returned video will be flushed.  note In general, this function should not be run on very long videos without the outfile kwarg, as it requires loading the video framewise into memory.",
"func":1
},
{
"ref":"vipy.video.Scene.show",
"url":16,
"doc":"Faster show using interative image show for annotated videos. This can visualize videos before video rendering is complete, but it cannot guarantee frame rates. Large videos with complex scenes will slow this down and will render at lower frame rates.",
"func":1
},
{
"ref":"vipy.video.Scene.thumbnail",
"url":16,
"doc":"Return annotated frame=k of video, save annotation visualization to provided outfile if provided, otherwise return vipy.image.Scene",
"func":1
},
{
"ref":"vipy.video.Scene.stabilize",
"url":16,
"doc":"Background stablization using flow based stabilization masking foreground region. - This will output a video with all frames aligned to the first frame, such that the background is static. - This uses the flow based approach described in  vipy.flow.Flow.stabilize Args: padheightfrac: [float] The height padding (relative to video height) to be applied to output video to allow for vertical stabilization padwidthfrac: [float] The width padding (relative to video width) to be applied to output video to allow for horizontal stabilization padheightpx: [int] The height padding to be applied to output video to allow for vertical stabilization. Overrides padheight. padwidthpx: [int] The width padding to be applied to output video to allow for horizontal stabilization. Overrides padwidth. gpu: [int] The GPU index to use, if opencv has been compiled with GPU support (this is rare) outfile: [str] The output filename to store the stabilized video Returns: A clone of this video with background pixels stabilized to the first frame.  note - If the camera pans outside the image rectangle, increase the padheight or padwidth to make sure that the actor stays inside the stabilized image rectangle - If there are moving actors in the scene, include bounding boxes for each and these boxes are ignored as keeyouts in the flow stabilization",
"func":1
},
{
"ref":"vipy.video.Scene.pixelmask",
"url":16,
"doc":"Replace all pixels in foreground boxes with pixelation (e.g. bigger pixels, like privacy glass)",
"func":1
},
{
"ref":"vipy.video.Scene.pixelize",
"url":16,
"doc":"Alias for pixelmask()",
"func":1
},
{
"ref":"vipy.video.Scene.pixelate",
"url":16,
"doc":"Alias for pixelmask()",
"func":1
},
{
"ref":"vipy.video.Scene.binarymask",
"url":16,
"doc":"Replace all pixels in foreground boxes with white, zero in background",
"func":1
},
{
"ref":"vipy.video.Scene.asfloatmask",
"url":16,
"doc":"Replace all pixels in foreground boxes with fg, and bg in background, return a copy",
"func":1
},
{
"ref":"vipy.video.Scene.meanmask",
"url":16,
"doc":"Replace all pixels in foreground boxes with mean color",
"func":1
},
{
"ref":"vipy.video.Scene.fgmask",
"url":16,
"doc":"Replace all pixels in foreground boxes with zero",
"func":1
},
{
"ref":"vipy.video.Scene.zeromask",
"url":16,
"doc":"Alias for fgmask",
"func":1
},
{
"ref":"vipy.video.Scene.blurmask",
"url":16,
"doc":"Replace all pixels in foreground boxes with gaussian blurred foreground",
"func":1
},
{
"ref":"vipy.video.Scene.downcast",
"url":16,
"doc":"Cast the object to a  vipy.video.Video class",
"func":1
},
{
"ref":"vipy.video.Scene.merge_tracks",
"url":16,
"doc":"Merge tracks if a track endpoint dilated by a fraction overlaps exactly one track startpoint, and the endpoint and startpoint are close enough together temporally.  note - This is useful for continuing tracking when the detection framerate was too low and the assignment falls outside the measurement gate. - This will not work for complex scenes, as it assumes that there is exactly one possible continuation for a track.",
"func":1
},
{
"ref":"vipy.video.Scene.assign",
"url":16,
"doc":"Assign a list of  vipy.object.Detection object detections and  vipy.activity.Activity activity detections at frame k to scene tracks and activities by greedy assignment. In-place update. Approach: - This approach is equivalent to greedy, constant velocity SORT tracking (https: arxiv.org/abs/1602.00763) - Individual detections are assigned to tracks using a greedy velocity only track propagation, sorted by  vipy.geometry.BoundingBox.maxcover and detection confidence within a spatial tracking gate - New tracks are created if the detection is unassigned and above a minimum confidence - Updated tracks resulting from assignment are stored in  vipy.video.Scene.tracks Args: frame: [int] The frame index to assign the detections into the scene dets: [list] A list of  vipy.object.Detection or  vipy.activity.Activity objects as returned from a detector miniou: [float] the minimum temporal IOU for activity assignment minconf: [float] the minimum confidence for a detection to be considered as a new track maxhistory: [int] the maximum propagation length of a track with no measurements, the frame history used for velocity estimates trackconfsamples: [int] the number of uniformly spaced samples along a track to compute a mean track confidence gate: [int] the gating distance in pixels used for assignment of fast moving detections. Useful for low detection framerates if a detection does not overlap with the track. trackcover: [float] the minimum cover necessary for assignment of a detection to a track activitymerge: [bool] if true, then merge overlapping activity detections of the same track and category, otherwise each activity detection is added as a new detection activitynms: [bool] if true, then perform non-maximum suppression of activity detections of the same actor and category that overlap more than activityiou Returns: This video object with each det assigned to corresponding track or activity.",
"func":1
},
{
"ref":"vipy.video.Scene.attributes",
"url":16,
"doc":""
},
{
"ref":"vipy.video.Scene.metadata",
"url":16,
"doc":"Return a dictionary of metadata about this video. Args: k [str]: If provided, return just the specified key of the attributes dictionary, otherwise return the attributes dictionary Returns: The 'attributes' dictionary, or just the value for the provided key k if provided",
"func":1
},
{
"ref":"vipy.video.Scene.sanitize",
"url":16,
"doc":"Remove all private keys from the attributes dictionary. The attributes dictionary is useful storage for arbitrary (key,value) pairs. However, this storage may contain sensitive information that should be scrubbed from the video before serialization. As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key. This is analogous to private or reserved attributes in the python lanugage. Users should reserve these keynames for those keys that should be sanitized and removed before any seerialization of this object.   assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey')  False  ",
"func":1
},
{
"ref":"vipy.video.Scene.videoid",
"url":16,
"doc":"Return a unique video identifier for this video, as specified in the 'video_id' attribute Args: newid: [str] If not None, then update the video_id as newid. Returns: The video ID if newid=None else self",
"func":1
},
{
"ref":"vipy.video.Scene.store",
"url":16,
"doc":"Store the current video file as an attribute of this object. Useful for archiving an object to be fully self contained without any external references.   v  v.store().restore(v.filename(    note -Remove this stored video using unstore() -Unpack this stored video and set up the video chains using restore() -This method is more efficient than load() followed by pkl(), as it stores the encoded video as a byte string. -Useful for creating a single self contained object for distributed processing.",
"func":1
},
{
"ref":"vipy.video.Scene.unstore",
"url":16,
"doc":"Delete the currently stored video from  vipy.video.Video.store",
"func":1
},
{
"ref":"vipy.video.Scene.restore",
"url":16,
"doc":"Save the currently stored video as set using  vipy.video.Video.store to filename, and set up filename",
"func":1
},
{
"ref":"vipy.video.Scene.concatenate",
"url":16,
"doc":"Temporally concatenate a sequence of videos into a single video stored in outfile.   (v1, v2, v3) = (vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32 vc = vipy.video.Video.concatenate v1, v2, v3), 'concatenated.mp4', youtube_chapters=lambda v: v.category(   In this example, vc will point to concatenated.mp4 which will contain (v1,v2,v3) concatenated temporally . Args: videos: a single video or an iterable of videos of type  vipy.video.Video or an iterable of video files outfile: the output filename to store the concatenation. youtube_chapters: [bool, callable]: If true, output a string that can be used to define the start and end times of chapters if this video is uploaded to youtube. The string output should be copied to the youtube video description in order to enable chapters on playback. This argument will default to the string representation ofo the video, but you may also pass a callable of the form: 'youtube_chapters=lambda v: str(v)' which will output the provided string for each video chapter. A useful lambda is 'youtube_chapters=lambda v: v.category()' framerate: [float]: The output frame rate of outfile Returns: A  vipy.video.Video object with filename()=outfile, such that outfile contains the temporal concatenation of pixels in (self, videos).  note - self will not be modified, this will return a new  vipy.video.Video object. - All videos must be the same shape(). If the videos are different shapes, you must pad them to a common size equal to self.shape(). Try  vipy.video.Video.zeropadlike . - The output video will be at the framerate of self.framerate(). - if you want to concatenate annotations, call  vipy.video.Scene.annotate first on the videos to save the annotations into the pixels, then concatenate.",
"func":1
},
{
"ref":"vipy.video.Scene.stream",
"url":16,
"doc":"Iterator to yield groups of frames streaming from video. A video stream is a real time iterator to read or write from a video. Streams are useful to group together frames into clips that are operated on as a group. The following use cases are supported:   v = vipy.video.RandomScene()   Stream individual video frames lagged by 10 frames and 20 frames   for (im1, im2) in zip(v.stream().frame(n=-10), v.stream().frame(n=-20 : print(im1, im2)   Stream overlapping clips such that each clip is a video n=16 frames long and starts at frame i, and the next clip is n=16 frames long and starts at frame i=i+m   for vc in v.stream().clip(n=16, m=4): print(vc)   Stream non-overlapping batches of frames such that each clip is a video of length n and starts at frame i, and the next clip is length n and starts at frame i+n   for vb in v.stream().batch(n=16): print(vb)   Create a write stream to incrementally add frames to long video.   vi = vipy.video.Video(filename='/path/to/output.mp4') vo = vipy.video.Video(filename='/path/to/input.mp4') with vo.stream(write=True) as s: for im in vi.stream(): s.write(im)  manipulate pixels of im, if desired   Create a 480p YouTube live stream from an RTSP camera at 5Hz   vo = vipy.video.Scene(url='rtmp: a.rtmp.youtube.com/live2/$SECRET_STREAM_KEY') vi = vipy.video.Scene(url='rtsp: URL').framerate(5) with vo.framerate(5).stream(write=True, bitrate='1000k') as s: for im in vi.framerate(5).resize(cols=854, rows=480): s.write(im)   Args: write: [bool] If true, create a write stream overwrite: [bool] If true, and the video output filename already exists, overwrite it bufsize: [int] The maximum queue size for the ffmpeg pipe thread in the primary iterator. The queue size is the maximum size of pre-fetched frames from the ffmpeg pip. This should be big enough that you are never waiting for queue fills bitrate: [str] The ffmpeg bitrate of the output encoder for writing, written like '2000k' bufsize: [int] The maximum size of the stream buffer in frames. The stream buffer length should be big enough so that all iterators can yield before deleting old frames Returns: A Stream object  note Using this iterator may affect PDB debugging due to stdout/stdin redirection. Use ipdb instead.",
"func":1
},
{
"ref":"vipy.video.Scene.bytes",
"url":16,
"doc":"Return a bytes representation of the video file",
"func":1
},
{
"ref":"vipy.video.Scene.frames",
"url":16,
"doc":"Alias for __iter__()",
"func":1
},
{
"ref":"vipy.video.Scene.commandline",
"url":16,
"doc":"Return the equivalent ffmpeg command line string that will be used to transcode the video. This is useful for introspecting the complex filter chain that will be used to process the video. You can try to run this command line yourself for debugging purposes, by replacing 'dummyfile' with an appropriately named output file.",
"func":1
},
{
"ref":"vipy.video.Scene.probeshape",
"url":16,
"doc":"Return the (height, width) of underlying video file as determined from ffprobe  warning this does not take into account any applied ffmpeg filters. The shape will be the (height, width) of the underlying video file.",
"func":1
},
{
"ref":"vipy.video.Scene.duration_in_seconds_of_videofile",
"url":16,
"doc":"Return video duration of the source filename (NOT the filter chain) in seconds, requires ffprobe. Fetch once and cache.  notes This is the duration of the source video and NOT the duration of the filter chain. If you load(), this may be different duration depending on clip() or framerate() directives.",
"func":1
},
{
"ref":"vipy.video.Scene.duration_in_frames_of_videofile",
"url":16,
"doc":"Return video duration of the source video file (NOT the filter chain) in frames, requires ffprobe.  notes This is the duration of the source video and NOT the duration of the filter chain. If you load(), this may be different duration depending on clip() or framerate() directives.",
"func":1
},
{
"ref":"vipy.video.Scene.duration",
"url":16,
"doc":"Return a video clipped with frame indexes between (0, frames) or (0,seconds self.framerate( or (0,minutes 60 self.framerate(). Return duration in seconds if no arguments are provided.",
"func":1
},
{
"ref":"vipy.video.Scene.duration_in_frames",
"url":16,
"doc":"Return the duration of the video filter chain in frames, equal to round(self.duration() self.framerate( . Requires a probe() of the video to get duration",
"func":1
},
{
"ref":"vipy.video.Scene.framerate_of_videofile",
"url":16,
"doc":"Return video framerate in frames per second of the source video file (NOT the filter chain), requires ffprobe.",
"func":1
},
{
"ref":"vipy.video.Scene.resolution_of_videofile",
"url":16,
"doc":"Return video resolution in (height, width) in pixels (NOT the filter chain), requires ffprobe.",
"func":1
},
{
"ref":"vipy.video.Scene.probe",
"url":16,
"doc":"Run ffprobe on the filename and return the result as a dictionary Args: Any keyword arguments supported by python-ffmpeg probe() - these are passed in as-is - for flags, use flag_name=None (e.g., show_frames=None) so that ffmpeg.probe() handles them correctly",
"func":1
},
{
"ref":"vipy.video.Scene.frame_meta",
"url":16,
"doc":"Return the frame metadata of the underlying video file using ffprobe for all frames as a list of dicts, each list element corresponding to a frame. This is useful for extracting frame types (e.g. i-frames). Args: k [int]: Return only the frame metadata for frame index k (relative to framerate of source videofile, not filter chain) Returns: a list of metadata dicts (one per frame) or a single dict for the requested frame.  notes - This will return a large amount of metadata for the entire source video (not the FFMPEG filter chain), use with caution. - To get frame metata for a filter chain use vipy.video.Video.savetemp().frame_meta(), which will save the video to a temporary file prior to extracting frame metadata",
"func":1
},
{
"ref":"vipy.video.Scene.metaframe",
"url":16,
"doc":"Alias for  vipy.video.Video.frame_meta ",
"func":1
},
{
"ref":"vipy.video.Scene.iframes",
"url":16,
"doc":"Return a list of i-frame indexes (e.g. intra-frame, a video frame that is independent from other frames for decoding) in this video file.  note - To return the i-frame indexes for the current filter chain use self.saveas().iframes() to save to a temporary file prior to i-frame index extraction. - To extract the i-frame itself, use [self.frame(k) for k in self.iframes()]",
"func":1
},
{
"ref":"vipy.video.Scene.print",
"url":16,
"doc":"Print the representation of the video This is useful for debugging in long fluent chains. Sleep is useful for adding in a delay for distributed processing. Args: prefix: prepend a string prefix to the video __repr__ when printing. Useful for logging. sleep: Integer number of seconds to sleep[ before returning Returns: The video object after sleeping",
"func":1
},
{
"ref":"vipy.video.Scene.printif",
"url":16,
"doc":"Call  vipy.video.Video.print if b=True. Useful for fluent chains to print periodically.",
"func":1
},
{
"ref":"vipy.video.Scene.dict",
"url":16,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding.",
"func":1
},
{
"ref":"vipy.video.Scene.take",
"url":16,
"doc":"Return n frames from the clip uniformly spaced as numpy array Args: n: Integer number of uniformly spaced frames to return Returns: A numpy array of shape (n,W,H)  warning This assumes that the entire video is loaded into memory (e.g. call  vipy.video.Video.load ). Use with caution.",
"func":1
},
{
"ref":"vipy.video.Scene.colorspace",
"url":16,
"doc":"Return or set the colorspace as ['rgb', 'bgr', 'lum', 'float']. This will not change pixels, only the colorspace interpretation of pixels.",
"func":1
},
{
"ref":"vipy.video.Scene.nourl",
"url":16,
"doc":"Remove the  vipy.video.Video.url from the video",
"func":1
},
{
"ref":"vipy.video.Scene.url",
"url":16,
"doc":"Video URL and URL download properties",
"func":1
},
{
"ref":"vipy.video.Scene.isloaded",
"url":16,
"doc":"Return True if the video has been loaded",
"func":1
},
{
"ref":"vipy.video.Scene.is_loaded",
"url":16,
"doc":"Return True if the video has been loaded",
"func":1
},
{
"ref":"vipy.video.Scene.isloadable",
"url":16,
"doc":"Return True if the video can be loaded successfully. This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version. Args: flush: [bool] If true, flush the video after it loads. This will clear the video pixel buffer Returns: True if load() can be called without FFMPEG exception. If flush=False, then self will contain the loaded video, which is helpful to avoid load() twice in some conditions  warning This requires loading and flushing the video. This is an expensive operation when performed on many videos and may result in out of memory conditions with long videos. Use with caution! Try  vipy.video.Video.canload to test if a single frame can be loaded as a less expensive alternative.",
"func":1
},
{
"ref":"vipy.video.Scene.canload",
"url":16,
"doc":"Return True if the video can be previewed at frame=k successfully. This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.  notes This will only try to preview a single frame. This will not check if the entire video is loadable. Use  vipy.video.Video.isloadable in this case This will hang if calling canload on a streaming URL.",
"func":1
},
{
"ref":"vipy.video.Scene.iscolor",
"url":16,
"doc":"Is the video a three channel color video as returned from  vipy.video.Video.channels ?",
"func":1
},
{
"ref":"vipy.video.Scene.isgrayscale",
"url":16,
"doc":"Is the video a single channel as returned from  vipy.video.Video.channels ?",
"func":1
},
{
"ref":"vipy.video.Scene.hasfilename",
"url":16,
"doc":"Does the filename returned from  vipy.video.Video.filename exist?",
"func":1
},
{
"ref":"vipy.video.Scene.isdownloaded",
"url":16,
"doc":"Alias for  vipy.video.Video.is_downloaded ",
"func":1
},
{
"ref":"vipy.video.Scene.is_downloaded",
"url":16,
"doc":"Does the filename returned from  vipy.video.Video.filename exist, meaning that the url has been downloaded to a local file?",
"func":1
},
{
"ref":"vipy.video.Scene.hasurl",
"url":16,
"doc":"Is the url returned from  vipy.video.Video.url a well formed url?",
"func":1
},
{
"ref":"vipy.video.Scene.array",
"url":16,
"doc":"Set or return the video buffer as a numpy array. Args: array: [np.array] A numpy array of size NxHxWxC = (frames, height, width, channels) of type uint8 or float32. array: [list] A list of  vipy.image.Image objects copy: [bool] If true, copy the buffer by value instaed of by reference. Copied buffers do not share pixels. Returns: if array=None, return a reference to the pixel buffer as a numpy array, otherwise return the video object with the array populated",
"func":1
},
{
"ref":"vipy.video.Scene.from_array",
"url":16,
"doc":"Create a new video from a shared array, Equivalent to self.array( ., copy=False)",
"func":1
},
{
"ref":"vipy.video.Scene.from_directory",
"url":16,
"doc":"Create a video from a directory of frames stored as individual image filenames. Given a directory with files: framedir/image_0001.jpg framedir/image_0002.jpg   vipy.video.Video(frames='/path/to/framedir')  ",
"func":1
},
{
"ref":"vipy.video.Scene.from_frames",
"url":16,
"doc":"Create a video from a list of frames",
"func":1
},
{
"ref":"vipy.video.Scene.from_annotation_sequence",
"url":16,
"doc":"Construct a video from an input image im where each frame is the acculation of annnotated objects in im. This is useful for visualization of a labeling sequence",
"func":1
},
{
"ref":"vipy.video.Scene.to_numpy",
"url":16,
"doc":"Alias for numpy()",
"func":1
},
{
"ref":"vipy.video.Scene.mutable",
"url":16,
"doc":"Return a video object with a writeable mutable frame array. Video must be loaded, triggers copy of underlying numpy array if the buffer is not writeable. Returns: This object with a mutable frame buffer in self.array() or self.numpy()",
"func":1
},
{
"ref":"vipy.video.Scene.numpy",
"url":16,
"doc":"Convert the video to a writeable numpy array, triggers a load() and copy() as needed. Returns the numpy array.",
"func":1
},
{
"ref":"vipy.video.Scene.filename",
"url":16,
"doc":"Update video Filename with optional copy or symlink from existing file (self.filename( to new file",
"func":1
},
{
"ref":"vipy.video.Scene.abspath",
"url":16,
"doc":"Change the path of the filename from a relative path to an absolute path (not relocatable)",
"func":1
},
{
"ref":"vipy.video.Scene.relpath",
"url":16,
"doc":"Replace the filename with a relative path to parent (or current working directory if none). Usage:   v = vipy.video.Video(filename='/path/to/dataset/video/category/out.mp4') v.relpath(parent='/path/to/dataset') v.filename()  'video/category/out.mp4'   If the current working directory is /path/to/dataset, and v.load() is called, the filename will be loaded. Args: parent [str]: A parent path of the current filename to remove and be relative to. If filename is '/path/to/video.mp4' then filename must start with parent, then parent will be remvoed from filename. start [str]: Return a relative filename starting from path start='/path/to/dir' that will create a relative path to this filename. If start='/a/b/c' and filename='/a/b/d/e/f.ext' then return filename ' /d/e/f.ext' Returns: This video object with the filename changed to be a relative path",
"func":1
},
{
"ref":"vipy.video.Scene.rename",
"url":16,
"doc":"Move the underlying video file preserving the absolute path, such that self.filename()  '/a/b/c.ext' and newname='d.ext', then self.filename() -> '/a/b/d.ext', and move the corresponding file",
"func":1
},
{
"ref":"vipy.video.Scene.filesize",
"url":16,
"doc":"Return the size in bytes of the filename(), None if the filename() is invalid",
"func":1
},
{
"ref":"vipy.video.Scene.downloadif",
"url":16,
"doc":"Download URL to filename if the filename has not already been downloaded",
"func":1
},
{
"ref":"vipy.video.Scene.fetch",
"url":16,
"doc":"Download only if hasfilename() is not found",
"func":1
},
{
"ref":"vipy.video.Scene.shape",
"url":16,
"doc":"Return (height, width) of the frames, requires loading a preview frame from the video if the video is not already loaded, or providing the shape=(height,width) by the user",
"func":1
},
{
"ref":"vipy.video.Scene.channelshape",
"url":16,
"doc":"Return a tuple (channels, height, width) for the video",
"func":1
},
{
"ref":"vipy.video.Scene.issquare",
"url":16,
"doc":"Return true if the video has square dimensions (height  width), else false",
"func":1
},
{
"ref":"vipy.video.Scene.channels",
"url":16,
"doc":"Return integer number of color channels",
"func":1
},
{
"ref":"vipy.video.Scene.width",
"url":16,
"doc":"Width (cols) in pixels of the video for the current filter chain",
"func":1
},
{
"ref":"vipy.video.Scene.height",
"url":16,
"doc":"Height (rows) in pixels of the video for the current filter chain",
"func":1
},
{
"ref":"vipy.video.Scene.aspect_ratio",
"url":16,
"doc":"The width/height of the video expressed as a fraction",
"func":1
},
{
"ref":"vipy.video.Scene.preview",
"url":16,
"doc":"Return selected frame of filtered video, return vipy.image.Image object. This is useful for previewing the frame shape of a complex filter chain or the frame contents at a particular location without loading the whole video",
"func":1
},
{
"ref":"vipy.video.Scene.load",
"url":16,
"doc":"Load a video using ffmpeg, applying the requested filter chain. Args: verbose: [bool] if True. then ffmpeg console output will be displayed. shape: [tuple (height, width, channels)] If provided, use this shape for reading and reshaping the byte stream from ffmpeg. This is useful for efficient loading in some scenarios. Knowing the final output shape can speed up loads by avoiding a preview() of the filter chain to get the frame size Returns: this video object, with the pixels loaded in self.array()  warning Loading long videos can result in out of memory conditions. Try to call clip() first to extract a video segment to load().",
"func":1
},
{
"ref":"vipy.video.Scene.cliprange",
"url":16,
"doc":"Return the planned clip (startframe, endframe) range. This is useful for introspection of the planned clip() before load(), such as for data augmentation purposes without triggering a load. Returns: (startframe, endframe) of the video() such that after load(), the pixel buffer will contain frame=0 equivalent to startframe in the source video, and frame=endframe-startframe-1 equivalent to endframe in the source video. (0, None) If a video does not have a clip() (e.g. clip() was never called, the filter chain does not include a 'trim')  notes The endframe can be retrieved (inefficiently) using:   int(round(self.duration_in_frames_of_videofile()  (self.framerate() / self.framerate_of_videofile(   ",
"func":1
},
{
"ref":"vipy.video.Scene.set_mindim",
"url":16,
"doc":"Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio, do nothing if dim=None",
"func":1
},
{
"ref":"vipy.video.Scene.randomcrop",
"url":16,
"doc":"Crop the video to shape=(H,W) with random position such that the crop contains only valid pixels, and optionally return the box",
"func":1
},
{
"ref":"vipy.video.Scene.centercrop",
"url":16,
"doc":"Crop the video to shape=(H,W) preserving the integer centroid position, and optionally return the box",
"func":1
},
{
"ref":"vipy.video.Scene.centersquare",
"url":16,
"doc":"Crop video of size (NxN) in the center, such that N=min(width,height), keeping the video centroid constant",
"func":1
},
{
"ref":"vipy.video.Scene.cropeven",
"url":16,
"doc":"Crop the video to the largest even (width,height) less than or equal to current (width,height). This is useful for some codecs or filters which require even shape.",
"func":1
},
{
"ref":"vipy.video.Scene.maxsquare",
"url":16,
"doc":"Pad the video to be square, preserving the upper left corner of the video",
"func":1
},
{
"ref":"vipy.video.Scene.minsquare",
"url":16,
"doc":"Return a square crop of the video, preserving the upper left corner of the video",
"func":1
},
{
"ref":"vipy.video.Scene.maxmatte",
"url":16,
"doc":"Return a square video with dimensions (self.maxdim(), self.maxdim( with zeropadded lack bars or mattes above or below the video forming a letterboxed video.",
"func":1
},
{
"ref":"vipy.video.Scene.pad",
"url":16,
"doc":"Alias for zeropad",
"func":1
},
{
"ref":"vipy.video.Scene.zeropadlike",
"url":16,
"doc":"Zero pad the video balancing the border so that the resulting video size is (width, height).",
"func":1
},
{
"ref":"vipy.video.Scene.pkl",
"url":16,
"doc":"save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.video.Scene.pklif",
"url":16,
"doc":"Save the object to the provided pickle file only if b=True. Uuseful for conditional intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.video.Scene.webp",
"url":16,
"doc":"Save a video to an animated WEBP file, with pause=N seconds on the last frame between loops. Args: strict: If true, assert that the filename must have an .webp extension pause: Integer seconds to pause between loops of the animation smallest: if true, create the smallest possible file but takes much longer to run smaller: If true, create a smaller file, which takes a little longer to run framerate [float]: The output framerate of the webp file. The default is the framerate of the video. Returns: The filename of the webp file for this video  warning This may be slow for very long or large videos",
"func":1
},
{
"ref":"vipy.video.Scene.gif",
"url":16,
"doc":"Save a video to an animated GIF file, with pause=N seconds between loops. Args: pause: Integer seconds to pause between loops of the animation smallest: If true, create the smallest possible file but takes much longer to run smaller: if trye, create a smaller file, which takes a little longer to run framerate [float]: The output framerate of the webp file. The default is the framerate of the video. Returns: The filename of the animated GIF of this video  warning This will be very large for big videos, consider using  vipy.video.Video.webp instead.",
"func":1
},
{
"ref":"vipy.video.Scene.save",
"url":16,
"doc":"Save video to new output video file. This function does not draw boxes, it saves pixels to a new video file. Args: outfile: the absolute path to the output video file. This extension can be .mp4 (for video) or [\".webp\",\".gif\"] (for animated image) flush: If true, then flush the buffer for this object right after saving the new video. This is useful for transcoding in parallel framerate: input framerate of the frames in the buffer, or the output framerate of the transcoded video. If not provided, use framerate of source video pause: an integer in seconds to pause between loops of animated images if the outfile is webp or animated gif Returns: a new video object with this video filename, and a clean video filter chain  note - If self.array() is loaded, then export the contents of self._array to the video file - If self.array() is not loaded, and there exists a valid video file, apply the filter chain directly to the input video - If outfile None or outfile self.filename(), then overwrite the current filename",
"func":1
},
{
"ref":"vipy.video.Scene.saveas",
"url":16,
"doc":"Call  vipy.video.Video.saveas using a new temporary video file, and return the video object with this new filename",
"func":1
},
{
"ref":"vipy.video.Scene.savetmp",
"url":16,
"doc":"Call  vipy.video.Video.saveas using a new temporary video file, and return the video object with this new filename",
"func":1
},
{
"ref":"vipy.video.Scene.ffplay",
"url":16,
"doc":"Play the video file using ffplay",
"func":1
},
{
"ref":"vipy.video.Scene.play",
"url":16,
"doc":"Play the saved video filename in self.filename() If there is no filename, try to download it. If the filter chain is dirty or the pixels are loaded, dump to temp video file first then play it. This uses 'ffplay' on the PATH if available, otherwise uses a fallback player by showing a sequence of matplotlib frames. If the output of the ffmpeg filter chain has modified this video, then this will be saved to a temporary video file. To play the original video (indepenedent of the filter chain of this video), use  vipy.video.Video.ffplay . Args: verbose: If true, show more verbose output notebook: If true, play in a jupyter notebook ffplay: If true, use ffplay to display the video (if available) Returns: The unmodified video object",
"func":1
},
{
"ref":"vipy.video.Scene.torch",
"url":16,
"doc":"Convert the loaded video of shape NxHxWxC frames to an MxCxHxW torch tensor/ Args: startframe: [int >= 0] The start frame of the loaded video to use for constructig the torch tensor endframe: [int >= 0] The end frame of the loaded video to use for constructing the torch tensor length: [int >= 0] The length of the torch tensor if endframe is not provided. stride: [int >= 1] The temporal stride in frames. This is the number of frames to skip. take: [int >= 0] The number of uniformly spaced frames to include in the tensor. boundary: ['repeat', 'cyclic'] The boundary handling for when the requested tensor slice goes beyond the end of the video order: ['nchw', 'nhwc', 'chwn', 'cnhw'] The axis ordering of the returned torch tensor N=number of frames (batchsize), C=channels, H=height, W=width verbose [bool]: Print out the slice used for contructing tensor withslice: [bool] Return a tuple (tensor, slice) that includes the slice used to construct the tensor. Useful for data provenance. scale: [float] An optional scale factor to apply to the tensor. Useful for converting [0,255] -> [0,1] withlabel: [bool] Return a tuple (tensor, labels) that includes the N framewise activity labels. nonelabel: [bool] returns tuple (t, None) if withlabel=False Returns Returns torch float tensor, analogous to torchvision.transforms.ToTensor() Return (tensor, slice) if withslice=True (withslice takes precedence) Returns (tensor, labellist) if withlabel=True  notes - This triggers a load() of the video - The precedence of arguments is (startframe, endframe) or (startframe, startframe+length), then stride and take. - Follows numpy slicing rules. Optionally return the slice used if withslice=True",
"func":1
},
{
"ref":"vipy.video.Scene.clone",
"url":16,
"doc":"Create deep copy of video object, flushing the original buffer if requested and returning the cloned object. Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned object which can be used for encoding and will be garbage collected. Args: flushforward: copy the object, and set the cloned object  vipy.video.Video.array to None. This flushes the video buffer for the clone, not the object flushbackward: copy the object, and set the object array() to None. This flushes the video buffer for the object, not the clone. flush: set the object array() to None and clone the object. This flushes the video buffer for both the clone and the object. flushfilter: Set the ffmpeg filter chain to the default in the new object, useful for saving new videos flushfile: Remove the filename and the URL from the video object. Useful for creating new video objects from loaded pixels. rekey: Generate new unique track ID and activity ID keys for this scene shallow: shallow copy everything (copy by reference), except for ffmpeg object. attributes dictionary is shallow copied sharedarray: deep copy of everything, except for pixel buffer which is shared. Changing the pixel buffer on self is reflected in the clone. sanitize: remove private attributes from self.attributes dictionary. A private attribute is any key with two leading underscores '__' which should not be propagated to clone Returns: A deepcopy of the video object such that changes to self are not reflected in the copy  note Cloning videos is an expensive operation and can slow down real time code. Use sparingly.",
"func":1
},
{
"ref":"vipy.video.Scene.flush",
"url":16,
"doc":"Alias for clone(flush=True), returns self not clone",
"func":1
},
{
"ref":"vipy.video.Scene.unload",
"url":16,
"doc":"Remove cached file and loaded array. Note that this will delete the underlying file returned by filename() if there is a backing url, cleaning up cached files and forcing re-download",
"func":1
},
{
"ref":"vipy.video.Scene.uncache",
"url":16,
"doc":"Alias for  vipy.image.Image.unload ",
"func":1
},
{
"ref":"vipy.video.Scene.returns",
"url":16,
"doc":"Return the provided value, useful for terminating long fluent chains without returning self",
"func":1
},
{
"ref":"vipy.video.Scene.flush_and_return",
"url":16,
"doc":"Flush the video and return the parameter supplied, useful for long fluent chains",
"func":1
},
{
"ref":"vipy.video.Scene.map",
"url":16,
"doc":"Apply lambda function to the loaded numpy array img, changes pixels not shape Lambda function must have the following signature:  newimg = func(img)  img: HxWxC numpy array for a single frame of video  newimg: HxWxC modified numpy array for this frame. Change only the pixels, not the shape The lambda function will be applied to every frame in the video in frame index order.",
"func":1
},
{
"ref":"vipy.video.Scene.gain",
"url":16,
"doc":"Pixelwise multiplicative gain, such that each pixel p_{ij} = g  p_{ij}",
"func":1
},
{
"ref":"vipy.video.Scene.bias",
"url":16,
"doc":"Pixelwise additive bias, such that each pixel p_{ij} = b + p_{ij}",
"func":1
},
{
"ref":"vipy.video.Scene.normalize",
"url":16,
"doc":"Pixelwise whitening, out =  scale in) - mean) / std); triggers load(). All computations float32",
"func":1
},
{
"ref":"vipy.video.Scene.hasattribute",
"url":16,
"doc":"Does the attributes dictionary (self.attributes) contain the provided key",
"func":1
},
{
"ref":"vipy.video.Scene.clearattributes",
"url":16,
"doc":"Remove all attributes",
"func":1
},
{
"ref":"vipy.video.Scene.clear_attributes",
"url":16,
"doc":"Remove all attributes",
"func":1
},
{
"ref":"vipy.video.Scene.get_attribute",
"url":16,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.video.RandomVideo",
"url":16,
"doc":"Return a random loaded vipy.video.video. Useful for unit testing, minimum size (32x32x32) for ffmpeg",
"func":1
},
{
"ref":"vipy.video.RandomScene",
"url":16,
"doc":"Return a random loaded vipy.video.Scene. Useful for unit testing.",
"func":1
},
{
"ref":"vipy.video.EmptyScene",
"url":16,
"doc":"Return an empty scene",
"func":1
},
{
"ref":"vipy.video.Transform",
"url":16,
"doc":"Transforms are static methods that implement common transformation patterns used in distributed processing. These are useful for parallel processing of noisy or corrupted videos when anonymous functions are not supported (e.g. multiprocessing) These functions are designed for use along with functools.partial >>> with vipy.globals.multiprocessing(4):  to download and save in parallel >>> vipy.dataset.registry('kinetics').map(vipy.video.Transform.downloader(outdir='/tmp' See also:  vipy.dataset.Dataset.minibatch for parallel processing of batches downloading, loading, resizing, cropping, augmenting, tensor prep etc."
},
{
"ref":"vipy.video.Transform.is_loaded",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Transform.download",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Transform.downloader",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.video.Transform.load",
"url":16,
"doc":"",
"func":1
},
{
"ref":"vipy.calibration",
"url":17,
"doc":""
},
{
"ref":"vipy.calibration.checkerboard",
"url":17,
"doc":"Create a 2D checkerboard pattern with squares of size (dx, dy) and image of size (dx ncols,dy nrows) with black and white colors with black in upper left and bottom right. Returns: 2D numpy array np.array() float32 in [0,1]",
"func":1
},
{
"ref":"vipy.calibration.red_checkerboard_image",
"url":17,
"doc":"Create a 2D color checkerboard pattern with squares of size (dx, dy) and image of size (dx ncols,dy nrows) with red colors. Returns: vipy.image.Image",
"func":1
},
{
"ref":"vipy.calibration.blue_checkerboard_image",
"url":17,
"doc":"Create a 2D color checkerboard pattern with squares of size (dx, dy) and image of size (dx ncols,dy nrows) with blue colors. Returns: vipy.image.Image",
"func":1
},
{
"ref":"vipy.calibration.color_checkerboard_image",
"url":17,
"doc":"Create a 2D color checkerboard pattern with squares of size (dx, dy) and image of size (dx ncols,dy nrows) with random colors Returns: vipy.image.Image",
"func":1
},
{
"ref":"vipy.calibration.color_checkerboard",
"url":17,
"doc":"Create a 2D color checkerboard pattern with squares of size (dx, dy) and image of size (dx ncols,dy nrows) with random colors. Returns: 3D numpy array with three channels, uint8",
"func":1
},
{
"ref":"vipy.calibration.testimage",
"url":17,
"doc":"Return a  vipy.image.Image object of a superb owl from wikipedia",
"func":1
},
{
"ref":"vipy.calibration.owl",
"url":17,
"doc":"Return a  vipy.image.Image object of a superb owl from wikipedia",
"func":1
},
{
"ref":"vipy.calibration.randomimage",
"url":17,
"doc":"Return a uniform random RGB image as uint8 numpy array of size (m,n,3)",
"func":1
},
{
"ref":"vipy.calibration.testimg",
"url":17,
"doc":"Return a numpy array for  vipy.calibration.testimage of a superb owl",
"func":1
},
{
"ref":"vipy.calibration.tile",
"url":17,
"doc":"Create a 2D tile pattern with texture T repeated (nrows, ncols) times. Returns: float32 numpy array of size (T.shape[0] nrows, T.shape[1] ncols)",
"func":1
},
{
"ref":"vipy.calibration.greenblock",
"url":17,
"doc":"Return an (dx, dy, 3) numpy array float64 RGB channel image with green channel=1.0",
"func":1
},
{
"ref":"vipy.calibration.redblock",
"url":17,
"doc":"Return an (dx, dy, 3) numpy array float64 RGB channel image with red channel=1.0",
"func":1
},
{
"ref":"vipy.calibration.blueblock",
"url":17,
"doc":"Return an (dx, dy, 3) numpy array float64 RGB channel image with blue channel=1.0",
"func":1
},
{
"ref":"vipy.calibration.bayer",
"url":17,
"doc":"Return an (M,N) tiled texture pattern of [blue, green, blue, green; green red green red; blue green blue green, green red green red] such that each subblock element is (dx,dy) and the total repeated subblock size is (4 dx, 4 dy)",
"func":1
},
{
"ref":"vipy.calibration.bayer_image",
"url":17,
"doc":"Return  vipy.calibration.bayer as  vipy.image.Image ",
"func":1
},
{
"ref":"vipy.calibration.dots",
"url":17,
"doc":"Create a sequence of dots (e.g. single pixels on black background) separated by strides (dx, dy) with image of size (dx ncols,dy nrows) Returns: float32 numpy array in range [0,1]",
"func":1
},
{
"ref":"vipy.calibration.vertical_gradient",
"url":17,
"doc":"Create 2D linear ramp image with the ramp increasing from top to bottom. Returns: uint8 numpy array of size (nrows, ncols) with veritical gradient increasing over rows",
"func":1
},
{
"ref":"vipy.calibration.centersquare",
"url":17,
"doc":"Create a white square on a black background of an image of shape (width, height). Returns: numpy array of appropriate channels of float64 in [0,1]",
"func":1
},
{
"ref":"vipy.calibration.centersquare_border",
"url":17,
"doc":"Create a white square with black interior on a black background of an image of shape (width, height). The border of the square has width of a single pixel Returns: numpy array of appropriate channels of float32 in [0,1] asimage=True: returns a vipy.image.Image object",
"func":1
},
{
"ref":"vipy.calibration.centersquare_image",
"url":17,
"doc":"Returns  vipy.image.Image for  vipy.calibration.centersquare numpy array",
"func":1
},
{
"ref":"vipy.calibration.imcentersquare",
"url":17,
"doc":"alias for  vipy.calibration.centersquare_image ",
"func":1
},
{
"ref":"vipy.calibration.circle",
"url":17,
"doc":"Create a white circle on a black background centered at (x,y) with radius r pixels, of shape (width, height). Returns: numpy array of appropriate channels of float32 in [0,1]",
"func":1
},
{
"ref":"vipy.calibration.imcircle",
"url":17,
"doc":"Create a white circle on a black background centered at (x,y) with radius r pixels, of shape (width, height). Returns:  vipy.image.Image object with array defined by  vipy.calibration.circle ",
"func":1
},
{
"ref":"vipy.calibration.imstep",
"url":17,
"doc":"Create a left black/right white step image of size (width, height) Returns:  vipy.image.Image object",
"func":1
},
{
"ref":"vipy.globals",
"url":18,
"doc":""
},
{
"ref":"vipy.globals.logger",
"url":18,
"doc":"",
"func":1
},
{
"ref":"vipy.globals.Dask",
"url":18,
"doc":"Dask distributed client"
},
{
"ref":"vipy.globals.Dask.num_workers",
"url":18,
"doc":"",
"func":1
},
{
"ref":"vipy.globals.Dask.shutdown",
"url":18,
"doc":"",
"func":1
},
{
"ref":"vipy.globals.Dask.client",
"url":18,
"doc":"",
"func":1
},
{
"ref":"vipy.globals.cache",
"url":18,
"doc":"The cache is the location that URLs are downloaded to on your system. This can be set here, or with the environment variable VIPY_CACHE >>> vipy.globals.cache('/path/to/.vipy') >>> cachedir = vipy.globals.cache() Args: cachedir: the location to store cached files when downloaded. Can also be set using the VIPY_CACHE environment variable. if none, return the current cachedir Returns: The current cachedir if cachedir=None else None",
"func":1
},
{
"ref":"vipy.globals.cf",
"url":18,
"doc":"",
"func":1
},
{
"ref":"vipy.globals.dask",
"url":18,
"doc":"Return the current Dask client, can be accessed globally for parallel processing. Args: pct: float in [0,1] the percentage of the current machine to use address: the dask scheduler of the form 'HOSTNAME:PORT' num_workers: the number of prpcesses to use on the current machine dashboard: [bool] whether to inialize the dask client with a web dashboard threaded: [bool] if true, create threaded workers intead of processes Returns: The  vipy.batch.Dask object pointing to the Dask Distrbuted object",
"func":1
},
{
"ref":"vipy.globals.parallel",
"url":18,
"doc":"Enable parallel processing with n>=1 processes or a percentage of system core (pct in [0,1]) . This can be be used as a context manager >>> with vipy.globals.parallel(n=4): >>> vipy.batch.Batch( .) or using the global variables: >>> vipy.globals.parallel(n=4): >>> vipy.batch.Batch( .) >>> vipy.globals.noparallel() To check the current parallelism level: >>> num_workers = vipy.globals.parallel().num_workers() To run with a dask scheduler: >>> with vipy.globals.parallel(scheduler='10.0.1.1:8585') >>> vipy.batch.Batch( .) Args: workers: [int] number of parallel workers pct: [float] the percentage [0,1] of system cores to dedicate to parallel processing threaded [bool]: if false, use processes (not recommended, since vipy parallel processing usually releases the GIL)",
"func":1
},
{
"ref":"vipy.globals.multithreading",
"url":18,
"doc":"Context manager for concurrent futures multithreaded executor, use with  vipy.dataset.Dataset ",
"func":1
},
{
"ref":"vipy.globals.multiprocessing",
"url":18,
"doc":"Context manager for concurrent futures multiprocessing executor, use with  vipy.dataset.Dataset ",
"func":1
},
{
"ref":"vipy.globals.noparallel",
"url":18,
"doc":"Disable all parallel processing",
"func":1
},
{
"ref":"vipy.globals.shutdown",
"url":18,
"doc":"Alias for  vipy.globals.noparallel ",
"func":1
},
{
"ref":"vipy.torch",
"url":19,
"doc":""
},
{
"ref":"vipy.torch.TorchDataset",
"url":19,
"doc":"Converter from a pycollector dataset to a torch dataset"
},
{
"ref":"vipy.torch.Tensordir",
"url":19,
"doc":"A torch dataset stored as a directory of .pkl.bz2 files each containing a list of [(tensor, str=json.dumps(label ,  .] tuples used for data augmented training. This is useful to use the default Dataset loaders in Torch. Usage:   vipy.torch.Tensordir('/path/to') vipy.torch.Tensordir( ('/path/to/1', '/path/to/2') )    note This requires python random() and not numpy random"
},
{
"ref":"vipy.torch.Tensordir.take",
"url":19,
"doc":"",
"func":1
},
{
"ref":"vipy.torch.Tensordir.filter",
"url":19,
"doc":"Keep elements that lambda evaluates true. The lambda operates on the  absolute path filename for the tensordir and not the contents. This is useful for filtering by instanceid in the  vipy.util.filebase .",
"func":1
},
{
"ref":"vipy.torch.Tensordir.clone",
"url":19,
"doc":"",
"func":1
},
{
"ref":"vipy.torch.TorchTensordir",
"url":19,
"doc":"A torch dataset stored as a directory of .pkl.bz2 files each containing a list of [(tensor, str=json.dumps(label ,  .] tuples used for data augmented training. This is useful to use the default Dataset loaders in Torch. Usage:   vipy.torch.Tensordir('/path/to') vipy.torch.Tensordir( ('/path/to/1', '/path/to/2') )    note This requires python random() and not numpy random"
},
{
"ref":"vipy.torch.TorchTensordir.filter",
"url":19,
"doc":"Keep elements that lambda evaluates true. The lambda operates on the  absolute path filename for the tensordir and not the contents. This is useful for filtering by instanceid in the  vipy.util.filebase .",
"func":1
},
{
"ref":"vipy.data",
"url":20,
"doc":""
},
{
"ref":"vipy.data.kinetics",
"url":21,
"doc":""
},
{
"ref":"vipy.data.kinetics.Kinetics700",
"url":21,
"doc":"Kinetics, provide a datadir='/path/to/store/kinetics'"
},
{
"ref":"vipy.data.kinetics.Kinetics700.download",
"url":21,
"doc":"",
"func":1
},
{
"ref":"vipy.data.kinetics.Kinetics700.isdownloaded",
"url":21,
"doc":"",
"func":1
},
{
"ref":"vipy.data.kinetics.Kinetics700.trainset",
"url":21,
"doc":"",
"func":1
},
{
"ref":"vipy.data.kinetics.Kinetics700.testset",
"url":21,
"doc":"",
"func":1
},
{
"ref":"vipy.data.kinetics.Kinetics700.valset",
"url":21,
"doc":"",
"func":1
},
{
"ref":"vipy.data.kinetics.Kinetics700.categories",
"url":21,
"doc":"",
"func":1
},
{
"ref":"vipy.data.kinetics.Kinetics700.analysis",
"url":21,
"doc":"",
"func":1
},
{
"ref":"vipy.data.kinetics.Kinetics600",
"url":21,
"doc":"Kinetics, provide a datadir='/path/to/store/kinetics'"
},
{
"ref":"vipy.data.kinetics.Kinetics400",
"url":21,
"doc":"Kinetics, provide a datadir='/path/to/store/kinetics'"
},
{
"ref":"vipy.data.cc12m",
"url":22,
"doc":""
},
{
"ref":"vipy.data.cc12m.CC12M",
"url":22,
"doc":"https: github.com/google-research-datasets/conceptual-12m"
},
{
"ref":"vipy.data.cc12m.CC12M.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.cc12m.CC12M.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.stanford_dogs",
"url":24,
"doc":""
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs",
"url":24,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize"
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.stanford_dogs.StanfordDogs.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.openimages",
"url":25,
"doc":""
},
{
"ref":"vipy.data.openimages.open_images_v7",
"url":25,
"doc":"https: storage.googleapis.com/openimages/web/download_v7.html https: github.com/cvdfoundation/open-images-dataset download-full-dataset-with-google-storage-transfer https: github.com/Tencent/tencent-ml-images?tab=readme-ov-file download-images   trainset = open_images_v7() d = trainset.take(16).map(lambda im: im.load(ignoreErrors=True .filter(lambda im: im.isloaded( vipy.visualize.montage(d.map(lambda im: im.mindim(512).centersquare().annotate( .list( .show()   This returns the tagged image and bounding boxes for the open_images v7 trainset This can take a long while to parse due to large csv files",
"func":1
},
{
"ref":"vipy.data.aflw",
"url":26,
"doc":""
},
{
"ref":"vipy.data.aflw.AFLW",
"url":26,
"doc":""
},
{
"ref":"vipy.data.aflw.AFLW.dataset",
"url":26,
"doc":"",
"func":1
},
{
"ref":"vipy.data.aflw.AFLW.export",
"url":26,
"doc":"Export sqlite database file to aflw.csv",
"func":1
},
{
"ref":"vipy.data.aflw.landmarks",
"url":26,
"doc":"Return 21x2 frame array of landmark positions in 1-21 order, NaN if occluded",
"func":1
},
{
"ref":"vipy.data.aflw.eyes_nose_chin",
"url":26,
"doc":"Return 4x2 frame array of left eye, right eye nose chin",
"func":1
},
{
"ref":"vipy.data.youtubefaces",
"url":27,
"doc":""
},
{
"ref":"vipy.data.youtubefaces.YouTubeFaces",
"url":27,
"doc":""
},
{
"ref":"vipy.data.youtubefaces.YouTubeFaces.subjects",
"url":27,
"doc":"",
"func":1
},
{
"ref":"vipy.data.youtubefaces.YouTubeFaces.videos",
"url":27,
"doc":"",
"func":1
},
{
"ref":"vipy.data.youtubefaces.YouTubeFaces.parse",
"url":27,
"doc":"Parse youtubefaces into a list of ImageDetections",
"func":1
},
{
"ref":"vipy.data.youtubefaces.YouTubeFaces.splits",
"url":27,
"doc":"",
"func":1
},
{
"ref":"vipy.data.lvis",
"url":28,
"doc":""
},
{
"ref":"vipy.data.lvis.LVIS",
"url":28,
"doc":"Caltech101, provide a datadir='/path/to/store/caltech101'"
},
{
"ref":"vipy.data.lvis.LVIS.trainset",
"url":28,
"doc":"",
"func":1
},
{
"ref":"vipy.data.lvis.LVIS.valset",
"url":28,
"doc":"",
"func":1
},
{
"ref":"vipy.data.pip",
"url":29,
"doc":""
},
{
"ref":"vipy.data.pip.PIP_175k",
"url":29,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize"
},
{
"ref":"vipy.data.pip.PIP_175k.URL",
"url":29,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.pip.PIP_175k.MD5",
"url":29,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.pip.PIP_175k.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.pip.PIP_175k.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized",
"url":29,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize"
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.URL",
"url":29,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.MD5",
"url":29,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.pip.PIP_370k_stabilized.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.celebA",
"url":30,
"doc":""
},
{
"ref":"vipy.data.celebA.CelebA",
"url":30,
"doc":"A thin wrapper around torchvision.datasets to import into vipy.dataset format. https: docs.pytorch.org/vision/0.21/generated/torchvision.datasets.CelebA.html torchvision.datasets.CelebA Requires gdown"
},
{
"ref":"vipy.data.celebA.CelebA.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.celebA.CelebA.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.vggface",
"url":31,
"doc":""
},
{
"ref":"vipy.data.vggface.VGGFaceURL",
"url":31,
"doc":""
},
{
"ref":"vipy.data.vggface.VGGFaceURL.subjects",
"url":31,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface.VGGFaceURL.dataset",
"url":31,
"doc":"Return a generator to iterate over dataset",
"func":1
},
{
"ref":"vipy.data.vggface.VGGFaceURL.take",
"url":31,
"doc":"Randomly select n frames from dataset",
"func":1
},
{
"ref":"vipy.data.vggface.VGGFace",
"url":31,
"doc":""
},
{
"ref":"vipy.data.vggface.VGGFace.subjects",
"url":31,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface.VGGFace.wordnetid_to_name",
"url":31,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface.VGGFace.dataset",
"url":31,
"doc":"Return a generator to iterate over dataset",
"func":1
},
{
"ref":"vipy.data.vggface.VGGFace.fastset",
"url":31,
"doc":"Return a generator to iterate over dataset",
"func":1
},
{
"ref":"vipy.data.vggface.VGGFace.take",
"url":31,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface.VGGFace.by_subject",
"url":31,
"doc":"",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102",
"url":32,
"doc":""
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102",
"url":32,
"doc":"Project: https: www.robots.ox.ac.uk/~vgg/data/flowers/102"
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.oxford_flowers_102.Flowers102.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.mit67",
"url":33,
"doc":""
},
{
"ref":"vipy.data.mit67.MIT67",
"url":33,
"doc":"IndoorSceneRecognition dataset: https: web.mit.edu/torralba/www/indoor.html"
},
{
"ref":"vipy.data.mit67.MIT67.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.mit67.MIT67.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.inaturalist",
"url":34,
"doc":""
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021",
"url":34,
"doc":"Project: https: github.com/visipedia/inat_comp/tree/master/2021"
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.trainset",
"url":34,
"doc":"",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.valset",
"url":34,
"doc":"",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.inaturalist.iNaturalist2021.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.charades",
"url":35,
"doc":""
},
{
"ref":"vipy.data.charades.Charades",
"url":35,
"doc":"Charades, provide paths such that datadir contains the contents of 'http: ai2-website.s3.amazonaws.com/data/Charades_v1.zip' and annodir contains 'http: ai2-website.s3.amazonaws.com/data/Charades.zip'. These are license restructed and must be downloaded by the user"
},
{
"ref":"vipy.data.charades.Charades.categories",
"url":35,
"doc":"",
"func":1
},
{
"ref":"vipy.data.charades.Charades.trainset",
"url":35,
"doc":"",
"func":1
},
{
"ref":"vipy.data.charades.Charades.testset",
"url":35,
"doc":"",
"func":1
},
{
"ref":"vipy.data.charades.Charades.review",
"url":35,
"doc":"Generate a standalone HTML file containing quicklooks for each annotated activity in the train set",
"func":1
},
{
"ref":"vipy.data.visualgenome",
"url":36,
"doc":""
},
{
"ref":"vipy.data.visualgenome.VisualGenome",
"url":36,
"doc":"Project: http: visualgenome.org/, version 1.4-objects"
},
{
"ref":"vipy.data.visualgenome.VisualGenome.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.visualgenome.VisualGenome.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.widerface",
"url":37,
"doc":""
},
{
"ref":"vipy.data.widerface.WiderFace",
"url":37,
"doc":"A thin wrapper around torchvision.datasets to import into vipy.dataset format. https: docs.pytorch.org/vision/0.21/generated/torchvision.datasets.WIDERFace.html torchvision.datasets.WIDERFace Requires gdown"
},
{
"ref":"vipy.data.widerface.WiderFace.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.widerface.WiderFace.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.mnist",
"url":38,
"doc":""
},
{
"ref":"vipy.data.food101",
"url":39,
"doc":""
},
{
"ref":"vipy.data.food101.Food101",
"url":39,
"doc":"Project: https: data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/"
},
{
"ref":"vipy.data.food101.Food101.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.food101.Food101.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.food101.Food101.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.food101.Food101.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.food101.Food101.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.food101.Food101.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.food101.Food101.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.food101.Food101.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.food101.Food101.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.food101.Food101.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.food101.Food101.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.food101.Food101.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.food101.Food101.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.food101.Food101.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.food101.Food101.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.food101.Food101.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.food101.Food101.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.food101.Food101.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.food101.Food101.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.food101.Food101.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.food101.Food101.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.food101.Food101.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.food101.Food101.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.food101.Food101.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.food101.Food101.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.food101.Food101.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.food101.Food101.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.food101.Food101.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.food101.Food101.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.food101.Food101.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.food101.Food101.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.food101.Food101.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.food101.Food101.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.food101.Food101.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.food101.Food101.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.food101.Food101.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.food101.Food101.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.food101.Food101.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.food101.Food101.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.food101.Food101.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.food101.Food101.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.abo",
"url":40,
"doc":""
},
{
"ref":"vipy.data.momentsintime",
"url":41,
"doc":""
},
{
"ref":"vipy.data.momentsintime.MultiMoments",
"url":41,
"doc":"Multi-Moments in Time: http: moments.csail.mit.edu/ You are required to fill out a license agreement and download the data yourself into datadir >>> d = MultiMoments('/path/to/dir') >>> valset = d.valset() >>> valset.categories()  return the dictionary mapping integer category to string >>> valset[1].categories()  return set of categories for this clip >>> valset[1].category()  return string encoded category for this clip (comma separated activity indexes) >>> valset[1].play()  Play the original clip >>> valset[1].mindim(224).show()  Resize the clip to have minimum dimension 224, then show the modified clip >>> valset[1].centersquare().mindim(112).saveas('out.mp4')  modify the clip as square crop from the center with mindim=112, and save to new file >>> valset[1].centersquare().mindim(112).normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225 .torch(startframe=0, length=16)  export 16x3x112x112 tensor"
},
{
"ref":"vipy.data.momentsintime.MultiMoments.categories",
"url":41,
"doc":"",
"func":1
},
{
"ref":"vipy.data.momentsintime.MultiMoments.trainset",
"url":41,
"doc":"",
"func":1
},
{
"ref":"vipy.data.momentsintime.MultiMoments.valset",
"url":41,
"doc":"",
"func":1
},
{
"ref":"vipy.data.facescrub",
"url":42,
"doc":""
},
{
"ref":"vipy.data.facescrub.FaceScrub",
"url":42,
"doc":""
},
{
"ref":"vipy.data.facescrub.FaceScrub.parse",
"url":42,
"doc":"Return a list of ImageDetections for all URLs in facescrub",
"func":1
},
{
"ref":"vipy.data.facescrub.FaceScrub.download",
"url":42,
"doc":"Download every URL in dataset and store in provided filename",
"func":1
},
{
"ref":"vipy.data.facescrub.FaceScrub.validate",
"url":42,
"doc":"Validate downloaded dataset and store cached list of valid bounding boxes and loadable images accessible with dataset()",
"func":1
},
{
"ref":"vipy.data.facescrub.FaceScrub.dataset",
"url":42,
"doc":"",
"func":1
},
{
"ref":"vipy.data.facescrub.FaceScrub.stats",
"url":42,
"doc":"",
"func":1
},
{
"ref":"vipy.data.facescrub.FaceScrub.subjects",
"url":42,
"doc":"",
"func":1
},
{
"ref":"vipy.data.facescrub.FaceScrub.split",
"url":42,
"doc":"",
"func":1
},
{
"ref":"vipy.data.cap",
"url":43,
"doc":""
},
{
"ref":"vipy.data.cap.CAP_classification_clip",
"url":43,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize"
},
{
"ref":"vipy.data.cap.CAP_classification_clip.URL",
"url":43,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.cap.CAP_classification_clip.MD5",
"url":43,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.cap.CAP_classification_clip.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_clip.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad",
"url":43,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize"
},
{
"ref":"vipy.data.cap.CAP_classification_pad.URL",
"url":43,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.cap.CAP_classification_pad.MD5",
"url":43,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.cap.CAP_classification_pad.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.cap.CAP_classification_pad.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection",
"url":43,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize"
},
{
"ref":"vipy.data.cap.CAP_detection.URL",
"url":43,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.cap.CAP_detection.MD5",
"url":43,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.cap.CAP_detection.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.cap.CAP_detection.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.ethzshapes",
"url":44,
"doc":""
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes",
"url":44,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize ETHZShapes, provide a datadir='/path/to/store/ethzshapes'"
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.ethzshapes.ETHZShapes.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.caltech256",
"url":45,
"doc":""
},
{
"ref":"vipy.data.caltech256.Caltech256",
"url":45,
"doc":"Caltech-256 dataset: https: data.caltech.edu/records/nyy15-4j048"
},
{
"ref":"vipy.data.caltech256.Caltech256.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.caltech256.Caltech256.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.food2k",
"url":46,
"doc":""
},
{
"ref":"vipy.data.food2k.Food2k",
"url":46,
"doc":"Project: http: 123.57.42.89/FoodProject.html"
},
{
"ref":"vipy.data.food2k.Food2k.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.food2k.Food2k.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.stanford_cars",
"url":47,
"doc":""
},
{
"ref":"vipy.data.stanford_cars.StanfordCars",
"url":47,
"doc":"Project: https: ai.stanford.edu/~jkrause/cars/car_dataset.html"
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.testset",
"url":47,
"doc":"",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.stanford_cars.StanfordCars.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.caltech101",
"url":48,
"doc":""
},
{
"ref":"vipy.data.caltech101.Caltech101",
"url":48,
"doc":"Caltech-101 dataset: https: data.caltech.edu/records/mzrjq-6wc02 Caltech101, provide a datadir='/path/to/store/caltech101'"
},
{
"ref":"vipy.data.caltech101.Caltech101.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.caltech101.Caltech101.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.activitynet",
"url":49,
"doc":""
},
{
"ref":"vipy.data.activitynet.ActivityNet",
"url":49,
"doc":"Activitynet, provide a datadir='/path/to/store/activitynet'"
},
{
"ref":"vipy.data.activitynet.ActivityNet.download",
"url":49,
"doc":"",
"func":1
},
{
"ref":"vipy.data.activitynet.ActivityNet.trainset",
"url":49,
"doc":"",
"func":1
},
{
"ref":"vipy.data.activitynet.ActivityNet.testset",
"url":49,
"doc":"ActivityNet test set does not include any annotations",
"func":1
},
{
"ref":"vipy.data.activitynet.ActivityNet.valset",
"url":49,
"doc":"",
"func":1
},
{
"ref":"vipy.data.activitynet.ActivityNet.categories",
"url":49,
"doc":"",
"func":1
},
{
"ref":"vipy.data.activitynet.ActivityNet.analysis",
"url":49,
"doc":"",
"func":1
},
{
"ref":"vipy.data.imagenet",
"url":50,
"doc":""
},
{
"ref":"vipy.data.imagenet.Imagenet2012",
"url":50,
"doc":"Imagenet2012 requires login at https: image-net.org from the same IP address as the download, and agreeing to the ImageNet terms: https: image-net.org/download-images.php term"
},
{
"ref":"vipy.data.imagenet.Imagenet2012.synset_to_category",
"url":50,
"doc":"",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet2012.classification_trainset",
"url":50,
"doc":"ImageNet2012 Classification, trainset",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet2012.classification_valset",
"url":50,
"doc":"ImageNet2012 Classification, valset",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet2012.faces",
"url":50,
"doc":"Return all annotated faces in 2012 train and val sets: https: image-net.org/face-obfuscation/",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet2012.localization_trainset",
"url":50,
"doc":"ImageNet2012 localization, imageset = {train, val}, this takes a long time to read the XML files, load and cache",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized",
"url":50,
"doc":"Imagenet21K_Resized requires login at https: image-net.org from the same IP address as the download, and agreeing to the ImageNet terms: https: image-net.org/download-images.php term https: image-net.org/download-images.php, imagenet-21K 2021 release (\"squish\" resized)"
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.synset_to_category",
"url":50,
"doc":"",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K_Resized.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K",
"url":50,
"doc":"Imagenet21K requires login at https: image-net.org from the same IP address as the download, and agreeing to the ImageNet terms: https: image-net.org/download-images.php term imagenet-21K 2021 winter release"
},
{
"ref":"vipy.data.imagenet.Imagenet21K.synset_to_category",
"url":50,
"doc":"",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet21K.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet2014_DET",
"url":50,
"doc":"Imagenet2014_DET requires login at https: image-net.org from the same IP address as the download, and agreeing to the ImageNet terms: https: image-net.org/download-images.php term"
},
{
"ref":"vipy.data.imagenet.Imagenet2014_DET.synset_to_category",
"url":50,
"doc":"",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet2014_DET.trainset",
"url":50,
"doc":"",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet2014_DET.valset",
"url":50,
"doc":"",
"func":1
},
{
"ref":"vipy.data.imagenet.Imagenet2014_DET.testset",
"url":50,
"doc":"",
"func":1
},
{
"ref":"vipy.data.ucf101",
"url":51,
"doc":""
},
{
"ref":"vipy.data.ucf101.UCF101",
"url":51,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize"
},
{
"ref":"vipy.data.ucf101.UCF101.as_space_separated_category",
"url":51,
"doc":"",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.to_space_separated_category",
"url":51,
"doc":"Convert CamelCase to a space separated phrase",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.ucf101.UCF101.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.ava",
"url":52,
"doc":""
},
{
"ref":"vipy.data.ava.AVA",
"url":52,
"doc":"AVA, provide a datadir='/path/to/store/ava'"
},
{
"ref":"vipy.data.ava.AVA.download",
"url":52,
"doc":"",
"func":1
},
{
"ref":"vipy.data.ava.AVA.categories",
"url":52,
"doc":"",
"func":1
},
{
"ref":"vipy.data.ava.AVA.trainset",
"url":52,
"doc":"",
"func":1
},
{
"ref":"vipy.data.ava.AVA.valset",
"url":52,
"doc":"",
"func":1
},
{
"ref":"vipy.data.megaface",
"url":53,
"doc":""
},
{
"ref":"vipy.data.megaface.MF2",
"url":53,
"doc":""
},
{
"ref":"vipy.data.megaface.MF2.tinyset",
"url":53,
"doc":"Return the first (size) image objects in the trainset",
"func":1
},
{
"ref":"vipy.data.megaface.Megaface",
"url":53,
"doc":""
},
{
"ref":"vipy.data.megaface.Megaface.tinyset",
"url":53,
"doc":"Return the first (size) image objects in the dataset",
"func":1
},
{
"ref":"vipy.data.coco",
"url":54,
"doc":""
},
{
"ref":"vipy.data.coco.COCO_2014",
"url":54,
"doc":"Project: https: cocodataset.org Detection_Train_Val_2014"
},
{
"ref":"vipy.data.coco.COCO_2014.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.coco.COCO_2014.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.youtubeBB",
"url":55,
"doc":""
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB",
"url":55,
"doc":"https: research.google.com/youtube-bb/download.html Usage: To show the clips centered on a track at 30Hz >>> dataset = vipy.data.youtubeBB.YoutubeBB() >>> v = dataset.takeone().download() >>> for t in v.trackclip(): >>> t.show() To extract the first annotated keyframes at 1Hz: >>> imlist = [t.framerate(1).frame(0) for t in dataset.takeone().trackclip()] >>> imlist[0].show() To extract all annotated keyframes at 1Hz for each tracked object: >>> framelist =  im for im in t.framerate(1).load()] for t in dataset.takeone().trackclip()] >>> vipy.visualize.montage([im.centersquare().annotate() for frames in framelist for im in frames]).show() The boxes are available as: >>> objectlist = [(o.category(), o.xywh( for frames in framelist for im in frames for o in im.objects()] Notes: - Some videos with a native framerate different from 30Hz may generate non-pixel accurate frames due to rounding errors in the ffmpeg fps filter chain - The videos are loaded with a framerate of 30Hz. Boxes are annotated at 1Hz. Objects are linearly interpolated to export at 30Hz but this means that some frames that have interpolated boxes may no longer precisely fall on the object - To recover the precise frame annotated once per second, use v.frame(n). For example, for the frame at timestamp 2000ms, use v.frame(int(30 (2000/1000 ) - Try v.show(timestamp=True) to show the frame index overlay along with the boxes to see which frame is being displayed - Delay the framerate conversion as late in the filter chain as possible (e.g. after trackclip)"
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.youtubeBB.YoutubeBB.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.kitti",
"url":56,
"doc":""
},
{
"ref":"vipy.data.kitti.KITTI",
"url":56,
"doc":"A thin wrapper around torchvision.datasets to import into vipy.dataset format. https: docs.pytorch.org/vision/main/generated/torchvision.datasets.Kitti.html"
},
{
"ref":"vipy.data.kitti.KITTI.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.kitti.KITTI.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.compcars",
"url":57,
"doc":""
},
{
"ref":"vipy.data.d2d",
"url":58,
"doc":""
},
{
"ref":"vipy.data.d2d.D2D",
"url":58,
"doc":"Describable Textures Dataset: https: www.robots.ox.ac.uk/~vgg/data/dtd/"
},
{
"ref":"vipy.data.d2d.D2D.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.d2d.D2D.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.tiny_virat",
"url":59,
"doc":""
},
{
"ref":"vipy.data.tiny_virat.TinyVIRAT",
"url":59,
"doc":""
},
{
"ref":"vipy.data.tiny_virat.TinyVIRAT.URL",
"url":59,
"doc":"The type of the None singleton."
},
{
"ref":"vipy.data.tiny_virat.TinyVIRAT.trainset",
"url":59,
"doc":"",
"func":1
},
{
"ref":"vipy.data.tiny_virat.TinyVIRAT.valset",
"url":59,
"doc":"",
"func":1
},
{
"ref":"vipy.data.tiny_virat.TinyVIRAT.testset",
"url":59,
"doc":"",
"func":1
},
{
"ref":"vipy.data.cifar",
"url":60,
"doc":""
},
{
"ref":"vipy.data.cifar.CIFAR10",
"url":60,
"doc":"vipy.data.cifar.CIFAR10 class >>> D = vipy.data.cifar.CIFAR10('/path/to/outdir') >>> d = D.trainset() >>> im = d[0].mindim(512).show()"
},
{
"ref":"vipy.data.cifar.CIFAR10.classes",
"url":60,
"doc":"",
"func":1
},
{
"ref":"vipy.data.cifar.CIFAR10.trainset",
"url":60,
"doc":"",
"func":1
},
{
"ref":"vipy.data.cifar.CIFAR10.testset",
"url":60,
"doc":"",
"func":1
},
{
"ref":"vipy.data.cifar.CIFAR100",
"url":60,
"doc":"vipy.data.cifar.CIFAR10 class >>> D = vipy.data.cifar.CIFAR10('/path/to/outdir') >>> d = D.trainset() >>> im = d[0].mindim(512).show()"
},
{
"ref":"vipy.data.kthactions",
"url":61,
"doc":""
},
{
"ref":"vipy.data.kthactions.KTHActions",
"url":61,
"doc":"KTH ACtions dataset, provide a datadir='/path/to/store/kthactions'"
},
{
"ref":"vipy.data.kthactions.KTHActions.split",
"url":61,
"doc":"",
"func":1
},
{
"ref":"vipy.data.kthactions.KTHActions.download_and_unpack",
"url":61,
"doc":"",
"func":1
},
{
"ref":"vipy.data.kthactions.KTHActions.dataset",
"url":61,
"doc":"",
"func":1
},
{
"ref":"vipy.data.coil100",
"url":62,
"doc":""
},
{
"ref":"vipy.data.coil100.COIL100",
"url":62,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize"
},
{
"ref":"vipy.data.coil100.COIL100.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.coil100.COIL100.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.casia",
"url":63,
"doc":""
},
{
"ref":"vipy.data.casia.WebFace",
"url":63,
"doc":""
},
{
"ref":"vipy.data.casia.WebFace.dataset",
"url":63,
"doc":"",
"func":1
},
{
"ref":"vipy.data.casia.WebFace.subjects",
"url":63,
"doc":"",
"func":1
},
{
"ref":"vipy.data.casia.WebFace.subjectid",
"url":63,
"doc":"",
"func":1
},
{
"ref":"vipy.data.imdb_wiki",
"url":64,
"doc":""
},
{
"ref":"vipy.data.places",
"url":65,
"doc":""
},
{
"ref":"vipy.data.places.Places365",
"url":65,
"doc":"Project: http: places2.csail.mit.edu/download-private.html"
},
{
"ref":"vipy.data.places.Places365.trainset",
"url":65,
"doc":"",
"func":1
},
{
"ref":"vipy.data.places.Places365.valset",
"url":65,
"doc":"",
"func":1
},
{
"ref":"vipy.data.eurosat",
"url":66,
"doc":""
},
{
"ref":"vipy.data.eurosat.EuroSAT",
"url":66,
"doc":"https: github.com/phelber/EuroSAT"
},
{
"ref":"vipy.data.eurosat.EuroSAT.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.eurosat.EuroSAT.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.lfw",
"url":67,
"doc":""
},
{
"ref":"vipy.data.lfw.LFW",
"url":67,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize Datadir contains the unpacked contents of LFW from $URL -> /path/to/lfw"
},
{
"ref":"vipy.data.lfw.LFW.subjects",
"url":67,
"doc":"List of all subject names",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.subject_images",
"url":67,
"doc":"List of Images of a subject",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.lfw.LFW.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.msceleb",
"url":68,
"doc":""
},
{
"ref":"vipy.data.msceleb.extract",
"url":68,
"doc":"https: github.com/cmusatyalab/openface/blob/master/data/ms-celeb-1m/extract.py",
"func":1
},
{
"ref":"vipy.data.msceleb.export",
"url":68,
"doc":"",
"func":1
},
{
"ref":"vipy.data.mmid",
"url":69,
"doc":""
},
{
"ref":"vipy.data.hmdb",
"url":70,
"doc":""
},
{
"ref":"vipy.data.hmdb.HMDB",
"url":70,
"doc":"Human motion dataset, provide a datadir='/path/to/store/hmdb'"
},
{
"ref":"vipy.data.hmdb.HMDB.download",
"url":70,
"doc":"",
"func":1
},
{
"ref":"vipy.data.hmdb.HMDB.dataset",
"url":70,
"doc":"Return a list of VideoCategory objects",
"func":1
},
{
"ref":"vipy.data.hf",
"url":71,
"doc":""
},
{
"ref":"vipy.data.hf.mnist",
"url":71,
"doc":"",
"func":1
},
{
"ref":"vipy.data.hf.cifar10",
"url":71,
"doc":"Huggingface wrapper for cifar10, returns (train,test) tuple",
"func":1
},
{
"ref":"vipy.data.hf.cifar100",
"url":71,
"doc":"Huggingface wrapper for cifar100 returns (train,test) tuple",
"func":1
},
{
"ref":"vipy.data.hf.oxford_pets",
"url":71,
"doc":"https: www.robots.ox.ac.uk/~vgg/data/pets/",
"func":1
},
{
"ref":"vipy.data.hf.sun397",
"url":71,
"doc":"Sun-397 dataset: https: vision.princeton.edu/projects/2010/SUN/",
"func":1
},
{
"ref":"vipy.data.hf.flickr30k",
"url":71,
"doc":"http: shannon.cs.illinois.edu/DenotationGraph/data/index.html",
"func":1
},
{
"ref":"vipy.data.hf.oxford_fgvc_aircraft",
"url":71,
"doc":"https: www.robots.ox.ac.uk/~vgg/data/fgvc-aircraft/",
"func":1
},
{
"ref":"vipy.data.hf.pascal_voc_2007",
"url":71,
"doc":"http: host.robots.ox.ac.uk/pascal/VOC/",
"func":1
},
{
"ref":"vipy.data.hf.yfcc100m",
"url":71,
"doc":"https: multimediacommons.wordpress.com/yfcc100m-core-dataset/ This dataset loads a bytes array containing an image on each row. Create a separate dataset that ignores the img column and replaces with the backing URL. This is useful for fast analysis of the dataset metadata.",
"func":1
},
{
"ref":"vipy.data.hf.tiny_imagenet",
"url":71,
"doc":"",
"func":1
},
{
"ref":"vipy.data.hf.coyo300m",
"url":71,
"doc":"https: huggingface.co/datasets/kakaobrain/coyo-labeled-300m (Machine labeled)",
"func":1
},
{
"ref":"vipy.data.hf.coyo700m",
"url":71,
"doc":"https: huggingface.co/datasets/kakaobrain/coyo-700m",
"func":1
},
{
"ref":"vipy.data.hf.laion2b",
"url":71,
"doc":"https: huggingface.co/datasets/laion/relaion2B-en-research-safe",
"func":1
},
{
"ref":"vipy.data.hf.datacomp_1b",
"url":71,
"doc":"https: huggingface.co/datasets/mlfoundations/datacomp_1b",
"func":1
},
{
"ref":"vipy.data.hf.imageinwords",
"url":71,
"doc":"https: huggingface.co/datasets/google/imageinwords",
"func":1
},
{
"ref":"vipy.data.hf.docci",
"url":71,
"doc":"https: huggingface.co/datasets/google/docci",
"func":1
},
{
"ref":"vipy.data.hf.as100m",
"url":71,
"doc":"",
"func":1
},
{
"ref":"vipy.data.hf.objects365",
"url":71,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface2",
"url":72,
"doc":""
},
{
"ref":"vipy.data.vggface2.VGGFace2",
"url":72,
"doc":""
},
{
"ref":"vipy.data.vggface2.VGGFace2.subjects",
"url":72,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.wordnetid_to_name",
"url":72,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.vggface2_to_vggface1",
"url":72,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.name_to_wordnetid",
"url":72,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.names",
"url":72,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.trainset",
"url":72,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.testset",
"url":72,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.split",
"url":72,
"doc":"Convert absolute path /path/to/subjectid/filename.jpg from training or testing set to (subjectid, filename.jpg)",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.frontalset",
"url":72,
"doc":"",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.dataset",
"url":72,
"doc":"Return a generator to iterate over dataset",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.fastset",
"url":72,
"doc":"Return a generator to iterate over dataset",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.take",
"url":72,
"doc":"Randomly select n images from the dataset, or n images of a given subjectid",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.take_per_subject",
"url":72,
"doc":"Randomly select n images per subject from the dataset",
"func":1
},
{
"ref":"vipy.data.vggface2.VGGFace2.subjectset",
"url":72,
"doc":"Iterator for single subject",
"func":1
},
{
"ref":"vipy.data.fddb",
"url":73,
"doc":""
},
{
"ref":"vipy.data.fddb.FDDB",
"url":73,
"doc":"Manages the FDDB dataset: http: vis-www.cs.umass.edu/fddb"
},
{
"ref":"vipy.data.fddb.FDDB.fold",
"url":73,
"doc":"Return the foldnum as a list of vipy.image.Scene objects, each containing all vipy.object.Detection faces in the current image",
"func":1
},
{
"ref":"vipy.data.objectnet",
"url":74,
"doc":""
},
{
"ref":"vipy.data.objectnet.Objectnet",
"url":74,
"doc":"Project: https: objectnet.dev, password set on website, must be bytes encoded (e.g. passwd=b'thepassword')"
},
{
"ref":"vipy.data.objectnet.Objectnet.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.data.objectnet.Objectnet.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.data.meva",
"url":75,
"doc":""
},
{
"ref":"vipy.data.meva.KF1",
"url":75,
"doc":"Parse MEVA annotations (http: mevadata.org) for Known Facility 1 dataset into vipy.video.Scene() objects To download videos: https: mevadata.org/resources/README-meva-kf1-data.html sh> cd /path/to/datadir sh> aws s3 sync s3: mevadata-public-01/drops-123-r13 . To download annotations: https: gitlab.kitware.com/meva/meva-data-repo sh> cd /path/to/datadir sh> git clone https: gitlab.kitware.com/meva/meva-data-repo.git Then for faster parsing: >>> with vipy.globals.multiprocessing(4): >>> kf1 = vipy.data.meva.KF1('/path/to/datadir') Args: datadir: [str] path to Directory containing subdirectories of the form '2018-03-05' and clone of https: gitlab.kitware.com/meva/meva-data-repo stride: [int] the integer temporal stride in frames for importing bounding boxes, vipy will do linear interpoluation and boundary handling n_videos: [int] only return an integer number of videos, useful for debugging or for previewing dataset withprefix: [list] only return videos with the filename containing one of the strings in withprefix list, useful for debugging contrib: [bool] include the noisy contrib anntations from DIVA performers d_category_to_shortlabel: [dict] is a dictionary mapping category names to a short displayed label on the video. The standard for visualization is that tracked objects are displayed with their category label (e.g. 'Person', 'Vehicle'), and activities are labeled according to the set of objects that performing the activity. When an activity occurs, the set of objects are labeled with the same color as 'Noun Verbing' (e.g. 'Person Entering', 'Person Reading', 'Vehicle Starting') where 'Verbing' is provided by the shortlabel. This is optional, and will use the default mapping if None verbose: [bool] Parsing verbosity merge: [bool] deduplicate annotations for each video across YAML files by merging them by mean spatial IoU per track (>0.5) and temporal IoU (>0) actor: [bool] Include only those activities that include an associated track for the primary actor: \"Person\" for \"person_ \" and \"hand_ \", else \"Vehicle\" disjoint: [bool]: Enforce that overlapping causal activities (open/close, enter/exit,  .) are disjoint for a track unpad: [bool] remove the arbitrary padding assigned during dataset creation Returns: a list of  vipy.video.Scene objects Kwiver packet format: https: gitlab.kitware.com/meva/meva-data-repo/blob/master/documents/KPF-specification-v4.pdf"
},
{
"ref":"vipy.data.meva.KF1.videos",
"url":75,
"doc":"Return list of activity videos",
"func":1
},
{
"ref":"vipy.data.meva.KF1.dataset",
"url":75,
"doc":"",
"func":1
},
{
"ref":"vipy.data.meva.KF1.tolist",
"url":75,
"doc":"",
"func":1
},
{
"ref":"vipy.data.meva.KF1.instances",
"url":75,
"doc":"Return list of activity instances",
"func":1
},
{
"ref":"vipy.data.meva.KF1.categories",
"url":75,
"doc":"Return a list of activity categories",
"func":1
},
{
"ref":"vipy.data.meva.KF1.analysis",
"url":75,
"doc":"Analyze the MEVA dataset to return helpful statistics and plots",
"func":1
},
{
"ref":"vipy.data.meva.KF1.review",
"url":75,
"doc":"Generate a standalone HTML file containing quicklooks for each annotated activity in dataset, along with some helpful provenance information for where the annotation came from",
"func":1
},
{
"ref":"vipy.data.mmcommons",
"url":76,
"doc":""
},
{
"ref":"vipy.noise",
"url":77,
"doc":""
},
{
"ref":"vipy.noise.left_shear",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.right_shear",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.rotate",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.barrel",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.left_swirl",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.right_swirl",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.horizontal_mirror",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.vertical_mirror",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.vertical_motion_blur",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.horizontal_motion_blur",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.ghost",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.crop",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.fliplr",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.flipud",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.rot90cw",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.rot90ccw",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.translate",
"url":77,
"doc":"Translate by (dx,dy) pixels, with zero border handling",
"func":1
},
{
"ref":"vipy.noise.isotropic_scale",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.zoom",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.blur",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.salt_and_pepper",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.jpeg_compression",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.bit_depth",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.solarize",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.permute_color_channels",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.greyscale",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.bgr",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.hot",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.rainbow",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.saturate",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.colorjitter",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.sharpness",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.gamma",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.autocontrast",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.edge",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.emboss",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.darken",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.negative",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.scan_lines",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.additive_gaussian_noise",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.Noise",
"url":77,
"doc":""
},
{
"ref":"vipy.noise.Noise.transformations",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.Noise.random_transformation",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.Noise.transform",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.Noise.montage",
"url":77,
"doc":"",
"func":1
},
{
"ref":"vipy.noise.RandomCrop",
"url":77,
"doc":""
},
{
"ref":"vipy.noise.Geometric",
"url":77,
"doc":""
},
{
"ref":"vipy.noise.Photometric",
"url":77,
"doc":""
},
{
"ref":"vipy.noise.Perturbation",
"url":77,
"doc":""
},
{
"ref":"vipy.dataset",
"url":23,
"doc":""
},
{
"ref":"vipy.dataset.Dataset",
"url":23,
"doc":"vipy.dataset.Dataset() class Common class to manipulate large sets of objects in parallel Args: - dataset [list, tuple, set, obj]: a python built-in type that supports indexing or a generic object that supports indexing and has a length - id [str]: an optional id of this dataset, which provides a descriptive name of the dataset - loader [callable]: a callable loader that will construct the object from a raw data element in dataset. This is useful for custom deerialization or on demand transformations Datasets can be indexed, shuffled, iterated, minibatched, sorted, sampled, partitioned. Datasets constructed of vipy objects are lazy loaded, delaying loading pixels until they are needed   (trainset, valset, testset) = vipy.dataset.registry('mnist') (trainset, valset) = trainset.partition(0.9, 0.1) categories = trainset.set(lambda im: im.category( smaller = testset.take(1024) preprocessed = smaller.map(lambda im: im.resize(32, 32).gain(1/256 for b in preprocessed.minibatch(128): print(b)  visualize the dataset (trainset, valset, testset) = vipy.dataset.registry('pascal_voc_2007') for im in trainset: im.mindim(1024).show().print(sleep=1).close()   Datasets can be constructed from directories of json files or image files ( vipy.dataset.Dataset.from_directory ) Datasets can be constructed from a single json file containing a list of objects ( vipy.dataset.Dataset.from_json )  note that if a lambda function is provided as loader then this dataset is not serializable. Use self.load() then serialize"
},
{
"ref":"vipy.dataset.Dataset.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.dataset.Dataset.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.dataset.Dataset.from_json",
"url":23,
"doc":"",
"func":1
},
{
"ref":"vipy.dataset.Dataset.cast",
"url":23,
"doc":"",
"func":1
},
{
"ref":"vipy.dataset.Dataset.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.dataset.Dataset.is_streaming",
"url":23,
"doc":"",
"func":1
},
{
"ref":"vipy.dataset.Dataset.len",
"url":23,
"doc":"",
"func":1
},
{
"ref":"vipy.dataset.Dataset.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.dataset.Dataset.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.dataset.Dataset.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.dataset.Dataset.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the optimal shuffling strategy for the dataset structure to maximize performance. This method will use either Dataset.streaming_shuffler (for iterable datasets) or Dataset.uniform_shuffler (for random access datasets)",
"func":1
},
{
"ref":"vipy.dataset.Dataset.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.dataset.Dataset.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.dataset.Dataset.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.dataset.Dataset.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.dataset.Dataset.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.dataset.Dataset.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.dataset.Dataset.countby",
"url":23,
"doc":"",
"func":1
},
{
"ref":"vipy.dataset.Dataset.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.dataset.Dataset.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.dataset.Dataset.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.dataset.Dataset.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.dataset.Dataset.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.dataset.Dataset.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.dataset.Dataset.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.dataset.Dataset.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.dataset.Dataset.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.dataset.Dataset.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.dataset.Dataset.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.dataset.Dataset.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.dataset.Dataset.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.dataset.Dataset.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.dataset.Dataset.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.dataset.Dataset.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.dataset.Dataset.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.dataset.Dataset.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.dataset.Dataset.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.dataset.Dataset.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.dataset.Dataset.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.dataset.Dataset.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.dataset.Dataset.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.dataset.Dataset.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.dataset.Dataset.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.dataset.Dataset.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.dataset.Dataset.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.dataset.Dataset.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.dataset.Paged",
"url":23,
"doc":"Paged dataset. A paged dataset is a dataset of length N=M P constructed from M archive files (the pages) each containing P elements (the pagesize). The paged dataset must be constructed with tuples of (pagesize, filename). The loader will fetch, load and cache the pages on demand using the loader, preserving the most recently used cachesize pages   D = vipy.dataset.Paged([(64, 'archive1.pkl'), (64, 'archive2.pkl')], lambda x,y: ivy.load(y    note  Shuffling this dataset is biased. Shuffling will be performed to mix the indexes, but not uniformly at random. The goal is to preserve data locality to minimize cache misses."
},
{
"ref":"vipy.dataset.Paged.shuffle",
"url":23,
"doc":"Permute elements while preserve page locality to minimize cache misses",
"func":1
},
{
"ref":"vipy.dataset.Paged.flush",
"url":23,
"doc":"",
"func":1
},
{
"ref":"vipy.dataset.Paged.chunk_shuffler",
"url":23,
"doc":"Split dataset into len(D)/chunksize non-overlapping chunks with some common property returned by chunker, shuffle chunk order and shuffle within chunks. - If chunksize=1 then this is equivalent to uniform_shuffler - chunker must be a callable of some property that is used to group into chunks",
"func":1
},
{
"ref":"vipy.dataset.Paged.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.dataset.Paged.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.dataset.Paged.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.dataset.Paged.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.dataset.Paged.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.dataset.Paged.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.dataset.Paged.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.dataset.Paged.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.dataset.Paged.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.dataset.Paged.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.dataset.Paged.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.dataset.Paged.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.dataset.Paged.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.dataset.Paged.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.dataset.Paged.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.dataset.Paged.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.dataset.Paged.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.dataset.Paged.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.dataset.Paged.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.dataset.Paged.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.dataset.Paged.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.dataset.Paged.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.dataset.Paged.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.dataset.Paged.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.dataset.Paged.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.dataset.Paged.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.dataset.Paged.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.dataset.Paged.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.dataset.Paged.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.dataset.Paged.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.dataset.Paged.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.dataset.Paged.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.dataset.Paged.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.dataset.Paged.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.dataset.Paged.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.dataset.Paged.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.dataset.Paged.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.dataset.Paged.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.dataset.Paged.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.dataset.Paged.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.dataset.Union",
"url":23,
"doc":"vipy.dataset.Union() class Common class to manipulate groups of vipy.dataset.Dataset objects in parallel Usage: >>> cifar10 = vipy.dataset.registry('cifar10') >>> mnist = vipy.dataset.registry('mnist') >>> dataset = vipy.dataset.Union(mnist, cifar10) >>> dataset = mnist | cifar10 Args: Datasets"
},
{
"ref":"vipy.dataset.Union.is_streaming",
"url":23,
"doc":"",
"func":1
},
{
"ref":"vipy.dataset.Union.index",
"url":23,
"doc":"Update the index, useful for filtering of large datasets",
"func":1
},
{
"ref":"vipy.dataset.Union.clone",
"url":23,
"doc":"Return a copy of the dataset object",
"func":1
},
{
"ref":"vipy.dataset.Union.datasets",
"url":23,
"doc":"Return the dataset union elements, useful for generating unions of unions",
"func":1
},
{
"ref":"vipy.dataset.Union.shuffle",
"url":23,
"doc":"Permute elements in this dataset uniformly at random in place using the best shuffler for the dataset structure",
"func":1
},
{
"ref":"vipy.dataset.Union.streaming_shuffler",
"url":23,
"doc":"A uniform shuffle (approximation) on the dataset elements for iterable access only",
"func":1
},
{
"ref":"vipy.dataset.Union.from_directory",
"url":23,
"doc":"Recursively search indir for filetype, construct a dataset from all discovered files of that type",
"func":1
},
{
"ref":"vipy.dataset.Union.from_image_urls",
"url":23,
"doc":"Construct a dataset from a list of image URLs",
"func":1
},
{
"ref":"vipy.dataset.Union.raw",
"url":23,
"doc":"Return a view of this dataset without the loader",
"func":1
},
{
"ref":"vipy.dataset.Union.id",
"url":23,
"doc":"Set or return the dataset id, useful for showing the name/split of the dataset in the representation string",
"func":1
},
{
"ref":"vipy.dataset.Union.repeat",
"url":23,
"doc":"Repeat the dataset n times. If n=0, the dataset is unchanged, if n=1 the dataset is doubled in length, etc.",
"func":1
},
{
"ref":"vipy.dataset.Union.tuple",
"url":23,
"doc":"Return the dataset as a tuple, applying the optional mapper lambda on each element, applying optional flattener on sequences returned by mapper, and applying the optional reducer lambda on the final tuple, return a generator",
"func":1
},
{
"ref":"vipy.dataset.Union.list",
"url":23,
"doc":"Return a tuple as a list, loading into memory",
"func":1
},
{
"ref":"vipy.dataset.Union.set",
"url":23,
"doc":"Return the dataset as a set. Mapper must be a lambda function that returns a hashable type",
"func":1
},
{
"ref":"vipy.dataset.Union.frequency",
"url":23,
"doc":"Frequency counts for which lamba returns the same value",
"func":1
},
{
"ref":"vipy.dataset.Union.count",
"url":23,
"doc":"Counts for each element for which lamba returns true. Args: f: [lambda] if provided, count the number of elements that return true. Returns: A length of elements that satisfy f(v) = True [if f is not None]",
"func":1
},
{
"ref":"vipy.dataset.Union.filter",
"url":23,
"doc":"In place filter with lambda function f, keeping those elements obj in-place where f(obj) evaluates true. Callable should return bool",
"func":1
},
{
"ref":"vipy.dataset.Union.take",
"url":23,
"doc":"Randomly Take n elements from the dataset, and return a dataset (in-place or cloned).",
"func":1
},
{
"ref":"vipy.dataset.Union.groupby",
"url":23,
"doc":"Group the dataset according to the callable f, returning dictionary of grouped datasets.",
"func":1
},
{
"ref":"vipy.dataset.Union.takeby",
"url":23,
"doc":"Filter the dataset according to the callable f, take n from each group and return a dataset. Callable should return bool",
"func":1
},
{
"ref":"vipy.dataset.Union.takelist",
"url":23,
"doc":"Take n elements and return list. The elements are loaded and not cloned.",
"func":1
},
{
"ref":"vipy.dataset.Union.takeone",
"url":23,
"doc":"Randomly take one element from the dataset and return a singleton",
"func":1
},
{
"ref":"vipy.dataset.Union.sample",
"url":23,
"doc":"Return a single element sampled uniformly at random",
"func":1
},
{
"ref":"vipy.dataset.Union.take_fraction",
"url":23,
"doc":"Randomly take a percentage of the dataset, returning a clone or in-place",
"func":1
},
{
"ref":"vipy.dataset.Union.inverse_frequency",
"url":23,
"doc":"Return the inverse frequency of elements grouped by the callable f. Returns a dictionary of the callable output to inverse frequency",
"func":1
},
{
"ref":"vipy.dataset.Union.load",
"url":23,
"doc":"Cache the entire dataset into memory",
"func":1
},
{
"ref":"vipy.dataset.Union.chunk",
"url":23,
"doc":"Yield n chunks as list. Last chunk will be ragged.",
"func":1
},
{
"ref":"vipy.dataset.Union.batch",
"url":23,
"doc":"Yield batches of size n as datasets. Last batch will be ragged. Batches are not loaded. Batches have appended id equal to the zero-indexed batch order",
"func":1
},
{
"ref":"vipy.dataset.Union.minibatch",
"url":23,
"doc":"Yield preprocessed minibatches of size n of this dataset. To yield chunks of this dataset, suitable for minibatch training/testing   D = vipy.dataset.Dataset( .) for b in D.minibatch(n): print(b)   To perform minibatch image downloading in parallel across four processes with the context manager:   D = vipy.dataset.registry('yfcc100m_url:train').take(128) with vipy.globals.parallel(4): for b in D.minibatch(16, loader=vipy.image.Transform.download, accepter=lambda im: im.is_downloaded( : print(b)  complete minibatch that passed accepter   Args: n [int]: The size of the minibatch ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped bufsize [int]: The size of the buffer used in parallel processing of elements. Useful for parallel loading accepter [callable]: A callable that returns true|false on an element, where only elements that return true are included in the minibatch. useful for parallel loading of elements that may fail to download Returns: Iterator over  vipy.dataset.Dataset elements of length n. Minibatches will be yielded loaded and preprocessed (processing done concurrently if vipy.parallel.executor() is initialized)  note The distributed iterator appends the minibatch index to the minibatch.id().  note If there exists a vipy.parallel.exeuctor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.dataset.Union.shift",
"url":23,
"doc":"Circular shift the dataset m elements to the left, so that self[k+m]  self.shift(m)[k]. Circular shift for boundary handling so that self.shift(m)[-1]  self[m-1]",
"func":1
},
{
"ref":"vipy.dataset.Union.slice",
"url":23,
"doc":"Slice the dataset to contain elements defined by slice(start, stop, step)",
"func":1
},
{
"ref":"vipy.dataset.Union.truncate",
"url":23,
"doc":"Truncate the dataset to contain the first m elements only",
"func":1
},
{
"ref":"vipy.dataset.Union.pipeline",
"url":23,
"doc":"Yield pipelined minibatches of size n with pipeline length m. A pipelined minibatch is a tuple (head, tail) such that (head, tail) are minibatches at different indexes in the dataset. Head corresponds to the current minibatch and tail corresponds to the minibatch left shifted by (m-1) minibatches. This structure is useful for yielding datasets for pipelined training where head contains the minibatch that will complete pipeline training on this iteration, and tail contains the next minibatch to be inserted into the pipeline on this iteration.   D = vipy.dataset.Dataset( .) for (head, tail) in D.pipeline(n, m, prepad=False, postpad=False): assert head  D[0:m] assert tail  D[n (m-1): n (m-1)+n] Args: n [int]: The size of each minibatch m [int]: The pipeline length in minibatches ragged [bool]: If ragged=true, then the last chunk will be ragged with len(chunk)<n, else skipped prepad: If true, yield (head, tail)  (None, batch) when filling the pipeline postpad: If true, yield (head, tail)  (batch, None) when flushing the pipeline Returns: Iterator over tuples (head,tail) of  vipy.dataset.Dataset elements of length n where tail is left shifted by n (m-1) elements.  note The distributed iterator is not order preserving over minibatches and yields minibatches as completed, however the tuple (head, tail) is order preserving within the pipeline  note If there exists a vipy.parallel.executor(), then loading and preprocessing will be performed concurrently",
"func":1
},
{
"ref":"vipy.dataset.Union.chunks",
"url":23,
"doc":"Partition the dataset into chunks of size given by the tuple in partitions, and give the dataset suffix if provided",
"func":1
},
{
"ref":"vipy.dataset.Union.partition",
"url":23,
"doc":"Partition the dataset into the requested (train,val,test) fractions. Args: trainfraction [float]: fraction of dataset for training set valfraction [float]: fraction of dataset for validation set testfraction [float]: fraction of dataset for test set trainsuffix: If not None, append this string the to trainset ID valsuffix: If not None, append this string the to valset ID testsuffix: If not None, append this string the to testset ID Returns: (trainset, valset, testset) such that trainset is the first trainfraction of the dataset.  note This does not permute the dataset. To randomize split, shuffle dataset first",
"func":1
},
{
"ref":"vipy.dataset.Union.split",
"url":23,
"doc":"Split the dataset into two datasets, one of length size, the other of length len(self)-size",
"func":1
},
{
"ref":"vipy.dataset.Union.streaming_map",
"url":23,
"doc":"Returns a generator that will apply the mapper and yield only those elements that return True from the accepter. Performs the map in parallel if used in the vipy.globals.parallel context manager",
"func":1
},
{
"ref":"vipy.dataset.Union.map",
"url":23,
"doc":"Parallel map. To perform this in parallel across four threads:   D = vipy.dataset.Dataset( .) with vipy.globals.parallel(4): D = D.map(lambda v:  .)   Args: f_map: [lambda] The lambda function to apply in parallel to all elements in the dataset. This must return a JSON serializable object (or set oneway=True) strict: [bool] If true, raise exception on distributed map failures, otherwise the map will return only those that succeeded oneway: [bool] If true, do not pass back results unless exception. This is useful for distributed processing Returns: A  vipy.dataset.Dataset containing the elements f_map(v). This operation is order preserving if ordered=True.  note - This method uses dask distributed and  vipy.batch.Batch operations - Due to chunking, all error handling is caught by this method. Use  vipy.batch.Batch to leverage dask distributed futures error handling. - Operations must be chunked and serialized because each dask task comes with overhead, and lots of small tasks violates best practices - Serialized results are deserialized by the client and returned a a new dataset",
"func":1
},
{
"ref":"vipy.dataset.Union.localmap",
"url":23,
"doc":"A map performed without any parallel processing",
"func":1
},
{
"ref":"vipy.dataset.Union.zip",
"url":23,
"doc":"Returns a new dataset constructed by applying the callable on elements from zip(self,iter)",
"func":1
},
{
"ref":"vipy.dataset.Union.sort",
"url":23,
"doc":"Sort the dataset in-place using the sortkey lambda function f To perform a sort of the dataset using some property of the instance, such as the object category (e.g. for vipy.image.ImageCategory)   dataset.sort(lambda im: im.category(  ",
"func":1
},
{
"ref":"vipy.dataset.Union.uniform_shuffler",
"url":23,
"doc":"A uniform shuffle on the dataset elements. Iterable access will be slow due to random access",
"func":1
},
{
"ref":"vipy.dataset.Union.identity_shuffler",
"url":23,
"doc":"Shuffler that does nothing",
"func":1
},
{
"ref":"vipy.dataset.registry",
"url":23,
"doc":"Common entry point for loading datasets by name. Usage: >>> trainset = vipy.dataset.registry('cifar10', split='train')  return a training split >>> valset = vipy.dataset.registry('cifar10:val', datadir='/tmp/cifar10')  download to a custom location >>> datasets = vipy.dataset.registry 'cifar10:train','cifar100:train'  return a union >>> vipy.dataset.registry()  print allowable datasets Args: name [str]: The string name for the dataset. If tuple, return a  vipy.dataset.Union . If None, return the list of registered datasets. Append name:train, name:val, name:test to output the requested split, or use the split keyword. datadir [str]: A path to a directory to store data. Defaults to environment variable VIPY_DATASET_REGISTRY_HOME (then VIPY_CACHE if not found). Also uses HF_HOME for huggingface datasets. Datasets will be stored in datadir/name freeze [bool]: If true, disable reference cycle counting for the loaded object (which will never contain cycles anyway) clean [bool]: If true, force a redownload of the dataset to correct for partial download errors download [bool]: If true, force a redownload of the dataset to correct for partial download errors split [str]: return 'train', 'val' or 'test' split. If None, return (trainset, valset, testset) tuple Datasets: 'mnist','cifar10','cifar100','caltech101','caltech256','oxford_pets','sun397', 'food101','stanford_dogs', 'flickr30k','oxford_fgvc_aircraft','oxford_flowers_102','eurosat','d2d','ethzshapes','coil100','kthactions', 'yfcc100m','yfcc100m_url','tiny_imagenet','coyo300m','coyo700m','pascal_voc_2007','coco_2014', 'ava', 'activitynet', 'open_images_v7', 'imagenet', 'imagenet21k', 'visualgenome' ,'widerface','meva_kf1', 'objectnet','lfw','inaturalist_2021','kinetics','hmdb','places365','ucf101','lvis','kitti', 'imagenet_localization','laion2b','datacomp_1b','imagenet2014_det','imagenet_faces','youtubeBB', 'pip_370k','pip_175k','cap','cap_pad','cap_detection','tiny_virat' Returns: (trainset, valset, testset) tuple where each is a  vipy.dataset.Dataset or None, or a single split if name has a \":SPLIT\" suffix or split kwarg provided",
"func":1
},
{
"ref":"vipy.util",
"url":78,
"doc":""
},
{
"ref":"vipy.util.class_registry",
"url":78,
"doc":"Return a dictionary mapping str(type(obj to a JSON loader for all vipy objects. This function is useful for JSON loading of vipy objects to map to the correct deserialization method.",
"func":1
},
{
"ref":"vipy.util.save",
"url":78,
"doc":"Save variables to an archive file. This function allows vipy objects to be serialized to disk for later loading.   im = vipy.image.owl() im = vipy.util.load(vipy.util.save(im  round trip   Args: vars: A python object to save. This can be any serializable python object outfile: An output file to save. Must have extension [.pkl, .json, .pkl.bz2]. If None, will save to a temporary JSON file. backup [bool]: If true and the outfile already exists, make a copy and save as outfile.bak before overwriting Returns A path to the saved archive file. Load using  vipy.util.load .  note JSON is preferred as an archive format for vipy. Be sure to install the excellent ultrajson library (pip install ujson) for fast serialization.",
"func":1
},
{
"ref":"vipy.util.load",
"url":78,
"doc":"Load variables from a relocatable archive file format, either dill pickle, JSON format or JSON directory format. Loading is performed by attemping the following: 1. If the input file is a directory, return a  vipy.dataset.Dataset with lazy loading of all pkl or json files recursively discovered in this directory. 2. If the input file is a pickle or json file, load it 3. if abspath=true, then convert relative paths to absolute paths for object when loaded 4. If freeze=True, then disable the python reference cycle garbage collector for the object loaded by this file   im = vipy.image.owl() f = vipy.util.save(im) im = vipy.util.load(im)   Args: infile: [str] file saved using  vipy.util.save with extension [.pkl, .json]. This may also be a directory tree containing json or pkl files abspath: [bool] If true, then convert all vipy objects with relative paths to absolute paths. If False, then preserve relative paths and warn user. freeze: [bool] If True, then disable python reference cycle garbage collector for this loaded object. relocatable: [bool] If True, then perform relocatable relative and absolute paths for vipy objects containing filenames Returns: The object in the archive file",
"func":1
},
{
"ref":"vipy.util.is_jsonable",
"url":78,
"doc":"Return true if can be successfully converted to json (without actually doing it) by recursive type checking",
"func":1
},
{
"ref":"vipy.util.dirload",
"url":78,
"doc":"Load a directory by recursively searching for loadable archives and loading them into a flat list",
"func":1
},
{
"ref":"vipy.util.dedupe",
"url":78,
"doc":"Deduplicate the list using the provided lambda function which transforms an element to a dedupe key, such that all elements with the same key are duplicates",
"func":1
},
{
"ref":"vipy.util.pklbz2",
"url":78,
"doc":"Read/Write a bz2 compressed pickle file",
"func":1
},
{
"ref":"vipy.util.catcher",
"url":78,
"doc":"Call the function f with the provided arguments, and return (True, result) on success and (False, exception) if there is any thrown exception. Useful for parallel processing Useful for wrapping a function where execptions are silent. For example, attempting to remove a file where the filename may be None or not present >>> vipy.util.catcher(lambda f: os.remove(f), None) >>> vipy.util.catcher(lambda f: os.remove(f), '/path/to/missing.txt' ",
"func":1
},
{
"ref":"vipy.util.mergedict",
"url":78,
"doc":"Combine keys of two or more dictionaries and return a dictionary deep copy.   d1 = {1:2} d2 = {3:4} d3 = mergedict(d1,d2) assert d3  {1:2, 3:4}  ",
"func":1
},
{
"ref":"vipy.util.env",
"url":78,
"doc":"Return the VIPY environment variable var, returning None if not present, or all environment variables if var=None. Var is optionally prepended with 'VIPY_'",
"func":1
},
{
"ref":"vipy.util.hascache",
"url":78,
"doc":"Is the VIPY_CACHE environment variable set?",
"func":1
},
{
"ref":"vipy.util.cache",
"url":78,
"doc":"If the VIPY_CACHE environment variable set, return it otherwise return tempdir()",
"func":1
},
{
"ref":"vipy.util.tocache",
"url":78,
"doc":"If the VIPY_CACHE environment variable is set, then return the filename=subpath/to/file.ext in the cache as VIPY_CACHE/subpath/to/file.ext. Otherwise, return the file in the system temp",
"func":1
},
{
"ref":"vipy.util.seconds_to_MMSS_colon_notation",
"url":78,
"doc":"Convert integer seconds into MM:SS colon format. If sec=121, then return '02:01'.",
"func":1
},
{
"ref":"vipy.util.try_import",
"url":78,
"doc":"Show a helpful error message for missing optional packages",
"func":1
},
{
"ref":"vipy.util.findyaml",
"url":78,
"doc":"Return a list of absolute paths to yaml files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findpkl",
"url":78,
"doc":"Return a list of absolute paths to pkl files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findpickle",
"url":78,
"doc":"Return a list of absolute paths to pkl files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findpklbz2",
"url":78,
"doc":"Return a list of absolute paths to .pkl.bz2 files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findpdf",
"url":78,
"doc":"Return a list of absolute paths to pdf files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findpng",
"url":78,
"doc":"Return a list of absolute paths to png files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findjpg",
"url":78,
"doc":"Return a list of absolute paths to jpg files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findjson",
"url":78,
"doc":"Return a list of absolute paths to json files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findtxt",
"url":78,
"doc":"Return a list of absolute paths to txt files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findtar",
"url":78,
"doc":"Return a list of absolute paths to tar files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findtargz",
"url":78,
"doc":"Return a list of absolute paths to .pkl.bz2 files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findimage",
"url":78,
"doc":"Return a list of absolute paths to image files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findimages",
"url":78,
"doc":"Alias for  vipy.util.findimage ",
"func":1
},
{
"ref":"vipy.util.findvideo",
"url":78,
"doc":"Return a list of absolute paths to video files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findwebp",
"url":78,
"doc":"Return a list of absolute paths to video files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findxml",
"url":78,
"doc":"Return a list of absolute paths to video files recursively discovered by walking the directory tree rooted at basedir",
"func":1
},
{
"ref":"vipy.util.findvideos",
"url":78,
"doc":"Alias for  vipy.util.findvideo ",
"func":1
},
{
"ref":"vipy.util.findloadable",
"url":78,
"doc":"Return a list of absolute paths to any archive file loadable by  vipy.load ( .pkl,  .json,  .pkl.bz2). Recursively search starting from basedir",
"func":1
},
{
"ref":"vipy.util.readyaml",
"url":78,
"doc":"Read a yaml file and return a parsed dictionary, this is slow for large yaml files",
"func":1
},
{
"ref":"vipy.util.count_images_in_subdirectories",
"url":78,
"doc":"Count the total number of images in indir/subdir1, indir/subdir2, go down only one level and no further .",
"func":1
},
{
"ref":"vipy.util.keymax",
"url":78,
"doc":"Return key in dictionary containing maximum value",
"func":1
},
{
"ref":"vipy.util.keymin",
"url":78,
"doc":"Return key in dictionary containing minimum value",
"func":1
},
{
"ref":"vipy.util.isjsonfile",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.writejson",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.readjson",
"url":78,
"doc":"Read jsonfile=/path/to/file.json and return the json parsed object, issue warning if jsonfile does not have .json extension and strict=True",
"func":1
},
{
"ref":"vipy.util.tryjson",
"url":78,
"doc":"Attempt to load the json file, return True if loadable, False if not",
"func":1
},
{
"ref":"vipy.util.groupby",
"url":78,
"doc":"groupby on unsorted input iterable (initer)",
"func":1
},
{
"ref":"vipy.util.vipy_groupby",
"url":78,
"doc":"groupby on unsorted inset",
"func":1
},
{
"ref":"vipy.util.groupbyasdict",
"url":78,
"doc":"Return dictionary of keys and lists from groupby on unsorted inset, where keyfunc is a lambda function on elements in inset Args: togroup: an iteraable of elements to group keyfunc: a lambda function to operate on elements of togroup such that the value returned from the lambda is the equality key for grouping valuefunc: a lambda function to operate on elements of to group such that the value returned from the lambda is a transform of the element to be grouped Returns: A dictionary with unique keys returned from keyfunc, and values are lists of elements in togroup with the same key",
"func":1
},
{
"ref":"vipy.util.countby",
"url":78,
"doc":"Return dictionary of keys and group sizes for a grouping of the input list by keyfunc lambda function, sorted by increasing count",
"func":1
},
{
"ref":"vipy.util.sumby",
"url":78,
"doc":"Given an inlist of tuples [('a',1), ('a',2), ('b',4)], group by the keyfunc, then sum over the values in valuefunc. Returns ductionary over keys, sum reduced over valuefunc. Example returns {'a':3,'b':4}.",
"func":1
},
{
"ref":"vipy.util.most_frequent",
"url":78,
"doc":"Return the most frequent element as determined by element equality",
"func":1
},
{
"ref":"vipy.util.countbyasdict",
"url":78,
"doc":"Alias for  vipy.util.countby ",
"func":1
},
{
"ref":"vipy.util.softmax",
"url":78,
"doc":"Row-wise softmax",
"func":1
},
{
"ref":"vipy.util.permutelist",
"url":78,
"doc":"randomly permute list order. Permutation is deterministic (same permutation on multiple calls) if specified. Shuffle is not in place",
"func":1
},
{
"ref":"vipy.util.shufflelist",
"url":78,
"doc":"Randomly shuffle a list, returning the shuffled list. Shuffle is not in-place",
"func":1
},
{
"ref":"vipy.util.flatlist",
"url":78,
"doc":"Convert list of tuples into a list expanded by concatenating tuples. If the input is already flat, return it unchanged.",
"func":1
},
{
"ref":"vipy.util.rmdir",
"url":78,
"doc":"Recursively remove directory and all contents (if the directory exists)",
"func":1
},
{
"ref":"vipy.util.dividelist",
"url":78,
"doc":"Divide inlist into a list of lists such that the size of each sublist is the requseted fraction of the original list. This operation is deterministic and generates the same division in multiple calls. Args: inlist: [list] fractions: [tuple] such as (0.1, 0.7, 0.2) An iterable of fractions that must be non-negative and sum to one",
"func":1
},
{
"ref":"vipy.util.pairwise",
"url":78,
"doc":"Equivalent to python-3.10 itertools.pairwise. >>> pairwise('ABCD')  > (A,B), (B,C), (C,D) >>> pairwise('ABCD', prepad=True, padval=0)  > (0,A), (A,B), (B,C), (C,D) >>> pairwise('ABCD', postpad=True)  > (A,B), (B,C), (C,D), (D,None) >>> pairwise([(1,1),(2,2)], prepad=True, postpad=True, padval=(None,None  > [ None, None), (1, 1 ,  1, 1), (2, 2 ,  2, 2), (None, None ]",
"func":1
},
{
"ref":"vipy.util.chunklist",
"url":78,
"doc":"Convert list into a list of lists of length num_chunks, such that each element is a list containing a sequential chunk of the original list.   (A,B,C) = vipy.util.chunklist(inlist, num_chunks=3) assert len(A)  len(inlist)  3    note The last chunk will be larger for ragged chunks",
"func":1
},
{
"ref":"vipy.util.chunkgen",
"url":78,
"doc":"Yield a list of lists of length num_chunks, such that each element is a list containing a sequential chunk of the original list.   A = next(vipy.util.chunkgen(inlist, num_chunks=3 assert len(A)  len(inlist)  3    note The last chunk will be larger for ragged chunks",
"func":1
},
{
"ref":"vipy.util.chunklistbysize",
"url":78,
"doc":"Convert list into a list of lists such that each element is a list containing a sequential chunk of the original list of length size_per_chunk",
"func":1
},
{
"ref":"vipy.util.chunkgenbysize",
"url":78,
"doc":"Yield a list of lists such that each element is a list containing a sequential chunk of the original list of length size_per_chunk",
"func":1
},
{
"ref":"vipy.util.triplets",
"url":78,
"doc":"Yield triplets (1,2,3), (4,5,6),  . from list inlist=[1,2,3,4,5,6, .]",
"func":1
},
{
"ref":"vipy.util.chunklistWithOverlap",
"url":78,
"doc":"Convert list into a list of lists such that each element is a list containing a sequential chunk of the original list of length size_per_chunk",
"func":1
},
{
"ref":"vipy.util.chunklistwithoverlap",
"url":78,
"doc":"Alias for chunklistWithOverlap",
"func":1
},
{
"ref":"vipy.util.imwritejet",
"url":78,
"doc":"Write a grayscale numpy image as a jet colormapped image to the given file",
"func":1
},
{
"ref":"vipy.util.isuint8",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.isnumber",
"url":78,
"doc":"Is the input a python type of a number or a string containing a number?",
"func":1
},
{
"ref":"vipy.util.isfloat",
"url":78,
"doc":"Is the input a float or a string that can be converted to float?",
"func":1
},
{
"ref":"vipy.util.imwritegray",
"url":78,
"doc":"Write a floating point grayscale numpy image in [0,1] as [0,255] grayscale",
"func":1
},
{
"ref":"vipy.util.imwrite",
"url":78,
"doc":"Write a floating point 2D numpy image as jet or gray, 3D numpy as rgb or bgr",
"func":1
},
{
"ref":"vipy.util.print_and_return",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.savetemp",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.gray2jet",
"url":78,
"doc":"[0,1] grayscale to [0.255] RGB",
"func":1
},
{
"ref":"vipy.util.jet",
"url":78,
"doc":"jet colormap",
"func":1
},
{
"ref":"vipy.util.is_email_address",
"url":78,
"doc":"Is the provided string an email address?",
"func":1
},
{
"ref":"vipy.util.is_hiddenfile",
"url":78,
"doc":"Does the filename start with a period?",
"func":1
},
{
"ref":"vipy.util.seq",
"url":78,
"doc":"Equivalent to matlab [start:step:stop]",
"func":1
},
{
"ref":"vipy.util.loadh5",
"url":78,
"doc":"Load an HDF5 file",
"func":1
},
{
"ref":"vipy.util.loadmat73",
"url":78,
"doc":"Matlab 7.3 format, keys should be a list of keys to access HDF5 file as f[key1][key2] . Returned as numpy array",
"func":1
},
{
"ref":"vipy.util.take",
"url":78,
"doc":"Take k elements at random from inlist",
"func":1
},
{
"ref":"vipy.util.takeone",
"url":78,
"doc":"Take one element at random from inlist or return None if empty",
"func":1
},
{
"ref":"vipy.util.takelast",
"url":78,
"doc":"Take last element from inlist or return None if empty",
"func":1
},
{
"ref":"vipy.util.tryload",
"url":78,
"doc":"Attempt to load a pkl file, and return the value if successful and None if not",
"func":1
},
{
"ref":"vipy.util.canload",
"url":78,
"doc":"Attempt to load an archive file, and return true if it can be successfully loaded, otherwise False",
"func":1
},
{
"ref":"vipy.util.repath",
"url":78,
"doc":"Change the filename with prefix srcpath to dstpath, for any element in v that supports the filename() api",
"func":1
},
{
"ref":"vipy.util.scpsave",
"url":78,
"doc":"Save an archive file to load via SCP. Use case: - This archive format is useful to allow access to videos and images that are accessible behind a remote server for which you have access via SSH key-based authentication. - You create this archive on the remote server, and all vipy objects are replaced with references to remote media. - Every video or image is replaced with a URL of the format 'scp: USER@HOST:/path/to.mp4'. - Vipy will use your SSH keys to SCP these media files from USER@HOST on demand, so that the videos are cached for you on your local machine when you need them. - This is useful for transparently visualizing large datasets that are hidden behind an SSH-only accessible server Usage:   outfile = vipy.util.scpsave([vipy.video.Video(filename='/path/to.mp4)])  run on remote machine that you have SSH key access V = vipy.util.scpload(outfile)  run on local machine that has SSH key access to remote machine V[0].load()  this will SCP the videos from 'scp: /path/to.mp4' to $VIPY_CACHE/to.mp4 transparently and on demand   Args: V: [vipy objects] A list of vipy objects or  vipy.dataset.Dataset username: [str] Your username on the remote machine to select the proper SSH key Returns: A temp archive file stored on the remote machine that will be downloaded and loaded via SCP, such that each element in the list will be fetched via scp when pixels are loaded.",
"func":1
},
{
"ref":"vipy.util.scpload",
"url":78,
"doc":"Load an archive file saved using  vipy.util.scpsave ",
"func":1
},
{
"ref":"vipy.util.load_opencv_yaml",
"url":78,
"doc":"Load a numpy array from YAML file exported from OpenCV",
"func":1
},
{
"ref":"vipy.util.matrix_to_opencv_yaml",
"url":78,
"doc":"Write list of matrices to OpenCV yaml file format with given variable names",
"func":1
},
{
"ref":"vipy.util.save_opencv_yaml",
"url":78,
"doc":"Save a numpy array to YAML file importable by OpenCV",
"func":1
},
{
"ref":"vipy.util.tofilename",
"url":78,
"doc":"Convert arbitrary string to valid filename with underscores replacing invalid chars",
"func":1
},
{
"ref":"vipy.util.isexe",
"url":78,
"doc":"Is the file an executable binary?",
"func":1
},
{
"ref":"vipy.util.isinstalled",
"url":78,
"doc":"Is the command is available on the path",
"func":1
},
{
"ref":"vipy.util.isextension",
"url":78,
"doc":"Does the filename end with the extension ext?   isextension('/path/to/myfile.json', 'json')  True isextension('/path/to/myfile.json', '.json')  True isextension('/path/to/myfile.json', '.pkl')  False  ",
"func":1
},
{
"ref":"vipy.util.ispkl",
"url":78,
"doc":"Is the file a pickle archive file",
"func":1
},
{
"ref":"vipy.util.ispklbz2",
"url":78,
"doc":"Is the file a pickle bz2 archive file",
"func":1
},
{
"ref":"vipy.util.is_pkl_gz",
"url":78,
"doc":"Is the file a pickle gzip archive file",
"func":1
},
{
"ref":"vipy.util.ispklfile",
"url":78,
"doc":"Is the file a pickle archive file",
"func":1
},
{
"ref":"vipy.util.ishtml",
"url":78,
"doc":"Is the file an HTMLfile",
"func":1
},
{
"ref":"vipy.util.ispickle",
"url":78,
"doc":"Is the file a pickle archive file",
"func":1
},
{
"ref":"vipy.util.ishdf5",
"url":78,
"doc":"Is the file an HDF5 file?",
"func":1
},
{
"ref":"vipy.util.filebase",
"url":78,
"doc":"Return c for filename /a/b/c.ext  warning Will return /a/b/c.d for multidot filenames wth more than two trailing dots like /a/b/c.d.e.f (e.g. /a/b/my.filename.tar.gz)",
"func":1
},
{
"ref":"vipy.util.filepath",
"url":78,
"doc":"Return /a/b/c for filename /a/b/c/d.ext, /a/b for filename /a/b/c/d.ext if depth=1, etc",
"func":1
},
{
"ref":"vipy.util.delpath",
"url":78,
"doc":"Return c/d.ext for filename /a/b/c/d.ext and indir /a/b",
"func":1
},
{
"ref":"vipy.util.newpath",
"url":78,
"doc":"Return /d/e/c.ext for filename /a/b/c.ext and newdir /d/e/",
"func":1
},
{
"ref":"vipy.util.newprefix",
"url":78,
"doc":"Return /a/b/c/h/i.ext for filename /f/g/h/i.ext and prefix /a/b/c and depth=1",
"func":1
},
{
"ref":"vipy.util.newpathdir",
"url":78,
"doc":"Return /a/b/n/d/e.ext for filename=/a/b/c/d/e.ext, olddir=c, newdir=n",
"func":1
},
{
"ref":"vipy.util.newpathroot",
"url":78,
"doc":"Return /r/b/c.ext for filename /a/b/c.ext and new root directory r",
"func":1
},
{
"ref":"vipy.util.topath",
"url":78,
"doc":"Alias for  vipy.util.newpath ",
"func":1
},
{
"ref":"vipy.util.filefull",
"url":78,
"doc":"Return /a/b/c for filename /a/b/c.ext",
"func":1
},
{
"ref":"vipy.util.filetail",
"url":78,
"doc":"Return c.ext for filename /a/b/c.ext",
"func":1
},
{
"ref":"vipy.util.matread",
"url":78,
"doc":"Whitespace separated values defining columns, lines define rows. Return numpy array",
"func":1
},
{
"ref":"vipy.util.imlist",
"url":78,
"doc":"return list of images with absolute path in a directory",
"func":1
},
{
"ref":"vipy.util.videolist",
"url":78,
"doc":"return list of videos with absolute path in a directory",
"func":1
},
{
"ref":"vipy.util.dirlist",
"url":78,
"doc":"return list of absolute paths to subdirectories in a directory",
"func":1
},
{
"ref":"vipy.util.dirlist_sorted_bycreation",
"url":78,
"doc":"Sort the directory list from newest first to oldest last by creation date",
"func":1
},
{
"ref":"vipy.util.extlist",
"url":78,
"doc":"return list of files with absolute path in a directory that have the provided extension (with the prepended dot, ext='.mp4')",
"func":1
},
{
"ref":"vipy.util.listext",
"url":78,
"doc":"Alias for extlist",
"func":1
},
{
"ref":"vipy.util.jsonlist",
"url":78,
"doc":"return list of fJSON iles with absolute path in a directory",
"func":1
},
{
"ref":"vipy.util.listjson",
"url":78,
"doc":"Alias for jsonlist",
"func":1
},
{
"ref":"vipy.util.writelist",
"url":78,
"doc":"Write list of strings to an output file with each row an element of the list",
"func":1
},
{
"ref":"vipy.util.readlist",
"url":78,
"doc":"Read each row of file as an element of the list",
"func":1
},
{
"ref":"vipy.util.readtxt",
"url":78,
"doc":"Read a text file one string per row",
"func":1
},
{
"ref":"vipy.util.writecsv",
"url":78,
"doc":"Write list of tuples to an output csv file with each list element on a row and tuple elements separated by commas. Examples:   vipy.util.writecsv([(1,2,3), (4,5,6)], '/tmp/out.csv') vipy.util.writecsv([(1,2,3), (4,5,6)], '/tmp/out.csv', separator=';' vipy.util.writecsv([(1,2,3), (4,5,6)], '/tmp/out.csv', header=('h1','h2','h3'   Args: list_of_tuples: a list of tuples each tuple is a row outfile: the csv file output mode: 'w' for overwrite, 'a' for append separator: a string specifying the separator between columns. defaults to ',' header: a tuple containing strings to be appended to the first row of the csv file comment: the comment symbol to be prepended to the header row Returns: the outfile path",
"func":1
},
{
"ref":"vipy.util.readcsv",
"url":78,
"doc":"Read a csv file into a list of lists, ignore any rows prepended with comment symbol, ignore first row if ignoreheader=True Args: infile: the csv file input separator: a string specifying the separator between columns. defaults to ',' ignoreheader: if true, ignore the first row of the csv file ignore_header: if true, ignore the first row of the csv file (argument synonym) comment: if provided, ignore all rows with this comment symbol prepended Returns: a list of lists, each list element containing a list of elements in the corresponding line of the csv file, parsed by separator  note this parser does not escape delimiters enclosed in double quotes, as may be assumed by some csv writers",
"func":1
},
{
"ref":"vipy.util.readcsvwithheader",
"url":78,
"doc":"Read a csv file into a list of lists",
"func":1
},
{
"ref":"vipy.util.imsavelist",
"url":78,
"doc":"Write out all images in a directory to a provided file with each line containing absolute path to image",
"func":1
},
{
"ref":"vipy.util.csvlist",
"url":78,
"doc":"Return a list of absolute paths of  .csv files in current directory",
"func":1
},
{
"ref":"vipy.util.pklist",
"url":78,
"doc":"Return a list of absolute paths of  .pk files in current directory",
"func":1
},
{
"ref":"vipy.util.listpkl",
"url":78,
"doc":"Return a list of absolute paths of  .pk files in current directory",
"func":1
},
{
"ref":"vipy.util.txtlist",
"url":78,
"doc":"Return a list of absolute paths of  .txt files in current directory",
"func":1
},
{
"ref":"vipy.util.imlistidx",
"url":78,
"doc":"Return index in list of filename containing index number",
"func":1
},
{
"ref":"vipy.util.mat2gray",
"url":78,
"doc":"Convert numpy array to float32 with 1.0=max and 0=min",
"func":1
},
{
"ref":"vipy.util.mdlist",
"url":78,
"doc":"Preallocate 2D list of size MxN",
"func":1
},
{
"ref":"vipy.util.isurl",
"url":78,
"doc":"Is a path a URL? It requires a url scheme and url netloc without any common unallowed characters",
"func":1
},
{
"ref":"vipy.util.shortuuid",
"url":78,
"doc":"Generate a short UUID with n charaters sampled uniformly at random from lowercase|uppercase|numbers",
"func":1
},
{
"ref":"vipy.util.stringhash",
"url":78,
"doc":"Generate a repeatable hash with n characters for a string s",
"func":1
},
{
"ref":"vipy.util.isimageurl",
"url":78,
"doc":"Is a path a URL with image extension?",
"func":1
},
{
"ref":"vipy.util.isvideourl",
"url":78,
"doc":"Is a path a URL with video extension?",
"func":1
},
{
"ref":"vipy.util.isS3url",
"url":78,
"doc":"Is a path a URL for an S3 object?",
"func":1
},
{
"ref":"vipy.util.isyoutubeurl",
"url":78,
"doc":"Is a path a youtube URL?",
"func":1
},
{
"ref":"vipy.util.isRTSPurl",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.isRTMPurl",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.is_rtmp_url",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.islist",
"url":78,
"doc":"Is an object a python list",
"func":1
},
{
"ref":"vipy.util.islistoflists",
"url":78,
"doc":"Is an object a python list of lists x= 1,2], [3,4 ",
"func":1
},
{
"ref":"vipy.util.istupleoftuples",
"url":78,
"doc":"Is an object a python list of lists x= 1,2], [3,4 ",
"func":1
},
{
"ref":"vipy.util.isimageobject",
"url":78,
"doc":"Is an object a vipy.image class Image, ImageCategory, ImageDetection?",
"func":1
},
{
"ref":"vipy.util.isvideotype",
"url":78,
"doc":"Is an object a vipy.video class Video, VideoCategory, Scene?",
"func":1
},
{
"ref":"vipy.util.isvideoobject",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.isvipyobject",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.totuple",
"url":78,
"doc":"Convert an object to a python tuple?",
"func":1
},
{
"ref":"vipy.util.to_iterable",
"url":78,
"doc":"Convert an object to a singleton tuple if not already a list, tuple or set iterable",
"func":1
},
{
"ref":"vipy.util.tolist",
"url":78,
"doc":"Convert a python tuple or singleton object to a list if not already a list",
"func":1
},
{
"ref":"vipy.util.singletonlist",
"url":78,
"doc":"Convert a singleton list to a singleton, otherwise return the list",
"func":1
},
{
"ref":"vipy.util.toset",
"url":78,
"doc":"Convert a python iterable to a set of not already a set",
"func":1
},
{
"ref":"vipy.util.tolist_or_singleton",
"url":78,
"doc":"Return list(x) if length of iterator x is not equal to one, else return x or None. This is useful to return single elements instead of single element lists.",
"func":1
},
{
"ref":"vipy.util.isimg",
"url":78,
"doc":"Is an object an image with a supported image extension ['.jpg','.jpeg','.png','.tif','.tiff','.pgm','.ppm','.gif','.bmp']?",
"func":1
},
{
"ref":"vipy.util.isimage",
"url":78,
"doc":"Alias for  vipy.util.isimg ",
"func":1
},
{
"ref":"vipy.util.isvideofile",
"url":78,
"doc":"Alias for  vipy.util.isvideo ",
"func":1
},
{
"ref":"vipy.util.isimgfile",
"url":78,
"doc":"Alias for  vipy.util.isimg ",
"func":1
},
{
"ref":"vipy.util.has_image_extension",
"url":78,
"doc":"Alias for  vipy.util.isimg ",
"func":1
},
{
"ref":"vipy.util.isimagefile",
"url":78,
"doc":"Alias for  vipy.util.isimg ",
"func":1
},
{
"ref":"vipy.util.isjpeg",
"url":78,
"doc":"is the file a .jpg or .jpeg extension?",
"func":1
},
{
"ref":"vipy.util.iswebp",
"url":78,
"doc":"is the file a .webp extension?",
"func":1
},
{
"ref":"vipy.util.ispng",
"url":78,
"doc":"is the file a .png or .apng extension?",
"func":1
},
{
"ref":"vipy.util.isgif",
"url":78,
"doc":"is the file a .gif extension?",
"func":1
},
{
"ref":"vipy.util.isjpg",
"url":78,
"doc":"Alias for  vipy.util.isjpeg ",
"func":1
},
{
"ref":"vipy.util.iscsv",
"url":78,
"doc":"Is a file a CSV file extension?",
"func":1
},
{
"ref":"vipy.util.isvideo",
"url":78,
"doc":"Is a filename in path a video with a known video extension ['.avi','.mp4','.mov','.wmv','.mpg', 'mkv', 'webm', '3gp']?",
"func":1
},
{
"ref":"vipy.util.isnumpy",
"url":78,
"doc":"Is a python object a numpy object?",
"func":1
},
{
"ref":"vipy.util.isnumpyarray",
"url":78,
"doc":"Is a python object a numpy array?",
"func":1
},
{
"ref":"vipy.util.istextfile",
"url":78,
"doc":"Is the given file a text file?",
"func":1
},
{
"ref":"vipy.util.isxml",
"url":78,
"doc":"Is the given file an xml file?",
"func":1
},
{
"ref":"vipy.util.bgr2gray",
"url":78,
"doc":"Wrapper for numpy uint8 BGR image to uint8 numpy grayscale",
"func":1
},
{
"ref":"vipy.util.gray2bgr",
"url":78,
"doc":"Wrapper for numpy float32 gray image to uint8 numpy BGR",
"func":1
},
{
"ref":"vipy.util.gray2rgb",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.bgr2rgb",
"url":78,
"doc":"Wrapper for numpy BGR uint8 to numpy RGB uint8",
"func":1
},
{
"ref":"vipy.util.rgb2bgr",
"url":78,
"doc":"same as bgr2rgb",
"func":1
},
{
"ref":"vipy.util.bgr2hsv",
"url":78,
"doc":"Convert a numpy array in BGR order to HSV",
"func":1
},
{
"ref":"vipy.util.gray2hsv",
"url":78,
"doc":"Convert a numpy array in floating point single channel greyscale order to HSV",
"func":1
},
{
"ref":"vipy.util.isarchive",
"url":78,
"doc":"Is filename a zip or gzip compressed tar archive?",
"func":1
},
{
"ref":"vipy.util.istgz",
"url":78,
"doc":"Is the filename a .tgz or .tar.gz extension?",
"func":1
},
{
"ref":"vipy.util.istar",
"url":78,
"doc":"Is the filename a .tar extension?",
"func":1
},
{
"ref":"vipy.util.istarbz2",
"url":78,
"doc":"Is the filename a .bz2 or .tar.bz2 extension?",
"func":1
},
{
"ref":"vipy.util.tempfilename",
"url":78,
"doc":"Create a temporary filename $TEMPDIR/$UUID.suffix, suffix should include the dot such as suffix='.jpg',",
"func":1
},
{
"ref":"vipy.util.totempdir",
"url":78,
"doc":"Convert a filename '/patj/to/filename.ext' to '/tempdir/filename.ext'",
"func":1
},
{
"ref":"vipy.util.templike",
"url":78,
"doc":"Create a new temporary filename with the same extension as filename",
"func":1
},
{
"ref":"vipy.util.cached",
"url":78,
"doc":"Create a new filename in the cache, or tempdir if not found",
"func":1
},
{
"ref":"vipy.util.tempimage",
"url":78,
"doc":"Create a temporary image with the given extension",
"func":1
},
{
"ref":"vipy.util.temppng",
"url":78,
"doc":"Create a temporay PNG file",
"func":1
},
{
"ref":"vipy.util.temppickle",
"url":78,
"doc":"Create a temporary pickle file",
"func":1
},
{
"ref":"vipy.util.tempjpg",
"url":78,
"doc":"Create a temporary JPG file in system temp directory",
"func":1
},
{
"ref":"vipy.util.tempMP4",
"url":78,
"doc":"Create a temporary MP4 file in system temp directory",
"func":1
},
{
"ref":"vipy.util.tempWEBP",
"url":78,
"doc":"Create a temporary WEBP file in system temp directory",
"func":1
},
{
"ref":"vipy.util.tmpjpg",
"url":78,
"doc":"Create a temporary JPG file in /tmp",
"func":1
},
{
"ref":"vipy.util.tempcsv",
"url":78,
"doc":"Create a temporary CSV file",
"func":1
},
{
"ref":"vipy.util.temphtml",
"url":78,
"doc":"Create a temporary HTMLfile",
"func":1
},
{
"ref":"vipy.util.temppkl",
"url":78,
"doc":"Create a temporary pickle file",
"func":1
},
{
"ref":"vipy.util.temppklbz2",
"url":78,
"doc":"Create a temporary .pkl.bz2 file",
"func":1
},
{
"ref":"vipy.util.tempyaml",
"url":78,
"doc":"Create a temporary YAML file",
"func":1
},
{
"ref":"vipy.util.tempjson",
"url":78,
"doc":"Create a temporary JSON file",
"func":1
},
{
"ref":"vipy.util.temppdf",
"url":78,
"doc":"Create a temporary PDF file",
"func":1
},
{
"ref":"vipy.util.mktemp",
"url":78,
"doc":"Create a temporary file with extension .ext",
"func":1
},
{
"ref":"vipy.util.tempdir",
"url":78,
"doc":"Wrapper around tempfile, because I can never remember the syntax",
"func":1
},
{
"ref":"vipy.util.imread",
"url":78,
"doc":"Wrapper for opencv imread. Note that color images are imported as BGR!",
"func":1
},
{
"ref":"vipy.util.imrescale",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.imresize",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.touch",
"url":78,
"doc":"Create an empty file containing mystr",
"func":1
},
{
"ref":"vipy.util.Stopwatch",
"url":78,
"doc":"Return elapsed system time in seconds between calls to enter and exit"
},
{
"ref":"vipy.util.Stopwatch.since",
"url":78,
"doc":"Return seconds since start or last call to this method",
"func":1
},
{
"ref":"vipy.util.Stopwatch.reset",
"url":78,
"doc":"",
"func":1
},
{
"ref":"vipy.util.Stopwatch.duration",
"url":78,
"doc":"Time in seconds since last reset",
"func":1
},
{
"ref":"vipy.util.Timer",
"url":78,
"doc":"Pretty print elapsed system time in seconds between calls to enter and exit  python t = Timer(): [some code] print(t) [some more code] print(t) with Timer(): [some code]  "
},
{
"ref":"vipy.util.isfile",
"url":78,
"doc":"Wrapper for os.path.isfile",
"func":1
},
{
"ref":"vipy.util.isstring",
"url":78,
"doc":"Is an object a python string or unicode string?",
"func":1
},
{
"ref":"vipy.util.timestamp",
"url":78,
"doc":"Return date and time string in form DDMMMYY_HHMMSS",
"func":1
},
{
"ref":"vipy.util.clockstamp",
"url":78,
"doc":"Datetime stamp in local timezone with second resolution with format Year-Month-Day Hour:Minute:Second",
"func":1
},
{
"ref":"vipy.util.minutestamp",
"url":78,
"doc":"Return date and time string in form DDMMMYY_HHMM",
"func":1
},
{
"ref":"vipy.util.datestamp",
"url":78,
"doc":"Return date and time string in form DDMMMYY",
"func":1
},
{
"ref":"vipy.util.remkdir",
"url":78,
"doc":"Create a given directory if not already exists",
"func":1
},
{
"ref":"vipy.util.rermdir",
"url":78,
"doc":"Recursively delete a given directory (if exists), and remake it",
"func":1
},
{
"ref":"vipy.util.premkdir",
"url":78,
"doc":"pre-create directory /path/to/subdir using  vipy.util.remkdir if it does not exist for outfile=/path/to/subdir/file.ext, and return filename",
"func":1
},
{
"ref":"vipy.util.newbase",
"url":78,
"doc":"Convert filename=/a/b/c.ext base=d -> /a/b/d.ext",
"func":1
},
{
"ref":"vipy.util.toextension",
"url":78,
"doc":"Convert filename='/path/to/myfile.ext' to /path/to/myfile.xyz, such that newext='xyz' or newext='.xyz'",
"func":1
},
{
"ref":"vipy.util.noextension",
"url":78,
"doc":"Convert filename='/path/to/myfile.ext' or filename='/path/to/myfile.ext1.ext2.ext3' to /path/to/myfile with no extension, removing the appended string past the first dot",
"func":1
},
{
"ref":"vipy.util.topkl",
"url":78,
"doc":"Convert filename='/path/to/myfile.ext' to /path/to/myfile.pkl",
"func":1
},
{
"ref":"vipy.util.splitext",
"url":78,
"doc":"Given /a/b/c.ext return tuple of strings ('/a/b/c', '.ext'), handling multi-dot extensions like .tar.gz",
"func":1
},
{
"ref":"vipy.util.hasextension",
"url":78,
"doc":"Does the provided filename have a file extension (e.g. /path/to/file.ext) or not (e.g. /path/to/file)",
"func":1
},
{
"ref":"vipy.util.fileext",
"url":78,
"doc":"Given filename /a/b/c.ext return '.ext', or /a/b/c.tar.gz return '.tar.gz'. If multidot=False, then return '.gz'. If withdot=False, return 'ext'. Multidot support at most two trailing dots",
"func":1
},
{
"ref":"vipy.util.mediaextension",
"url":78,
"doc":"Return '.mp4' for filename='/a/b/c.mp4'",
"func":1
},
{
"ref":"vipy.util.ismacosx",
"url":78,
"doc":"Is the current platform MacOSX?",
"func":1
},
{
"ref":"vipy.util.islinux",
"url":78,
"doc":"is the current platform Linux?",
"func":1
},
{
"ref":"vipy.util.imcrop",
"url":78,
"doc":"Crop a 2D or 3D numpy image given a vipy.geometry.BoundingBox",
"func":1
},
{
"ref":"vipy.util.Failed",
"url":78,
"doc":"Raised when unit test fails to throw an exception"
},
{
"ref":"vipy.util.string_to_pil_interpolation",
"url":78,
"doc":"Internal function to convert interp string to interp object",
"func":1
},
{
"ref":"vipy.util.symlink",
"url":78,
"doc":"Create a symlink from src to dst, overwriting the existing symlink at dst if overwrite=True",
"func":1
},
{
"ref":"vipy.util.truncate_string",
"url":78,
"doc":"If string s is greater than maxlen, truncate and append an ellipsis",
"func":1
},
{
"ref":"vipy.util.escape_string_for_innerHTML",
"url":78,
"doc":"Convert a string by replacing escape characters with equivalents suitable for copying into an innerHTML element in html. The escaping characters are provided as  character, replacemant),  .) Given an html file with the format:    INNER_HTML   This function converts a string s to an escaped_string such that INNER_HTML replaced with the escaped string will render properly as the string s in-browser. This is useful for  vipy.visualize.scene_explorer to escape json prior to copying into the template This is pretty hacky, there has got to be a better way  .",
"func":1
},
{
"ref":"vipy.object",
"url":79,
"doc":""
},
{
"ref":"vipy.object.Object",
"url":79,
"doc":""
},
{
"ref":"vipy.object.Object.category",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.new_category",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.confidence",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.tags",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.confidences",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.add_tag",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.add_tags",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.has_attribute",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.get_attribute",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.set_attribute",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.del_attribute",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.clear_attributes",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Object.append_attribute",
"url":79,
"doc":"Append the value to attribute key, creating the key as an empty list if it does not exist",
"func":1
},
{
"ref":"vipy.object.Object.has_normalized_coordinates",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Detection",
"url":79,
"doc":"vipy.object.Detection class This class represent a single object detection in the form a bounding box with a label and confidence. The constructor of this class follows a subset of the constructor patterns of vipy.geometry.BoundingBox   d = vipy.object.Detection(category='Person', xmin=0, ymin=0, width=50, height=100) d = vipy.object.Detection(label='Person', xmin=0, ymin=0, width=50, height=100)  \"label\" is an alias for \"category\" d = vipy.object.Detection(label='Person', xywh=[0,0,50,100]) d = vipy.object.Detection( ., id=True)  generate a unique UUID for this detection retrievable with d.id()   Args: - normalized_coordinates [bool]: if True, then all of the (x,y) track coordinates are normalized to [0,1] where (0,0) is the upper left and (1,1) is bottom right. Tracks are converted to pixel coordinates on load(). This is useful for legacy datasets where bounding boxes were stored in a scale invariant manner. This flag avoids having to probe the image to determine the size in the constructor and delays conversion until pixels are loaded."
},
{
"ref":"vipy.object.Detection.cast",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Detection.downcast",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Detection.json",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Detection.from_json",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Detection.dict",
"url":79,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding",
"func":1
},
{
"ref":"vipy.object.Detection.id",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Detection.clone",
"url":79,
"doc":"Copy the object, if deep=True, then include a deep copy of the attribute dictionary, else a shallow copy. Cloned object has the same id()",
"func":1
},
{
"ref":"vipy.object.Detection.attributes",
"url":79,
"doc":""
},
{
"ref":"vipy.object.Detection.xmin",
"url":80,
"doc":"x coordinate of upper left corner of box, x-axis is image column",
"func":1
},
{
"ref":"vipy.object.Detection.ul",
"url":80,
"doc":"Upper left coordinate (x,y)",
"func":1
},
{
"ref":"vipy.object.Detection.ulx",
"url":80,
"doc":"Upper left coordinate (x)",
"func":1
},
{
"ref":"vipy.object.Detection.uly",
"url":80,
"doc":"Upper left coordinate (y)",
"func":1
},
{
"ref":"vipy.object.Detection.ur",
"url":80,
"doc":"Upper right coordinate (x,y)",
"func":1
},
{
"ref":"vipy.object.Detection.urx",
"url":80,
"doc":"Upper right coordinate (x)",
"func":1
},
{
"ref":"vipy.object.Detection.ury",
"url":80,
"doc":"Upper right coordinate (y)",
"func":1
},
{
"ref":"vipy.object.Detection.ll",
"url":80,
"doc":"Lower left coordinate (x,y), synonym for bl()",
"func":1
},
{
"ref":"vipy.object.Detection.bl",
"url":80,
"doc":"Bottom left coordinate (x,y), synonym for ll()",
"func":1
},
{
"ref":"vipy.object.Detection.blx",
"url":80,
"doc":"Bottom left coordinate (x)",
"func":1
},
{
"ref":"vipy.object.Detection.bly",
"url":80,
"doc":"Bottom left coordinate (y)",
"func":1
},
{
"ref":"vipy.object.Detection.lr",
"url":80,
"doc":"Lower right coordinate (x,y), synonym for br()",
"func":1
},
{
"ref":"vipy.object.Detection.br",
"url":80,
"doc":"Bottom right coordinate (x,y), synonym for lr()",
"func":1
},
{
"ref":"vipy.object.Detection.brx",
"url":80,
"doc":"Bottom right coordinate (x)",
"func":1
},
{
"ref":"vipy.object.Detection.bry",
"url":80,
"doc":"Bottom right coordinate (y)",
"func":1
},
{
"ref":"vipy.object.Detection.ymin",
"url":80,
"doc":"y coordinate of upper left corner of box, y-axis is image row, set if provided",
"func":1
},
{
"ref":"vipy.object.Detection.xmax",
"url":80,
"doc":"x coordinate of lower right corner of box, x-axis is image column",
"func":1
},
{
"ref":"vipy.object.Detection.ymax",
"url":80,
"doc":"y coordinate of lower right corner of box, y-axis is image row",
"func":1
},
{
"ref":"vipy.object.Detection.upperleft",
"url":80,
"doc":"Return the (x,y) upper left corner coordinate of the box",
"func":1
},
{
"ref":"vipy.object.Detection.bottomleft",
"url":80,
"doc":"Return the (x,y) lower left corner coordinate of the box",
"func":1
},
{
"ref":"vipy.object.Detection.upperright",
"url":80,
"doc":"Return the (x,y) upper right corner coordinate of the box",
"func":1
},
{
"ref":"vipy.object.Detection.bottomright",
"url":80,
"doc":"Return the (x,y) lower right corner coordinate of the box",
"func":1
},
{
"ref":"vipy.object.Detection.int",
"url":80,
"doc":"Convert corners to integer with rounding, in-place update",
"func":1
},
{
"ref":"vipy.object.Detection.float",
"url":80,
"doc":"Convert corners to float",
"func":1
},
{
"ref":"vipy.object.Detection.significant_digits",
"url":80,
"doc":"Convert corners to have at most n significant digits for efficient JSON storage",
"func":1
},
{
"ref":"vipy.object.Detection.translate",
"url":80,
"doc":"Translate the bounding box by dx in x and dy in y",
"func":1
},
{
"ref":"vipy.object.Detection.to_origin",
"url":80,
"doc":"Translate the bounding box so that (xmin, ymin) = (0,0)",
"func":1
},
{
"ref":"vipy.object.Detection.set_origin",
"url":80,
"doc":"Set the origin of the coordinates of this bounding box to be relative to the upper left of the other bounding box",
"func":1
},
{
"ref":"vipy.object.Detection.offset",
"url":80,
"doc":"Alias for translate",
"func":1
},
{
"ref":"vipy.object.Detection.invalid",
"url":80,
"doc":"Is the box a valid bounding box?",
"func":1
},
{
"ref":"vipy.object.Detection.setwidth",
"url":80,
"doc":"Set new width keeping centroid constant",
"func":1
},
{
"ref":"vipy.object.Detection.setheight",
"url":80,
"doc":"Set new height keeping centroid constant",
"func":1
},
{
"ref":"vipy.object.Detection.centroid",
"url":80,
"doc":"(x,y) tuple of centroid position of bounding box",
"func":1
},
{
"ref":"vipy.object.Detection.xcentroid",
"url":80,
"doc":"Alias for x_centroid()",
"func":1
},
{
"ref":"vipy.object.Detection.centroid_x",
"url":80,
"doc":"Alias for x_centroid()",
"func":1
},
{
"ref":"vipy.object.Detection.ycentroid",
"url":80,
"doc":"Alias for y_centroid()",
"func":1
},
{
"ref":"vipy.object.Detection.centroid_y",
"url":80,
"doc":"Alias for y_centroid()",
"func":1
},
{
"ref":"vipy.object.Detection.area",
"url":80,
"doc":"Return the area=width height of the bounding box, internal method useful for multiple inheritance",
"func":1
},
{
"ref":"vipy.object.Detection.to_xywh",
"url":80,
"doc":"Return bounding box corners as (x,y,width,height) tuple",
"func":1
},
{
"ref":"vipy.object.Detection.xywh",
"url":80,
"doc":"Alias for to_xywh",
"func":1
},
{
"ref":"vipy.object.Detection.cxywh",
"url":80,
"doc":"Return or set bounding box corners as (centroidx,centroidy,width,height) tuple",
"func":1
},
{
"ref":"vipy.object.Detection.ulbr",
"url":80,
"doc":"Return bounding box corners as upper left, bottom right (xmin, ymin, xmax, ymax)",
"func":1
},
{
"ref":"vipy.object.Detection.to_ulbr",
"url":80,
"doc":"Alias for ulbr()",
"func":1
},
{
"ref":"vipy.object.Detection.dx",
"url":80,
"doc":"Offset bounding box by same xmin as provided box",
"func":1
},
{
"ref":"vipy.object.Detection.dy",
"url":80,
"doc":"Offset bounding box by ymin of provided box",
"func":1
},
{
"ref":"vipy.object.Detection.sqdist",
"url":80,
"doc":"Squared Euclidean distance between upper left corners of two bounding boxes",
"func":1
},
{
"ref":"vipy.object.Detection.dist",
"url":80,
"doc":"Distance between centroids of two bounding boxes",
"func":1
},
{
"ref":"vipy.object.Detection.pdist",
"url":80,
"doc":"Normalized Gaussian distance in [0,1] between centroids of two bounding boxes, where 0 is far and 1 is same with sigma=maxdim() of this box",
"func":1
},
{
"ref":"vipy.object.Detection.iou",
"url":80,
"doc":"area of intersection / area of union",
"func":1
},
{
"ref":"vipy.object.Detection.intersection_over_union",
"url":80,
"doc":"Alias for iou",
"func":1
},
{
"ref":"vipy.object.Detection.area_of_intersection",
"url":80,
"doc":"area of intersection",
"func":1
},
{
"ref":"vipy.object.Detection.cover",
"url":80,
"doc":"Fraction of this bounding box intersected by other bbox (bb).  note - Cover is often more useful than  vipy.geometry.BoundingBox.iou as a measure of overlap due to bounding box distortion from partially occluded object proposals. - For example, an object proposal of a person may generate a smaller box (e.g. just the torso) when the lower body is occluded whereas a track will have the full body box. -  vipy.geometry.BoundingBox.maxcover is a better measure of assignment in this case.",
"func":1
},
{
"ref":"vipy.object.Detection.maxcover",
"url":80,
"doc":"The maximum cover of self to bb and bb to self",
"func":1
},
{
"ref":"vipy.object.Detection.shapeiou",
"url":80,
"doc":"Shape IoU is the IoU with the upper left corners aligned. This measures the deformation of the two boxes by removing the effect of translation",
"func":1
},
{
"ref":"vipy.object.Detection.intersection",
"url":80,
"doc":"Intersection of two bounding boxes, throw an error on degeneracy of intersection result (if strict=True)",
"func":1
},
{
"ref":"vipy.object.Detection.hasintersection",
"url":80,
"doc":"Return true if self and bb overlap by any amount, or by the cover threshold (if provided) or the iou threshold (if provided). This is a convenience function that allows for shared computation for fast non-maximum suppression.",
"func":1
},
{
"ref":"vipy.object.Detection.union",
"url":80,
"doc":"Union of one or more bounding boxes with this box",
"func":1
},
{
"ref":"vipy.object.Detection.isinside",
"url":80,
"doc":"Is this boundingbox fully within the provided bounding box?",
"func":1
},
{
"ref":"vipy.object.Detection.ispointinside",
"url":80,
"doc":"Is the 2D point p=(x,y) inside this boundingbox, or is the p=boundingbox() inside this bounding box?",
"func":1
},
{
"ref":"vipy.object.Detection.is_point_inside",
"url":80,
"doc":"synonym for  vipy.geometry.BoundingBox.ispointinside ",
"func":1
},
{
"ref":"vipy.object.Detection.dilate",
"url":80,
"doc":"Change scale of bounding box keeping centroid constant",
"func":1
},
{
"ref":"vipy.object.Detection.dilatepx",
"url":80,
"doc":"Dilate by a given pixel amount on all sides, keeping centroid constant",
"func":1
},
{
"ref":"vipy.object.Detection.dilate_height",
"url":80,
"doc":"Change scale of bounding box in y direction keeping centroid constant",
"func":1
},
{
"ref":"vipy.object.Detection.dilate_width",
"url":80,
"doc":"Change scale of bounding box in x direction keeping centroid constant",
"func":1
},
{
"ref":"vipy.object.Detection.top",
"url":80,
"doc":"Make top of box taller (closer to top of image) by an offset dy",
"func":1
},
{
"ref":"vipy.object.Detection.bottom",
"url":80,
"doc":"Make bottom of box taller (closer to bottom of image) by an offset dy",
"func":1
},
{
"ref":"vipy.object.Detection.left",
"url":80,
"doc":"Make left of box wider (closer to left side of image) by an offset dx",
"func":1
},
{
"ref":"vipy.object.Detection.right",
"url":80,
"doc":"Make right of box wider (closer to right side of image) by an offset dx",
"func":1
},
{
"ref":"vipy.object.Detection.rescale",
"url":80,
"doc":"Multiply the box corners by a scale factor",
"func":1
},
{
"ref":"vipy.object.Detection.scale_x",
"url":80,
"doc":"Multiply the box corners in the x dimension by a scale factor",
"func":1
},
{
"ref":"vipy.object.Detection.scale_y",
"url":80,
"doc":"Multiply the box corners in the y dimension by a scale factor",
"func":1
},
{
"ref":"vipy.object.Detection.resize",
"url":80,
"doc":"Change the aspect ratio width and height of the box",
"func":1
},
{
"ref":"vipy.object.Detection.rot90cw",
"url":80,
"doc":"Rotate a bounding box such that if an image of size (H,W) is rotated 90 deg clockwise, the boxes align",
"func":1
},
{
"ref":"vipy.object.Detection.rot90ccw",
"url":80,
"doc":"Rotate a bounding box such that if an image of size (H,W) is rotated 90 deg counter clockwise, the boxes align",
"func":1
},
{
"ref":"vipy.object.Detection.fliplr",
"url":80,
"doc":"Flip the box left/right consistent with fliplr of the provided img (or consistent with the image width)",
"func":1
},
{
"ref":"vipy.object.Detection.flipud",
"url":80,
"doc":"Flip the box up/down consistent with flipud of the provided img (or consistent with the image height)",
"func":1
},
{
"ref":"vipy.object.Detection.imscale",
"url":80,
"doc":"Given a vipy.image object im, scale the box to be within [0,1], relative to height and width of image",
"func":1
},
{
"ref":"vipy.object.Detection.maxsquare",
"url":80,
"doc":"Set the bounding box to be square by setting width and height to the maximum dimension of the box, keeping centroid constant",
"func":1
},
{
"ref":"vipy.object.Detection.iseven",
"url":80,
"doc":"Are all corners even number integers?",
"func":1
},
{
"ref":"vipy.object.Detection.even",
"url":80,
"doc":"Force all corners to be even number integers. This is helpful for FFMPEG crop filters.",
"func":1
},
{
"ref":"vipy.object.Detection.minsquare",
"url":80,
"doc":"Set the bounding box to be square by setting width and height to the minimum dimension of the box, keeping centroid constant",
"func":1
},
{
"ref":"vipy.object.Detection.hasoverlap",
"url":80,
"doc":"Does the bounding box intersect with the provided image rectangle?",
"func":1
},
{
"ref":"vipy.object.Detection.isinterior",
"url":80,
"doc":"Is this boundingbox fully within the provided image rectangle?  If border in [0,1], then the image is dilated by a border percentage prior to computing interior, useful to check if self is near the image edge  If border=0.8, then the image rectangle is dilated by 80% (smaller) keeping the centroid constant.",
"func":1
},
{
"ref":"vipy.object.Detection.iminterior",
"url":80,
"doc":"Transform bounding box to be interior to the image rectangle with shape (W,H). Transform is applyed by computing smallest (dx,dy) translation that it is interior to the image rectangle, then clip to the image rectangle if it is too big to fit",
"func":1
},
{
"ref":"vipy.object.Detection.imclip",
"url":80,
"doc":"Clip bounding box to image rectangle [0,0,width,height] or img.shape=(width, height) and, throw an exception on an invalid box",
"func":1
},
{
"ref":"vipy.object.Detection.imclipshape",
"url":80,
"doc":"Clip bounding box to image rectangle [0,0,W-1,H-1], throw an exception on an invalid box",
"func":1
},
{
"ref":"vipy.object.Detection.convexhull",
"url":80,
"doc":"Given a set of points  x1,y1],[x2,xy], .], return the bounding rectangle, typecast to float",
"func":1
},
{
"ref":"vipy.object.Detection.aspectratio",
"url":80,
"doc":"Return the aspect ratio (width/height) of the box",
"func":1
},
{
"ref":"vipy.object.Detection.shape",
"url":80,
"doc":"Return the (height, width) tuple for the box shape",
"func":1
},
{
"ref":"vipy.object.Detection.mindimension",
"url":80,
"doc":"Return min(width, height) typecast to float",
"func":1
},
{
"ref":"vipy.object.Detection.mindim",
"url":80,
"doc":"Return min(width, height) typecast to float",
"func":1
},
{
"ref":"vipy.object.Detection.maxdim",
"url":80,
"doc":"Return max(width, height) typecast to float",
"func":1
},
{
"ref":"vipy.object.Detection.ellipse",
"url":80,
"doc":"Convert the boundingbox to a vipy.geometry.Ellipse object",
"func":1
},
{
"ref":"vipy.object.Detection.average",
"url":80,
"doc":"Compute the average bounding box between self and other, and set self to the average. Other may be a singleton bounding box or a list of bounding boxes",
"func":1
},
{
"ref":"vipy.object.Detection.averageshape",
"url":80,
"doc":"Compute the average bounding box width and height between self and other. Other may be a singleton bounding box or a list of bounding boxes",
"func":1
},
{
"ref":"vipy.object.Detection.medianshape",
"url":80,
"doc":"Compute the median bounding box width and height between self and other. Other may be a singleton bounding box or a list of bounding boxes",
"func":1
},
{
"ref":"vipy.object.Detection.shapedist",
"url":80,
"doc":"L1 distance between (width,height) of two boxes",
"func":1
},
{
"ref":"vipy.object.Detection.affine",
"url":80,
"doc":"Apply an 2x3 affine transformation to the box centroid.  note This transformation is performed on the centroid and not the box corners, so the box will still be rectilinear after the transform",
"func":1
},
{
"ref":"vipy.object.Detection.projective",
"url":80,
"doc":"Apply an 3x3 projective transformation to the box centroid.  note This transformation is performed on the centroid and not the box corners, so the box will still be rectilinear after the transform",
"func":1
},
{
"ref":"vipy.object.Detection.crop",
"url":80,
"doc":"Crop an HxW 2D numpy image, HxWxC 3D numpy image, or NxHxWxC 4D numpy image array using this bounding box applied to HxW dimensions. Crop is performed in-place.",
"func":1
},
{
"ref":"vipy.object.Detection.grid",
"url":80,
"doc":"Split a bounding box into the smallest grid of non-overlapping bounding boxes such that the union is the original box",
"func":1
},
{
"ref":"vipy.object.Detection.append_attribute",
"url":79,
"doc":"Append the value to attribute key, creating the key as an empty list if it does not exist",
"func":1
},
{
"ref":"vipy.object.Keypoint2d",
"url":79,
"doc":"vipy.object.Keypoint2d class 2D point parameterization"
},
{
"ref":"vipy.object.Keypoint2d.clone",
"url":79,
"doc":"Copy the object, if deep=True, then include a deep copy of the attribute dictionary, else a shallow copy. Cloned object has the same id()",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.guid",
"url":79,
"doc":""
},
{
"ref":"vipy.object.Keypoint2d.id",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.from_json",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.json",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.attributes",
"url":79,
"doc":""
},
{
"ref":"vipy.object.Keypoint2d.significant_digits",
"url":80,
"doc":"Convert corners to have at most n significant digits for efficient JSON storage",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.translate",
"url":80,
"doc":"Translate the coordinates by dx in x and dy in y",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.offset",
"url":80,
"doc":"Alias for translate",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.rescale",
"url":80,
"doc":"Multiply the coordinates by a scale factor",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.scale_x",
"url":80,
"doc":"Multiply the x coordinate (and radius) by a scale factor",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.scale_y",
"url":80,
"doc":"Multiply the y coordinate by a scale factor",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.scale_r",
"url":80,
"doc":"Multiply the r coordinate by a scale factor",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.int",
"url":80,
"doc":"Convert coords to integer with rounding, in-place update",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.float",
"url":80,
"doc":"Convert coords to float",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.fliplr",
"url":80,
"doc":"Flip the x coordinate left/right consistent with fliplr of the provided img (or consistent with the image width)",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.flipud",
"url":80,
"doc":"Flip the y coordinate up/down consistent with flipud of the provided img (or consistent with the image height)",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.rot90cw",
"url":80,
"doc":"Rotate a point such that if an image of size (H,W) is rotated 90 deg clockwise, the point rotates with the image",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.rot90ccw",
"url":80,
"doc":"Rotate a point such that if an image of size (H,W) is rotated 90 deg counter clockwise, the point rotates with the image",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.hasoverlap",
"url":80,
"doc":"Does the point inside with the provided image rectangle?",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.imclip",
"url":80,
"doc":"clip does not apply to points",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.area_of_intersection",
"url":80,
"doc":"area of intersection",
"func":1
},
{
"ref":"vipy.object.Keypoint2d.append_attribute",
"url":79,
"doc":"Append the value to attribute key, creating the key as an empty list if it does not exist",
"func":1
},
{
"ref":"vipy.object.Track",
"url":79,
"doc":"vipy.object.Track class A track represents one or more labeled bounding boxes of an object instance through time. A track is defined as a finite set of labeled boxes observed at keyframes, which are discrete observations of this instance. Each keyframe has an associated vipy.geometry.BoundingBox() which defines the spatial bounding box of the instance in this keyframe. The kwarg \"interpolation\" defines how the track is interpolated between keyframes, and the kwarg \"boundary\" defines how the track is interpolated outside the (min,max) of the keyframes. Valid constructors are:   t = vipy.object.Track(keyframes=[0,100], boxes=[vipy.geometry.BoundingBox(0,0,10,10), vipy.geometry.BoundingBox(0,0,20,20)], label='Person') t = vipy.object.Track(keyframes=[0,100], boxes=[vipy.geometry.BoundingBox(0,0,10,10), vipy.geometry.BoundingBox(0,0,20,20)], label='Person', interpolation='linear') t = vipy.object.Track(keyframes=[10,100], boxes=[vipy.geometry.BoundingBox(0,0,10,10), vipy.geometry.BoundingBox(0,0,20,20)], label='Person', boundary='strict')   Tracks can be constructed incrementally:   t = vipy.object.Track('Person') t.add(0, vipy.geometry.BoundingBox(0,0,10,10 t.add(100, vipy.geometry.BoundingBox(0,0,20,20   Tracks can be resampled at a new framerate, as long as the framerate is known when the keyframes are extracted   t.framerate(newfps)  "
},
{
"ref":"vipy.object.Track.from_json",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.json",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.isempty",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.has_normalized_coordinates",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.confidence",
"url":79,
"doc":"The confidence of a track is the mean confidence of all (or just last=last frames, or samples=samples uniformly spaced) keyboxes (if confidences are available) else 0",
"func":1
},
{
"ref":"vipy.object.Track.isdegenerate",
"url":79,
"doc":"Is the track degenerate? A degenerate track has: - Unequal length keyboxes and keyframes - length zero track - Non increasing keyframes - Invalid keyboxes",
"func":1
},
{
"ref":"vipy.object.Track.dict",
"url":79,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding",
"func":1
},
{
"ref":"vipy.object.Track.add",
"url":79,
"doc":"Add a new keyframe and associated box to track, preserve sorted order of keyframes. If keyframe is already in track, throw an exception. In this case use update() instead -strict [bool]: If box is degenerate, throw an exception if strict=True, otherwise just don't add it  note The BoundingBox is added by reference. If you want to this to be a copy, pass in bbox.clone()",
"func":1
},
{
"ref":"vipy.object.Track.update",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.replace",
"url":79,
"doc":"Replace the keyframe and associated box(es), preserve sorted order of keyframes",
"func":1
},
{
"ref":"vipy.object.Track.delete",
"url":79,
"doc":"Replace a keyframe and associated box to track, preserve sorted order of keyframes",
"func":1
},
{
"ref":"vipy.object.Track.keyframes",
"url":79,
"doc":"Return keyframe frame indexes where there are track observations",
"func":1
},
{
"ref":"vipy.object.Track.num_keyframes",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.keyboxes",
"url":79,
"doc":"Return keyboxes where there are track observations",
"func":1
},
{
"ref":"vipy.object.Track.meanshape",
"url":79,
"doc":"Return the mean (width,height) of the box during the track, or None if the track is degenerate",
"func":1
},
{
"ref":"vipy.object.Track.meanbox",
"url":79,
"doc":"Return the mean bounding box during the track, or None if the track is degenerate",
"func":1
},
{
"ref":"vipy.object.Track.shapevariance",
"url":79,
"doc":"Return the variance (width, height) of the box shape relative to  vipy.object.Track.meanbox during the track or None if the track is degenerate. This is useful for filtering spurious tracks where the aspect ratio changes rapidly and randomly Returns: (width_variance, height_variance) of the box shape during the track (or None)",
"func":1
},
{
"ref":"vipy.object.Track.framerate",
"url":79,
"doc":"Resample keyframes from known original framerate set by constructor to be new framerate fps. Args: fps: [float] The new frame rate in frames per second speed: [float] An optional speed factor which will multiply the current framerate by this factor (e.g. speed=2  > fps=self.framerate() 2) Returns: This track object with the keyframes resampled to the new framerate",
"func":1
},
{
"ref":"vipy.object.Track.startframe",
"url":79,
"doc":"Return the startframe of the track or None if there are no keyframes. The frame index is relative to the framerate set in the constructor.",
"func":1
},
{
"ref":"vipy.object.Track.endframe",
"url":79,
"doc":"Return the endframe of the track or None if there are no keyframes. The frame index is relative to the framerate set in the constructor.",
"func":1
},
{
"ref":"vipy.object.Track.duration",
"url":79,
"doc":"The length of the track in seconds. Returns: The duration in seconds of this track object",
"func":1
},
{
"ref":"vipy.object.Track.linear_interpolation",
"url":79,
"doc":"Linear bounding box interpolation at frame=f given observed boxes (x,y,w,h) at keyframes. This returns a  vipy.object.Detection which is the interpolation of the  vipy.object.Track at frame k - If self._boundary='extend', then boxes are repeated if the interpolation is outside the keyframes - If self._boundary='strict', then interpolation returns None if the interpolation is outside the keyframes  note - The returned BoundingBox object is not cloned when possible for speed purposes, be careful when modifying this object. clone() the returned object if necessary - This means that we return a reference to the underlying keybox upgraded with track properties and cast as  vipy.object.Detection . If you modify this object, then the track keybox will be modfied.",
"func":1
},
{
"ref":"vipy.object.Track.category",
"url":79,
"doc":"Set the track category to label. Updates all keyboxes",
"func":1
},
{
"ref":"vipy.object.Track.categoryif",
"url":79,
"doc":"If the current category is equal to ifcategory, then change it to newcategory. Args: ifcategory [dict, str]: May be a dictionary {ifcategory:tocategory}, or just an ifcategory tocategory [str]: the target category Returns: this object with the category changed.  note This is useful for converting synonyms such as self.categoryif('motorbike', 'motorcycle')",
"func":1
},
{
"ref":"vipy.object.Track.label",
"url":79,
"doc":"Alias for category",
"func":1
},
{
"ref":"vipy.object.Track.during",
"url":79,
"doc":"Does the track contain a keyframe during the time interval (startframe, endframe) inclusive?",
"func":1
},
{
"ref":"vipy.object.Track.during_interval",
"url":79,
"doc":"Does the track contain a keyframe during the inclusive frame interval (startframe, endframe)?  note The start and end frames are inclusive",
"func":1
},
{
"ref":"vipy.object.Track.within",
"url":79,
"doc":"Is the track within the frame range (startframe, endframe)?",
"func":1
},
{
"ref":"vipy.object.Track.offset",
"url":79,
"doc":"Apply a temporal shift of dt frames, and a spatial shift of (dx, dy) pixels. Args: dt: [int] frame offset dx: [float] horizontal spatial offset dy: [float] vertical spatial offset Returns: This box updated in place",
"func":1
},
{
"ref":"vipy.object.Track.uncrop",
"url":79,
"doc":"Apply a transformation to the track that will undo a crop of a bounding box with an optional scale factor. A typical operation is as follows. A video is cropped and zommed in order to run a detector on a region of interest. However, we want to align the resulting tracks on the original video before the crop and zoom. Args: bb: [ vipy.geometry.BoundingBox ]. A bounding box which was used to crop this track s: [float] A scale factor applied after the bounding box crop Returns: This track after undoing the scale and crop",
"func":1
},
{
"ref":"vipy.object.Track.frameoffset",
"url":79,
"doc":"Offset boxes by (dx,dy) in each frame. This is used to apply a different offset for each frame. To apply one offset to all frames, use  vipy.object.Track.offset . Args: dx: [list] This should be a list of frame offsets at each keyframe the same length as the number of keyboxes dy: [list] This should be a list of frame offsets at each keyframe the same length as the number of keyboxes Returns: This track updated in place",
"func":1
},
{
"ref":"vipy.object.Track.truncate",
"url":79,
"doc":"Truncate a track so that any keyframes less than startframe or greater than endframe (inclusive) are removed. Interpolate keyboxes at (startframe, endframe) endpoints. Args: start: [int|float] The start of the truncation relative to the track framerate. All keyframes less than or equal to startframe are included. If the keyframe does not exist at startframe, one is interpolated and added. end: [int|float] The end of the truncation relative to the track framerate. All keyframes greater than or equal to the endframe are included. If the keyfrmae does not exist at endframe, one is interpolated and added. Returns: This track such that all keyboxes  = endframe are removed.  note The startframe and endframe for truncation are inclusive.",
"func":1
},
{
"ref":"vipy.object.Track.rescale",
"url":79,
"doc":"Rescale track boxes by scale factor s",
"func":1
},
{
"ref":"vipy.object.Track.scale",
"url":79,
"doc":"Alias for rescale",
"func":1
},
{
"ref":"vipy.object.Track.scale_x",
"url":79,
"doc":"Rescale track boxes by scale factor sx",
"func":1
},
{
"ref":"vipy.object.Track.scale_y",
"url":79,
"doc":"Rescale track boxes by scale factor sx",
"func":1
},
{
"ref":"vipy.object.Track.dilate",
"url":79,
"doc":"Dilate track boxes by scale factor s",
"func":1
},
{
"ref":"vipy.object.Track.maxsquare",
"url":79,
"doc":"Set all of the track boxes to maxsquare",
"func":1
},
{
"ref":"vipy.object.Track.rot90cw",
"url":79,
"doc":"Rotate an image with (H,W)=shape 90 degrees clockwise and update all boxes to be consistent",
"func":1
},
{
"ref":"vipy.object.Track.rot90ccw",
"url":79,
"doc":"Rotate an image with (H,W)=shape 90 degrees clockwise and update all boxes to be consistent",
"func":1
},
{
"ref":"vipy.object.Track.fliplr",
"url":79,
"doc":"Flip an image left and right (mirror about vertical axis)",
"func":1
},
{
"ref":"vipy.object.Track.flipud",
"url":79,
"doc":"Flip an image left and right (mirror about vertical axis)",
"func":1
},
{
"ref":"vipy.object.Track.id",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.clone",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.clone_during",
"url":79,
"doc":"Clone a track during a specific interval (startframe, endframe) relative to the framerate of the track. - This is useful for copying a small segment of a long track without the expense of copying the whole track. - All keyframes and keyboxes not in (startframe, endframe) are not copied. - Boundary keyframes are copied to enable proper interpolation.",
"func":1
},
{
"ref":"vipy.object.Track.boundingbox",
"url":79,
"doc":"The bounding box of a track is the smallest spatial box that contains all of the BoundingBoxes of the track within startframe and endframe, or None if there are no detections. Args: startframe: [int] the startframe of the track to compute the bounding box. endframe: [int] the endframe of the track to compute the bounding box. Returns:  vipy.geometry.BoundingBox which is the smallest box that contains all boxes of the track from (startframe, endframe)",
"func":1
},
{
"ref":"vipy.object.Track.smallestbox",
"url":79,
"doc":"The smallest box of a track is the smallest spatial box in area along the track",
"func":1
},
{
"ref":"vipy.object.Track.biggestbox",
"url":79,
"doc":"The biggest box of a track is the largest spatial box in area along the track",
"func":1
},
{
"ref":"vipy.object.Track.pathlength",
"url":79,
"doc":"The path length of a track is the cumulative Euclidean distance in pixels that the box travels",
"func":1
},
{
"ref":"vipy.object.Track.startbox",
"url":79,
"doc":"The startbox is the first bounding box in the track",
"func":1
},
{
"ref":"vipy.object.Track.endbox",
"url":79,
"doc":"The endbox is the last box in the track",
"func":1
},
{
"ref":"vipy.object.Track.loop_closure_distance",
"url":79,
"doc":"The loop closure track distance is the Euclidean distance in pixels between the start frame bounding box and end frame bounding box",
"func":1
},
{
"ref":"vipy.object.Track.boundary",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.clip",
"url":79,
"doc":"Clip a track to be within (start,end) with strict boundary handling. Start and end may be frame numbers (int) or seconds (float). Frames are relative to the current frame rate. Args: start [int|float]: The start of the clip in frames|seconds end [int|float|None]: The end of the clip in frames|seconds (if provided)",
"func":1
},
{
"ref":"vipy.object.Track.iou",
"url":79,
"doc":"Compute the spatial IoU between two tracks as the mean IoU per frame in the range (self.startframe(), self.endframe( ",
"func":1
},
{
"ref":"vipy.object.Track.segment_maxiou",
"url":79,
"doc":"Return the maximum framewise bounding box IOU between self and other in the range (startframe, endframe)",
"func":1
},
{
"ref":"vipy.object.Track.maxiou",
"url":79,
"doc":"Compute the maximum spatial IoU between two tracks per frame in the range (self.startframe(), self.endframe( ",
"func":1
},
{
"ref":"vipy.object.Track.fragmentiou",
"url":79,
"doc":"A fragment is a track that is fully contained within self",
"func":1
},
{
"ref":"vipy.object.Track.endpointiou",
"url":79,
"doc":"Compute the mean spatial IoU between two tracks at the two overlapping endpoints. useful for track continuation",
"func":1
},
{
"ref":"vipy.object.Track.segmentiou",
"url":79,
"doc":"Compute the mean spatial IoU between two tracks at the overlapping segment, sampling by dt. Useful for track continuation for densely overlapping tracks",
"func":1
},
{
"ref":"vipy.object.Track.segmentcover",
"url":79,
"doc":"Compute the mean spatial cover between two tracks at the overlapping segment, sampling by dt. Useful for track continuation for densely overlapping tracks",
"func":1
},
{
"ref":"vipy.object.Track.rankiou",
"url":79,
"doc":"Compute the mean spatial IoU between two tracks per frame in the range (self.startframe(), self.endframe( using only the top-k (rank) frame overlaps Sample tracks at endpoints and n uniformly spaced frames or a stride of dt frames. - rank [>1]: The top-k best IOU overlaps to average when computing the rank IOU - This is useful for track continuation where the box deforms in the overlapping segment at the end due to occlusion. - This is useful for track correspondence where a ground truth box does not match an estimated box precisely (e.g. loose box, non-visually grounded box) - This is the robust version of segmentiou. - Use percentileiou to determine the rank based a fraction of the length of the overlap, which will be more efficient for long tracks",
"func":1
},
{
"ref":"vipy.object.Track.percentileiou",
"url":79,
"doc":"Percentile iou returns rankiou for rank=percentile len(overlap(self, other -other [Track] -percentile [0,1]: The top-k best overlaps to average when computing rankiou -samples: The number of uniformly spaced samples to take along the track for computing the rankiou",
"func":1
},
{
"ref":"vipy.object.Track.segment_percentileiou",
"url":79,
"doc":"percentiliou on the overlapping segment with other",
"func":1
},
{
"ref":"vipy.object.Track.segment_percentilecover",
"url":79,
"doc":"percentile cover on the overlapping segment with other",
"func":1
},
{
"ref":"vipy.object.Track.union",
"url":79,
"doc":"Compute the union of two tracks. Overlapping boxes between self and other: Inputs - average [bool]: average framewise interpolated boxes at overlapping keyframes - replace [bool]: replace the box with other if other and self overlap at a keyframe - keep [bool]: keep the box from self (discard other) at a keyframe",
"func":1
},
{
"ref":"vipy.object.Track.average",
"url":79,
"doc":"Compute the average of two tracks by the framewise interpolated boxes at the keyframes of this track",
"func":1
},
{
"ref":"vipy.object.Track.temporal_distance",
"url":79,
"doc":"The temporal distance between two tracks is the minimum number of frames separating them",
"func":1
},
{
"ref":"vipy.object.Track.smooth",
"url":79,
"doc":"Track smoothing by averaging neighboring keyboxes",
"func":1
},
{
"ref":"vipy.object.Track.smoothshape",
"url":79,
"doc":"Track smoothing by averaging width and height of neighboring keyboxes",
"func":1
},
{
"ref":"vipy.object.Track.medianshape",
"url":79,
"doc":"Track smoothing by median width and height of neighboring keyboxes",
"func":1
},
{
"ref":"vipy.object.Track.spline",
"url":79,
"doc":"Track smoothing by cubic spline fit, will return resampled dt=1 track. Smoothing factor will increase with smoothing > 1 and decrease with 0 < smoothing < 1 This function requires optional package scipy",
"func":1
},
{
"ref":"vipy.object.Track.linear_extrapolation",
"url":79,
"doc":"Track extrapolation by linear fit.  Requires at least 2 keyboxes.  Returned boxes may be degenerate.  shape=True then both the position and shape (width, height) of the box is extrapolated",
"func":1
},
{
"ref":"vipy.object.Track.imclip",
"url":79,
"doc":"Clip the track to the image rectangle (width, height). If a keybox is outside the image rectangle, remove it otherwise clip to the image rectangle. This operation can change the length of the track and the size of the keyboxes. The result may be an empty track if the track is completely outside the image rectangle, which results in an exception.",
"func":1
},
{
"ref":"vipy.object.Track.resample",
"url":79,
"doc":"Resample the track using a stride of dt frames. This reduces the density of keyframes by interpolating new keyframes as a uniform stride of dt. This is useful for track compression",
"func":1
},
{
"ref":"vipy.object.Track.significant_digits",
"url":79,
"doc":"Round the coordinates of all boxes so that they have n significant digits for efficient serialization",
"func":1
},
{
"ref":"vipy.object.Track.bearing",
"url":79,
"doc":"The bearing of a track at frame f is the angle of the velocity vector relative to the (x,y) image coordinate frame, in radians [-pi, pi]",
"func":1
},
{
"ref":"vipy.object.Track.bearing_change",
"url":79,
"doc":"The bearing change of a track from frame f1 (or start) and frame f2 (or end) is the relative angle of the velocity vectors in radians [-pi,pi]. Args: f1: [int] the start frame for computing the bearing change. If None, then use self.startframe() f2: [int] the end frame for computing the bearing change. if None, then use self.endframe() dt: [int] The number of frames between computations of the velocity vector for bearing minspeed: [float] The minimum speed in frames per second used to threshold bearing computations if there is no motion samples: [int] The number of samples to average for computing the bearing change Returns: The floating point bearing change in radians in [-pi, pi] from (f1,f2) where bearing is computed at samples=n points, and each bearing is computed with a velocity stride of dt frames.",
"func":1
},
{
"ref":"vipy.object.Track.acceleration",
"url":79,
"doc":"Return the (x,y) track acceleration magnitude at frame f computed using central finite differences of velocity. Returns: acceleration in (pixels / seconds^2) using velocity computed at (f-2 dt, f-dt), (f+dt, f+2 dt)",
"func":1
},
{
"ref":"vipy.object.Track.velocity",
"url":79,
"doc":"Return the (x,y) track velocity at frame f in units of pixels per frame computed by mean finite difference of the box centroid",
"func":1
},
{
"ref":"vipy.object.Track.speed",
"url":79,
"doc":"",
"func":1
},
{
"ref":"vipy.object.Track.boxmap",
"url":79,
"doc":"Apply the lambda function to each keybox",
"func":1
},
{
"ref":"vipy.object.Track.shape_invariant_velocity",
"url":79,
"doc":"Return the (x,y) track velocity at frame f in units of pixels per frame computed by minimum mean finite differences of any box corner independent of changes in shape, over a finite time window of [f-dt, f]",
"func":1
},
{
"ref":"vipy.object.Track.velocity_x",
"url":79,
"doc":"Return the left/right velocity at frame f in units of pixels per frame computed by mean finite difference over a fixed time window (dt, frames) of the box centroid",
"func":1
},
{
"ref":"vipy.object.Track.velocity_y",
"url":79,
"doc":"Return the up/down velocity at frame f in units of pixels per frame computed by mean finite difference over a fixed time window (dt, frames) of the box centroid",
"func":1
},
{
"ref":"vipy.object.Track.velocity_w",
"url":79,
"doc":"Return the width velocity at frame f in units of pixels per frame computed by finite difference",
"func":1
},
{
"ref":"vipy.object.Track.velocity_h",
"url":79,
"doc":"Return the height velocity at frame f in units of pixels per frame computed by finite difference",
"func":1
},
{
"ref":"vipy.object.Track.nearest_keyframe",
"url":79,
"doc":"Nearest keyframe to frame f",
"func":1
},
{
"ref":"vipy.object.Track.nearest_keybox",
"url":79,
"doc":"Nearest keybox to frame f",
"func":1
},
{
"ref":"vipy.object.Track.ismoving",
"url":79,
"doc":"Is the track moving in the frame range (startframe,endframe)?",
"func":1
},
{
"ref":"vipy.object.Track.attributes",
"url":79,
"doc":""
},
{
"ref":"vipy.object.non_maximum_suppression",
"url":79,
"doc":"Compute greedy non-maximum suppression of a list of vipy.object.Detection() based on spatial IOU threshold (iou) and cover threhsold (cover) sorted by confidence (conf). Args: detlist: [list  vipy.object.Detection ] conf: [float] minimum confidence for non-maximum suppression iou: [float] minimum iou for non-maximum suporession bycategory: [bool] NMS only within the same category cover: [float, None] A minimum cover for NMS (stricter than iou) gridsize: [tuple, (rows, cols)] An optional grid for fast intersection lookups Returns: List of  vipy.object.Detection non-maximum suppressed, sorted by increasing confidence",
"func":1
},
{
"ref":"vipy.object.greedy_assignment",
"url":79,
"doc":"Compute a greedy one-to-one assignment of each vipy.object.Detection() in srclist to a unique element in dstlist with the largest IoU greater than miniou, else None Args: srclist: [list,  vipy.object.Detection ] dstlist: [list,  vipy.object.Detection ] miniou: [float, >=0,  dstlist[j]",
"func":1
},
{
"ref":"vipy.object.greedy_track_assignment",
"url":79,
"doc":"Compute a greedy one-to-ine assignment of each  vipy.object.Track in srclist to a unique element in dstlist with the largest assignment score. - Assignment score:  vipy.object.Track.segment_percentileiou   vipy.object.Track.confidence , if maxiou() > miniou else 0 - Assigment order: longest to shortest src track Args: srclist: [list,  vipy.object.Track ] dstlist: [list,  vipy.object.Track ] miniou: [float, >=0,  dstlist[j]",
"func":1
},
{
"ref":"vipy.object.RandomDetection",
"url":79,
"doc":"Return a random  vipy.object.Detection in the range (0 < xmin < W, 0 < ymin < H, height < 100, width < 100). Useful for unit testing.",
"func":1
},
{
"ref":"vipy.linalg",
"url":81,
"doc":""
},
{
"ref":"vipy.linalg.random_positive_semidefinite_matrix",
"url":81,
"doc":"Return a randomly generated numpy float64 positive semidefinite matrix of size NxN",
"func":1
},
{
"ref":"vipy.linalg.column_stochastic",
"url":81,
"doc":"Given a numpy array X of size MxN, return column stochastic matrix such that each of N columns sum to one. Args: X: [numpy] A 2D array eps: [float] a small floating point value to avoid divide by zero Returns: Matrix X such that columns sum to one.",
"func":1
},
{
"ref":"vipy.linalg.row_stochastic",
"url":81,
"doc":"Given a numpy array X of size MxN, return row stochastic matrix such that each of M rows sum to one. Args: X: [numpy] A 2D array eps: [float] a small floating point value to avoid divide by zero Returns: Matrix X such that rows sum to one.",
"func":1
},
{
"ref":"vipy.linalg.rowstochastic",
"url":81,
"doc":"Alias for  vipy.linalg.row_stochastic ",
"func":1
},
{
"ref":"vipy.linalg.bistochastic",
"url":81,
"doc":"Given a square numpy array X of size NxN, return bistochastic matrix such that each of N rows and N columns sum to one. Bistochastic matrix (doubly stochastic matrix) using Sinkhorn normalization. Args: X: [numpy] A square 2D array eps: [float] a small floating point value to avoid divide by zero numIterations: [int] The number of sinkhorn normalization iterations to apply Returns: Bistochastic matrix X",
"func":1
},
{
"ref":"vipy.linalg.rectangular_bistochastic",
"url":81,
"doc":"Given a rectangular numpy array X of size MxN, return bistochastic matrix such that each of M rows sum to N/M and each if N columns sum to 1. Bistochastic matrix using Sinkhorn normalization on rectangular matrices Args: X: [numpy] A 2D array eps: [float] a small floating point value to avoid divide by zero numIterations: [int] The number of sinkhorn normalization iterations to apply Returns: Rectangular bistochastic matrix X",
"func":1
},
{
"ref":"vipy.linalg.row_normalized",
"url":81,
"doc":"Given a rectangular numpy array X of size MxN, return a matrix such that each row has unit L2 norm. Args: X: [numpy] A 2D array Returns: Row normalized matrix X such that np.linalg.norm(X[i])  1, for all rows i",
"func":1
},
{
"ref":"vipy.linalg.row_ssqrt",
"url":81,
"doc":"Given a rectangular numpy array X of size MxN, return a matrix such that each element is the signed square root of the element in X. Args: X: [numpy] A rectangular 2D array Returns: Matrix M such that elements M[i,j] preserve the sign of corresponding element in X, but the value is M[i,j] = sign(X[i,j])  sqrt(abs(X[i,j] ",
"func":1
},
{
"ref":"vipy.linalg.normalize",
"url":81,
"doc":"Given a numpy vector X of size N, return a vector with unit norm. Args: X: [numpy] A 1D array or a 2D array with one dim  1 Returns: Unit L2 norm of x, flattened to 1D",
"func":1
},
{
"ref":"vipy.linalg.rowvectorize",
"url":81,
"doc":"Alias for  vipy.linalg.rowvector ",
"func":1
},
{
"ref":"vipy.linalg.columnvectorize",
"url":81,
"doc":"Alias for  vipy.linalg.columnvector ",
"func":1
},
{
"ref":"vipy.linalg.vectorize",
"url":81,
"doc":"Convert a tuple X=([1], [2,3], [4,5,6]) to a numpy vector [1,2,3,4,5,6]. Args: X: [list of lists, tuple of tuples] Returns: 1D numpy array with all elements in X stacked horizontally",
"func":1
},
{
"ref":"vipy.linalg.columnvector",
"url":81,
"doc":"Convert a tuple with N elements to an Nx1 column vector",
"func":1
},
{
"ref":"vipy.linalg.columnize",
"url":81,
"doc":"Convert a numpy array into a flattened Nx1 column vector",
"func":1
},
{
"ref":"vipy.linalg.rowvector",
"url":81,
"doc":"Convert a tuple with N elements to an 1xN row vector",
"func":1
},
{
"ref":"vipy.linalg.is_poweroftwo",
"url":81,
"doc":"Is the number x a power of two? >>> assert vipy.linalg.is_poweroftwo(4)  True >>> assert vipy.linalg.is_poweroftwo(3)  False",
"func":1
},
{
"ref":"vipy.linalg.ndmax",
"url":81,
"doc":"Return the (i,j, .)=(row, col, .) entry corresponding to the maximum element in the nd numpy matrix A >>> A = np.array( 1,2,3],[4,100,6 ) >>> assert vipy.linalg.ndmax(A)  (1,2)",
"func":1
},
{
"ref":"vipy.linalg.ndmin",
"url":81,
"doc":"Return the (i,j, .)=(row,col, .) entry corresponding to the minimum element in the nd numpy matrix A >>> A = np.array( 1,2,3],[4,100,6 ) >>> assert vipy.linalg.ndmin(A)  (0,0)",
"func":1
},
{
"ref":"vipy.videosearch",
"url":82,
"doc":""
},
{
"ref":"vipy.videosearch.isactiveyoutuber",
"url":82,
"doc":"Does the youtube user have any uploaded videos?",
"func":1
},
{
"ref":"vipy.videosearch.youtubeuser",
"url":82,
"doc":"return all unique /user/ urls returned for a search for a given query tag",
"func":1
},
{
"ref":"vipy.videosearch.is_downloadable_url",
"url":82,
"doc":"Check to see if yt-dlp can download the path, this requires exeecuting 'yt-dlp $URL -q -j' to see if the returncode is non-zero",
"func":1
},
{
"ref":"vipy.videosearch.youtube",
"url":82,
"doc":"Return a list of YouTube URLs for the given tag and optional channel",
"func":1
},
{
"ref":"vipy.videosearch.liveleak",
"url":82,
"doc":"",
"func":1
},
{
"ref":"vipy.videosearch.download",
"url":82,
"doc":"Use yt-dlp to download a video URL to a video file",
"func":1
},
{
"ref":"vipy.videosearch.bulkdownload",
"url":82,
"doc":"Use yt-dlp to download a list of video URLs to video files using the provided sprintf outpattern=/path/to/out_%d.mp4 where the index is provided by the URL list index",
"func":1
},
{
"ref":"vipy.batch",
"url":83,
"doc":""
},
{
"ref":"vipy.batch.Batch",
"url":83,
"doc":"vipy.batch.Batch class This class provides a representation of a set of vipy objects. All of the object types must be the same. If so, then an operation on the batch is performed on each of the elements in the batch in parallel. Examples: >>> b = vipy.batch.Batch([Image(filename='img_%06d.png' % k) for k in range(0,100)]) >>> b.map(lambda im: im.bgr( >>> b.map(lambda im: np.sum(im.array( ) >>> b.map(lambda im, f: im.saveas(f), args=['out%d.jpg' % k for k in range(0,100)]) >>> v = vipy.video.RandomSceneActivity() >>> b = vipy.batch.Batch(v, n_processes=16) >>> b.map(lambda v,k: v[k], args=[(k,) for k in range(0, len(v ])  paralle interpolation >>> d = vipy.data.kinetics.Kinetics700('/path/to/kinetics').download().trainset() >>> b = vipy.batch.Batch(d, n_processes=32) >>> b.map(lambda v: v.download().save(  will download and clip dataset in parallel >>> b.result()  retrieve results after a sequence of map or filter chains >>> list(b)  equivalent to b.result() Args: strict: [bool] if distributed processing fails, return None for that element and print the exception rather than raise as_completed: [bool] Return the objects to the scheduler as they complete, this can introduce instabilities for large complex objects, use with caution ordered: [bool]: If True, then preserve the order of objects in objlist in distributed processing  notes  vipy.dataset.Dataset.map supports batch processing and is the preferred method for paralle processing of a dataset Create a batch of homogeneous vipy.image objects from an iterable that can be operated on with a single parallel function call"
},
{
"ref":"vipy.batch.Batch.result",
"url":83,
"doc":"Return the result of the batch processing, ordered",
"func":1
},
{
"ref":"vipy.batch.Batch.map",
"url":83,
"doc":"Run the lambda function on each of the elements of the batch and return the batch object. >>> iml = [vipy.image.RandomScene(512,512) for k in range(0,1000)] >>> imb = vipy.image.Batch(iml) >>> imb.map(lambda im: im.rgb( The lambda function f_lambda should not include closures. If it does, construct the lambda with default parameter capture: >>> f = lambda x, prm1=42: x+prm1 instead of: >>> prm1 = 42 >>> f = lambda x: x+prm1",
"func":1
},
{
"ref":"vipy.batch.Batch.filter",
"url":83,
"doc":"Run the lambda function on each of the elements of the batch and filter based on the provided lambda keeping those elements that return true",
"func":1
},
{
"ref":"vipy.batch.Batch.scattermap",
"url":83,
"doc":"Scatter obj to all workers, and apply lambda function f(obj, im) to each element in batch Usage: >>> Batch(mylist, ngpu=8).scattermap(lambda net, im: net(im), net).result() This will scatter the large object net to all workers, and pin it to a specific GPU. Within the net object, you can call vipy.global.gpuindex() to retrieve your assigned GPU index, which can be used by torch.cuda.device(). Then, the net object processes each element in the batch using net according to the lambda, and returns the results. This function includes ngpu processes, and assumes there are ngpu available on the target machine. Each net is replicated in a different process, so it is the callers responsibility for getting vipy.global.gpuindex() from within the process and setting net to take advantage of this GPU rather than using the default cuda:0.",
"func":1
},
{
"ref":"vipy.flow",
"url":84,
"doc":""
},
{
"ref":"vipy.flow.Image",
"url":84,
"doc":"vipy.flow.Image() class"
},
{
"ref":"vipy.flow.Image.min",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.max",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.scale",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.threshold",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.width",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.height",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.shape",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.flow",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.colorflow",
"url":84,
"doc":"Flow visualization image (HSV: H=flow angle, V=flow magnitude), returns vipy.image.Image()",
"func":1
},
{
"ref":"vipy.flow.Image.warp",
"url":84,
"doc":"Warp image imfrom=vipy.image.Image() to imto=vipy.image.Image() using flow computed as imfrom->imto, updating objects",
"func":1
},
{
"ref":"vipy.flow.Image.alphapad",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.zeropad",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.dx",
"url":84,
"doc":"Return dx (horizontal) component of flow",
"func":1
},
{
"ref":"vipy.flow.Image.dy",
"url":84,
"doc":"Return dy (vertical) component of flow",
"func":1
},
{
"ref":"vipy.flow.Image.shift",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.show",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.rescale",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.resize_like",
"url":84,
"doc":"Resize flow buffer to be the same size as the provided vipy.image.Image()",
"func":1
},
{
"ref":"vipy.flow.Image.resize",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.magnitude",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.angle",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.clone",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Image.print",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Video",
"url":84,
"doc":"vipy.flow.Video() class"
},
{
"ref":"vipy.flow.Video.min",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Video.max",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Video.width",
"url":84,
"doc":"Width (cols) in pixels of the video for the current filter chain",
"func":1
},
{
"ref":"vipy.flow.Video.height",
"url":84,
"doc":"Height (rows) in pixels of the video for the current filter chain",
"func":1
},
{
"ref":"vipy.flow.Video.flow",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Video.colorflow",
"url":84,
"doc":"Flow visualization video",
"func":1
},
{
"ref":"vipy.flow.Video.magnitude",
"url":84,
"doc":"",
"func":1
},
{
"ref":"vipy.flow.Video.show",
"url":84,
"doc":"Alias for play",
"func":1
},
{
"ref":"vipy.flow.Video.print",
"url":84,
"doc":"Print the representation of the video This is useful for debugging in long fluent chains. Sleep is useful for adding in a delay for distributed processing. Args: prefix: prepend a string prefix to the video __repr__ when printing. Useful for logging. sleep: Integer number of seconds to sleep[ before returning Returns: The video object after sleeping",
"func":1
},
{
"ref":"vipy.flow.Video.cast",
"url":16,
"doc":"Cast a conformal video object to a  vipy.video.Video object. This is useful for downcasting superclasses.   vs = vipy.video.RandomScene() v = vipy.video.Video.cast(vs)  ",
"func":1
},
{
"ref":"vipy.flow.Video.from_json",
"url":16,
"doc":"Import a json string as a  vipy.video.Video object. This will perform a round trip from a video to json and back to a video object. This same operation is used for serialization of all vipy objects to JSON for storage.   v = vipy.video.Video.from_json(vipy.video.RandomVideo().json(  ",
"func":1
},
{
"ref":"vipy.flow.Video.metadata",
"url":16,
"doc":"Return a dictionary of metadata about this video. Args: k [str]: If provided, return just the specified key of the attributes dictionary, otherwise return the attributes dictionary Returns: The 'attributes' dictionary, or just the value for the provided key k if provided",
"func":1
},
{
"ref":"vipy.flow.Video.sanitize",
"url":16,
"doc":"Remove all private keys from the attributes dictionary. The attributes dictionary is useful storage for arbitrary (key,value) pairs. However, this storage may contain sensitive information that should be scrubbed from the video before serialization. As a general rule, any key that is of the form '__keyname' prepended by two underscores is a private key. This is analogous to private or reserved attributes in the python lanugage. Users should reserve these keynames for those keys that should be sanitized and removed before any seerialization of this object.   assert self.setattribute('__mykey', 1).sanitize().hasattribute('__mykey')  False  ",
"func":1
},
{
"ref":"vipy.flow.Video.videoid",
"url":16,
"doc":"Return a unique video identifier for this video, as specified in the 'video_id' attribute Args: newid: [str] If not None, then update the video_id as newid. Returns: The video ID if newid=None else self",
"func":1
},
{
"ref":"vipy.flow.Video.frame",
"url":16,
"doc":"Return the kth frame as an  vipy.image Image object",
"func":1
},
{
"ref":"vipy.flow.Video.store",
"url":16,
"doc":"Store the current video file as an attribute of this object. Useful for archiving an object to be fully self contained without any external references.   v  v.store().restore(v.filename(    note -Remove this stored video using unstore() -Unpack this stored video and set up the video chains using restore() -This method is more efficient than load() followed by pkl(), as it stores the encoded video as a byte string. -Useful for creating a single self contained object for distributed processing.",
"func":1
},
{
"ref":"vipy.flow.Video.unstore",
"url":16,
"doc":"Delete the currently stored video from  vipy.video.Video.store",
"func":1
},
{
"ref":"vipy.flow.Video.restore",
"url":16,
"doc":"Save the currently stored video as set using  vipy.video.Video.store to filename, and set up filename",
"func":1
},
{
"ref":"vipy.flow.Video.concatenate",
"url":16,
"doc":"Temporally concatenate a sequence of videos into a single video stored in outfile.   (v1, v2, v3) = (vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32), vipy.video.RandomVideo(128,128,32 vc = vipy.video.Video.concatenate v1, v2, v3), 'concatenated.mp4', youtube_chapters=lambda v: v.category(   In this example, vc will point to concatenated.mp4 which will contain (v1,v2,v3) concatenated temporally . Args: videos: a single video or an iterable of videos of type  vipy.video.Video or an iterable of video files outfile: the output filename to store the concatenation. youtube_chapters: [bool, callable]: If true, output a string that can be used to define the start and end times of chapters if this video is uploaded to youtube. The string output should be copied to the youtube video description in order to enable chapters on playback. This argument will default to the string representation ofo the video, but you may also pass a callable of the form: 'youtube_chapters=lambda v: str(v)' which will output the provided string for each video chapter. A useful lambda is 'youtube_chapters=lambda v: v.category()' framerate: [float]: The output frame rate of outfile Returns: A  vipy.video.Video object with filename()=outfile, such that outfile contains the temporal concatenation of pixels in (self, videos).  note - self will not be modified, this will return a new  vipy.video.Video object. - All videos must be the same shape(). If the videos are different shapes, you must pad them to a common size equal to self.shape(). Try  vipy.video.Video.zeropadlike . - The output video will be at the framerate of self.framerate(). - if you want to concatenate annotations, call  vipy.video.Scene.annotate first on the videos to save the annotations into the pixels, then concatenate.",
"func":1
},
{
"ref":"vipy.flow.Video.stream",
"url":16,
"doc":"Iterator to yield groups of frames streaming from video. A video stream is a real time iterator to read or write from a video. Streams are useful to group together frames into clips that are operated on as a group. The following use cases are supported:   v = vipy.video.RandomScene()   Stream individual video frames lagged by 10 frames and 20 frames   for (im1, im2) in zip(v.stream().frame(n=-10), v.stream().frame(n=-20 : print(im1, im2)   Stream overlapping clips such that each clip is a video n=16 frames long and starts at frame i, and the next clip is n=16 frames long and starts at frame i=i+m   for vc in v.stream().clip(n=16, m=4): print(vc)   Stream non-overlapping batches of frames such that each clip is a video of length n and starts at frame i, and the next clip is length n and starts at frame i+n   for vb in v.stream().batch(n=16): print(vb)   Create a write stream to incrementally add frames to long video.   vi = vipy.video.Video(filename='/path/to/output.mp4') vo = vipy.video.Video(filename='/path/to/input.mp4') with vo.stream(write=True) as s: for im in vi.stream(): s.write(im)  manipulate pixels of im, if desired   Create a 480p YouTube live stream from an RTSP camera at 5Hz   vo = vipy.video.Scene(url='rtmp: a.rtmp.youtube.com/live2/$SECRET_STREAM_KEY') vi = vipy.video.Scene(url='rtsp: URL').framerate(5) with vo.framerate(5).stream(write=True, bitrate='1000k') as s: for im in vi.framerate(5).resize(cols=854, rows=480): s.write(im)   Args: write: [bool] If true, create a write stream overwrite: [bool] If true, and the video output filename already exists, overwrite it bufsize: [int] The maximum queue size for the ffmpeg pipe thread in the primary iterator. The queue size is the maximum size of pre-fetched frames from the ffmpeg pip. This should be big enough that you are never waiting for queue fills bitrate: [str] The ffmpeg bitrate of the output encoder for writing, written like '2000k' bufsize: [int] The maximum size of the stream buffer in frames. The stream buffer length should be big enough so that all iterators can yield before deleting old frames Returns: A Stream object  note Using this iterator may affect PDB debugging due to stdout/stdin redirection. Use ipdb instead.",
"func":1
},
{
"ref":"vipy.flow.Video.clear",
"url":16,
"doc":"no-op for  vipy.video.Video object, used only for  vipy.video.Scene ",
"func":1
},
{
"ref":"vipy.flow.Video.bytes",
"url":16,
"doc":"Return a bytes representation of the video file",
"func":1
},
{
"ref":"vipy.flow.Video.frames",
"url":16,
"doc":"Alias for __iter__()",
"func":1
},
{
"ref":"vipy.flow.Video.commandline",
"url":16,
"doc":"Return the equivalent ffmpeg command line string that will be used to transcode the video. This is useful for introspecting the complex filter chain that will be used to process the video. You can try to run this command line yourself for debugging purposes, by replacing 'dummyfile' with an appropriately named output file.",
"func":1
},
{
"ref":"vipy.flow.Video.probeshape",
"url":16,
"doc":"Return the (height, width) of underlying video file as determined from ffprobe  warning this does not take into account any applied ffmpeg filters. The shape will be the (height, width) of the underlying video file.",
"func":1
},
{
"ref":"vipy.flow.Video.duration_in_seconds_of_videofile",
"url":16,
"doc":"Return video duration of the source filename (NOT the filter chain) in seconds, requires ffprobe. Fetch once and cache.  notes This is the duration of the source video and NOT the duration of the filter chain. If you load(), this may be different duration depending on clip() or framerate() directives.",
"func":1
},
{
"ref":"vipy.flow.Video.duration_in_frames_of_videofile",
"url":16,
"doc":"Return video duration of the source video file (NOT the filter chain) in frames, requires ffprobe.  notes This is the duration of the source video and NOT the duration of the filter chain. If you load(), this may be different duration depending on clip() or framerate() directives.",
"func":1
},
{
"ref":"vipy.flow.Video.duration",
"url":16,
"doc":"Return a video clipped with frame indexes between (0, frames) or (0,seconds self.framerate( or (0,minutes 60 self.framerate(). Return duration in seconds if no arguments are provided.",
"func":1
},
{
"ref":"vipy.flow.Video.duration_in_frames",
"url":16,
"doc":"Return the duration of the video filter chain in frames, equal to round(self.duration() self.framerate( . Requires a probe() of the video to get duration",
"func":1
},
{
"ref":"vipy.flow.Video.framerate_of_videofile",
"url":16,
"doc":"Return video framerate in frames per second of the source video file (NOT the filter chain), requires ffprobe.",
"func":1
},
{
"ref":"vipy.flow.Video.resolution_of_videofile",
"url":16,
"doc":"Return video resolution in (height, width) in pixels (NOT the filter chain), requires ffprobe.",
"func":1
},
{
"ref":"vipy.flow.Video.probe",
"url":16,
"doc":"Run ffprobe on the filename and return the result as a dictionary Args: Any keyword arguments supported by python-ffmpeg probe() - these are passed in as-is - for flags, use flag_name=None (e.g., show_frames=None) so that ffmpeg.probe() handles them correctly",
"func":1
},
{
"ref":"vipy.flow.Video.frame_meta",
"url":16,
"doc":"Return the frame metadata of the underlying video file using ffprobe for all frames as a list of dicts, each list element corresponding to a frame. This is useful for extracting frame types (e.g. i-frames). Args: k [int]: Return only the frame metadata for frame index k (relative to framerate of source videofile, not filter chain) Returns: a list of metadata dicts (one per frame) or a single dict for the requested frame.  notes - This will return a large amount of metadata for the entire source video (not the FFMPEG filter chain), use with caution. - To get frame metata for a filter chain use vipy.video.Video.savetemp().frame_meta(), which will save the video to a temporary file prior to extracting frame metadata",
"func":1
},
{
"ref":"vipy.flow.Video.metaframe",
"url":16,
"doc":"Alias for  vipy.video.Video.frame_meta ",
"func":1
},
{
"ref":"vipy.flow.Video.iframes",
"url":16,
"doc":"Return a list of i-frame indexes (e.g. intra-frame, a video frame that is independent from other frames for decoding) in this video file.  note - To return the i-frame indexes for the current filter chain use self.saveas().iframes() to save to a temporary file prior to i-frame index extraction. - To extract the i-frame itself, use [self.frame(k) for k in self.iframes()]",
"func":1
},
{
"ref":"vipy.flow.Video.printif",
"url":16,
"doc":"Call  vipy.video.Video.print if b=True. Useful for fluent chains to print periodically.",
"func":1
},
{
"ref":"vipy.flow.Video.dict",
"url":16,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding.",
"func":1
},
{
"ref":"vipy.flow.Video.json",
"url":16,
"doc":"Return a json representation of the video. Args: encode: If true, return a JSON encoded string using json.dumps Returns: A JSON encoded string if encode=True, else returns a dictionary object  note If the video is loaded, then the JSON will not include the pixels. Try using  vipy.video.Video.store to serialize videos, or call  vipy.video.Video.flush first.",
"func":1
},
{
"ref":"vipy.flow.Video.take",
"url":16,
"doc":"Return n frames from the clip uniformly spaced as numpy array Args: n: Integer number of uniformly spaced frames to return Returns: A numpy array of shape (n,W,H)  warning This assumes that the entire video is loaded into memory (e.g. call  vipy.video.Video.load ). Use with caution.",
"func":1
},
{
"ref":"vipy.flow.Video.framerate",
"url":16,
"doc":"Change the input framerate for the video and update frame indexes for all annotations Args: fps: [Float] frames per second to process the underlying video round ['up','down','near'] the rounding option for the ffmpeg fps filter Returns: If fps is None, return the current framerate, otherwise set the framerate to fps",
"func":1
},
{
"ref":"vipy.flow.Video.colorspace",
"url":16,
"doc":"Return or set the colorspace as ['rgb', 'bgr', 'lum', 'float']. This will not change pixels, only the colorspace interpretation of pixels.",
"func":1
},
{
"ref":"vipy.flow.Video.nourl",
"url":16,
"doc":"Remove the  vipy.video.Video.url from the video",
"func":1
},
{
"ref":"vipy.flow.Video.url",
"url":16,
"doc":"Video URL and URL download properties",
"func":1
},
{
"ref":"vipy.flow.Video.isloaded",
"url":16,
"doc":"Return True if the video has been loaded",
"func":1
},
{
"ref":"vipy.flow.Video.is_loaded",
"url":16,
"doc":"Return True if the video has been loaded",
"func":1
},
{
"ref":"vipy.flow.Video.isloadable",
"url":16,
"doc":"Return True if the video can be loaded successfully. This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version. Args: flush: [bool] If true, flush the video after it loads. This will clear the video pixel buffer Returns: True if load() can be called without FFMPEG exception. If flush=False, then self will contain the loaded video, which is helpful to avoid load() twice in some conditions  warning This requires loading and flushing the video. This is an expensive operation when performed on many videos and may result in out of memory conditions with long videos. Use with caution! Try  vipy.video.Video.canload to test if a single frame can be loaded as a less expensive alternative.",
"func":1
},
{
"ref":"vipy.flow.Video.canload",
"url":16,
"doc":"Return True if the video can be previewed at frame=k successfully. This is useful for filtering bad videos or filtering videos that cannot be loaded using your current FFMPEG version.  notes This will only try to preview a single frame. This will not check if the entire video is loadable. Use  vipy.video.Video.isloadable in this case This will hang if calling canload on a streaming URL.",
"func":1
},
{
"ref":"vipy.flow.Video.iscolor",
"url":16,
"doc":"Is the video a three channel color video as returned from  vipy.video.Video.channels ?",
"func":1
},
{
"ref":"vipy.flow.Video.isgrayscale",
"url":16,
"doc":"Is the video a single channel as returned from  vipy.video.Video.channels ?",
"func":1
},
{
"ref":"vipy.flow.Video.hasfilename",
"url":16,
"doc":"Does the filename returned from  vipy.video.Video.filename exist?",
"func":1
},
{
"ref":"vipy.flow.Video.isdownloaded",
"url":16,
"doc":"Alias for  vipy.video.Video.is_downloaded ",
"func":1
},
{
"ref":"vipy.flow.Video.is_downloaded",
"url":16,
"doc":"Does the filename returned from  vipy.video.Video.filename exist, meaning that the url has been downloaded to a local file?",
"func":1
},
{
"ref":"vipy.flow.Video.hasurl",
"url":16,
"doc":"Is the url returned from  vipy.video.Video.url a well formed url?",
"func":1
},
{
"ref":"vipy.flow.Video.array",
"url":16,
"doc":"Set or return the video buffer as a numpy array. Args: array: [np.array] A numpy array of size NxHxWxC = (frames, height, width, channels) of type uint8 or float32. array: [list] A list of  vipy.image.Image objects copy: [bool] If true, copy the buffer by value instaed of by reference. Copied buffers do not share pixels. Returns: if array=None, return a reference to the pixel buffer as a numpy array, otherwise return the video object with the array populated",
"func":1
},
{
"ref":"vipy.flow.Video.from_array",
"url":16,
"doc":"Create a new video from a shared array, Equivalent to self.array( ., copy=False)",
"func":1
},
{
"ref":"vipy.flow.Video.from_directory",
"url":16,
"doc":"Create a video from a directory of frames stored as individual image filenames. Given a directory with files: framedir/image_0001.jpg framedir/image_0002.jpg   vipy.video.Video(frames='/path/to/framedir')  ",
"func":1
},
{
"ref":"vipy.flow.Video.from_frames",
"url":16,
"doc":"Create a video from a list of frames",
"func":1
},
{
"ref":"vipy.flow.Video.from_annotation_sequence",
"url":16,
"doc":"Construct a video from an input image im where each frame is the acculation of annnotated objects in im. This is useful for visualization of a labeling sequence",
"func":1
},
{
"ref":"vipy.flow.Video.to_numpy",
"url":16,
"doc":"Alias for numpy()",
"func":1
},
{
"ref":"vipy.flow.Video.mutable",
"url":16,
"doc":"Return a video object with a writeable mutable frame array. Video must be loaded, triggers copy of underlying numpy array if the buffer is not writeable. Returns: This object with a mutable frame buffer in self.array() or self.numpy()",
"func":1
},
{
"ref":"vipy.flow.Video.numpy",
"url":16,
"doc":"Convert the video to a writeable numpy array, triggers a load() and copy() as needed. Returns the numpy array.",
"func":1
},
{
"ref":"vipy.flow.Video.filename",
"url":16,
"doc":"Update video Filename with optional copy or symlink from existing file (self.filename( to new file",
"func":1
},
{
"ref":"vipy.flow.Video.abspath",
"url":16,
"doc":"Change the path of the filename from a relative path to an absolute path (not relocatable)",
"func":1
},
{
"ref":"vipy.flow.Video.relpath",
"url":16,
"doc":"Replace the filename with a relative path to parent (or current working directory if none). Usage:   v = vipy.video.Video(filename='/path/to/dataset/video/category/out.mp4') v.relpath(parent='/path/to/dataset') v.filename()  'video/category/out.mp4'   If the current working directory is /path/to/dataset, and v.load() is called, the filename will be loaded. Args: parent [str]: A parent path of the current filename to remove and be relative to. If filename is '/path/to/video.mp4' then filename must start with parent, then parent will be remvoed from filename. start [str]: Return a relative filename starting from path start='/path/to/dir' that will create a relative path to this filename. If start='/a/b/c' and filename='/a/b/d/e/f.ext' then return filename ' /d/e/f.ext' Returns: This video object with the filename changed to be a relative path",
"func":1
},
{
"ref":"vipy.flow.Video.rename",
"url":16,
"doc":"Move the underlying video file preserving the absolute path, such that self.filename()  '/a/b/c.ext' and newname='d.ext', then self.filename() -> '/a/b/d.ext', and move the corresponding file",
"func":1
},
{
"ref":"vipy.flow.Video.filesize",
"url":16,
"doc":"Return the size in bytes of the filename(), None if the filename() is invalid",
"func":1
},
{
"ref":"vipy.flow.Video.downloadif",
"url":16,
"doc":"Download URL to filename if the filename has not already been downloaded",
"func":1
},
{
"ref":"vipy.flow.Video.download",
"url":16,
"doc":"Download URL to filename provided by constructor, or to temp filename. Args: timeout: [int] An integer timeout in seconds for the download to connect verbose: [bool] If trye, show more verbose console output max_filesize: [str] A string of the form 'NNNg' or 'NNNm' for youtube downloads to limit the maximum size of a URL to '350m' 350MB or '12g' for 12GB. Returns: This video object with the video downloaded to the filename()",
"func":1
},
{
"ref":"vipy.flow.Video.fetch",
"url":16,
"doc":"Download only if hasfilename() is not found",
"func":1
},
{
"ref":"vipy.flow.Video.shape",
"url":16,
"doc":"Return (height, width) of the frames, requires loading a preview frame from the video if the video is not already loaded, or providing the shape=(height,width) by the user",
"func":1
},
{
"ref":"vipy.flow.Video.channelshape",
"url":16,
"doc":"Return a tuple (channels, height, width) for the video",
"func":1
},
{
"ref":"vipy.flow.Video.issquare",
"url":16,
"doc":"Return true if the video has square dimensions (height  width), else false",
"func":1
},
{
"ref":"vipy.flow.Video.channels",
"url":16,
"doc":"Return integer number of color channels",
"func":1
},
{
"ref":"vipy.flow.Video.aspect_ratio",
"url":16,
"doc":"The width/height of the video expressed as a fraction",
"func":1
},
{
"ref":"vipy.flow.Video.preview",
"url":16,
"doc":"Return selected frame of filtered video, return vipy.image.Image object. This is useful for previewing the frame shape of a complex filter chain or the frame contents at a particular location without loading the whole video",
"func":1
},
{
"ref":"vipy.flow.Video.thumbnail",
"url":16,
"doc":"Return annotated frame=k of video, save annotation visualization to provided outfile. This is functionally equivalent to  vipy.video.Video.frame with an additional outfile argument to easily save an annotated thumbnail image. Args: outfile: [str] an optional outfile to save the annotated frame frame: [int >= 0] The frame to output the thumbnail Returns: A  vipy.image.Image object for frame k.",
"func":1
},
{
"ref":"vipy.flow.Video.load",
"url":16,
"doc":"Load a video using ffmpeg, applying the requested filter chain. Args: verbose: [bool] if True. then ffmpeg console output will be displayed. shape: [tuple (height, width, channels)] If provided, use this shape for reading and reshaping the byte stream from ffmpeg. This is useful for efficient loading in some scenarios. Knowing the final output shape can speed up loads by avoiding a preview() of the filter chain to get the frame size Returns: this video object, with the pixels loaded in self.array()  warning Loading long videos can result in out of memory conditions. Try to call clip() first to extract a video segment to load().",
"func":1
},
{
"ref":"vipy.flow.Video.speed",
"url":16,
"doc":"Change the speed by a multiplier s. If s=1, this will be the same speed, s=0.5 for half-speed (slower playback), s=2 for double-speed (faster playback)",
"func":1
},
{
"ref":"vipy.flow.Video.clip",
"url":16,
"doc":"Clip the video to between (start, end). This clip is relative to clip() shown by __repr__(). Args: start: [int|float] the start frame|second relative to the video framerate() for the clip end: [int|float] the end frame|second relative to the video framerate for the clip, may be none Returns: This video object, clipped so that a load() will result in frame=0 equivalent to startframe.  note: - This does not load the video. This updates the ffmpeg filter chain to temporally trim the video. See self.commandline() for the updated filter chain to run.",
"func":1
},
{
"ref":"vipy.flow.Video.cliprange",
"url":16,
"doc":"Return the planned clip (startframe, endframe) range. This is useful for introspection of the planned clip() before load(), such as for data augmentation purposes without triggering a load. Returns: (startframe, endframe) of the video() such that after load(), the pixel buffer will contain frame=0 equivalent to startframe in the source video, and frame=endframe-startframe-1 equivalent to endframe in the source video. (0, None) If a video does not have a clip() (e.g. clip() was never called, the filter chain does not include a 'trim')  notes The endframe can be retrieved (inefficiently) using:   int(round(self.duration_in_frames_of_videofile()  (self.framerate() / self.framerate_of_videofile(   ",
"func":1
},
{
"ref":"vipy.flow.Video.rot90cw",
"url":16,
"doc":"Rotate the video 90 degrees clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.flow.Video.rot90ccw",
"url":16,
"doc":"Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.flow.Video.fliplr",
"url":16,
"doc":"Mirror the video left/right by flipping horizontally",
"func":1
},
{
"ref":"vipy.flow.Video.flipud",
"url":16,
"doc":"Rotate the video 90 degrees counter-clockwise, can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.flow.Video.rescale",
"url":16,
"doc":"Rescale the video by factor s, such that the new dimensions are (s H, s W), can only be applied prior to load()",
"func":1
},
{
"ref":"vipy.flow.Video.resize",
"url":16,
"doc":"Resize the video to be (rows=height, cols=width)",
"func":1
},
{
"ref":"vipy.flow.Video.mindim",
"url":16,
"doc":"Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio, return the minimum dimension if dim=None",
"func":1
},
{
"ref":"vipy.flow.Video.set_mindim",
"url":16,
"doc":"Resize the video so that the minimum of (width,height)=dim, preserving aspect ratio, do nothing if dim=None",
"func":1
},
{
"ref":"vipy.flow.Video.maxdim",
"url":16,
"doc":"Resize the video so that the maximum of (width,height)=dim, preserving aspect ratio",
"func":1
},
{
"ref":"vipy.flow.Video.randomcrop",
"url":16,
"doc":"Crop the video to shape=(H,W) with random position such that the crop contains only valid pixels, and optionally return the box",
"func":1
},
{
"ref":"vipy.flow.Video.centercrop",
"url":16,
"doc":"Crop the video to shape=(H,W) preserving the integer centroid position, and optionally return the box",
"func":1
},
{
"ref":"vipy.flow.Video.centersquare",
"url":16,
"doc":"Crop video of size (NxN) in the center, such that N=min(width,height), keeping the video centroid constant",
"func":1
},
{
"ref":"vipy.flow.Video.cropeven",
"url":16,
"doc":"Crop the video to the largest even (width,height) less than or equal to current (width,height). This is useful for some codecs or filters which require even shape.",
"func":1
},
{
"ref":"vipy.flow.Video.maxsquare",
"url":16,
"doc":"Pad the video to be square, preserving the upper left corner of the video",
"func":1
},
{
"ref":"vipy.flow.Video.minsquare",
"url":16,
"doc":"Return a square crop of the video, preserving the upper left corner of the video",
"func":1
},
{
"ref":"vipy.flow.Video.maxmatte",
"url":16,
"doc":"Return a square video with dimensions (self.maxdim(), self.maxdim( with zeropadded lack bars or mattes above or below the video forming a letterboxed video.",
"func":1
},
{
"ref":"vipy.flow.Video.zeropad",
"url":16,
"doc":"Zero pad the video with padwidth columns before and after, and padheight rows before and after  notes Older FFMPEG implementations can throw the error \"Input area  : : : not within the padded area  : : : or zero-sized, this is often caused by odd sized padding. Recommend calling self.cropeven().zeropad( .) to avoid this",
"func":1
},
{
"ref":"vipy.flow.Video.pad",
"url":16,
"doc":"Alias for zeropad",
"func":1
},
{
"ref":"vipy.flow.Video.zeropadlike",
"url":16,
"doc":"Zero pad the video balancing the border so that the resulting video size is (width, height).",
"func":1
},
{
"ref":"vipy.flow.Video.crop",
"url":16,
"doc":"Spatially crop the video using the supplied vipy.geometry.BoundingBox, can only be applied prior to load().  note Crop is performed in place overwriting pixels of self.array(). Clone() before crop() if array() must be preserved.",
"func":1
},
{
"ref":"vipy.flow.Video.pkl",
"url":16,
"doc":"save the object to a pickle file and return the object, useful for intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.flow.Video.pklif",
"url":16,
"doc":"Save the object to the provided pickle file only if b=True. Uuseful for conditional intermediate saving in long fluent chains",
"func":1
},
{
"ref":"vipy.flow.Video.webp",
"url":16,
"doc":"Save a video to an animated WEBP file, with pause=N seconds on the last frame between loops. Args: strict: If true, assert that the filename must have an .webp extension pause: Integer seconds to pause between loops of the animation smallest: if true, create the smallest possible file but takes much longer to run smaller: If true, create a smaller file, which takes a little longer to run framerate [float]: The output framerate of the webp file. The default is the framerate of the video. Returns: The filename of the webp file for this video  warning This may be slow for very long or large videos",
"func":1
},
{
"ref":"vipy.flow.Video.gif",
"url":16,
"doc":"Save a video to an animated GIF file, with pause=N seconds between loops. Args: pause: Integer seconds to pause between loops of the animation smallest: If true, create the smallest possible file but takes much longer to run smaller: if trye, create a smaller file, which takes a little longer to run framerate [float]: The output framerate of the webp file. The default is the framerate of the video. Returns: The filename of the animated GIF of this video  warning This will be very large for big videos, consider using  vipy.video.Video.webp instead.",
"func":1
},
{
"ref":"vipy.flow.Video.save",
"url":16,
"doc":"Save video to new output video file. This function does not draw boxes, it saves pixels to a new video file. Args: outfile: the absolute path to the output video file. This extension can be .mp4 (for video) or [\".webp\",\".gif\"] (for animated image) flush: If true, then flush the buffer for this object right after saving the new video. This is useful for transcoding in parallel framerate: input framerate of the frames in the buffer, or the output framerate of the transcoded video. If not provided, use framerate of source video pause: an integer in seconds to pause between loops of animated images if the outfile is webp or animated gif Returns: a new video object with this video filename, and a clean video filter chain  note - If self.array() is loaded, then export the contents of self._array to the video file - If self.array() is not loaded, and there exists a valid video file, apply the filter chain directly to the input video - If outfile None or outfile self.filename(), then overwrite the current filename",
"func":1
},
{
"ref":"vipy.flow.Video.saveas",
"url":16,
"doc":"Call  vipy.video.Video.saveas using a new temporary video file, and return the video object with this new filename",
"func":1
},
{
"ref":"vipy.flow.Video.savetmp",
"url":16,
"doc":"Call  vipy.video.Video.saveas using a new temporary video file, and return the video object with this new filename",
"func":1
},
{
"ref":"vipy.flow.Video.ffplay",
"url":16,
"doc":"Play the video file using ffplay",
"func":1
},
{
"ref":"vipy.flow.Video.play",
"url":16,
"doc":"Play the saved video filename in self.filename() If there is no filename, try to download it. If the filter chain is dirty or the pixels are loaded, dump to temp video file first then play it. This uses 'ffplay' on the PATH if available, otherwise uses a fallback player by showing a sequence of matplotlib frames. If the output of the ffmpeg filter chain has modified this video, then this will be saved to a temporary video file. To play the original video (indepenedent of the filter chain of this video), use  vipy.video.Video.ffplay . Args: verbose: If true, show more verbose output notebook: If true, play in a jupyter notebook ffplay: If true, use ffplay to display the video (if available) Returns: The unmodified video object",
"func":1
},
{
"ref":"vipy.flow.Video.quicklook",
"url":16,
"doc":"Generate a montage of n uniformly spaced frames. Montage increases rowwise for n uniformly spaced frames, starting from frame zero and ending on the last frame. Input: n: Number of images in the quicklook mindim: The minimum dimension of each of the elements in the montage animate: If true, return a video constructed by animating the quicklook into a video by showing dt consecutive frames dt: The number of frames for animation startframe: The initial frame index to start the n uniformly sampled frames for the quicklook thumbnail [ vipy.image.Image ]: If provided, prepent the first element in the montage with this thumbnail. This is useful for showing a high resolution image (e.g. a face, small object) to be contained in the video for review. aspectratio [float]: the ratio of gridcols/gridrows in vipy.visualize.montage  note The first frame in the upper left is guaranteed to be the start frame of the labeled activity, but the last frame in the bottom right may not be precisely the end frame and may be off by at most len(video)/9.",
"func":1
},
{
"ref":"vipy.flow.Video.torch",
"url":16,
"doc":"Convert the loaded video of shape NxHxWxC frames to an MxCxHxW torch tensor/ Args: startframe: [int >= 0] The start frame of the loaded video to use for constructig the torch tensor endframe: [int >= 0] The end frame of the loaded video to use for constructing the torch tensor length: [int >= 0] The length of the torch tensor if endframe is not provided. stride: [int >= 1] The temporal stride in frames. This is the number of frames to skip. take: [int >= 0] The number of uniformly spaced frames to include in the tensor. boundary: ['repeat', 'cyclic'] The boundary handling for when the requested tensor slice goes beyond the end of the video order: ['nchw', 'nhwc', 'chwn', 'cnhw'] The axis ordering of the returned torch tensor N=number of frames (batchsize), C=channels, H=height, W=width verbose [bool]: Print out the slice used for contructing tensor withslice: [bool] Return a tuple (tensor, slice) that includes the slice used to construct the tensor. Useful for data provenance. scale: [float] An optional scale factor to apply to the tensor. Useful for converting [0,255] -> [0,1] withlabel: [bool] Return a tuple (tensor, labels) that includes the N framewise activity labels. nonelabel: [bool] returns tuple (t, None) if withlabel=False Returns Returns torch float tensor, analogous to torchvision.transforms.ToTensor() Return (tensor, slice) if withslice=True (withslice takes precedence) Returns (tensor, labellist) if withlabel=True  notes - This triggers a load() of the video - The precedence of arguments is (startframe, endframe) or (startframe, startframe+length), then stride and take. - Follows numpy slicing rules. Optionally return the slice used if withslice=True",
"func":1
},
{
"ref":"vipy.flow.Video.clone",
"url":16,
"doc":"Create deep copy of video object, flushing the original buffer if requested and returning the cloned object. Flushing is useful for distributed memory management to free the buffer from this object, and pass along a cloned object which can be used for encoding and will be garbage collected. Args: flushforward: copy the object, and set the cloned object  vipy.video.Video.array to None. This flushes the video buffer for the clone, not the object flushbackward: copy the object, and set the object array() to None. This flushes the video buffer for the object, not the clone. flush: set the object array() to None and clone the object. This flushes the video buffer for both the clone and the object. flushfilter: Set the ffmpeg filter chain to the default in the new object, useful for saving new videos flushfile: Remove the filename and the URL from the video object. Useful for creating new video objects from loaded pixels. rekey: Generate new unique track ID and activity ID keys for this scene shallow: shallow copy everything (copy by reference), except for ffmpeg object. attributes dictionary is shallow copied sharedarray: deep copy of everything, except for pixel buffer which is shared. Changing the pixel buffer on self is reflected in the clone. sanitize: remove private attributes from self.attributes dictionary. A private attribute is any key with two leading underscores '__' which should not be propagated to clone Returns: A deepcopy of the video object such that changes to self are not reflected in the copy  note Cloning videos is an expensive operation and can slow down real time code. Use sparingly.",
"func":1
},
{
"ref":"vipy.flow.Video.flush",
"url":16,
"doc":"Alias for clone(flush=True), returns self not clone",
"func":1
},
{
"ref":"vipy.flow.Video.unload",
"url":16,
"doc":"Remove cached file and loaded array. Note that this will delete the underlying file returned by filename() if there is a backing url, cleaning up cached files and forcing re-download",
"func":1
},
{
"ref":"vipy.flow.Video.uncache",
"url":16,
"doc":"Alias for  vipy.image.Image.unload ",
"func":1
},
{
"ref":"vipy.flow.Video.returns",
"url":16,
"doc":"Return the provided value, useful for terminating long fluent chains without returning self",
"func":1
},
{
"ref":"vipy.flow.Video.flush_and_return",
"url":16,
"doc":"Flush the video and return the parameter supplied, useful for long fluent chains",
"func":1
},
{
"ref":"vipy.flow.Video.map",
"url":16,
"doc":"Apply lambda function to the loaded numpy array img, changes pixels not shape Lambda function must have the following signature:  newimg = func(img)  img: HxWxC numpy array for a single frame of video  newimg: HxWxC modified numpy array for this frame. Change only the pixels, not the shape The lambda function will be applied to every frame in the video in frame index order.",
"func":1
},
{
"ref":"vipy.flow.Video.gain",
"url":16,
"doc":"Pixelwise multiplicative gain, such that each pixel p_{ij} = g  p_{ij}",
"func":1
},
{
"ref":"vipy.flow.Video.bias",
"url":16,
"doc":"Pixelwise additive bias, such that each pixel p_{ij} = b + p_{ij}",
"func":1
},
{
"ref":"vipy.flow.Video.normalize",
"url":16,
"doc":"Pixelwise whitening, out =  scale in) - mean) / std); triggers load(). All computations float32",
"func":1
},
{
"ref":"vipy.flow.Video.hasattribute",
"url":16,
"doc":"Does the attributes dictionary (self.attributes) contain the provided key",
"func":1
},
{
"ref":"vipy.flow.Video.clearattributes",
"url":16,
"doc":"Remove all attributes",
"func":1
},
{
"ref":"vipy.flow.Video.clear_attributes",
"url":16,
"doc":"Remove all attributes",
"func":1
},
{
"ref":"vipy.flow.Video.get_attribute",
"url":16,
"doc":"Return the key k in the attributes dictionary (self.attributes) if present, else None",
"func":1
},
{
"ref":"vipy.flow.Flow",
"url":84,
"doc":"vipy.flow.Flow() class"
},
{
"ref":"vipy.flow.Flow.imageflow",
"url":84,
"doc":"Default opencv dense flow, from im to imprev. This should be overloaded",
"func":1
},
{
"ref":"vipy.flow.Flow.videoflow",
"url":84,
"doc":"Compute optical flow for a video framewise skipping framestep frames, compute optical flow acrsos flowstep frames,",
"func":1
},
{
"ref":"vipy.flow.Flow.videoflowframe",
"url":84,
"doc":"Computer the videoflow for a single frame",
"func":1
},
{
"ref":"vipy.flow.Flow.keyflow",
"url":84,
"doc":"Compute optical flow for a video framewise relative to keyframes separated by keystep",
"func":1
},
{
"ref":"vipy.flow.Flow.keyflowframe",
"url":84,
"doc":"Compute the keyflow for a single frame",
"func":1
},
{
"ref":"vipy.flow.Flow.affineflow",
"url":84,
"doc":"Return a flow field of size (height=H, width=W) consistent with a 2x3 affine transformation A",
"func":1
},
{
"ref":"vipy.flow.Flow.euclideanflow",
"url":84,
"doc":"Return a flow field of size (height=H, width=W) consistent with an Euclidean transform parameterized by a 2x2 Rotation and 2x1 translation",
"func":1
},
{
"ref":"vipy.flow.Flow.stabilize",
"url":84,
"doc":"Affine stabilization to frame zero using multi-scale optical flow correspondence with foreground object keepouts. Recommended usage: use the  vipy.video.Scene.stabilize method on a  vipy.video.Video object.   v = vipy.video.Scene(filename='/path/to/my/video.mp4').stabilize()   Args: v: [ vipy.video.Scene ]: The input video to stabilize, should be resized to mindim=256 keystep: [int] The local stabilization step between keyframes (should be <= 30) padheightfrac: [float] The height padding (relative to video height) to be applied to output video to allow for vertical stabilization padwidthfrac: [float] The width padding (relative to video width) to be applied to output video to allow for horizontal stabilization padheightpx: [int] The height padding to be applied to output video to allow for vertical stabilization. Overrides padheight. padwidthpx: [int] The width padding to be applied to output video to allow for horizontal stabilization. Overrides padwidth. border: [float] The border keepout fraction to ignore during flow correspondence. This should be proportional to the maximum frame to frame flow dilate: [float] The dilation to apply to the foreground object boxes to define a foregroun keepout for flow computation contrast: [float] The minimum gradient necessary for flow correspondence, to avoid flow on low contrast regions rigid: [bool] Euclidean stabilization affine: [bool] Affine stabilization verbose: [bool] This takes a while to run so show some progress  . strict: [bool] If true, throw an exception on error, otherwise return the original video and set v.hasattribute('unstabilized'), useful for large scale stabilization outfile: [str] the file path to the stabilized output video preload [bool]: If true, load the input video into memory before stabilizing. Faster, but requires video to fit into memory. framerate [float]: The framerate at which to compute the stabilization. Videos will be stabilized at the native framerate of the input video, but will be linearly interpolated between keyframes aligned at this framerate Returns: A cloned  vipy.video.Scene with filename=outfile, such that pixels and tracks are background stabilized.  notes - The remaining distortion after stabilization is due to: rolling shutter distortion, perspective distortion and non-keepout moving objects in background - If the video contains objects, the object boxes will be transformed along with the stabilization - This requires loading videos entirely into memory. Be careful with stabilizing long videos. - The returned video has the attribute 'stabilize' which contains the mean and median residual of the flow field relative to the motion model. This can be used for stabilization quality filtering. - Higher framerates result in more accurate stabilization, but take significantly longer.",
"func":1
},
{
"ref":"vipy.geometry",
"url":80,
"doc":""
},
{
"ref":"vipy.geometry.covariance_to_ellipse",
"url":80,
"doc":"2x2 covariance matrix to ellipse (major_axis_length, minor_axis_length, angle_in_radians)",
"func":1
},
{
"ref":"vipy.geometry.dehomogenize",
"url":80,
"doc":"Convert 3x1 homogenous point (x,y,h) to 2x1 non-homogenous point (x/h, y/h)",
"func":1
},
{
"ref":"vipy.geometry.homogenize",
"url":80,
"doc":"Convert 2xN non-homogenous points (x,y) to 3xN non-homogenous point (x, y, 1)",
"func":1
},
{
"ref":"vipy.geometry.apply_homography",
"url":80,
"doc":"Apply a 3x3 homography H to non-homogenous point p and return a transformed point",
"func":1
},
{
"ref":"vipy.geometry.similarity_transform_2x3",
"url":80,
"doc":"Return a 2x3 similarity transform with rotation r (radians), scale s and origin c=(x,y)",
"func":1
},
{
"ref":"vipy.geometry.similarity_transform",
"url":80,
"doc":"Return a 3x3 similarity transformation with translation tuple txy=(x,y), rotation r (radians, scale=s",
"func":1
},
{
"ref":"vipy.geometry.affine_transform",
"url":80,
"doc":"Compose and return a 3x3 affine transformation for translation txy=(0,0), rotation r (radians), scalex=sx, scaley=sy, shearx=kx, sheary=ky. Usage:   A = vipy.geometry.affine_transform(r=np.pi/4) vipy.image.Image(array=vipy.geometry.imtransform(im.array(), A), colorspace='float')   Equivalently:   im = vipy.image.RandomImage().affine_transform(A)  ",
"func":1
},
{
"ref":"vipy.geometry.random_affine_transform",
"url":80,
"doc":"Return a random 3x3 affine transformation matrix for the provided ranges, inputs must be tuples",
"func":1
},
{
"ref":"vipy.geometry.imtransform",
"url":80,
"doc":"Transform an numpy array image (MxNx3) following the affine or similiarity transformation A",
"func":1
},
{
"ref":"vipy.geometry.normalize",
"url":80,
"doc":"Given a vector x, return the vector unit normalized as float64",
"func":1
},
{
"ref":"vipy.geometry.imagebox",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox",
"url":80,
"doc":"Core bounding box class with flexible constructors in this priority order: (xmin,ymin,xmax,ymax) (xmin,ymin,width,height) (centroid[0],centroid[1],width,height) (xcentroid,ycentroid,width,height) xywh=(xmin,ymin,width,height) ulbr=(xmin,ymin,xmax,ymax) bounding rectangle of binary mask image"
},
{
"ref":"vipy.geometry.BoundingBox.cast",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.from_json",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.dict",
"url":80,
"doc":"Return a python dictionary containing the relevant serialized attributes suitable for JSON encoding",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.json",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.clone",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.bbclone",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.xmin",
"url":80,
"doc":"x coordinate of upper left corner of box, x-axis is image column",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ul",
"url":80,
"doc":"Upper left coordinate (x,y)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ulx",
"url":80,
"doc":"Upper left coordinate (x)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.uly",
"url":80,
"doc":"Upper left coordinate (y)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ur",
"url":80,
"doc":"Upper right coordinate (x,y)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.urx",
"url":80,
"doc":"Upper right coordinate (x)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ury",
"url":80,
"doc":"Upper right coordinate (y)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ll",
"url":80,
"doc":"Lower left coordinate (x,y), synonym for bl()",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.bl",
"url":80,
"doc":"Bottom left coordinate (x,y), synonym for ll()",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.blx",
"url":80,
"doc":"Bottom left coordinate (x)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.bly",
"url":80,
"doc":"Bottom left coordinate (y)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.lr",
"url":80,
"doc":"Lower right coordinate (x,y), synonym for br()",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.br",
"url":80,
"doc":"Bottom right coordinate (x,y), synonym for lr()",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.brx",
"url":80,
"doc":"Bottom right coordinate (x)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.bry",
"url":80,
"doc":"Bottom right coordinate (y)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ymin",
"url":80,
"doc":"y coordinate of upper left corner of box, y-axis is image row, set if provided",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.xmax",
"url":80,
"doc":"x coordinate of lower right corner of box, x-axis is image column",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ymax",
"url":80,
"doc":"y coordinate of lower right corner of box, y-axis is image row",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.upperleft",
"url":80,
"doc":"Return the (x,y) upper left corner coordinate of the box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.bottomleft",
"url":80,
"doc":"Return the (x,y) lower left corner coordinate of the box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.upperright",
"url":80,
"doc":"Return the (x,y) upper right corner coordinate of the box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.bottomright",
"url":80,
"doc":"Return the (x,y) lower right corner coordinate of the box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.isinteger",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.int",
"url":80,
"doc":"Convert corners to integer with rounding, in-place update",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.float",
"url":80,
"doc":"Convert corners to float",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.significant_digits",
"url":80,
"doc":"Convert corners to have at most n significant digits for efficient JSON storage",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.translate",
"url":80,
"doc":"Translate the bounding box by dx in x and dy in y",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.to_origin",
"url":80,
"doc":"Translate the bounding box so that (xmin, ymin) = (0,0)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.set_origin",
"url":80,
"doc":"Set the origin of the coordinates of this bounding box to be relative to the upper left of the other bounding box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.offset",
"url":80,
"doc":"Alias for translate",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.invalid",
"url":80,
"doc":"Is the box a valid bounding box?",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.valid",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.isvalid",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.isdegenerate",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.isnonnegative",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.width",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.setwidth",
"url":80,
"doc":"Set new width keeping centroid constant",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.setheight",
"url":80,
"doc":"Set new height keeping centroid constant",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.height",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.centroid",
"url":80,
"doc":"(x,y) tuple of centroid position of bounding box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.x_centroid",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.xcentroid",
"url":80,
"doc":"Alias for x_centroid()",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.centroid_x",
"url":80,
"doc":"Alias for x_centroid()",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.y_centroid",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ycentroid",
"url":80,
"doc":"Alias for y_centroid()",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.centroid_y",
"url":80,
"doc":"Alias for y_centroid()",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.area",
"url":80,
"doc":"Return the area=width height of the bounding box, internal method useful for multiple inheritance",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.to_xywh",
"url":80,
"doc":"Return bounding box corners as (x,y,width,height) tuple",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.xywh",
"url":80,
"doc":"Alias for to_xywh",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.cxywh",
"url":80,
"doc":"Return or set bounding box corners as (centroidx,centroidy,width,height) tuple",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ulbr",
"url":80,
"doc":"Return bounding box corners as upper left, bottom right (xmin, ymin, xmax, ymax)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.to_ulbr",
"url":80,
"doc":"Alias for ulbr()",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.dx",
"url":80,
"doc":"Offset bounding box by same xmin as provided box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.dy",
"url":80,
"doc":"Offset bounding box by ymin of provided box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.sqdist",
"url":80,
"doc":"Squared Euclidean distance between upper left corners of two bounding boxes",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.dist",
"url":80,
"doc":"Distance between centroids of two bounding boxes",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.pdist",
"url":80,
"doc":"Normalized Gaussian distance in [0,1] between centroids of two bounding boxes, where 0 is far and 1 is same with sigma=maxdim() of this box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.iou",
"url":80,
"doc":"area of intersection / area of union",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.intersection_over_union",
"url":80,
"doc":"Alias for iou",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.area_of_intersection",
"url":80,
"doc":"area of intersection",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.area_of_union",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.cover",
"url":80,
"doc":"Fraction of this bounding box intersected by other bbox (bb).  note - Cover is often more useful than  vipy.geometry.BoundingBox.iou as a measure of overlap due to bounding box distortion from partially occluded object proposals. - For example, an object proposal of a person may generate a smaller box (e.g. just the torso) when the lower body is occluded whereas a track will have the full body box. -  vipy.geometry.BoundingBox.maxcover is a better measure of assignment in this case.",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.maxcover",
"url":80,
"doc":"The maximum cover of self to bb and bb to self",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.shapeiou",
"url":80,
"doc":"Shape IoU is the IoU with the upper left corners aligned. This measures the deformation of the two boxes by removing the effect of translation",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.intersection",
"url":80,
"doc":"Intersection of two bounding boxes, throw an error on degeneracy of intersection result (if strict=True)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.hasintersection",
"url":80,
"doc":"Return true if self and bb overlap by any amount, or by the cover threshold (if provided) or the iou threshold (if provided). This is a convenience function that allows for shared computation for fast non-maximum suppression.",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.union",
"url":80,
"doc":"Union of one or more bounding boxes with this box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.isinside",
"url":80,
"doc":"Is this boundingbox fully within the provided bounding box?",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ispointinside",
"url":80,
"doc":"Is the 2D point p=(x,y) inside this boundingbox, or is the p=boundingbox() inside this bounding box?",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.is_point_inside",
"url":80,
"doc":"synonym for  vipy.geometry.BoundingBox.ispointinside ",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.dilate",
"url":80,
"doc":"Change scale of bounding box keeping centroid constant",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.dilatepx",
"url":80,
"doc":"Dilate by a given pixel amount on all sides, keeping centroid constant",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.dilate_height",
"url":80,
"doc":"Change scale of bounding box in y direction keeping centroid constant",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.dilate_width",
"url":80,
"doc":"Change scale of bounding box in x direction keeping centroid constant",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.top",
"url":80,
"doc":"Make top of box taller (closer to top of image) by an offset dy",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.bottom",
"url":80,
"doc":"Make bottom of box taller (closer to bottom of image) by an offset dy",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.left",
"url":80,
"doc":"Make left of box wider (closer to left side of image) by an offset dx",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.right",
"url":80,
"doc":"Make right of box wider (closer to right side of image) by an offset dx",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.rescale",
"url":80,
"doc":"Multiply the box corners by a scale factor",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.scale_x",
"url":80,
"doc":"Multiply the box corners in the x dimension by a scale factor",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.scale_y",
"url":80,
"doc":"Multiply the box corners in the y dimension by a scale factor",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.resize",
"url":80,
"doc":"Change the aspect ratio width and height of the box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.rot90cw",
"url":80,
"doc":"Rotate a bounding box such that if an image of size (H,W) is rotated 90 deg clockwise, the boxes align",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.rot90ccw",
"url":80,
"doc":"Rotate a bounding box such that if an image of size (H,W) is rotated 90 deg counter clockwise, the boxes align",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.fliplr",
"url":80,
"doc":"Flip the box left/right consistent with fliplr of the provided img (or consistent with the image width)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.flipud",
"url":80,
"doc":"Flip the box up/down consistent with flipud of the provided img (or consistent with the image height)",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.imscale",
"url":80,
"doc":"Given a vipy.image object im, scale the box to be within [0,1], relative to height and width of image",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.maxsquare",
"url":80,
"doc":"Set the bounding box to be square by setting width and height to the maximum dimension of the box, keeping centroid constant",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.issquare",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.iseven",
"url":80,
"doc":"Are all corners even number integers?",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.even",
"url":80,
"doc":"Force all corners to be even number integers. This is helpful for FFMPEG crop filters.",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.minsquare",
"url":80,
"doc":"Set the bounding box to be square by setting width and height to the minimum dimension of the box, keeping centroid constant",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.hasoverlap",
"url":80,
"doc":"Does the bounding box intersect with the provided image rectangle?",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.isinterior",
"url":80,
"doc":"Is this boundingbox fully within the provided image rectangle?  If border in [0,1], then the image is dilated by a border percentage prior to computing interior, useful to check if self is near the image edge  If border=0.8, then the image rectangle is dilated by 80% (smaller) keeping the centroid constant.",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.iminterior",
"url":80,
"doc":"Transform bounding box to be interior to the image rectangle with shape (W,H). Transform is applyed by computing smallest (dx,dy) translation that it is interior to the image rectangle, then clip to the image rectangle if it is too big to fit",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.imclip",
"url":80,
"doc":"Clip bounding box to image rectangle [0,0,width,height] or img.shape=(width, height) and, throw an exception on an invalid box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.imclipshape",
"url":80,
"doc":"Clip bounding box to image rectangle [0,0,W-1,H-1], throw an exception on an invalid box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.convexhull",
"url":80,
"doc":"Given a set of points  x1,y1],[x2,xy], .], return the bounding rectangle, typecast to float",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.aspectratio",
"url":80,
"doc":"Return the aspect ratio (width/height) of the box",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.shape",
"url":80,
"doc":"Return the (height, width) tuple for the box shape",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.mindimension",
"url":80,
"doc":"Return min(width, height) typecast to float",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.mindim",
"url":80,
"doc":"Return min(width, height) typecast to float",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.maxdim",
"url":80,
"doc":"Return max(width, height) typecast to float",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.ellipse",
"url":80,
"doc":"Convert the boundingbox to a vipy.geometry.Ellipse object",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.average",
"url":80,
"doc":"Compute the average bounding box between self and other, and set self to the average. Other may be a singleton bounding box or a list of bounding boxes",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.averageshape",
"url":80,
"doc":"Compute the average bounding box width and height between self and other. Other may be a singleton bounding box or a list of bounding boxes",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.medianshape",
"url":80,
"doc":"Compute the median bounding box width and height between self and other. Other may be a singleton bounding box or a list of bounding boxes",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.shapedist",
"url":80,
"doc":"L1 distance between (width,height) of two boxes",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.affine",
"url":80,
"doc":"Apply an 2x3 affine transformation to the box centroid.  note This transformation is performed on the centroid and not the box corners, so the box will still be rectilinear after the transform",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.projective",
"url":80,
"doc":"Apply an 3x3 projective transformation to the box centroid.  note This transformation is performed on the centroid and not the box corners, so the box will still be rectilinear after the transform",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.crop",
"url":80,
"doc":"Crop an HxW 2D numpy image, HxWxC 3D numpy image, or NxHxWxC 4D numpy image array using this bounding box applied to HxW dimensions. Crop is performed in-place.",
"func":1
},
{
"ref":"vipy.geometry.BoundingBox.grid",
"url":80,
"doc":"Split a bounding box into the smallest grid of non-overlapping bounding boxes such that the union is the original box",
"func":1
},
{
"ref":"vipy.geometry.Ellipse",
"url":80,
"doc":"Ellipse parameterization, for length of semimajor (half width of ellipse) and semiminor axis (half height), center point and angle phi in radians"
},
{
"ref":"vipy.geometry.Ellipse.dict",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Ellipse.area",
"url":80,
"doc":"Area of ellipse",
"func":1
},
{
"ref":"vipy.geometry.Ellipse.center",
"url":80,
"doc":"Return centroid",
"func":1
},
{
"ref":"vipy.geometry.Ellipse.centroid",
"url":80,
"doc":"Alias for center",
"func":1
},
{
"ref":"vipy.geometry.Ellipse.axes",
"url":80,
"doc":"Return the (major,minor) axis lengths",
"func":1
},
{
"ref":"vipy.geometry.Ellipse.angle",
"url":80,
"doc":"Return the angle phi (in degrees)",
"func":1
},
{
"ref":"vipy.geometry.Ellipse.rescale",
"url":80,
"doc":"Scale ellipse by scale factor",
"func":1
},
{
"ref":"vipy.geometry.Ellipse.boundingbox",
"url":80,
"doc":"Estimate an equivalent bounding box based on scaling to a common area. Note, this does not factor in rotation. (c l) (c w) = a_e  > c = sqrt(a_e / a_r)",
"func":1
},
{
"ref":"vipy.geometry.Ellipse.inside",
"url":80,
"doc":"Return true if a point p=(x,y) is inside the ellipse",
"func":1
},
{
"ref":"vipy.geometry.Ellipse.mask",
"url":80,
"doc":"Return a binary mask of size equal to the bounding box such that the pixels correspond to the interior of the ellipse",
"func":1
},
{
"ref":"vipy.geometry.union",
"url":80,
"doc":"Return the union of a list of vipy.geometry.BoundingBox",
"func":1
},
{
"ref":"vipy.geometry.RandomBox",
"url":80,
"doc":"Return a random  vipy.geometry.BoundindBox for unit testing",
"func":1
},
{
"ref":"vipy.geometry.Point2d",
"url":80,
"doc":"vipy.geometry.Point2d class 2D point parameterization"
},
{
"ref":"vipy.geometry.Point2d.x",
"url":80,
"doc":""
},
{
"ref":"vipy.geometry.Point2d.y",
"url":80,
"doc":""
},
{
"ref":"vipy.geometry.Point2d.r",
"url":80,
"doc":""
},
{
"ref":"vipy.geometry.Point2d.radius",
"url":80,
"doc":""
},
{
"ref":"vipy.geometry.Point2d.diameter",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.coord",
"url":80,
"doc":""
},
{
"ref":"vipy.geometry.Point2d.from_json",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.origin",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.boundingbox",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.dict",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.json",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.is_positive",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.is_inside_boundingbox",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.dist",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.is_inside_radius",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.is_inside_imagebox",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.significant_digits",
"url":80,
"doc":"Convert corners to have at most n significant digits for efficient JSON storage",
"func":1
},
{
"ref":"vipy.geometry.Point2d.translate",
"url":80,
"doc":"Translate the coordinates by dx in x and dy in y",
"func":1
},
{
"ref":"vipy.geometry.Point2d.offset",
"url":80,
"doc":"Alias for translate",
"func":1
},
{
"ref":"vipy.geometry.Point2d.rescale",
"url":80,
"doc":"Multiply the coordinates by a scale factor",
"func":1
},
{
"ref":"vipy.geometry.Point2d.scale_x",
"url":80,
"doc":"Multiply the x coordinate (and radius) by a scale factor",
"func":1
},
{
"ref":"vipy.geometry.Point2d.scale_y",
"url":80,
"doc":"Multiply the y coordinate by a scale factor",
"func":1
},
{
"ref":"vipy.geometry.Point2d.scale_r",
"url":80,
"doc":"Multiply the r coordinate by a scale factor",
"func":1
},
{
"ref":"vipy.geometry.Point2d.isinteger",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.int",
"url":80,
"doc":"Convert coords to integer with rounding, in-place update",
"func":1
},
{
"ref":"vipy.geometry.Point2d.float",
"url":80,
"doc":"Convert coords to float",
"func":1
},
{
"ref":"vipy.geometry.Point2d.fliplr",
"url":80,
"doc":"Flip the x coordinate left/right consistent with fliplr of the provided img (or consistent with the image width)",
"func":1
},
{
"ref":"vipy.geometry.Point2d.flipud",
"url":80,
"doc":"Flip the y coordinate up/down consistent with flipud of the provided img (or consistent with the image height)",
"func":1
},
{
"ref":"vipy.geometry.Point2d.dilate",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.clone",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.rot90cw",
"url":80,
"doc":"Rotate a point such that if an image of size (H,W) is rotated 90 deg clockwise, the point rotates with the image",
"func":1
},
{
"ref":"vipy.geometry.Point2d.rot90ccw",
"url":80,
"doc":"Rotate a point such that if an image of size (H,W) is rotated 90 deg counter clockwise, the point rotates with the image",
"func":1
},
{
"ref":"vipy.geometry.Point2d.hasoverlap",
"url":80,
"doc":"Does the point inside with the provided image rectangle?",
"func":1
},
{
"ref":"vipy.geometry.Point2d.imclip",
"url":80,
"doc":"clip does not apply to points",
"func":1
},
{
"ref":"vipy.geometry.Point2d.area_of_intersection",
"url":80,
"doc":"area of intersection",
"func":1
},
{
"ref":"vipy.geometry.Point2d.area_of_union",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.iou",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.cover",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.has_intersection",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.xmin",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.xmax",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.ymin",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.ymax",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.width",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.height",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.Point2d.union",
"url":80,
"doc":"",
"func":1
},
{
"ref":"vipy.geometry.RandomPoint2d",
"url":80,
"doc":"",
"func":1
}
]